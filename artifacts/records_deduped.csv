Ref_ID,canonical_id,source,original_ids,title,authors,year,doi,abstract,pdf_url,url,language,stage_title_abstract_decision,stage_title_abstract_label,stage_title_abstract_evidence,stage_full_text_decision,stage_full_text_label,stage_full_text_evidence,task_category,confidence,bias_score,bias_flags
pubmed:40800536,pubmed:40800536,PubMed,pubmed:40800536,Surfing beta burst waveforms to improve motor imagery-based BCI.,Sotirios Papadopoulos;Ludovic Darmet;Maciej J Szul;Marco Congedo;James J Bonaiuto;Jérémie Mattout,2024,10.7554/elife.80160,"Our understanding of motor-related, macroscale brain processes has been significantly shaped by the description of the event-related desynchronization (ERD) and synchronization (ERS) phenomena in the mu and beta frequency bands prior to, during, and following movement. The demonstration of reproducible, spatially- and band-limited signal power changes has, consequently, attracted the interest of non-invasive brain-computer interface (BCI) research for a long time. BCIs often rely on motor imagery (MI) experimental paradigms that are expected to generate brain signal modulations analogous to movement-related ERD and ERS. However, a number of recent neuroscience studies has questioned the nature of these phenomena. Beta band activity has been shown to occur, on a single-trial level, in short, transient, and heterogeneous events termed bursts rather than sustained oscillations. In a previous study, we established that an analysis of hand MI binary classification tasks based on beta bursts can be superior to beta power in terms of classification score. In this article, we elaborate on this idea, proposing a signal processing algorithm that is comparable to- and compatible with state-of-the-art techniques. Our pipeline filters brain recordings by convolving them with kernels extracted from beta bursts and then applies spatial filtering before classification. This data-driven filtering allowed for a simple and efficient analysis of signals from multiple sensors, thus being suitable for online applications. By adopting a time-resolved decoding approach, we explored MI dynamics and showed the specificity of the new classification features. In accordance with previous results, beta bursts improved classification performance compared to beta band power, while often increasing information transfer rate compared to state-of-the-art approaches.",https://pubmed.ncbi.nlm.nih.gov/40800536/,https://pubmed.ncbi.nlm.nih.gov/40800536/,English,Include,,Surfing beta burst waveforms to improve motor imagery-based BCI.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40800422,pubmed:40800422,PubMed,pubmed:40800422,Context-dependent neural preparation for information relevance vs. probability.,José M G Peñalver;Carlos González-García;Ana F Palenciano;David López-García;María Ruz,2024,10.1523/jneurosci.2873-18.2019,"Preparation is a top-down phenomenon known to improve performance across different situations. In light of recent electrophysiological findings that suggest that anticipatory neural preactivations linked to preparation are context-specific and do not generalize across domains, in the current study we used fMRI to investigate the brain regions involved in these differential patterns. We applied multivariate decoding to data obtained in a paradigm where, in different blocks, cues provided information about the relevance or probability of incoming target stimuli. Results showed that the anticipated stimulus category was preactivated in both conditions, mostly in different brain regions within the ventral visual cortex and with differential overlap with actual target perception. Crucially, there was scarce cross-classification across attention and expectation contexts except on a patch of the fusiform gyrus, indicating mostly differential neural coding of anticipated contents in relevance and probability scenarios. Finally, a model-based fMRI-EEG fusion showed that these regions differentially code for specific conditions during preparation, as well as specifically preparing for category anticipation in a ramping-up manner. Overall, our results stress the specificity of anticipatory neural processing depending on its informative role while highlighting a key hub of commonality in the fusiform gyrus.",https://pubmed.ncbi.nlm.nih.gov/40800422/,https://pubmed.ncbi.nlm.nih.gov/40800422/,English,Include,,Context-dependent neural preparation for information relevance vs. probability.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40800381,pubmed:40800381,PubMed,pubmed:40800381,No evidence that visual impulses enhance the readout of retrieved long-term memory contents from EEG activity.,Sander van Bree;Abbie Sarah Mackenzie;Maria Wimber,2024,10.1016/j.tics.2018.03.004,"The application of multivariate pattern analysis (MVPA) to electroencephalography (EEG) data allows neuroscientists to track neural representations at temporally fine-grained scales. This approach has been leveraged to study the locus and evolution of long-term memory contents in the brain, but a limiting factor is that decoding performance remains low. A key reason for this is that processes such as encoding and retrieval are intrinsically dynamic across trials and participants, and this runs in tension with MVPA and other techniques that rely on consistently unfolding neural codes to generate predictions about memory contents. The presentation of visually perturbing stimuli may experimentally regularize brain dynamics, making neural codes more stable across measurements to enhance representational readouts. Such enhancements, which have repeatedly been demonstrated in working memory contexts, could offer a tool to improve decoding in long-term memory tasks. In this study, we evaluated whether visual perturbations-or",https://pubmed.ncbi.nlm.nih.gov/40800381/,https://pubmed.ncbi.nlm.nih.gov/40800381/,English,Include,,No evidence that visual impulses enhance the readout of retrieved long-term memory contents from EEG activity.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:40800368,pubmed:40800368,PubMed,pubmed:40800368,Assessing the consistency and sensitivity of the neural correlates of narrative stimuli using functional near-infrared spectroscopy.,Matthew Kolisnyk;Sergio Novi;Androu Abdalmalak;Reza Moulavi Ardakani;Karnig Kazazian;Geoffrey Laforge;Derek B Debicki;Adrian M Owen,2024,10.1016/j.neuroimage.2010.12.007,"Investigating how the brain responds to rich and complex narratives, such as engaging movies, has helped researchers study higher-order cognition in ""real-world"" scenarios. These neural correlates are particularly useful in populations where behavioral evidence of cognition alone is inadequate, such as children and certain patient populations. While this research has been primarily conducted in fMRI and EEG, whether functional near-infrared spectroscopy (fNIRS) can reliably detect these neural correlates at an individual level, which is required for effective use in these populations, has yet to be established. This study replicated widespread inter-subject correlations (ISCs) in the frontal, parietal, and temporal cortices in fNIRS in healthy participants when they watched part of the TV episode",https://pubmed.ncbi.nlm.nih.gov/40800368/,https://pubmed.ncbi.nlm.nih.gov/40800368/,English,Include,,Assessing the consistency and sensitivity of the neural correlates of narrative stimuli using functional near-infrared spectroscopy.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:40800348,pubmed:40800348,PubMed,pubmed:40800348,Task-related modulation of event-related potentials does not reflect changes to sensory representations.,Reuben Rideaux,2024,10.1038/nn.2223,"Attention supports efficient perception by increasing the neural signals of targets while suppressing those of distractors. Decades of work studying the event-related potentials of electroencephalography (EEG) recordings have established our understanding of attention in the human brain, but many aspects of this phenomenon remain unknown. Several recent studies suggest that multivariate analyses may provide new insights into how attention shapes the neural representations of stimuli; however, it is unclear whether the increased multivariate decoding accuracy associated with task relevance represents a change in the stimulus representation or an additional cognitive process. To understand what the change in multivariate information that is associated with task relevance reflects, here we used inverted encoding to characterise how task relevance shapes the neural representation of space and colour. For both spatial and feature-based tasks, we found that the change in the EEG recordings associated with task relevance is not related to the stimulus representation. Rather, our findings indicate that this phenomenon reflects an additional cognitive process, such as target recognition.",https://pubmed.ncbi.nlm.nih.gov/40800348/,https://pubmed.ncbi.nlm.nih.gov/40800348/,English,Include,,Task-related modulation of event-related potentials does not reflect changes to sensory representations.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40656101,pubmed:40656101,PubMed,pubmed:40656101,ADHD detection based on human action recognition.,Yichun Li;Rajesh Nair;Syed Mohsen Naqvi,2024,10.1016/j.nsa.2024.104093,"Attention Deficit Hyperactivity Disorder (ADHD) is a highly prevalent human neurobehavioral and neurodevelopmental disorder worldwide. Recently, deep learning-based techniques have been exploited in ADHD detection and diagnosis due to their outstanding performance. However, the majority of these methods relying on fMRI and EEG data suffer from the limitation of requiring expensive equipment and incurring high operational costs. Therefore, inspired by the fact that the symptoms of ADHD may manifest in actions and daily behaviors (as stated in the Medical Statistical Manual of Mental Disorders, Fifth Edition (DSM-V)), we introduce a novel ADHD detection system based on human action recognition. We design a novel hyperactivity test for capturing ADHD features and record a real multimodal ADHD dataset (M-ADHD) for the first time. The proposed system detects ADHD symptoms based on acquired action characters from raw RGB videos from the M-ADHD. Our system outperforms conventional competitors in terms of accuracy and AUC on the real multimodal ADHD dataset. Our proposed method, based on simple, non-wearable sensors, has the advantages of being cost-efficient and easy to operate. It is widely applicable for remote ADHD screening and further applies to understanding, treating, and preventing brain disorders.",https://pubmed.ncbi.nlm.nih.gov/40656101/,https://pubmed.ncbi.nlm.nih.gov/40656101/,English,Include,,ADHD detection based on human action recognition.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40417558,pubmed:40417558,PubMed,pubmed:40417558,Neural Mosaics: Detecting Aberrant Brain Interactions using Algebraic Topology and Generative Artificial Intelligence.,Katrina Prantzalos;Dipak Upadhyaya;Pedram Golnari;Guadalupe Fernandez-BacaVaca;Geronimo Pacheco Aispuro;Saeideh Salehizadeh;Suraj Thyagaraj;Nick Gurski;Kenneth Yoshimoto;Subhashini Sivagnanam;Amitava Majumdar;Satya S Sahoo,2024,10.48550/arxiv.2005.14165,"Epilepsy affects over 50 million persons worldwide, with less than 50% achieving long-term success following surgery. Traditional electrophysiology signal-based seizure detection methods are resource-intensive, laborious, and overlook multifocal brain interactions. Algebraic topology methods, particularly persistent homology, offer robust representations of complex brain interaction patterns. Leveraging persistent homology and the Google Gemini Pro Vision 1.0 large language model (LLM), we present a novel prompting template to classify topological structures computed from intracranial electroencephalography (iEEG) recordings from refractory epilepsy patients. This study marks the first use of persistence diagrams as input to a LLM for analyzing brain interaction dynamics. Our results indicate that simply prompting LLMs with persistence diagrams is insufficient for accurate seizure detection. Nonetheless, unlike traditional approaches using machine learning algorithms for EEG classification, our approach does not require large volumes of representative training data or brittle hyperparameter tuning, which highlights the promise of more scalable analyses in the future.",https://pubmed.ncbi.nlm.nih.gov/40417558/,https://pubmed.ncbi.nlm.nih.gov/40417558/,English,Include,,Neural Mosaics: Detecting Aberrant Brain Interactions using Algebraic Topology and Generative Artificial Intelligence.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40391296,pubmed:40391296,PubMed,pubmed:40391296,Adaptive Spatial-Temporal Aware Graph Learning for EEG-Based Emotion Recognition.,Weishan Ye;Jiyuan Wang;Lin Chen;Lifei Dai;Zhe Sun;Zhen Liang,2024,10.6084/m9.figshare2016;4244171:v2,"An intelligent emotion recognition system based on electroencephalography (EEG) signals shows considerable potential in various domains such as healthcare, entertainment, and education, thanks to its portability, high temporal resolution, and real-time capabilities. However, the existing research in this field faces limitations stemming from the nonstationary nature and individual variability of EEG signals. In this study, we present a novel EEG emotion recognition model, named GraphEmotionNet, designed to enhance the accuracy of EEG-based emotion recognition through the incorporation of a spatiotemporal attention mechanism and transfer learning. The proposed GraphEmotionNet model can effectively learn the intrinsic connections between EEG channels and construct an adaptive graph. This graph's adaptive nature is crucial in optimizing spatial-temporal graph convolutions, which in turn enhances spatial-temporal feature characterization and contributes to the process of emotion classification. Moreover, an integration of domain adaptation aligns the extracted features across different domains, further alleviating the impact of individual EEG variability. We evaluate the model performance on two benchmark databases, employing two types of cross-validation protocols: within-subject cross-validation and cross-subject cross-validation. The experimental results affirm the model's efficacy in extracting EEG features linked to emotional semantics and demonstrate its promising performance in emotion recognition.",https://pubmed.ncbi.nlm.nih.gov/40391296/,https://pubmed.ncbi.nlm.nih.gov/40391296/,English,Include,,Adaptive Spatial-Temporal Aware Graph Learning for EEG-Based Emotion Recognition.,Include,,"tions stemming from the nonstationary nature and individual variability of EEG signals. In this study, we present a novel EEG emotion recognition model, named GraphEmotionNet, designed to enhance the accuracy of EEG-based emotion recognition through the incorporation of a spatiotemporal attention mechanism and transfer learning. The proposed GraphEmotionNet model can effectively learn the intrinsi",,0.95,0.25,cv_reported
pubmed:40370581,pubmed:40370581,PubMed,pubmed:40370581,Time Scale Network: An Efficient Shallow Neural Network For Time Series Data in Biomedical Applications.,Trevor Meyer;Camden Shultz;Najim Dehak;Laureano Moro-Velázquez;Pedro Irazoqui,2025,10.1093/eurheartj/ehab569,"Time series data is often composed of information at multiple time scales, particularly in biomedical data. While numerous deep learning strategies exist to capture this information, many make networks larger, require more data, are more demanding to compute, and are difficult to interpret. This limits their usefulness in real-world settings facing even modest computational or data constraints and can further complicate their translation into real-time processing or edge device applicaitons. We present a minimal, computationally efficient Time Scale Network combining the translation and dilation sequence used in discrete wavelet transforms with traditional convolutional neural networks and back-propagation. The network simultaneously learns features at many time scales for sequence classification with significantly reduced parameters and operations. We demonstrate advantages in Atrial Dysfunction detection including: superior accuracy-per-parameter and accuracy-per-operation, fast training and inference speeds, and visualization and interpretation of learned patterns in atrial dysfunction detection on ECG signals. We also demonstrate impressive performance in seizure prediction using EEG signals, where our network isolated a few time scales that could be strategically selected to achieve 90.9% accuracy using only 1,133 active parameters and consistently converged on pulsatile waveform shapes. This method does not rest on any constraints or assumptions regarding signal content and could be leveraged in any area of time series analysis dealing with signals containing features at many time scales.",,https://pubmed.ncbi.nlm.nih.gov/40370581/,English,Exclude,Outside date range,Time Scale Network: An Efficient Shallow Neural Network For Time Series Data in Biomedical Applications.,,,,,0.95,0.6,
pubmed:40256223,pubmed:40256223,PubMed,pubmed:40256223,Smart IoT-driven biosensors for EEG-based driving fatigue detection: A CNN-XGBoost model enhancing healthcare quality.,Khosro Rezaee;Asmar Nazerian;Hossein Ghayoumi Zadeh;Hani Attar;Mohamadreza Khosravi;Mohammad Kanan,2025,10.1155/2024/9898333,"Drowsy driving is a significant contributor to accidents, accounting for 35 to 45% of all crashes. Implementation of an internet of things (IoT) system capable of alerting fatigued drivers has the potential to substantially reduce road fatalities and associated issues. Often referred to as the internet of medical things (IoMT), this system leverages a combination of biosensors, actuators, detectors, cloud-based and edge computing, machine intelligence, and communication networks to deliver reliable performance and enhance quality of life in smart societies. Electroencephalogram (EEG) signals offer potential insights into fatigue detection. However, accurately identifying fatigue from brain signals is challenging due to inter-individual EEG variability and the difficulty of collecting sufficient data during periods of exhaustion. To address these challenges, a novel evolutionary optimization method combining convolutional neural networks (CNNs) and XGBoost, termed CNN-XGBoost Evolutionary Learning, was proposed to improve fatigue identification accuracy. The research explored various subbands of decomposed EEG data and introduced an innovative approach of transforming EEG recordings into RGB scalograms. These scalogram images were processed using a 2D Convolutional Neural Network (2DCNN) to extract essential features, which were subsequently fed into a dense layer for training. The resulting model achieved a noteworthy accuracy of 99.80% on a substantial driver fatigue dataset, surpassing existing methods. By integrating this approach into an IoT framework, researchers effectively addressed previous challenges and established an artificial intelligence of things (AIoT) infrastructure for critical driving conditions. This IoT-based system optimizes data processing, reduces computational complexity, and enhances overall system performance, enabling accurate and timely detection of fatigue in extreme driving environments.",,https://pubmed.ncbi.nlm.nih.gov/40256223/,English,Exclude,Outside date range,Smart IoT-driven biosensors for EEG-based driving fatigue detection: A CNN-XGBoost model enhancing healthcare quality.,,,,,0.95,0.6,
pubmed:40231042,pubmed:40231042,PubMed,pubmed:40231042,"Examination of intracranial arachnoid cysts in children, symptomatic or asymptomatic.",Yiğithan Güzin;Safa Mete Dağdaş;Pınar Gençpınar;Figen Baydan;Özkan Alataş;Ümit Belet;Gamze Sarıkaya Uzan;Nihal Olgaç Dündar,2024,10.18502/cjn.v23i3.17546,,,https://pubmed.ncbi.nlm.nih.gov/40231042/,English,Exclude,Not EEG-BCI focused,"Examination of intracranial arachnoid cysts in children, symptomatic or asymptomatic.",,,,,0.9,0.6,
pubmed:40200952,pubmed:40200952,PubMed,pubmed:40200952,Electroencephalogram-based time-frequency analysis for Alzheimer's disease detection using machine learning.,Sérgio Daniel Rodrigues;Pedro Miguel Rodrigues,2025,10.3390/electronics13183671,"Alzheimer's disease (AD) is the most common form of dementia. The lack of effective prevention or cure makes AD a significant concern, as it is a progressive disease with symptoms that worsen over time. The aim of this study is to develop an algorithm capable of differentiating between patients with early-stage AD (mild cognitive impairment [MCI]), moderate AD, and healthy controls (C) using electroencephalogram (EEG) signals. A publicly available EEG database was utilized, with seven EEG recordings selected from each study group (MCI, AD, and C) to ensure a balanced dataset. For each 1-s segment of EEG data, 43 time-frequency features were computed. These features were then compressed over time using 10 statistical measures. Subsequently, 15 classifiers were employed to distinguish between paired groups using a 7-fold cross-validation. The strategy yielded better results than state-of-the-art methods, achieving a 100% accuracy in both C versus MCI and C versus AD binary classifications. This improvement translated to a 2% increase in accuracy for C versus MCI and a 4% increase for C versus AD, despite a 1.2% decrease in performance for AD versus MCI. In addition, the proposed method outperformed prior work on the same database by 4.8% for the AD versus MCI comparison. The present study highlights the potential of EEG as a promising tool for early AD diagnosis. Nevertheless, a more extensive database should be used to enhance the generalizability of the results in future work.",,https://pubmed.ncbi.nlm.nih.gov/40200952/,English,Exclude,Outside date range,Electroencephalogram-based time-frequency analysis for Alzheimer's disease detection using machine learning.,,,,,0.95,0.25,cv_reported
pubmed:40190604,pubmed:40190604,PubMed,pubmed:40190604,Evaluating Somfit's pulse arterial tonometry for detection of obstructive sleep apnoea.,Marcus McMahon;Jeremy Goldin;Elizabeth Susan Kealy;Darrel Joseph Wicks;Eugene Zilberg;Warwick Freeman;Behzad Aliahmad,2025,10.1007/s41105-024-00559-4,"This study evaluates the diagnostic accuracy of Somfit against polysomnography (PSG) for detecting obstructive sleep apnoea (OSA). Somfit is a wearable home-sleep monitoring device attached to the forehead, combining pulse arterial tonometry, oximetry, and actigraphy with sleep staging, arousals, and total sleep time (TST) derived from frontal neurological signals. Ninety-two participants suspected of having OSA were assessed using Somfit and simultaneous overnight PSG recordings at three Australian sites. Each PSG study was manually scored by three independent scorers. The reported statistics include standard measures of agreement between Somfit's TST, Oxygen-Saturation Index (ODI), Apnoea-Hypopnea Index (AHI), and the average of those metrics from the three PSG scorers. The overall inter-scorer agreement was 76% (kappa = 0.772). TST, ODI, and AHI from Somfit were highly correlated with similar metrics from PSG (all r > 0.84, ",,https://pubmed.ncbi.nlm.nih.gov/40190604/,English,Exclude,Outside date range,Evaluating Somfit's pulse arterial tonometry for detection of obstructive sleep apnoea.,,,,,0.95,0.8,small_sample_mentioned
pubmed:40166115,pubmed:40166115,PubMed,pubmed:40166115,Critical biomarkers for responsive deep brain stimulation and responsive focal cortex stimulation in epilepsy field.,Zhikai Yu;Binghao Yang;Penghu Wei;Hang Xu;Yongzhi Shan;Xiaotong Fan;Huaqiang Zhang;Changming Wang;Jingjing Wang;Shan Yu;Guoguang Zhao,2025,10.1016/j.fmre.2024.05.018,"To derive critical signal features from intracranial electroencephalograms of epileptic patients in order to design instructions for feedback-type electrical stimulation systems. The Detrended Fluctuation Analysis (DFA) exponent is chosen as the classification exponent, and the disparities between indicators representing distinct seizure states and the classification efficacy of rudimentary machine learning models are computed. The DFA exponent exhibited a statistically significant variation among the pre-ictal, ictal period, and post-ictal stages. The Linear Discriminant Analysis model demonstrates the highest accuracy among the three basic machine learning models, whereas the Naive Bayesian model necessitates the least amount of computational and storage space. The set of DFA exponents is employed as an intermediary variable in the machine learning process. The resultant model possesses the capability to function as a feedback trigger program for electrical stimulation systems of the feedback variety, specifically within the domain of neural modulation in epilepsy.",,https://pubmed.ncbi.nlm.nih.gov/40166115/,English,Exclude,Outside date range,Critical biomarkers for responsive deep brain stimulation and responsive focal cortex stimulation in epilepsy field.,,,,,0.95,0.6,
pubmed:40134901,pubmed:40134901,PubMed,pubmed:40134901,Robustness of ML-Based Seizure Prediction Using Noisy EEG Data From Limited Channels.,Umair Mohammad;Fahad Saeed,2024,10.1109/dcoss-iot61029.2024.00097,"Seizures pose a significant health hazard for over 50 million individuals with epilepsy worldwide, with approximately 56% experiencing uncontrollable seizures according to the CDC. Predicting seizures is challenging even with the availability of various sensors (gyroscopes, pulse rate sensors, heart rate monitors, etc). Electroencephalography (EEG) data can directly measure the activity of the brain and has been the choice of leveraging deep learning (DL) models for seizure prediction. Despite DL models achieving over 95% accuracy on retroactive clinical-grade EEG data, this performance fails to translate in real-world settings where the accuracy goes down to 66% - which warrants further investigation. Moreover, consumer-grade wearable EEG headsets, characterized by lower data quality and a varying number of channels across brands, present additional challenges. In this paper, we estimate the robustness of DL models which are trained on clinical-grade EEG data but tested on the type of data expected from consumer-grade wearable EEG headsets. We select the previously published model SPERTL to estimate its robustness when: (1) predicting with data from less leads/channels, (2) predicting when faced with streaming data, (3) evaluating performance on imbalanced data with more interictal segments. Our results are compared against baseline results from the SPERTL model which we have re-configured to operate independently of the number of channels with an average baseline area under the curve (AUC) score of 98.56%. Our results demonstrate that though the model is surprisingly resilient to streaming and noisy data, reducing the number of channels and a higher class imbalance have a more severe degradation. The AUC across all cross-validation sets degrades only by 2% and 3% on average for noisy and streaming data, respectively. However, a performance reduction, on average, is observed by 32% when imbalance is increased with higher percentage of interictal samples, and up to 16% when using lower number of channels.",https://pubmed.ncbi.nlm.nih.gov/40134901/,https://pubmed.ncbi.nlm.nih.gov/40134901/,English,Include,,Robustness of ML-Based Seizure Prediction Using Noisy EEG Data From Limited Channels.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.25,cv_reported
pubmed:40110612,pubmed:40110612,PubMed,pubmed:40110612,Multi-modality NDE fusion using encoder-decoder networks for identify multiple neurological disorders from EEG signals.,Shraddha Jain;Rajeev Srivastava,2025,10.1177/09287329241291334,"The complexity and diversity of brain activity patterns make it difficult to accurately diagnose neurological disorders such epilepsy, Parkinson's disease, schizophrenia, stroke, and Alzheimer's disease. Integrated and effective analysis of multiple data sources is often beyond the scope of traditional diagnostic procedures. With the use of multi-modal data, recent developments in neural network approaches present encouraging opportunities for raising diagnostic accuracy. A novel approach has been proposed toward the integration of different Nondestructive Evaluation data with EEG signals for improving the diagnosis of neurological disorders such as stroke, epilepsy, Parkinson's disease, and schizophrenia, by leveraging advanced neural network techniques in order to improve the identification and correlation of shared latent features across heterogeneous NDE datasets. We determined the 2D scalogram images using a specific encoder-decoder neural network after transforming the EEG signals using wavelet signal processing. Several NDE data types can be easily integrated for thorough analysis due to this network's ability to extract and correlate important aspects from each form of data. Aiming to uncover common patterns indicating of neurological disorders, the technique was evaluated on datasets containing EEG signals and corresponding NDE data. Our method demonstrated a significant improvement in diagnostic accuracy and efficiency. The encoder-decoder network effectively identified shared latent features across the heterogeneous NDE datasets, leading to more precise and reliable diagnoses. The fusion of multi-modality NDE data with EEG signals provided a robust framework for the automatic identification of multiple neurological disorders. This innovative approach represents a substantial advancement in the field of neurological disorder diagnosis. By integrating diverse NDE data with EEG signals through advanced neural network techniques, we have developed a method that enhances the accuracy and efficiency of diagnosing multiple neurological conditions. This fusion of multi-modality data has the potential to revolutionize current diagnostic practices in neurology, paving the way for more precise and automated identification of neurological disorders.",,https://pubmed.ncbi.nlm.nih.gov/40110612/,English,Exclude,Outside date range,Multi-modality NDE fusion using encoder-decoder networks for identify multiple neurological disorders from EEG signals.,,,,,0.95,0.6,
pubmed:40103837,pubmed:40103837,PubMed,pubmed:40103837,Accelerated algorithms for source orientation detection and spatiotemporal LCMV beamforming in EEG source localization.,Ava Yektaeian Vaziri;Bahador Makkiabadi,2024,10.3390/signals2030024,"This paper illustrates the development of two efficient source localization algorithms for electroencephalography (EEG) data, aimed at enhancing real-time brain signal reconstruction while addressing the computational challenges of traditional methods. Accurate EEG source localization is crucial for applications in cognitive neuroscience, neurorehabilitation, and brain-computer interfaces (BCIs). To make significant progress toward precise source orientation detection and improved signal reconstruction, we introduce the Accelerated Linear Constrained Minimum Variance (ALCMV) beamforming toolbox and the Accelerated Brain Source Orientation Detection (AORI) toolbox. The ALCMV algorithm speeds up EEG source reconstruction by utilizing recursive covariance matrix calculations, while AORI simplifies source orientation detection from three dimensions to one, reducing computational load by 66% compared to conventional methods. Using both simulated and real EEG data, we demonstrate that these algorithms maintain high accuracy, with orientation errors below 0.2% and signal reconstruction accuracy within 2%. These findings suggest that the proposed toolboxes represent a substantial advancement in the efficiency and speed of EEG source localization, making them well-suited for real-time neurotechnological applications.",https://pubmed.ncbi.nlm.nih.gov/40103837/,https://pubmed.ncbi.nlm.nih.gov/40103837/,English,Include,,Accelerated algorithms for source orientation detection and spatiotemporal LCMV beamforming in EEG source localization.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40098821,pubmed:40098821,PubMed,pubmed:40098821,Cenobamate modulates EEG cortical activity and connectivity in individuals with drug-resistant epilepsy: a pharmaco-EEG study.,G Assenza;B Sancetta;L Ricci;C Vico;F Narducci;M Boscarino;J Lanzone;P Menna;C Liguori;F Izzi;N B Mercuri;V Di Lazzaro;M Tombini,2024,10.1111/j.1528-1167.2011.03325.x,"Quantitative electroencephalography (qEEG) metrics are demonstrated to correlate with and predict clinical response in individuals with epilepsy. Cenobamate is an effective anti-seizure medication recently approved as an add-on therapy for individuals with epilepsy, but its effects on qEEG are unknown. We aimed to evaluate the modulation of qEEG metrics induced by cenobamate and its relationship with clinical response. We performed a prospective study with a cohort of 18 individuals with epilepsy (8 women, 47 ± 16 years old) and 25 healthy subjects (HS). They underwent a 19-channel EEG before and 6 months after cenobamate administration. Power spectral density (PSD) and phase locking value (PLV) for delta, theta, alpha, beta, and gamma frequency bands were calculated. Correlation analysis and analysis of covariance exhibited significant cenobamate-induced changes in qEEG and their relationship with seizure frequency changes. A regression analysis was performed to evaluate the association with clinical responders. A total of 11 out of 16 individuals with epilepsy (69%, with 2 dropping out) were cenobamate responders (≥50% seizure frequency reduction). Cenobamate did not modify any PSD parameter but induced significant changes in PLV levels ( Cenobamate induces an EEG connectivity modulation that is highly associated with cenobamate clinical response. Connectivity analysis of pharmaco-EEG can provide new hints toward the development of innovative biomarkers and precision medicine in individuals with epilepsy.",,https://pubmed.ncbi.nlm.nih.gov/40098821/,English,Exclude,Not classification-focused,Cenobamate modulates EEG cortical activity and connectivity in individuals with drug-resistant epilepsy: a pharmaco-EEG study.,,,,,0.85,0.6,
pubmed:40041397,pubmed:40041397,PubMed,pubmed:40041397,Lightweight Transformer exhibits comparable performance to LLMs for Seizure Prediction: A case for light-weight models for EEG data.,Paras Parani;Umair Mohammad;Fahad Saeed,2024,10.1101/2024.11.03.621742,"Predicting seizures ahead of time will have a significant positive clinical impact for people with epilepsy. Advances in machine learning/artificial intelligence (ML/AI) has provided us the tools needed to perform such predictive tasks. To date, advanced deep learning (DL) architectures such as the convolutional neural network (CNN) and long short-term memory (LSTM) have been used with mixed results. However, highly connected activity exhibited by epileptic seizures necessitates the design of more complex ML techniques which can better capture the complex interconnected neurological processes. Other challenges include the variability of EEG sensor data quality, different epilepsy and seizure profiles, lack of annotated datasets and absence of ML-ready benchmarks. In addition, successful models will need to perform inference in almost real-time using limited hardware compute-capacity. To address these challenges, we propose a lightweight architecture, called ",https://pubmed.ncbi.nlm.nih.gov/40041397/,https://pubmed.ncbi.nlm.nih.gov/40041397/,English,Include,,Lightweight Transformer exhibits comparable performance to LLMs for Seizure Prediction: A case for light-weight models for EEG data.,Include,,"xed results. However, highly connected activity exhibited by epileptic seizures necessitates the design of more complex ML techniques which can better capture the complex interconnected neurological processes. Other challenges include the variability of EEG sensor data quality, different epilepsy and seizure profiles, lack of annotated datasets and absence of ML-ready benchmarks. In addition, succ",,0.95,0.6,
pubmed:40040215,pubmed:40040215,PubMed,pubmed:40040215,Focused State Recognition Using EEG with Eye Movement-Assisted Annotation.,Tian-Hua Li;Tian-Fang Ma;Dan Peng;Wei-Long Zheng;Bao-Liang Lu,2024,10.1109/embc53108.2024.10781939,"With the rapid advancement in machine learning, the recognition and analysis of brain activity based on EEG and eye movement signals have attained a high level of sophistication. Utilizing deep learning models for learning EEG and eye movement features proves effective in classifying brain activities. A focused state indicates intense concentration on a task or thought. Distinguishing focused and unfocused states can be achieved through eye movement behaviors, reflecting variations in brain activities. By calculating binocular focusing point disparity in eye movement signals and integrating relevant EEG features, we propose an annotation method for focused states. The resulting comprehensive dataset, derived from raw data processed through a bio-acquisition device, includes both EEG features and focused labels annotated by eye movements. Extensive training and testing on several deep learning models, particularly the Transformer, yielded a 90.16% accuracy on the subject-dependent experiments. The validity of this approach was demonstrated, with cross-subject experiments, key frequency band and brain region analyses confirming its generalizability and providing physiological explanations.",https://pubmed.ncbi.nlm.nih.gov/40040215/,https://pubmed.ncbi.nlm.nih.gov/40040215/,English,Include,,Focused State Recognition Using EEG with Eye Movement-Assisted Annotation.,Include,,"sition device, includes both EEG features and focused labels annotated by eye movements. Extensive training and testing on several deep learning models, particularly the Transformer, yielded a 90.16% accuracy on the subject-dependent experiments. The validity of this approach was demonstrated, with cross-subject experiments, key frequency band and brain region analyses confirming its generalizabil",,0.95,0.6,
pubmed:40040208,pubmed:40040208,PubMed,pubmed:40040208,Domain-Incremental Learning Framework for Continual Motor Imagery EEG Classification Task.,Dan Li;Hye-Bin Shin;Kang Yin;Seong-Whan Lee,2024,10.1109/embc53108.2024.10781886,"Due to inter-subject variability in electroencephalogram (EEG) signals, the generalization ability of many existing brain-computer interface (BCI) models is significantly limited. Although transfer learning (TL) offers a temporary solution, in scenarios requiring sustained knowledge transfer, the performance of TL-based models gradually declines as the number of transfers increases-a phenomenon known as catastrophic forgetting. To address this issue, we introduce a novel domain-incremental learning framework for the continual motor imagery (MI) EEG classification. Specifically, to learn and retain common features between subjects, we separate latent representations into subject-invariant and subject-specific features through adversarial training, while also proposing an extensible architecture to preserve features that are easily forgotten. Additionally, we incorporate a memory replay mechanism to reinforce previously acquired knowledge. Through extensive experiments, we demonstrate our framework's effectiveness in mitigating forgetting within the continual MI-EEG classification task.",https://pubmed.ncbi.nlm.nih.gov/40040208/,https://pubmed.ncbi.nlm.nih.gov/40040208/,English,Include,,Domain-Incremental Learning Framework for Continual Motor Imagery EEG Classification Task.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40040206,pubmed:40040206,PubMed,pubmed:40040206,EEG Channel Localization and Selection via Training with Noise Injection for BCI Applications.,Chun-Ming Huang;Wei-Lin Lai;Chih-Chyau Yang;Yi-Jie Hsieh;Chien-Ming Wu;Chu-Hui Lee,2024,10.1109/embc53108.2024.10782774,"Electroencephalography (EEG) is crucial for monitoring brain activity in neuroscience and clinical applications. However, the multitude of channels recorded by scalp electrodes poses challenges, including impractical usage and high model complexity. This paper addresses the challenges of high dimensionality in EEG data and introduces an innovative EEG channel selection algorithm, LSvT-NI, based on model training and noise injection, achieving substantial reductions in channels, model size, and complexity while maintaining high classification accuracy. Validated through experiments on EEGNet and the BCI Competition IV 2a dataset, the algorithm proves beneficial for practical and cost-efficient scenarios. Specifically, experiments on the BCI Competition IV 2a dataset demonstrate that LSvT-NI with white noise and pink noise at 5dB SNR achieves a remarkable 77.3% and 72.7% reduction in channels, along with 11.7% and 11% reductions in model size, and 86.9% and 71.8% in computation complexity.",https://pubmed.ncbi.nlm.nih.gov/40040206/,https://pubmed.ncbi.nlm.nih.gov/40040206/,English,Include,,EEG Channel Localization and Selection via Training with Noise Injection for BCI Applications.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40040203,pubmed:40040203,PubMed,pubmed:40040203,UMAP for Dimensionality Reduction in Sleep Stage Classification Using EEG Data.,Yangfan Deng;Hamad Albidah;Haoliang Cheng;Ahmed Dallal;Jijun Yin;Zhi-Hong Mao,2024,10.1109/embc53108.2024.10782097,"Sleep is vital for wellness, and electroencephalography (EEG) serves as an instrumental tool in the study of sleep. Sleep is classified into four stages: stages N1-N3, and rapid eye movement (REM). To acquire effective and robust EEG features for sleep detection and analysis, we explore the dimensionality reduction effects of Uniform Manifold Approximation and Projection (UMAP) on various features of the EEG signals. Compared with traditional band power analysis, UMAP demonstrated higher accuracy for sleep stage classification and better reliability. Using UMAP, we observed an average of 11% increase in accuracy and an average of 20% increase in Macro-F1 Score on the same dataset. Particularly, in the wakefulness stage, Macro-F1 Score increased by 23%. Moreover, the 2D visual analysis revealed the outstanding ability of UMAP to cluster EEG signals after significant dimensionality reduction of the data.",https://pubmed.ncbi.nlm.nih.gov/40040203/,https://pubmed.ncbi.nlm.nih.gov/40040203/,English,Include,,UMAP for Dimensionality Reduction in Sleep Stage Classification Using EEG Data.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40040201,pubmed:40040201,PubMed,pubmed:40040201,Exploring Schizophrenia Classification in fMRI Data: A Common Spatial Patterns(CSP) Approach for Enhanced Feature Extraction and Classification.,M Moein Esfahani;Robyn Miller;V D Calhoun,2024,10.1109/embc53108.2024.10782387,"In the exploration of dynamic changes in network connectivity within resting-state functional magnetic resonance imaging (rs-fMRI), the dominant focus has traditionally been on a holistic study of the entire brain. Various methodologies and analyses have been applied in prior research within this domain. This study takes a novel approach by delving into a comparative analysis of the similarities between electroencephalogram (EEG) signals with motor imagery tasks and rs-fMRI signal. Both data types collect time series data from their respective datasets. Drawing from the insights of previous research, the common spatial patterns (CSP) method, mostly used for its efficacy in handling EEG signals, was employed. Notably, CSP is a supervised learning transformation of signals, offering advantages over the implementation of deep learning models. this study pioneers the integration of the CSP method with fMRI datasets. Validation of this approach was conducted through a rs-fMRI study focused on schizophrenia, includes two primary classes: patients and controls. In addition to CSP, principal component analysis (PCA) was explored as an unsupervised dimensionality reduction technique, serving as a benchmark for comparison. The results revealed that CSP has better performance relative to PCA and other examined methods. This study contributes to the expanding landscape of understanding time-varying network connectivity, emphasizing the potential applicability of CSP beyond its traditional domain of EEG signals, and take benefit of its effectiveness in the context of rs-fMRI.",https://pubmed.ncbi.nlm.nih.gov/40040201/,https://pubmed.ncbi.nlm.nih.gov/40040201/,English,Include,,Exploring Schizophrenia Classification in fMRI Data: A Common Spatial Patterns(CSP) Approach for Enhanced Feature Extraction and Classification.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40040170,pubmed:40040170,PubMed,pubmed:40040170,An online brain-computer interface for a precise positioning of target based on rapid serial visual presentation.,Jiayuan Meng;Mingming Yang;Sheng Zhang;Minpeng Xu;Lin Meng;Dong Ming,2024,10.1109/embc53108.2024.10782815,"The brain-computer interface (BCI) based on rapid serial visual presentation (RSVP) provides a novel approach for efficiently optimizing traditional machine-based target detection, revealing a broad application prospect in security, entrainment, monitoring, etc. A bottleneck of current RSVP-BCI is that its detectable result is limited to a binary way, i.e., target vs. non-target, more detailed and important information about targets, such as the precise position, remains undetectable. To solve this problem, this study investigated the relationship between targets positions (up, down, left, right) and electroencephalogram (EEG) characteristics, and tested the separability of EEGs induced by the four targets positions in an online RSVP-BCI. Twelve healthy subjects participated in this study, event-related potential (ERP), topographies, laterality index (LI), discriminant canonical pattern matching (DCPM) methods were used to analyzed the EEG data. Consequently, left-right targets induced ipsilateral ERPs between bilateral hemispheres; when targets appeared at up and down positions, opposite ERPs were found between frontal and occipital areas; up-down and left-right difference reached its maximum in the 140~190ms and 190~240ms temporal window, respectively. Single-trial classification showed five-class balanced accuracy (BACC) (non-target, target at up/ down/ left/ right position) was 71.02% and 67.91% for offline and online sessions, respectively. The results provide new understanding of the RSVP features for developing BCIs.",https://pubmed.ncbi.nlm.nih.gov/40040170/,https://pubmed.ncbi.nlm.nih.gov/40040170/,English,Include,,An online brain-computer interface for a precise positioning of target based on rapid serial visual presentation.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40040166,pubmed:40040166,PubMed,pubmed:40040166,Time Window Optimization for Riemannian Geometry-based Motor Imagery EEG Classification.,Fanbo Zhuo;Bo Lv;Fengzhen Tang,2024,10.1109/embc53108.2024.10782640,"The existing Riemannian geometry-based approaches for brain computer interface (BCI) employ fixed time windows. However, the inherent variability and dynamic changes among subjects necessitate robust and adaptive solutions for time window optimization. Recognizing the current limitations of Riemannian classifiers, we propose a time window selection confidence metric (TWSCM) based on Riemannian geometry. This metric operates on the manifold of symmetric positive definite (SPD) matrices, providing a theoretically grounded and computationally efficient approach for time window optimization. The optimization process is unsupervised, which is able to deal with the online scenario without training labels. Experimental results on the BCI competition IV dataset IIa demonstrate that the classification performance is significantly improved for most subjects. The average performance over six subjects improved by 7.52%. The simulated online experiment shows enhanced performance in comparison to baseline experiments without time window optimization. Additionally, an in-depth analysis of TWSCM provides insights into performance variations among subjects. Overall, this paper introduces the first time window optimization method within the Riemannian geometric framework, presenting an effective and interpretable approach for optimizing time windows in motor imagery classification, providing a novel and promising perspective in EEG signal analysis.",https://pubmed.ncbi.nlm.nih.gov/40040166/,https://pubmed.ncbi.nlm.nih.gov/40040166/,English,Include,,Time Window Optimization for Riemannian Geometry-based Motor Imagery EEG Classification.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40040137,pubmed:40040137,PubMed,pubmed:40040137,Profiling a Raspberry Pi-Based Motor Imagery Classification to Facilitate At-Home BCI for Children with Disabilities.,Oluwagbenga Paul Idowu;Eli Kinney-Lang;Adam Gulamhusein;Brian Irvine;Adam Kirton;Hatem Abou-Zeid,2024,10.1109/embc53108.2024.10781873,"There has been incremental progress in moving BCI out of the laboratory environment and into the homes of those who would benefit most, especially children living with severe physical disabilities. Practical issues, such as available computational resources and long calibration times, have slowed down the adoption of such systems. To develop an efficient and scalable machine learning framework consistent with early approaches that facilitate at-home BCI use, this study provides valuable insights into measuring the behavioral characteristics of a Raspberry Pi 4 (RPi4) during the operation and execution of standard BCI processes, including the training and evaluation of classifier models. The results, which evaluated ten standard classifiers, including the Riemannian Geometry (RG) framework and more advanced deep learning approaches like Artificial Neural Network (ANN), were profiled on RPi4. These were compared to Desktop and MacBook computations for metrics such as training time, inference time, peak memory, and incremental memory usage, with computational bottlenecks identified. Our assessment revealed comparable performance metrics (84.3% of accuracy, recall, and f1_score, and 84.7% precision) for the neural network models despite the lower computational resources. Profiling results, including 1.74 sec training time, 0.405 sec inference time, 1154.9 MiB peak memory, and 405.2 MiB incremental memory usage, also demonstrated that the RPi4 is a potentially viable device for low-cost BCI systems. However, high-resource demanding classifiers such as ANN may need to be carefully considered in their implementation, which, in turn, will scale down the potential cost and complexity of adopting practical, impactful at-home BCI systems.",https://pubmed.ncbi.nlm.nih.gov/40040137/,https://pubmed.ncbi.nlm.nih.gov/40040137/,English,Include,,Profiling a Raspberry Pi-Based Motor Imagery Classification to Facilitate At-Home BCI for Children with Disabilities.,Include,,"r metrics such as training time, inference time, peak memory, and incremental memory usage, with computational bottlenecks identified. Our assessment revealed comparable performance metrics (84.3% of accuracy, recall, and f1_score, and 84.7% precision) for the neural network models despite the lower computational resources. Profiling results, including 1.74 sec training time, 0.405 sec inference t",,0.95,0.6,
pubmed:40040133,pubmed:40040133,PubMed,pubmed:40040133,Attention on Sleep Stage Specific Characteristics.,Iris A M Huijben;Sebastiaan Overeem;Merel M van Gilst;Ruud J G van Sloun,2024,10.1109/embc53108.2024.10782554,"Manual sleep stage classification relies on visual inspection of 30-second windows comprising multi-sensor measurements The ability of neural networks to model complex relations has made them a popular, faster, alternative. However, it often remains unclear which parts of the data predominantly contributed to the model's decision. This is especially ambiguous in sleep staging, where the coarse labeling per 30-second windows may assign mixtures of class-specific features to a single class. To boost the transparency of deep neural classifiers, we propose a dynamic discrete attention module that actively selects the subset of the input space aligned with the class label. The module can be combined with a typical classification network, and may additionally serve as a data-driven tool to discover sleep stage specific features in polysomnography data. We validate the method on synthetic and patient data. We observe that only a small subset of data from the 30-second window is required to retain accurate classification, and that the attention mechanism boosts performance. Analysis of the dynamic attention masks, moreover, shows clear sleep stage adaptive channel selection.",,https://pubmed.ncbi.nlm.nih.gov/40040133/,English,Exclude,Not EEG-BCI focused,Attention on Sleep Stage Specific Characteristics.,,,,,0.9,0.6,
pubmed:40040130,pubmed:40040130,PubMed,pubmed:40040130,Dataset-Independent EEG Channel Selection for Emotion Recognition.,Shyamal Y Dharia;Sergio G Camorlinga;Camilo E Valderrama;Mahdis Hojjati,2024,10.1109/embc53108.2024.10782444,"Electroencephalography (EEG) stands as a noninvasive and cost-effective method for recording neural activity, holding potential for applications such as identifying neural processes underlying human emotions. This paper delves into the transferability and generalizability of EEG channel selection in emotion recognition, adopting a dataset-independent approach. By leveraging Power Spectral Density (PSD), we identify high-contributing EEG channels in the SEED V dataset and validate our approach on the independent SEED IV dataset using a Convolutional Neural Network (CNN) model. The channel selection method helped in eliminating insignificant EEG channels, which can improve the applicability of developing more efficient EEG devices for daily use to monitor emotions, as well as in individuals suffering from various neurodegenerative diseases. Through extensive experiments varying the number of channels and features, our model achieves classification accuracies of 77.02%, 75.42%, 71.31%, and 64.31% with 62, 30, 20, and 10 EEG channels, accompanied by 310, 90, 60, and 30 Differential Entropy (DE) features respectively. Further, the proposed approach is tested by introducing Gaussian noise to the training set and evaluating its sensitivity to signal noise. Finally, results are compared with state-of-the-art models highlighting the potential of our dataset-independent channel selection method.",https://pubmed.ncbi.nlm.nih.gov/40040130/,https://pubmed.ncbi.nlm.nih.gov/40040130/,English,Include,,Dataset-Independent EEG Channel Selection for Emotion Recognition.,Include,,"Electroencephalography (EEG) stands as a noninvasive and cost-effective method for recording neural activity, holding potential for applications such as identifying neural processes underlying human emotions. This paper delves into the transferability and generalizability of EEG channel selection in emotion recognition, adopting a dataset-independent approach. By leverag",,0.95,0.6,
pubmed:40040127,pubmed:40040127,PubMed,pubmed:40040127,Multi-modal Adversarial Regressive Transformer for Cross-subject Fatigue Detection.,Mingyu Gou;Hao-Long Yin;Bao-Liang Lu;Wei-Long Zheng,2024,10.1109/embc53108.2024.10782078,"Fatigue driving constitutes a factor to traffic accidents, necessitating the importance of fatigue detection. In this paper, we propose leveraging Electroencephalogram (EEG) and Electrooculogram (EOG) data for fatigue detection, developing the Multi-modal Adversarial Regressive Transformer (MART) model. MART encodes and concatenates multiple modalities into an embedded sequence, processed by Transformer focusing on isolated and mixed modalities. Transformer outputs contribute to a regressor for prediction and a domain classifier for domain generalization. MART is flexible to accommodate various modality inputs and allow reducing individual differences with adversarial domain generalization. We test the performance of our proposed method and baselines on the SEED-VIG dataset. This dataset contains 23 subjects, using EEG and EOG features as data and corresponding PERCLOS as labels. Under the subject-dependent setup, our model achieves an RMSE of 0.1015. Under the cross-subject setup, the RMSE of 0.1556 is obtained and decreased to 0.1249 with adversarial domain generalization. This result highlights efficacy and adaptability of MART in fatigue monitoring across subjects.",https://pubmed.ncbi.nlm.nih.gov/40040127/,https://pubmed.ncbi.nlm.nih.gov/40040127/,English,Include,,Multi-modal Adversarial Regressive Transformer for Cross-subject Fatigue Detection.,Include,,"rooculogram (EOG) data for fatigue detection, developing the Multi-modal Adversarial Regressive Transformer (MART) model. MART encodes and concatenates multiple modalities into an embedded sequence, processed by Transformer focusing on isolated and mixed modalities. Transformer outputs contribute to a regressor for prediction and a domain classifier for domain generalization. MART is flexible to a",,0.95,0.6,
pubmed:40040110,pubmed:40040110,PubMed,pubmed:40040110,EEG Pattern Comparison and Classification Performance of Motor Imagery Between Supernumerary and Inherent Limbs.,Zhuang Wang;Yuan Liu;Wenlai Wu;Shuaifei Huang;Xingwei An;Dong Ming,2024,10.1109/embc53108.2024.10782967,"Adding supernumerary robotic limbs (SRLs) to humans and controlling them directly through the brain are main goals for movement augmentation. However, whether neural patterns that are distinct from the traditional inherent limbs motor imagery (MI) paradigm can be extracted, which is essential for the high-dimensional control of external equipment. In this study, a novel type of MI paradigm based on SRLs was proposed, consisting of ""the sixth-finger"", ""the third-arm"" and ""the third-leg"", and validated the distinctness of EEG response patterns between the novel and the traditional (hand, arm and leg) MI paradigm. The results showed that imagining extra limbs induced more obvious event-related desynchronization (ERD) phenomenon in sensorimotor areas compared to imagining inherent limbs. Classification results indicate well separable performance among different mental tasks (all above 86%, with a maximum of 90.5%). This work proposed a novel type of MI paradigm, and offered new way for widening the control bandwidth of the BCI system.",https://pubmed.ncbi.nlm.nih.gov/40040110/,https://pubmed.ncbi.nlm.nih.gov/40040110/,English,Include,,EEG Pattern Comparison and Classification Performance of Motor Imagery Between Supernumerary and Inherent Limbs.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40040096,pubmed:40040096,PubMed,pubmed:40040096,Baseline-Guided Representation Learning for Noise-Robust EEG Signal Classification.,Elissa Yanting Lim;Kang Yin;Hye-Bin Shin;Seong-Whan Lee,2024,10.1109/embc53108.2024.10781970,"Brain-computer interfaces (BCIs) suffer from limited accuracy due to noisy electroencephalography (EEG) signals. Existing denoising methods often remove artifacts such as eye movement or use techniques such as linear detrending, which inadvertently discard crucial task-relevant information. To address this issue, we present BGNet, a novel deep learning framework that leverages underutilized baseline EEG signals for dynamic noise mitigation and robust feature extraction to improve motor imagery (MI) EEG classification. Our approach employs data augmentation to strengthen model robustness, an autoencoder to extract features from baseline and MI signals, a feature alignment module to separate specific task and noise, and a classifier. We achieve state-of-the-art performance, an improvement of 5.9% and 3.7% on the BCIC IV 2a and 2b datasets, respectively. The qualitative analysis of our learned features proves superior representational power over baseline models, a critical aspect in dealing with noisy EEG signals. Our findings demonstrate the efficacy of readily available baseline signals in enhancing performance, opening possibilities for simplified BCI systems in brain-based communication applications.",https://pubmed.ncbi.nlm.nih.gov/40040096/,https://pubmed.ncbi.nlm.nih.gov/40040096/,English,Include,,Baseline-Guided Representation Learning for Noise-Robust EEG Signal Classification.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40040082,pubmed:40040082,PubMed,pubmed:40040082,Deciphering Odor Perception through EEG Brain Activity and Gas Sensors.,Hsin-Ping Peng;Hao-Lung Hsiao;Chien-Hui Su;Yang-Chen Lin;Po-Chih Kuo,2024,10.1109/embc53108.2024.10782394,"Recent technological advances have led to innovations like electronic noses and gas sensors, proficient in detecting distinct odors. Despite this, the field of AI and robotics has only marginally explored olfaction, a sense crucial for evoking emotions and memories. Our study investigates the correlation between gas sensor signals and EEG activity during odor recognition. By comparing our findings with questionnaire results, we suggest that individual experiences might influence odor recognition in the human brain. We designed an odor-dispensing system and recorded EEG responses from 15 subjects to six odors, alongside concentration data of four gases for each odor. These EEG and gas sensor data were analyzed using two neural networks for odor classification. Combining EEG and gas sensor data, we attained a 44% accuracy in 6-class odor discrimination, indicating the potential of this integrated approach as a unique 'odor fingerprint' for odor identification.",https://pubmed.ncbi.nlm.nih.gov/40040082/,https://pubmed.ncbi.nlm.nih.gov/40040082/,English,Include,,Deciphering Odor Perception through EEG Brain Activity and Gas Sensors.,Include,,"ide concentration data of four gases for each odor. These EEG and gas sensor data were analyzed using two neural networks for odor classification. Combining EEG and gas sensor data, we attained a 44% accuracy in 6-class odor discrimination, indicating the potential of this integrated approach as a unique 'odor fingerprint' for odor identification.",,0.95,0.6,
pubmed:40040056,pubmed:40040056,PubMed,pubmed:40040056,Enhancement of Functional Connectivity in Frontal-Parietal Regions After BCI-Actuated Supernumerary Robotic Finger Training.,Shuaifei Huang;Yuan Liu;Weiguo Xu;Zhuang Wang;Dong Ming,2024,10.1109/embc53108.2024.10781807,"The supernumerary robotic finger (SRF) can expand human hand abilities to achieve motor augmentation, and integrate with brain computer interface (BCI) to free the occupation of inherent body degrees of freedom. However, the neuro remodeling mechanisms of brain-actuated SRF training is not clear. In this study, a BCI-actuated SRF was used to investigate the concurrent changes in behavior and brain activity. After 4 weeks BCI-SRF training, the novel sequence operation accuracy rate enhanced by more than 350% compared with innate finger training (IFT). Task-based fMRI showed a significant increase in lateral activation of sensorimotor cortex and found a significant activation change in S1M1_L area. Moreover, BCI-SRF training significantly increase functional connectivity (FC) between S1M1_L and Frontal_Mid_L compared with IFT at post stage. And this FC increase in frontal-parietal is also significant at post vs pre in BCI-SRF group and significantly correlated with the improvement of motor sequence accuracy rate. Our findings provide useful insights into the enhanced human-machine interaction and this efficacy exhibited significant potential for clinical rehabilitation application.",https://pubmed.ncbi.nlm.nih.gov/40040056/,https://pubmed.ncbi.nlm.nih.gov/40040056/,English,Include,,Enhancement of Functional Connectivity in Frontal-Parietal Regions After BCI-Actuated Supernumerary Robotic Finger Training.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40040050,pubmed:40040050,PubMed,pubmed:40040050,Uncertainty Estimation and Model Calibration in EEG Signal Classification for Epileptic Seizures Detection.,H U Jiahao;Muhammad Mahboob Ur Rahman;Tareq Al-Naffouri;Taous-Meriem Laleg-Kirati,2024,10.1109/embc53108.2024.10782858,"This paper studies Bayesian modeling, uncertainty estimation and model calibration for Electroencephalography (EEG) signal classification. Prior research lacks studies that combine uncertainty estimation with model calibration in EEG data analysis for epileptic seizures. In this work, we implement the Gaussian process, the Monte-Carlo dropout and the Bayesian neural network as three representative Bayesian models. The Gaussian Process offers a flexible non-parametric framework for capturing underlying patterns in EEG data, while the Bayesian Neural Network and MC Dropout enhance predictive uncertainty estimation and model robustness. Moreover, the model calibration technique is employed to refine the final probabilities, ensuring improved reliability of the classification outcomes. Through evaluation on Temple and Lemon EEG datasets, the proposed approach shows promising results, i.e., 7.3% improvement in area under curve, 38% reduction in negative log likelihood and 43% reduction in the Brier score, demonstrating its potential in accurate uncertainty estimation and calibrated EEG epileptic signal classification.",https://pubmed.ncbi.nlm.nih.gov/40040050/,https://pubmed.ncbi.nlm.nih.gov/40040050/,English,Include,,Uncertainty Estimation and Model Calibration in EEG Signal Classification for Epileptic Seizures Detection.,Include,,"G) signal classification. Prior research lacks studies that combine uncertainty estimation with model calibration in EEG data analysis for epileptic seizures. In this work, we implement the Gaussian process, the Monte-Carlo dropout and the Bayesian neural network as three representative Bayesian models. The Gaussian Process offers a flexible non-parametric framework for capturing underlying patter",,0.95,0.6,
pubmed:40040036,pubmed:40040036,PubMed,pubmed:40040036,Detection of High-Frequency Oscillations from Intracranial EEG Data with Switching State Space Model.,Zeyu Gu;Shihao Yang;Zhongyuan Yu;Feng Liu,2024,10.1109/embc53108.2024.10782110,"High Frequency Oscillations (HFOs) is an important biomarker that can potentially pinpoint the epileptogenic zones (EZs). However, the duration of HFO is short with around 4 cycles, which might be hard to recognize when embedded within signals of lower frequency oscillatory background. In addition, annotating HFOs manually can be time-consuming given long-time recordings and up to hundreds of intracranial electrodes. We propose to leverage a Switching State Space Model (SSSM) to identify the HFOs events automatically and instantaneously without relying on extracting features from sliding windows. The effectiveness of the SSSM for HFOs detection is fully validated in the intracranial EEG recording from human subjects undergoing the presurgical evaluations and showed improved accuracy when capturing the HFOs occurrence and their duration.",https://pubmed.ncbi.nlm.nih.gov/40040036/,https://pubmed.ncbi.nlm.nih.gov/40040036/,English,Include,,Detection of High-Frequency Oscillations from Intracranial EEG Data with Switching State Space Model.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40040035,pubmed:40040035,PubMed,pubmed:40040035,Precision Enhancement in Sustained Visual Attention Training Platforms: Offline EEG Signal Analysis for Classifier Fine-Tuning.,Maryam Norouzi;Mohammad Zaeri Amirani;Yalda Shahriari;Reza Abiri,2024,10.1109/embc53108.2024.10782784,"In this study, a novel open-source brain-computer interface (BCI) platform was developed to decode scalp electroencephalography (EEG) signals associated with sustained attention. The EEG signal collection was conducted using a wireless headset during a sustained visual attention task, where participants were instructed to discriminate between composite images superimposed with scenes and faces, responding only to the relevant subcategory while ignoring the irrelevant ones. Seven volunteers participated in this experiment. The data collected were subjected to analyses through event-related potential (ERP), Hilbert Transform, and Wavelet Transform to extract temporal and spectral features. For each participant, utilizing its extracted features, personalized Support Vector Machine (SVM) and Random Forest (RF) models with tuned hyperparameters were developed. The models aimed to decode the participant's attentional state towards the face and scene stimuli. The SVM models achieved a higher average accuracy of 80% and an Area Under the Curve (AUC) of 0.86, while the RF models showed an average accuracy of 78% and AUC of 0.8. This work suggests potential applications for the evaluation of visual attention and the development of closed-loop brainwave regulation systems in the future.",https://pubmed.ncbi.nlm.nih.gov/40040035/,https://pubmed.ncbi.nlm.nih.gov/40040035/,English,Include,,Precision Enhancement in Sustained Visual Attention Training Platforms: Offline EEG Signal Analysis for Classifier Fine-Tuning.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:40040033,pubmed:40040033,PubMed,pubmed:40040033,Enhancing Auditory BCI Performance: Incorporation of Connectivity Analysis.,Talukdar Raian Ferdous;Luca Pollonini;Joseph Thachil Francis,2024,10.1109/embc53108.2024.10782147,"Brain connectivity analysis to classify auditory stimuli applicable to invasive auditory BCI technology, particularly intracranial electroencephalography (iEEG) remains an exciting frontier. This study revealed insights into brain network dynamics, improving analysis precision to distinguish related auditory stimuli such as speech and music. We thereby contribute to advancing auditory BCI systems to bridge the gap between noninvasive and invasive BCI by utilizing noninvasive BCI methodological frameworks to invasive BCI (iEEG) data. We focused on the viability of using connectivity matrices in BCI calculated across brain waves such as alpha, beta, theta, and gamma. The research highlights that the traditional machine learning classifier, Support Vector Machine (SVM), demonstrates exceptional capabilities in handling brain connectivity data, exhibiting an outstanding 97% accuracy in classifying brain states, surpassing previous relevant studies with an improvement of 9.64% The results are significant as we show that neural activity in the gamma band provides the best classification performance using connectivity matrices calculated with Phase Locking Values and Coherence methods.",https://pubmed.ncbi.nlm.nih.gov/40040033/,https://pubmed.ncbi.nlm.nih.gov/40040033/,English,Include,,Enhancing Auditory BCI Performance: Incorporation of Connectivity Analysis.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40040018,pubmed:40040018,PubMed,pubmed:40040018,The Seizure Detection Based on a Novel Electroencephalogram Segmentation.,Mingxia Shi;Guan Yang;Wen Wang;Yueyang Hu;Lin Wan;Qingya Li;Xiaoyan Tao,2024,10.1109/embc53108.2024.10781928,"Due to the non-stationary nature of electroencephalogram (EEG) signals, it is imperative to partition the EEG into quasi-stationary intervals with similar statistical characteristics. This study introduces an innovative method leveraging the relative stability of synchronous brain electrical activity for the automatic segmentation of EEG signals, eliminating the need for human intervention. The experiments illustrate that EEG signals segmented using this method demonstrate a certain level of stability across different frequency ranges and frequency power distribution. This consistency ensures the EEG signals remain quasi-stationary to a significant degree. For validation, this method was applied to seizure detection. The evaluation, utilizing EEG data from the department of pediatrics of Chinese PLA General Hospital, reveals that our method outperforms existing techniques. Notably, the approach achieved a seizure detection accuracy of 92.26%, specificity of 91.43%, and sensitivity of 92.93%.",https://pubmed.ncbi.nlm.nih.gov/40040018/,https://pubmed.ncbi.nlm.nih.gov/40040018/,English,Include,,The Seizure Detection Based on a Novel Electroencephalogram Segmentation.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40040010,pubmed:40040010,PubMed,pubmed:40040010,Interictal Epileptiform Discharge Detection Using Time-Frequency Analysis and Transfer Learning.,Munawara Saiyara Munia;MohammadSaleh Hosseini;Mehrdad Nourani;Jay Harvey,2024,10.1109/embc53108.2024.10782120,"Interictal epileptiform discharges (IEDs) are electrophysiological events that intermittently occur in between seizures in Epilepsy patients. Automated detection of IEDs is crucial for assisting clinicians in epilepsy diagnosis as they can help identify the extent of cortical irritations and may indicate an upcoming seizure, thus helping in preventing seizure. It also minimizes visual inspection of very long EEG signals by physicians. This paper presents a transfer-learning-based approach for analyzing time-frequency representations of different types of IEDs from scalp EEG data using a fine-tuned deep residual network. The proposed method was evaluated using the publicly available Temple University Events EEG dataset. Experimental results show that our method demonstrates promising performance, by achieving an F1-score of 88.52% on this dataset for binary classification of IEDs.",https://pubmed.ncbi.nlm.nih.gov/40040010/,https://pubmed.ncbi.nlm.nih.gov/40040010/,English,Include,,Interictal Epileptiform Discharge Detection Using Time-Frequency Analysis and Transfer Learning.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40039997,pubmed:40039997,PubMed,pubmed:40039997,Diagnosing Suicidal Ideation from Resting State EEG Data Using a Machine Learning Algorithm.,Mary Margarette Sanchez;Maryam Ravan;Gary Hasey;James Reilly;Luciano Minuzzi,2024,10.1109/embc53108.2024.10782191,"Suicide poses a global health crisis with significant social and economic impact. Prevention may be possible if objective quantitative methods are developed to supplement the often inaccurate interview-based risk assessments. Our research goal is to develop a machine learning algorithm (MLA) to predict the presence of suicide ideation from resting state electroencephalography (EEG) data collected from 224 subjects with major depressive disorder (MDD) in the Establishing Moderators and Biosignatures of Antidepressant Response for Clinical Care for Depression (EMBARC) study. Using the Concise Health Risk Tracking Self-Report (CHRT-SR14) questionnaire, 194 subjects acknowledged having suicidal ideation (group 1) and 30 did not (group 2). We balanced the database by matching 30 subjects from group 1 using propensity score analysis. A four-step prediction algorithm was then applied to the selected data including 1) EEG data preprocessing, 2) brain source localization (BSL) using the robust exact low-resolution electromagnetic tomography (ReLORETA) method, 3) determining the connectivity between the brain regions using symbolic transfer entropy (STE), 4) applying MLA to the STE features. Three common classifiers, Support Vector Machine (SVM), Random Forest (RF), and K-Nearest Neighbor (KNN) were used in this study. Using 70% of the data for training and evaluation and 30% for testing, all three classifiers delivered a high accuracy, where the highest performance belonged to SVM with 88.9% accuracy. These findings support the potential utility of ML analysis of EEG data as a non-verbal way to enhance the accuracy of suicide risk evaluation.",https://pubmed.ncbi.nlm.nih.gov/40039997/,https://pubmed.ncbi.nlm.nih.gov/40039997/,English,Include,,Diagnosing Suicidal Ideation from Resting State EEG Data Using a Machine Learning Algorithm.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40039996,pubmed:40039996,PubMed,pubmed:40039996,EEG Spectral Power and Neurovascular Coupling as Early Predictors of Neurodevelopmental Outcome in Neonatal Hypoxic-Ischemic Encephalopathy.,Srinivas Kota;Yu-Lun Liu;Lynn Bitar;Lina Chalak,2024,10.1016/j.compbiomed.2015.05.017,"Hypoxic ischemic encephalopathy (HIE) remains one of the leading causes of morbidity and mortality in newborns. There is a strong need to predict their neurodevelopmental impairment (NDI) within early hours of life, tailoring treatment strategies accordingly. This study aims to explore the discriminatory capabilities of electroencephalogram (EEG) delta power (DP) and total power (TP), along with neurovascular coupling (NVC) to predict NDI. The study evaluates the relationships of single biomarkers (DP, TP, and NVC) with NDI using univariate logistic regression models. The predictive accuracy of single (DP, TP, and NVC) and combination of biomarkers (DP+NVC, TP+NVC) on NDI is further assessed through the receiver operating characteristic (ROC) curve, with the area under the ROC curve (AUC). Utilizing EEG and near infrared spectroscopy (NIRS) data from 35 newborns with mild and moderate HIE, we found that a one-unit increase in DP or TP significantly lowered the odds of NDI. The combination of DP or TP and NVC is most effective in distinguishing newborns who may develop NDI. These findings suggest that continuous multimodal real-time neuromonitoring could offer valuable insights into HIE severity, aiding in predicting brain injury and NDI.",https://pubmed.ncbi.nlm.nih.gov/40039996/,https://pubmed.ncbi.nlm.nih.gov/40039996/,English,Include,,EEG Spectral Power and Neurovascular Coupling as Early Predictors of Neurodevelopmental Outcome in Neonatal Hypoxic-Ischemic Encephalopathy.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40039991,pubmed:40039991,PubMed,pubmed:40039991,Identification of hunger and satiety states from EEG data.,Deepesh V V Kalahasti;Edward Sazonov;Evie Malaia,2024,10.1109/embc53108.2024.10782290,"Hunger and satiety states modulate brain areas to adapt behavior to energy needs. Thus, neurophysiological state of an individual measured by EEG may be indicative of one's hunger/satiety state. In this work, we evaluate applicability of spectrotemporal parameters of EEG for classification hunger and satiety. EEG recordings of resting state brain activity were made in 20 individuals after overnight fasting of at least 8 hours (hunger state), and again after a meal (satiated state). The data were acquired with a 64-channel EGI Hydrocel Geodesic Sensor nets. Spectrotemporal features of EEG likely to index metabolic state (peak alpha frequency, peak alpha power, average spectral power and 1/f exponent) were computed from EEG data. In comparison across machine learning models using Leave-One-Participant-Out Cross-Validation, alpha peak frequency yielded the highest accuracy (≥ 85%). Linking the hunger state to neural decision drivers and behavioral outputs promises rich insights into regulation of energy homeostasis, and might allow to categorize mixed metabolic-cognitive states from spectrotemporal EEG features.",https://pubmed.ncbi.nlm.nih.gov/40039991/,https://pubmed.ncbi.nlm.nih.gov/40039991/,English,Include,,Identification of hunger and satiety states from EEG data.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.25,cv_reported
pubmed:40039982,pubmed:40039982,PubMed,pubmed:40039982,Using Attentive Network Layers for Identifying Relevant EEG channels for Subject-Independent Emotion Recognition Approaches.,Camilo E Valderrama,2024,10.1109/embc53108.2024.10781782,"Emotion recognition approaches using electroencephalographic (EEG) signals can be evaluated using two distinct approaches: subject-dependent and subject-independent. While subject-independent models are more generalizable and practical than subject-dependent models, they face challenges due to the high variability of EEG signals among individuals. One solution is identifying shared patterns during emotional processing. As deep learning has become a common practice for emotion recognition, using attentive network layers can help identify shared predictive patterns. This study explores this approach by using attentive network layers to identify brain areas relevant for predicting four emotions evoked by video clips in 15 individuals. The model achieved an average accuracy of 46% (95% CI: 41.3-50.7%) among subjects, indicating that the EEG channels in the right hemisphere were more relevant for predicting happy and neutral emotions, while those in the left hemisphere were more relevant for sadness and fear. These findings highlight the importance of including EEG channels from both hemispheres to ensure the prediction of different emotion types in subject-independent approaches. Clinical relevance- This study identifies shared neuronal patterns in emotion prediction, supporting the development of generalizable emotion recognition systems that can help diagnose and treat disorders such as depression, anxiety, and neurodegenerative diseases.",https://pubmed.ncbi.nlm.nih.gov/40039982/,https://pubmed.ncbi.nlm.nih.gov/40039982/,English,Include,,Using Attentive Network Layers for Identifying Relevant EEG channels for Subject-Independent Emotion Recognition Approaches.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40039972,pubmed:40039972,PubMed,pubmed:40039972,EEG-GMACN: Interpretable EEG Graph Mutual Attention Convolutional Network.,Haili Ye;Stephan Goerttler;Fei He,2024,10.1109/embc53108.2024.10782694,"Electroencephalogram (EEG) is a valuable technique to record brain electrical activity through electrodes placed on the scalp. Analyzing EEG signals contributes to the understanding of neurological conditions and developing brain-computer interface. Graph Signal Processing (GSP) has emerged as a promising method for EEG spatial-temporal analysis, by further considering the topological relationships between electrodes. However, existing GSP studies lack interpretability of electrode importance and the credibility of prediction confidence. This work proposes an EEG Graph Mutual Attention Convolutional Network (EEG-GMACN), by introducing an 'Inverse Graph Weight Module' to output interpretable electrode graph weights, enhancing the clinical credibility and interpretability of EEG classification results. Additionally, we incorporate a mutual attention mechanism module into the model to improve its capability to distinguish critical electrodes and introduce credibility calibration to assess the uncertainty of prediction results. This study enhances the transparency and effectiveness of EEG analysis, paving the way for its widespread use in clinical and neuroscience research.",https://pubmed.ncbi.nlm.nih.gov/40039972/,https://pubmed.ncbi.nlm.nih.gov/40039972/,English,Include,,EEG-GMACN: Interpretable EEG Graph Mutual Attention Convolutional Network.,Include,,"in electrical activity through electrodes placed on the scalp. Analyzing EEG signals contributes to the understanding of neurological conditions and developing brain-computer interface. Graph Signal Processing (GSP) has emerged as a promising method for EEG spatial-temporal analysis, by further considering the topological relationships between electrodes. However, existing GSP studies lack interpr",,0.95,0.6,
pubmed:40039961,pubmed:40039961,PubMed,pubmed:40039961,Detection of Hypoglycemia using ear-EEG.,Alvaro Fuentes Cabrera;Eva M Gram-Kampmann;Simon Lind Kappel;Line Sofie Remvig;Hans Olaf Toft;Rasmus Elsborg Madsen;Claus Juhl;Preben Kidmose;Mike Lind Rank,2024,10.1109/embc53108.2024.10781651,"Hypoglycemia refers to a condition in which the blood glucose level is below physiological normal level. It has previously been demonstrated that hypoglycemia results in characteristic changes in the EEG signals recorded from electrodes on the scalp. Scalp EEG is not suitable for continuous measurements, due to its obtrusive nature and limited capabilities for monitoring in real-life environments. The aim of this study was to assess the feasibility of detecting hypoglycemia episodes using EEG signals recorded with dry-contact in-ear electrodes, which have the potential for long-term EEG monitoring in real-life situations and provide similar information to that recorded with scalp EEG. Data from 5 diabetic patients was used for this study. Six ear-EEG channels recorded from the right ear, and channels C3, Pz, T7, and T8 were used for the analysis and classification procedures. A Support Vector Machine was used to detect the hypoglycemic episodes, using the RMS of the θ, α, β, and γ frequency bands as features. The results showed that there were no statistical differences between the sensitivity and specificity of the scalp-scalp and ear-scalp EEG channels.",https://pubmed.ncbi.nlm.nih.gov/40039961/,https://pubmed.ncbi.nlm.nih.gov/40039961/,English,Include,,Detection of Hypoglycemia using ear-EEG.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40039954,pubmed:40039954,PubMed,pubmed:40039954,Bispectrum Analysis of Noninvasive EEG Signals Discriminates Complex and Natural Grasp Types.,Sima Ghafoori;Ali Rabiee;Anna Cetera;Yalda Shahriari;Reza Abiri,2024,10.1109/embc53108.2024.10782163,"The bispectrum stands out as a revolutionary tool in frequency domain analysis, leaping the usual power spectrum by capturing crucial phase information between frequency components. In our innovative study, we have utilized the bispectrum to analyze and decode complex grasping movements, gathering EEG data from five human subjects. We put this data through its paces with three classifiers, focusing on both magnitude and phase-related features. The results highlight the bispectrum's incredible ability to delve into neural activity and differentiate between various grasping motions with the Support Vector Machine (SVM) classifier emerging as a standout performer. In binary classification, it achieved a remarkable 97% accuracy in identifying power grasp, and in the more complex multiclass tasks, it maintained an impressive 94.93% accuracy. This finding not only underscores the bispectrum's analytical strength but also showcases the SVM's exceptional capability in classification, opening new doors in our understanding of movement and neural dynamics.",https://pubmed.ncbi.nlm.nih.gov/40039954/,https://pubmed.ncbi.nlm.nih.gov/40039954/,English,Include,,Bispectrum Analysis of Noninvasive EEG Signals Discriminates Complex and Natural Grasp Types.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40039945,pubmed:40039945,PubMed,pubmed:40039945,A Study on Changes in Estimation Accuracy for EEG Data During Calibration and Operation in MI-BCI.,Takuya Kanda;Takashi Isezaki;Kengo Okitsu,2024,10.1109/embc53108.2024.10782616,"Changes in psychological factors have been suggested to cause variations in brain-computer interface (BCI) performance. More specifically, differences in psychological variables between the calibration and operation phases may cause a decrease in accuracy during operation, presenting a potential challenge for the adoption of BCI technology. The purpose of this study is to analyze the differences in accuracy between the calibration and operation phases of a BCI using a deep learning model. We structured tasks to simulate the calibration and operation phases, and participants performed motor imagery tasks under both conditions. The analysis revealed a significant decrease in accuracy for data obtained under the operation condition, highlighting the need for techniques capable of adapting to the electroencephalography signal data produced when users execute operations.",https://pubmed.ncbi.nlm.nih.gov/40039945/,https://pubmed.ncbi.nlm.nih.gov/40039945/,English,Include,,A Study on Changes in Estimation Accuracy for EEG Data During Calibration and Operation in MI-BCI.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:40039943,pubmed:40039943,PubMed,pubmed:40039943,Patient-Involved Validation of A Somatosensory ERP-BCI Facilitated by Electric Stimulation for Stroke Rehabilitation.,Junlin Wang;Xiaodong Li;Yaohui Huang;Dongyi Xiao;Yingjie Fan;Wei Huang;Yong Hu,2024,10.1109/embc53108.2024.10781706,"Brain-computer interface (BCI) is emerging as an effective complementary solution in the field of rehabilitation for the interaction between patients and robotic assistive devices. Specifically, the somatosensory event-related potentials (ERP) BCI has unique advantage for post-stroke motor rehabilitation scenarios and has been proven feasible on healthy subjects. We conducted the first patient-involved somatosensory ERP-BCI experiment with electric stimulation to evaluate its feasibility for real-world clinical usage. In the experiment, participant selectively attended to electric stimuli applied on either left or right wrist, which represented the operation of robot-assisted exercise of corresponding hand. An integrated platform that included exercise, stimulation, and electroencephalography (EEG) sampling modules was used. For evaluation, we used convolutional neural network (CNN) with transformer module to construct subject-specific intent decoder. The network demonstrated on average 58.95% accuracy in classifying target response from a single ERP trial. When using the classification from multiple consecutive trials, the decoder achieved a maximum of 80.12% mean accuracy in recognizing participants intent, and the highest rate from a single participant was 97.21%. The best information transfer rate (ITR) achieved was 1.956 Bit/min. These results demonstrated that the proposed BCI paradigm could be a valid choice for stroke rehabilitation. In the next stage, we anticipate the involvement of larger patient population, real-time feedback training, and the subsequent quantified motor function recovery results.",https://pubmed.ncbi.nlm.nih.gov/40039943/,https://pubmed.ncbi.nlm.nih.gov/40039943/,English,Include,,Patient-Involved Validation of A Somatosensory ERP-BCI Facilitated by Electric Stimulation for Stroke Rehabilitation.,Include,," sampling modules was used. For evaluation, we used convolutional neural network (CNN) with transformer module to construct subject-specific intent decoder. The network demonstrated on average 58.95% accuracy in classifying target response from a single ERP trial. When using the classification from multiple consecutive trials, the decoder achieved a maximum of 80.12% mean accuracy in recognizing p",,0.95,0.8,small_sample_mentioned
pubmed:40039935,pubmed:40039935,PubMed,pubmed:40039935,Proxy-based Masking Module for Revealing Relevance of Characteristics in Motor Imagery.,Hyeon-Taek Han;Sung-Jin Kim;Dae-Hyeok Lee;Seong-Whan Lee,2024,10.1109/embc53108.2024.10782698,"Brain-computer interface (BCI) has been developed for communication between users and external devices by reflecting users' status and intentions. Motor imagery (MI) is one of the BCI paradigms for controlling external devices by imagining muscle movements. MI-based EEG signals generally tend to contain signals with sparse MI characteristics (sparse MI signals). When conducting domain adaptation (DA) on MI signals with sparse MI signals, it could interrupt the training process. In this paper, we proposed the proxy-based masking module (PMM) for masking sparse MI signals within MI signals. The proposed module was designed to suppress the amplitude of sparse MI signals using the negative similarity-based mask generated between the proxy of rest signals and the feature vectors of MI signals. We attached our proposed module to the conventional DA methods (i.e., the DJDAN, the MAAN, and the DRDA) to verify the effectiveness in the cross-subject environment on dataset 2a of BCI competition IV. When our proposed module was attached to each conventional DA method, the average accuracy was improved by much as 4.67 %, 0.76 %, and 1.72 %, respectively. Hence, we demonstrated that our proposed module could emphasize the information related to MI characteristics. The code of our implementation is accessible on GitHub.",https://pubmed.ncbi.nlm.nih.gov/40039935/,https://pubmed.ncbi.nlm.nih.gov/40039935/,English,Include,,Proxy-based Masking Module for Revealing Relevance of Characteristics in Motor Imagery.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40039926,pubmed:40039926,PubMed,pubmed:40039926,Enhanced BCI Performance using Diffusion Model for EEG Generation.,Yucun Zhong;Lin Yao;Yueming Wang,2024,10.1109/embc53108.2024.10782900,"In the realm of Motor Imagery (MI)-based Brain-Computer Interface (BCI), the widespread adoption of deep learning-based algorithms has resulted in an increased demand for a larger training sample size, thereby placing a heightened burden on users. This study advocates the utilization of one of the most advanced generative models, the denoising diffusion probabilistic model (DDPM), for the artificial synthesis of Electroencephalogram (EEG) raw signals. The quality of the generated EEG signals is evaluated through both qualitative and quantitative analyses. Through dimensionality reduction projection, we observed a notable similarity in the data distributions between the generated EEG signals and real EEG signals. Additionally, spectral analysis indicates a striking similarity in energy distribution between the two, accompanied by the presence of an event-related synchronization (ERS) phenomenon in the generated EEG signals. Quantitative analysis reveals that the accuracy of generated EEG signals for left and right-hand motor imagery tasks is 89.81 ± 2.11%, with discriminative information related to classes predominantly concentrated in the motor-sensory cortex area and alpha-beta frequency band. Furthermore, the integration of generated EEG samples contributes to a 3.17% improvement in the classification performance of BCI-deficiency subjects. These artificially generated EEG signals exhibit promising potential for application in calibrating MI-BCI deep learning models, thereby alleviating the burden on participants.",https://pubmed.ncbi.nlm.nih.gov/40039926/,https://pubmed.ncbi.nlm.nih.gov/40039926/,English,Include,,Enhanced BCI Performance using Diffusion Model for EEG Generation.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:40039924,pubmed:40039924,PubMed,pubmed:40039924,Channel- and Label-Flip Data Augmentation for Motor Imagery-Based Brain-Computer Interfaces.,Takayuki Hoshino;Suguru Kanoga;Atsushi Aoyama,2024,10.1109/embc53108.2024.10782028,"Achieving high classification accuracy in motor-imagery-based brain-computer interfaces (BCIs) requires substantial amounts of training data. A challenge arises because of the impracticality of measuring large amounts of data from users. Data augmentation (DA) has emerged as a promising solution for this challenge. We propose a novel DA method called channel&label-flip DA that involves not only flipping channels but also flipping class labels. This method is based on the neuroscience finding that motor imageries of left- and right-hand movements are roughly symmetrical. The efficiency of the proposed method was evaluated using the OpenBMI dataset, which comprises electroencephalograms collected from 54 participants engaged in left- and right-hand motor imagery tasks. To compare the impact on classifiers, we employed three classical machine learning models utilizing filter bank common spatial pattern features, along with a deep learning-based model that uses raw signal input. As a result, the channel&label-flip DA improved the classification accuracy on average, whereas simple flipping of the channels reduced the classification accuracy compared to the case without DA.",https://pubmed.ncbi.nlm.nih.gov/40039924/,https://pubmed.ncbi.nlm.nih.gov/40039924/,English,Include,,Channel- and Label-Flip Data Augmentation for Motor Imagery-Based Brain-Computer Interfaces.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:40039918,pubmed:40039918,PubMed,pubmed:40039918,Effect Investigation of Mask on Facial Expression Recognition Using Cerebral Evoked Potentials.,Baijun Song;Tomohiko Igasaki;Saori Nishikawa,2024,10.1109/embc53108.2024.10782072,"There is little physiological evidence on mechanisms of facial expression recognition, which involves visual processing, feature extraction, emotion-processing, and cognitive integration. Therefore, this study aims to delve into the cerebral mechanisms underlying facial expression recognition using evoked potentials and understand how face masks affect these processes. We recorded the behavioral psychological and electrophysiological responses to facial expression stimuli: behavioral measures (accuracy and response time) and evoked potentials at 19 sites, which were measured in 12 subjects, corresponding to the type of facial expression and mask presence. The latencies and amplitudes of the five components (P1, N1, P2, N2, and P3) were analyzed at each site. For the behavioral measures, repeated two-way analysis of variance (ANOVA) demonstrated that accuracy was significantly affected by the type of facial expression (p < 0.001) and the presence of a mask (p < 0.01), with an interaction effect (p < 0.001). Response time was significantly affected by the type of facial expression (p < 0.001) and interaction (p < 0.01), however, it was not affected by the presence of a mask (p > 0.05). For evoked potentials, there were no significant differences in latency and amplitude for each site and component by type of facial expression (p > 0.05, one-way ANOVA). Nevertheless, there were significant differences in latency and amplitude for many sites and components with and without masks (p < 0.05, paired t-test). In addition, repeated two-way ANOVA revealed an interaction (p < 0.05) between N1 latency at F3, T3, C3, and Pz. In total, all these results suggest that the presence of a mask affects cognitive processing, and the presence of a mask for the type of facial expression affects central resources, both from a behavioral psychological and electrophysiological point of view.",,https://pubmed.ncbi.nlm.nih.gov/40039918/,English,Exclude,Not EEG-BCI focused,Effect Investigation of Mask on Facial Expression Recognition Using Cerebral Evoked Potentials.,,,,,0.9,0.6,
pubmed:40039910,pubmed:40039910,PubMed,pubmed:40039910,Schizophrenia detection using Entropy Difference-based Electroencephalogram Channel Selection Approach.,T Sunil Kumar;Shishir Maheshwari;Kandala N V P S Rajesh,2024,10.1109/embc53108.2024.10782840,"In this work, we propose a novel approach for identifying schizophrenia using an entropy difference (ED)- based electroencephalogram (EEG) channel selection algorithm. At the core of our approach is an ED-based channel selection algorithm, which selects the most significant EEG channels that contain discriminative information for schizophrenia detection using entropy difference values. This process not only selects the discriminative channels but also reduces the computational complexity of schizophrenia detection. After selecting the significant channels, we decompose the selected EEG signals into subbands using discrete wavelet transform (DWT). Furthermore, we extract symmetrically-weighted local binary patterns to capture subband variations. The features are then subjected to the support vector machine (SVM) to differentiate individuals with schizophrenia based on their EEG signals. The proposed approach achieves a classification accuracy of 100% when features from only one channel are used, outperforming the existing approaches in schizophrenia detection. Also, the ED-based channel selection approach outperforms the existing entropy-based channel selection approach in schizophrenia detection.",https://pubmed.ncbi.nlm.nih.gov/40039910/,https://pubmed.ncbi.nlm.nih.gov/40039910/,English,Include,,Schizophrenia detection using Entropy Difference-based Electroencephalogram Channel Selection Approach.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40039901,pubmed:40039901,PubMed,pubmed:40039901,A Multimodal Myanmar Emotion Dataset for Emotion Recognition.,Khin Pa Pa Aung;Hao-Long Yin;Tian-Fang Ma;Wei-Long Zheng;Bao-Liang Lu,2024,10.1109/embc53108.2024.10782660,"Effective emotion recognition is vital for human interaction and has an impact on several fields such as psychology, social sciences, human-computer interaction, and emotional artificial intelligence. This study centers on the innovative contribution of a novel Myanmar emotion dataset to enhance emotion recognition technology in diverse cultural contexts. Our unique dataset is derived from a carefully designed emotion elicitation paradigm, using 15 video clips per session for three emotions (positive, neutral, and negative), with five clips per emotion. We collected electroencephalogram (EEG) signals and eye-tracking data from 20 subjects, and each subject took three sessions spaced over several days. Notably, all video clips used in experiments have been well rated by Myanmar citizens through the Self-Assessment Manikin scale. We validated the proposed dataset's uniqueness using three baseline unimodal classification methods, alongside two traditional multimodal approaches and a deep multimodal approach (DCCA-AM) under subject-dependent and subject-independent settings. Unimodal classification achieved accuracies ranging from 62.57% to 77.05%, while multimodal fusion techniques achieved accuracies ranging from 75.43% to 87.91%. These results underscore the effectiveness of the models, and highlighting the value of our unique dataset for cross-cultural applications.",https://pubmed.ncbi.nlm.nih.gov/40039901/,https://pubmed.ncbi.nlm.nih.gov/40039901/,English,Include,,A Multimodal Myanmar Emotion Dataset for Emotion Recognition.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40039876,pubmed:40039876,PubMed,pubmed:40039876,The Impact of Cross-Validation Schemes for EEG-Based Auditory Attention Detection with Deep Neural Networks.,Gabriel Ivucic;Saurav Pahuja;Felix Putze;Siqi Cai;Haizhou Li;Tanja Schultz,2024,10.1109/embc53108.2024.10782636,"This study assesses the performance of different cross-validation splits for brain-signal-based Auditory Attention Decoding (AAD) using deep neural networks on three publicly available Electroencephalography datasets. We investigate the effect of trial-specific knowledge during training and assess adaptability to diverse scenarios with a trial-independent split. Introducing a causal time-series split, and simulating online decoding, our results demonstrate a consistent performance increase for auditory attention classification. These positive outcomes provide valuable insights for the development of future brain-signal-based AAD systems, emphasizing the potential for practical, person-dependent AAD applications. The results highlight the importance of diverse evaluation methodologies for enhancing generalizability in developing effective neurofeedback systems and assistive technologies for auditory processing disorders under more real-life conditions.",https://pubmed.ncbi.nlm.nih.gov/40039876/,https://pubmed.ncbi.nlm.nih.gov/40039876/,English,Include,,The Impact of Cross-Validation Schemes for EEG-Based Auditory Attention Detection with Deep Neural Networks.,Include,,cations. The results highlight the importance of diverse evaluation methodologies for enhancing generalizability in developing effective neurofeedback systems and assistive technologies for auditory processing disorders under more real-life conditions.,,0.95,0.25,cv_reported
pubmed:40039850,pubmed:40039850,PubMed,pubmed:40039850,Default Mode Network Detection using EEG in Real-time.,Navin Cooray;Chetan Gohil;Brendan Harris;Shaun Frost;Cameron Higgins,2024,10.1109/embc53108.2024.10782631,"Mental health disorders affect countless people worldwide and present a major challenge for mental health services, which are struggling with the demand on a global scale. Recent studies have indicated that activity of the brain's Default Mode Network (DMN) could prove insightful in monitoring patient recovery from depression and has been used as a therapeutic target itself. An opportunity exists to replicate recent therapeutic protocols targeting DMN connectivity via functional magnetic resonance imaging using the more economically scalable modality of electroencephalogram (EEG). The aim of this work was to validate the accuracy of real-time DMN detection methods applied to EEG data, using a publicly available dataset. Using a Hidden Markov Model to identify a 12-state resting-state network, this work achieved an overall DMN detection accuracy of 95%. Furthermore, the model was able to achieve a correlation of 0.617 between the baseline and calculated DMN fractional occupancy. These results demonstrate the ability of real-time analysis to effectively identify the DMN through EEG data providing an avenue for further applications that monitor and treat mental health disorders.",https://pubmed.ncbi.nlm.nih.gov/40039850/,https://pubmed.ncbi.nlm.nih.gov/40039850/,English,Include,,Default Mode Network Detection using EEG in Real-time.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40039816,pubmed:40039816,PubMed,pubmed:40039816,Explainable framework to detect Parkinson's disease related depression from EEG.,Luyao Jin;Running Zhao;Junyi Cao;Vincent C K Cheung;Wei-Hsin Liao,2024,10.1109/embc53108.2024.10782333,"Depression is a non-motor symptom inherent to Parkinson's disease (PD). As an early manifestation of PD, PD-related depression is hard to diagnose, thereby contributing to morbidity. Recent endeavors have employed deep learning networks to assist in the diagnosis of PD and depression, achieving commendable levels of accuracy. However, little attention has been directed toward PD-related depression, and the decision process of the network lacks transparency and explainability. What has been learned by the network and whether pathological mechanisms contribute to the classifier's result remain mysterious. In this study, we propose an explainable functional connectivity framework to recognize depression in PD. Specifically, the diagnosis feature extraction module learns high-dimensional information from functional connectivity features, followed by the diagnosis module making decisions. Furthermore, the explainable module provides interpretation and validation for the decisions on functional connectivity. Evaluation of the dataset demonstrates superb subject-wise predictive performance and provides visual evidence of the underlying pathology in EEG. The interpretation results bridge the gap between pathophysiological mechanisms and computer-aided diagnosis.",https://pubmed.ncbi.nlm.nih.gov/40039816/,https://pubmed.ncbi.nlm.nih.gov/40039816/,English,Include,,Explainable framework to detect Parkinson's disease related depression from EEG.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40039811,pubmed:40039811,PubMed,pubmed:40039811,Enhancing sleep stage classification with 2-class stratification and permutation-based channel selection.,Luis Alfredo Moctezuma;Yoko Suzuki;Junya Furuki;Marta Molinas;Takashi Abe,2024,10.1109/embc53108.2024.10781882,"We present a method that uses a convolutional neural network (CNN) called EEGNeX to extract and classify the characteristics of sleep-related waveforms from electroencephalographic (EEG) signals in different stages of sleep. Our results showed that the CNN model with 128 channels achieved high performance, distributing the sleep stages into 2-class models. We used a permutation-based channel selection process and using the top 3 channels, we achieved a performance greater than 80% in accuracy, Fscore, precision, recall, area under the receiver operating characteristic (AUROC) and kappa value, except when classifying N1 versus N2, where the average kappa value was 0.52. Performance is shown to decrease when using the 3 channels recommended by the American Academy of Sleep Medicine (AASM) or 3 random channels. Overall, the results showed that 2-class CNN models with 3 channels selected with a permutation-based approach achieve good performance in the classification of sleep stages from EEG signals, with a computational cost much lower than using 128 EEG channels.",https://pubmed.ncbi.nlm.nih.gov/40039811/,https://pubmed.ncbi.nlm.nih.gov/40039811/,English,Include,,Enhancing sleep stage classification with 2-class stratification and permutation-based channel selection.,Include,," high performance, distributing the sleep stages into 2-class models. We used a permutation-based channel selection process and using the top 3 channels, we achieved a performance greater than 80% in accuracy, Fscore, precision, recall, area under the receiver operating characteristic (AUROC) and kappa value, except when classifying N1 versus N2, where the average kappa value was 0.52. Performance",,0.95,0.6,
pubmed:40039787,pubmed:40039787,PubMed,pubmed:40039787,Toward the TCN-based Real-Time BCI System for Target Detection.,Eunji Won;Seongyeon Lim;Yeomin Kim;Suh-Yeon Dong,2024,10.1109/embc53108.2024.10782928,"This study focuses on developing a real-time Brain-Computer Interface (BCI) system, specifically designed for military applications, to enhance target detection in rapid serial visual presentation (RSVP) tasks. The proposed BCI system utilizes electroencephalogram (EEG) signals based on dry electrodes, known for their exceptional temporal resolution, to identify swiftly specific target symbols within sequences of visual stimuli. Leveraging deep learning techniques, particularly Temporal Convolutional Networks (TCN), this study demonstrates the accuracy and efficiency improvement in target detection for RSVP tasks. According to our findings, the adaptability and efficacy of TCN in handling temporal dynamics of EEG signals exhibit outstanding performance in target detection, thus offering the potential for accurate and efficient real-time BCI system.",https://pubmed.ncbi.nlm.nih.gov/40039787/,https://pubmed.ncbi.nlm.nih.gov/40039787/,English,Include,,Toward the TCN-based Real-Time BCI System for Target Detection.,Include,,"n, to identify swiftly specific target symbols within sequences of visual stimuli. Leveraging deep learning techniques, particularly Temporal Convolutional Networks (TCN), this study demonstrates the accuracy and efficiency improvement in target detection for RSVP tasks. According to our findings, the adaptability and efficacy of TCN in handling temporal dynamics of EEG signals exhibit outstanding",,0.95,0.6,
pubmed:40039768,pubmed:40039768,PubMed,pubmed:40039768,Prediction errors from distinct perspectives induce separable EEG features for brain-computer interface.,Feng He;Sheng Zhang;Mingming Yang;Jiayuan Meng;Minpeng Xu;Lin Meng;Dong Ming,2024,10.1109/embc53108.2024.10781933,"The ability to efficiently detect error is fundamental for human adaptive behaviors, and plays an increasingly crucial role in developing more intelligent brain-computer interface (BCI). Error-related potential (ErrP), which can reflect prediction error, has been widely used by the BCI to read whether outcomes accord with users' expectation or not. However, current ErrP-BCI cannot distinguish the prediction error is induced by user's own (first-person perspective, 1PP) or other's (third-person perspective, 3PP) wrong action, hindering it from being applied in social interactions. This study used virtual reality (VR) to make subjects aware of prediction errors from the first- or third-person perspective, and recorded electroencephalogram (EEG) data of 22 healthy subjects. Event-related potential (ERP), event-related spectral perturbation (ERSP), inter-trial coherence (ITC) and shrinkage discriminant canonical pattern matching (SKDCPM) algorithm were used to investigate EEG features and the separability of prediction errors induced by distinct perspectives. Consequently, ErrP induced by the 1PP emerged significantly earlier than that of 3PP, and caused greater ERSP and ITC in the prefrontal region in the theta and alpha bands. Decoding result achieved 76.4%± 9.13% accuracy for the two types of errors (1PP-incorrect vs 3PP-incorrect). This study fills in the fine-grained classification of different error types and provides a finer metric for the systematic error correction efficiency of two-person collaborative brain control, which is the basis for future human-machine hybrid intelligence.",https://pubmed.ncbi.nlm.nih.gov/40039768/,https://pubmed.ncbi.nlm.nih.gov/40039768/,English,Include,,Prediction errors from distinct perspectives induce separable EEG features for brain-computer interface.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40039763,pubmed:40039763,PubMed,pubmed:40039763,Seizure onset zone classification of intracranial EEG signals from epilepsy patients.,M Mohammadpour;C Kapeller;M Korostenskaja;L Schreiner;J Scharinger;C Guger,2024,10.1109/embc53108.2024.10781769,"The intracranial electroencephalographic (iEEG) signals contain information about seizures and their onset location. Several seizure onset patterns are used in the literature to detect onset zones, which have clinical significance in neurosurgery. This study introduces a supervised machine learning method to detect seizure onset patterns from iEEG signals. The iEEG signals were marked three seconds long at the time of each seizure onset pattern. Thirty-five features representing the time, frequency, and time-frequency domain characteristics were extracted from 100 seizures originating from 29 patients, collectively containing 297 seizure channels. A Linear Discriminant analysis (LDA) is applied to the features to classify seizure onset patterns. The classification output is the class of each seizure signal, which is either non-SOZ or a class of six onset patterns. The classifier performance is assessed through accuracy, precision, recall, and F-score metrics. In summary, employing machine learning to classify seizure onset patterns can offer an objective approach, and the method could help neurosurgeons objectively choose seizure onset locations based on various ambiguous patterns.",https://pubmed.ncbi.nlm.nih.gov/40039763/,https://pubmed.ncbi.nlm.nih.gov/40039763/,English,Include,,Seizure onset zone classification of intracranial EEG signals from epilepsy patients.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40039757,pubmed:40039757,PubMed,pubmed:40039757,Detecting Post-Stroke Aphasia Via Brain Responses to Speech in a Deep Learning Framework.,Pieter De Clercq;Corentin Puffay;Jill Kries;Hugo Van Hamme;Maaike Vandermosten;Tom Francart;Jonas Vanthornhout,2024,10.1109/embc53108.2024.10781830,"Aphasia, a language disorder primarily caused by a stroke, is traditionally diagnosed using behavioral language tests. However, these tests are time-consuming, require manual interpretation by trained clinicians, suffer from low ecological validity, and diagnosis can be biased by comorbid motor and cognitive problems present in aphasia. In this study, we introduce an automated screening tool for speech processing impairments in aphasia that relies on time-locked brain responses to speech, known as neural tracking, within a deep learning framework. We modeled electroencephalography (EEG) responses to acoustic, segmentation, and linguistic speech representations of a story using convolutional neural networks trained on a large sample of healthy participants, serving as a model for intact neural tracking of speech. Subsequently, we evaluated our models on an independent sample comprising 26 individuals with aphasia (IWA) and 22 healthy controls. Our results reveal decreased tracking of all speech representations in IWA. Utilizing a support vector machine classifier with neural tracking measures as input, we demonstrate high accuracy in aphasia detection at the individual level (85.42%) in a time-efficient manner (requiring 9 minutes of EEG data). Given its high robustness, time efficiency, and generalizability to unseen data, our approach holds significant promise for clinical applications.",https://pubmed.ncbi.nlm.nih.gov/40039757/,https://pubmed.ncbi.nlm.nih.gov/40039757/,English,Include,,Detecting Post-Stroke Aphasia Via Brain Responses to Speech in a Deep Learning Framework.,Include,,"healthy controls. Our results reveal decreased tracking of all speech representations in IWA. Utilizing a support vector machine classifier with neural tracking measures as input, we demonstrate high accuracy in aphasia detection at the individual level (85.42%) in a time-efficient manner (requiring 9 minutes of EEG data). Given its high robustness, time efficiency, and generalizability to unseen ",,0.95,0.8,small_sample_mentioned
pubmed:40039728,pubmed:40039728,PubMed,pubmed:40039728,Exploring the Use of Spatial Information in Emotion Classification Using Functional Connectivity and Channel Distribution.,Yuzeng Xu;Sho Otsuka;Seiji Nakagawa,2024,10.1109/embc53108.2024.10781684,"Advancements in neuroscience, especially in estimation technique of functional connectivity and brain networks, have been instrumental in emotion classification. However, conventional methods that utilize feature vectors or connectivity matrices do not entirely harness the spatial information of brain activity. We propose the Sliding Functional Connectivity Convolution (SFCC), which constructs brain networks by leveraging the spatial information of channel distribution of electroencephalogram (EEG). Similar to image convolution, SFCC begins by defining a matrix to be processed and an operation kernel, both derived from a channel projection. We then calculate the functional connectivity between the matrix elements and elements of the kernel while sliding the kernel across the matrix. The resultant brain networks provide additional spatial information for a classifier compared to conventional methods. Comparison between brain networks constructed using conventional feature vectors and connectivity matrices with those created by the proposed method showed a significant enhancement in classification performance.",https://pubmed.ncbi.nlm.nih.gov/40039728/,https://pubmed.ncbi.nlm.nih.gov/40039728/,English,Include,,Exploring the Use of Spatial Information in Emotion Classification Using Functional Connectivity and Channel Distribution.,Include,,"CC), which constructs brain networks by leveraging the spatial information of channel distribution of electroencephalogram (EEG). Similar to image convolution, SFCC begins by defining a matrix to be processed and an operation kernel, both derived from a channel projection. We then calculate the functional connectivity between the matrix elements and elements of the kernel while sliding the kernel ",,0.95,0.6,
pubmed:40039722,pubmed:40039722,PubMed,pubmed:40039722,Machine Learning Approach for Music Familiarity Classification with Single-Channel EEG.,Nahyeon Kim;Debanjan Borthakur;Manob Jyoti Saikia,2024,10.1109/embc53108.2024.10782402,"Recognition of familiar music on brainwaves through machine learning (ML) can be instrumental in innovative therapeutic devices that improve memory and communication in dementia patients. In this study, a variety of machine learning algorithms were applied, including Random Forest (RF), Linear Discriminant Analysis (LDA), Support Vector Machine (SVM), K-Nearest Neighbor (KNN), and Deep Learning (DL), to EEG brainwaves from a mobile headset's Fp2 channel. EEG data from 20 participants assessing familiarity with 20 Christmas carols were used. For ML methods (excluding DL), particular frequency bands were selected (theta, alpha, low beta, and high beta), and six statistical features were used to train classifiers. In contrast, DL employed spectrograms and 2D convolutional neural networks. 67% accuracy was achieved with SVM using only the kurtosis features. Due to the variability of the participants, individualized training and testing produced an average accuracy of 72.4%. In dementia care, these results suggest promising therapeutic avenues.",https://pubmed.ncbi.nlm.nih.gov/40039722/,https://pubmed.ncbi.nlm.nih.gov/40039722/,English,Include,,Machine Learning Approach for Music Familiarity Classification with Single-Channel EEG.,Include,,"nds were selected (theta, alpha, low beta, and high beta), and six statistical features were used to train classifiers. In contrast, DL employed spectrograms and 2D convolutional neural networks. 67% accuracy was achieved with SVM using only the kurtosis features. Due to the variability of the participants, individualized training and testing produced an average accuracy of 72.4%. In dementia care",,0.95,0.8,small_sample_mentioned
pubmed:40039706,pubmed:40039706,PubMed,pubmed:40039706,ADHD Diagnosis through Resting-State EEG Frequency Analysis with Random Forest.,Guilherme R Pedrollo;Leia B Bagesteiro;Alexandre R Franco;Alexandre Balbinot,2024,10.1109/embc53108.2024.10782906,"Attention-deficit hyperactivity disorder (ADHD) affects about 5% of the population. In order to minimize ADHD effects, it is important to identify its biomarkers. We analyzed electroencephalographic (EEG) signals using a random forest (RF) classifier optimized with a genetic algorithm (GA) to find differences between control and ADHD groups. Data from 856 participants were analyzed with a preprocessing procedure that included artifact subspace reconstruction (ASR) and independent component analysis (ICA). After preprocessing and GA optimization, the RF classifier achieved 88.6% total average accuracy considering the theta frequency band. This outcome suggests that this approach has great potential as a biomarker analyzer for ADHD diagnosis.",https://pubmed.ncbi.nlm.nih.gov/40039706/,https://pubmed.ncbi.nlm.nih.gov/40039706/,English,Include,,ADHD Diagnosis through Resting-State EEG Frequency Analysis with Random Forest.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:40039682,pubmed:40039682,PubMed,pubmed:40039682,LightIED: Explainable AI with Light CNN for Interictal Epileptiform Discharge Detection.,Ibuki Inoue;Xuyang Zhao;Shuji Komeiji;Noboru Yoshida;Hidenori Sugano;Madoka Nakajima;Toshihisa Tanaka,2024,10.1109/embc53108.2024.10782804,"Interictal epileptic discharge (IED) detection from electroencephalography (EEG) is an important but difficult step in the epilepsy diagnosis. To reduce the workload of doctors, some diagnostic auxiliary methods based on deep learning have been proposed. However, deep learning models often need more explainability, and even if they are explainable, their structure is usually complex. This paper presents a lightweight and explainable machine learning-based model named LightIED for detecting IEDs in EEG. The EEG data is first plotted as the image in the experiment and fed into the model for the IED detection task. Then, the Grad-CAM is used to analyze the output results and visualize the basis of inference. The detection accuracy of IEDs with the LightIED is almost equivalent to the current state-of-the-art (SoTA) model, Satelight, and higher than other Vision Transformer-based models. Moreover, the number of parameters is less than one-third compared to Satelight, the existing lightweight model. In addition, the visualizing results by Grad-CAM highlight the IEDs. Our results demonstrate that the proposed LightIED effectively detects IEDs with reasonable visualization.",https://pubmed.ncbi.nlm.nih.gov/40039682/,https://pubmed.ncbi.nlm.nih.gov/40039682/,English,Include,,LightIED: Explainable AI with Light CNN for Interictal Epileptiform Discharge Detection.,Include,," plotted as the image in the experiment and fed into the model for the IED detection task. Then, the Grad-CAM is used to analyze the output results and visualize the basis of inference. The detection accuracy of IEDs with the LightIED is almost equivalent to the current state-of-the-art (SoTA) model, Satelight, and higher than other Vision Transformer-based models. Moreover, the number of paramete",,0.95,0.6,
pubmed:40039672,pubmed:40039672,PubMed,pubmed:40039672,Benchmarking motor imagery algorithms for pediatric users of brain-computer interfaces.,Brian Irvine;Hatem Abou-Zeid;Adam Kirton;Eli Kinney-Lang,2024,10.1109/embc53108.2024.10782164,"Brain-computer interfaces (BCIs) can enable opportunities for self-expression and life participation for children with severe neurological disabilities. Unfortunately, the development and evaluation of state-of-the-art algorithms has largely neglected pediatric users. This work tests 12 state-of-the-art algorithms for motor imagery classification on three datasets of typically developing pediatric users (n=94 ages 5-17). When all datasets were combined, there were no significant differences between most non-deep learning algorithms, with all having a mean AUC score of 0.64 or 0.65. All the non-deep learning algorithms significantly outperformed the deep learning algorithms, which can be partially attributed to a lack of hyperparameter tuning. The best of the deep learning algorithms was ShallowConvNet, with a mean AUC score of 0.57. Of the algorithms tested, only the filter bank common spatial pattern (FBCSP) and ShallowConvNet exhibited significant age effects. This general lack of age effects, combined with examples of children as young as 6 having AUC scores as high as 0.8, provides evidence that young children are capable of producing measurable motor imagery activations. The age effects that were present for some algorithms suggest that the changing EEG patterns associated with development could have a measurable impact on classification algorithm outcomes, and such algorithms should be evaluated to ensure that they are not performing disproportionately poorly for younger children. This work serves as a first step towards ensuring that the state-of-the-art improvements in BCI classification can be evaluated, and where necessary, adapted to meet the needs of pediatric users.",https://pubmed.ncbi.nlm.nih.gov/40039672/,https://pubmed.ncbi.nlm.nih.gov/40039672/,English,Include,,Benchmarking motor imagery algorithms for pediatric users of brain-computer interfaces.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:40039658,pubmed:40039658,PubMed,pubmed:40039658,Comparison of Quantitative EEG Features for the Prediction of Neurological Recovery after Cardiac Arrest in Rodents.,Mingfeng Cao;Yinong Chen;Yunfan Zou;Yuxin Du;Nitish Thakor,2024,10.1109/embc53108.2024.10782302,"The clinical practices of electrophysiological monitoring for the prognosis of neurological recovery in patients were limited by the lack of objective and quantitative assessment. Quantitative EEG (QEEG), a method that utilizes advanced mathematic and signal processing techniques to analyze EEG signals, shows promise in increasing the accuracy of predictions. In this study, we applied wavelet decomposition to EEG signals collected in rodents that suffered asphyxial cardiac arrest and found significant differences in relative band powers and spectral entropies (p<0.05) between rats with favorable and unfavorable recovered outcomes. We trained an SVM classifier with the highest accuracy of 0.864. We also compared the accuracy, sensitivity, and specificity of different predictors.",https://pubmed.ncbi.nlm.nih.gov/40039658/,https://pubmed.ncbi.nlm.nih.gov/40039658/,English,Include,,Comparison of Quantitative EEG Features for the Prediction of Neurological Recovery after Cardiac Arrest in Rodents.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40039656,pubmed:40039656,PubMed,pubmed:40039656,Transformer-Based Wavelet-Scalogram Deep Learning for Improved Seizure Pattern Recognition in Post-Hypoxic-Ischemic Fetal Sheep EEG.,Ali Roozbehi;Hamid Abbasi;Simerdeep Kaur Dhillon;Joanne Davidson;Alistair Jan Gunn;Laura Bennet,2024,10.1109/embc53108.2024.10782632,"Hypoxic-ischemic (HI) events in newborns can trigger seizures, which are highly associated with later neurodevelopmental impairment. The precise detection of these seizures is a complex task requiring considerable very specialized expertise, underscoring the necessity for automated methods to support diagnosis and therapeutic interventions. We have previously shown the effectiveness of deep-learning algorithms, involving a 17-layer deep convolutional neural network (CNN), to identify and quantify post-HI high-amplitude seizures (HAS) in preterm fetal sheep models. This method, which incorporated 2D wavelet scalogram (WS) images of EEG patterns, achieved a cross-validated overall accuracy of 97.19% (AUC=0.96). In the current study, we now assess the utility of Transformer models for seizure detection in the EEG of pre- and near-term fetal sheep during the first 48 hours of recovery after HI. We trained a series of Transformer models on a smaller subset of the original dataset, comprising 800 WS of EEG seizure and non-seizure patterns. Out of all classifiers, the Visual Transformer (ViT) exceeded the performance of the previous deep CNNs, achieving an overall accuracy of 99.5% with an AUC of 0.995.Clinical relevance-This study showcases the superior performance, efficiency, and robustness of Transformer models for identifying HI-induced EEG seizures, with high potential to be clinical decision support tools to identify neonatal seizures at the cotside.",https://pubmed.ncbi.nlm.nih.gov/40039656/,https://pubmed.ncbi.nlm.nih.gov/40039656/,English,Include,,Transformer-Based Wavelet-Scalogram Deep Learning for Improved Seizure Pattern Recognition in Post-Hypoxic-Ischemic Fetal Sheep EEG.,Include,," and quantify post-HI high-amplitude seizures (HAS) in preterm fetal sheep models. This method, which incorporated 2D wavelet scalogram (WS) images of EEG patterns, achieved a cross-validated overall accuracy of 97.19% (AUC=0.96). In the current study, we now assess the utility of Transformer models for seizure detection in the EEG of pre- and near-term fetal sheep during the first 48 hours of rec",,0.95,0.6,
pubmed:40039653,pubmed:40039653,PubMed,pubmed:40039653,Automatic Monitoring of High-Frequency Autoimmune Disorder Related Seizures with Wearable Devices.,Jie Cui;Andrea Duque Lopez;Gabriella Brinkmann;Boney Joseph;Louis Faust;Julianna Ethridge;Gregory Worrell;Divyanshu Dubey;Benjamin Brinkmann,2024,10.1109/embc53108.2024.10782939,"The detection of Faciobrachial Dystonic Seizures (FBDS) in patients with LGI1-IgG associated autoimmune encephalitis is challenging due to their high frequency and the absence of a clear signal on EEG. This study explores the use of wearable devices as a noninvasive and convenient method for recording these events, thereby providing an objective seizure diary. We investigated the feasibility of using a wrist-worn device to reliably identify and distinguish FBDS from normal arousals. Seven patients with LGI1-IgG autoimmunity (including two who had recordings before and after immunotherapy) and four control subjects were monitored with Empatica wristbands in both hospital and ambulatory environments. We developed a two-stage semi-supervised learning approach, utilizing a Support Vector Machine (SVM) classifier to detect abnormal events based on a small set of labeled events identified by a proprietary algorithm. Significant differences in wearable signal characteristics were found before and after treatment. Putative FBDS events in pre-treatment signals were significantly more frequent than nocturnal arousals in the control group (P1-a: 13.63 event/hour, P2-a: 24.88, vs Control: 3.51, p < 0.001), lasted longer, and were associated with increases in both tonic and phasic Electrodermal Activity (EDA) during events. These findings affirm the potential of wearable technology in providing an automatic and objective measure of FBDS, particularly during sleep, with minimal burden on patients for maintaining a seizure diary.",https://pubmed.ncbi.nlm.nih.gov/40039653/,https://pubmed.ncbi.nlm.nih.gov/40039653/,English,Include,,Automatic Monitoring of High-Frequency Autoimmune Disorder Related Seizures with Wearable Devices.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40039636,pubmed:40039636,PubMed,pubmed:40039636,Improving EEG-Based Cross-Subject Mental Workload Classification Performance with Euclidean-Aligned Periodic and Aperiodic Features.,Tao Wang;Yufeng Ke;Feng He;Dong Ming,2024,10.1109/embc53108.2024.10782484,"Enhancing the cross-subject classification performance of EEG-based mental workload (MWL) monitoring models poses a significant challenge. Traditional methods require gathering calibration data for new users to prevent performance decline. However, the calibration data collection process is time-consuming and labor-intensive. In this study, we proposed a novel cross-subject MWL classification model that does not require calibration data. Specifically, we used periodic and aperiodic components obtained through EEG spectrum decomposition as features, replacing the commonly used power spectral density (PSD) features. These features are then aligned across subjects using a modified Euclidean alignment method. Our results show that the aligned periodic and aperiodic combined features achieve the highest classification accuracy (0.791±0.077), significantly surpassing raw PSD features without alignment (0.731±0.086, p<0.05). Moreover, we found a significantly negative correlation between inter-subject distances calculated from periodic features in resting-state data and inter-subject pairwise classification accuracy (r=-0.472, p<0.001). This finding suggests a promising approach to leverage resting-state data for selecting source subjects that closely match the target subjects.",https://pubmed.ncbi.nlm.nih.gov/40039636/,https://pubmed.ncbi.nlm.nih.gov/40039636/,English,Include,,Improving EEG-Based Cross-Subject Mental Workload Classification Performance with Euclidean-Aligned Periodic and Aperiodic Features.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40039626,pubmed:40039626,PubMed,pubmed:40039626,Bi-hemisphere Interaction Convolutional Neural Network for Motor Imagery Classification.,Xiaohao Lin;Emadeldeen Eldele;Zhenghua Chen;Min Wu;Han Wei Ng;Cuntai Guan,2024,10.1109/embc53108.2024.10782755,"Decoding EEG-based, Motor Imagery Brain-Computer Interfaces (MI-BCI) in a subject-independent manner is very challenging due to high dimensionality of the EEG signal, and high inter-subject variability. In recent years, Convolutional neural networks (CNNs) have significantly enhanced decoding accuracy. Nevertheless, the majority of these CNN designs did not explicitly incorporate the inter-hemisphere functional connections, omitting crucial spatial information. Notably, in binary MI decoding of the left-hand versus right-hand, the Event-Related Desynchronization is observed in the contralateral hemisphere. Building upon this concept and various Neuroscience research, we have designed a CNN architecture that forges a functional connection between the two hemispheres. Specifically, we applied the Channel Average Referencing to one hemisphere and compared the output with all channels of the opposite hemisphere. Then, we utilized the cosine similarity to identify the most correlated channels and combined with them the original hemisphere for spatial filtering to learn the inter-hemispheric connections. This innovative technique aligns more closely with the actual brain functionality. Our method has demonstrated superior results on the Cho2017 and OpenBMI datasets, underscoring its effectiveness.",https://pubmed.ncbi.nlm.nih.gov/40039626/,https://pubmed.ncbi.nlm.nih.gov/40039626/,English,Include,,Bi-hemisphere Interaction Convolutional Neural Network for Motor Imagery Classification.,Include,,"manner is very challenging due to high dimensionality of the EEG signal, and high inter-subject variability. In recent years, Convolutional neural networks (CNNs) have significantly enhanced decoding accuracy. Nevertheless, the majority of these CNN designs did not explicitly incorporate the inter-hemisphere functional connections, omitting crucial spatial information. Notably, in binary MI decodi",,0.95,0.6,
pubmed:40039616,pubmed:40039616,PubMed,pubmed:40039616,Exploring Novel Practical Approach to Post-Stroke Upper-Limb Neurorehabilitation Based on Complex Motor Imagery Tasks.,Cristian D Guerrero-Mendez;H Rivera-Flor;Ana C Villa-Parra;Teodiano F Bastos-Filho,2024,10.1109/embc53108.2024.10782286,"Motor imagery (MI) is one of the main strategies for upper-limb movement rehabilitation in post-stroke individuals. Promising results of MI applied for rehabilitation have been reported in the literature. However, there is currently a need related to the recovery of movements aimed to Activities of Daily Living (ADLs) for individuals with severe motor impairments. Therefore, this study presents the evaluation of a novel MI protocol for post-stroke upper-limb neurorehabilitation using complex tasks related to the manipulation of a drinking cup. The protocol is based on the Action Observation (AO), which was used under a first-person 2D virtual reality. Subjects had to simultaneously imagine the movements presented in AO for the manipulation of a cup varying in four positions. EEG signals were recorded from 16 channels located mainly in the motor cortex of the brain. Two computational strategies based on Riemannian Geometry (RG) with and without Feature Selection (FS) using Pair-Wise Feature Proximity (PWFP) were implemented for the binary identification of each complex MI-Task vs. MI-Rest. This approach was evaluated on 30 healthy individuals and 2 post-stroke individuals. Using Linear Discriminant Analysis (LDA) as a classifier, the results report a maximum accuracy of 0.78 for both healthy and post-stroke individuals, and a minimum FPR of 0.21 and 0.13 for healthy and post-stroke individuals, respectively. This highlights the potential use of this type of paradigms for the implementation of more robust BCI systems that allow the rehabilitation of movements close to ADLs. Therefore, complex MI tasks may be a suitable variant for rehabilitation in post-stroke individuals.",https://pubmed.ncbi.nlm.nih.gov/40039616/,https://pubmed.ncbi.nlm.nih.gov/40039616/,English,Include,,Exploring Novel Practical Approach to Post-Stroke Upper-Limb Neurorehabilitation Based on Complex Motor Imagery Tasks.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40039604,pubmed:40039604,PubMed,pubmed:40039604,An Explainable Transfer Learning Method for EEG-based Seizure Type Classification.,Lan Wei;Catherine Mooney,2024,10.1109/embc53108.2024.10782701,"Epilepsy, traditionally conceptualized as a neurological disorder characterized by a persistent inclination toward epileptic seizures, is commonly diagnosed and monitored through EEGs. However, manual analysis of EEG data can be exceedingly time-consuming. The integration of automated seizure classification methods represents a valuable resource for clinicians engaged in epilepsy analysis. In this study, we introduce an explainable transfer learning method designed to classify seizure types within EEG recordings. Our method relies on the utilization of spectrograms derived from EEGs that capture seizure events, enabling the discrimination between normal EEG patterns and focal or generalized seizures. To achieve this, we employed four pre-trained transfer learning models, namely Inception, ResNet, DenseNet, and VGG16, using spectrogram data from 19 EEG channels as inputs. The model demonstrated high accuracy when assessed on an independent test dataset. To enhance clinician trust, we leveraged the LIME technique to elucidate model predictions, creating heatmap visualizations that emphasize explanation weights. The incorporation of a colorbar further facilitates clinician comprehension of predictions and aids in the identification of EEG seizure events. This method holds great promise for the effective classification of epilepsy types, providing support to neurologists in their comprehensive analysis of epilepsy cases.",https://pubmed.ncbi.nlm.nih.gov/40039604/,https://pubmed.ncbi.nlm.nih.gov/40039604/,English,Include,,An Explainable Transfer Learning Method for EEG-based Seizure Type Classification.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.35,external_test_reported
pubmed:40039594,pubmed:40039594,PubMed,pubmed:40039594,Event-Related Potentials and Event-Related Spectral Perturbation for Classification of Apolipoprotein E ϵ4 Allele Carriers in Alzheimer Disease Patients and Healthy Controls.,Kaue O Frassao;Sandro M S Filho;Renata Valle Pedroso;Carla Manuela Crispim Nascimento;Henrique Pott;Marcia Regina Cominetti;Francisco J Fraga,2024,10.1109/embc53108.2024.10782085,"In this paper we used Event-Related Potentials and Event-Related Spectral Perturbation as features for classification of apolipoprotein E ϵ4 allele (APOE ε4) carriers in Alzheimer disease (AD) patients and healthy controls. The study participants were 37 healthy older adults and 47 AD patients, which performed an auditory oddball task using an EEG equipment with 21 channels. A leave-one-subject-out cross-validation approach was used to perform feature selection and classification with Support Vector Machine classifiers. After feature extraction and selection, we achieved a classification accuracy of 86,90% in the APOE ε4 carriers versus non-carriers comparison (regardless of diagnosis) and 85,71% in the AD patients versus healthy controls comparison (regardless of APOE ε4 status). When combining the results of all participants we reached a global accuracy of 73,81% in the four-class classification (AD patients carriers and non-carriers, healthy elderly carriers and non-carriers). We hope our work could help clinicians to make a more accurate and earlier AD diagnosis, considering the presence of the APOE ε4 allele.",https://pubmed.ncbi.nlm.nih.gov/40039594/,https://pubmed.ncbi.nlm.nih.gov/40039594/,English,Include,,Event-Related Potentials and Event-Related Spectral Perturbation for Classification of Apolipoprotein E ϵ4 Allele Carriers in Alzheimer Disease Patients and Healthy Controls.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.45,cv_reported;small_sample_mentioned
pubmed:40039576,pubmed:40039576,PubMed,pubmed:40039576,Evaluation of EEG and MEG responses during Fine Motor Imagery from the same limb.,Rui Jiang;Shuang Qiu;Yu Wang;Chuncheng Zhang;Huiguang He,2024,10.1109/embc53108.2024.10782038,"Motor imagery (MI) is an important brain-computer interface (BCI) paradigm. BCI systems based on fine MI can provide an intuitive control pathway of the outer device. Electroencephalography (EEG) is a widely used modality for MI due to its high temporal resolution and portability. Magnetoencephalography (MEG) has high spatial and temporal resolution, which has received more and more attention. This study designed four kinds of MI tasks of different joints from the same upper limb, including finger, wrist, elbow, and shoulder joints, and additionally added a resting task. The EEG and MEG signals of eight subjects were acquired synchronously. Analysis was conducted on the EEG and MEG data to find the time, time-frequency, and spatial difference between MI tasks of different joints from the same limb. The induced event-related desynchronization (ERD) in EEG signals at the electrode position of the left motor area are more broad and stronger in the alpha frequency band than that in MEG signals during fine MI tasks. From the topographical distribution, different MI tasks affects the area and intensity of the activated area, and topographical distribution of MEG signals in different MI tasks are more discriminative than that of EEG signals. Moreover, the analysis of movement-related cortical potentials (MRCP) showed that significant negative potentials were detected near the onset of the motor imagery events and there is a significant difference in temporal dimension between magnetoencephalogram and electroencephalogram signals. The work implies that there exist the separable differences between EEG and MEG during fine MI tasks, which can be utilized to build a multimodal classification method for fine MI-BCI systems.",https://pubmed.ncbi.nlm.nih.gov/40039576/,https://pubmed.ncbi.nlm.nih.gov/40039576/,English,Include,,Evaluation of EEG and MEG responses during Fine Motor Imagery from the same limb.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40039573,pubmed:40039573,PubMed,pubmed:40039573,Role of Scalp EEG Brain Connectivity in Motor Imagery Decoding for BCI Applications.,Fatemeh Delavari;Sabato Santaniello,2024,10.1109/embc53108.2024.10781532,"Brain Connectivity (BC) features of multichannel EEG have been proposed for Motor Imagery (MI) decoding in Brain-Computer Interface applications, but the advantages of BC features vs. single-channel features are unclear. Here, we consider three BC features, i.e., Phase Locking Value (PLV), Granger Causality, and weighted Phase Lag Index, and investigate the relationship between the most central nodes in BC-based networks and the most influential EEG channels in single-channel classification based on common spatial pattern filtering. Then, we compare the accuracy of MI decoders that use BC features in source vs. sensor space. Applied to the BCI Competition VI Dataset 2a (left- vs. right-hand MI decoding), our study found that PLV in sensor space achieves the highest classification accuracy among BC features and has similar performance compared to single-channel features, while the transition from sensor to source space reduces the average accuracy of BC features. Across all BC measures, the network topology is similar in left- vs. right-hand MI tasks, and the most central nodes in BC-based networks partially overlap with the most influential channels in single-channel classification.",https://pubmed.ncbi.nlm.nih.gov/40039573/,https://pubmed.ncbi.nlm.nih.gov/40039573/,English,Include,,Role of Scalp EEG Brain Connectivity in Motor Imagery Decoding for BCI Applications.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40039571,pubmed:40039571,PubMed,pubmed:40039571,Epileptic State Prediction using Phase Space Domain and Machine Learning Algorithms.,Boluwatife Faremi;Yedukondala Rao Veeranki;Hugo F Posada-Quintero,2024,10.1109/embc53108.2024.10781513,"Epilepsy is a disease of the brain that causes unprovoked or reflex seizures that affects millions of individuals worldwide. Traditionally, identifying epileptic states involves assessing neuroimaging scans or brain electrical signals recorded by EEG devices. However, due to the complex nature of these signals, there are growing demands for developing predictive systems that can improve the detection of this brain condition through unseen discriminating features. This study investigates predicting and detecting epileptic states by transforming 2-dimensional EEG time series data to the Phase space domain. The angular distance and probability density function between phase vectors were computed in the new domain to extract features. Renyi and Tsallis complex features were mainly extracted to train probabilistic, discriminatory, tree, and kernel-based models. The performance of the learning algorithms was evaluated using leaveone-subject-out cross-validation. Results revealed that the probabilistic models combined with complex features from the phase domain had a 91.5% accuracy compared to other algorithms. This result indicates the efficacy of the phase space domain for detecting and predicting epilepsy states.",https://pubmed.ncbi.nlm.nih.gov/40039571/,https://pubmed.ncbi.nlm.nih.gov/40039571/,English,Include,,Epileptic State Prediction using Phase Space Domain and Machine Learning Algorithms.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.25,cv_reported
pubmed:40039565,pubmed:40039565,PubMed,pubmed:40039565,Toward EEG-Based Objective Assessment of Emotion Intensity.,Pin-Han Ho;Yong-Sheng Chen;Chun-Shu Wei,2024,10.1109/embc53108.2024.10781662,"Understanding the temporal dynamics of emotion poses a significant challenge due to the lack of methods to measure them objectively. In this study, we propose a novel approach to tracking intensity (EI) based on electroencephalogram (EEG) during continuous exposure to affective stimulation. We design selective sampling strategies to validate the association between the prediction outcome of an EEG-based emotion recognition model and the prominence of emotion-related EEG patterns, evidenced by the improvement in the classification task of discriminating arousal and valence by 2.01% and 1.71%, respectively. This study constitutes a breakthrough in the objective evaluation of the temporal dynamics of emotions, proposing a promising avenue to refine EEG-based emotion recognition models through intensity-selective sampling. Furthermore, our findings can contribute to future affective studies by providing a reliable and objective measurement method to profile emotion dynamics.",https://pubmed.ncbi.nlm.nih.gov/40039565/,https://pubmed.ncbi.nlm.nih.gov/40039565/,English,Include,,Toward EEG-Based Objective Assessment of Emotion Intensity.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40039552,pubmed:40039552,PubMed,pubmed:40039552,Network analysis of meditative states in highly skilled meditators using EEG and horizontal visibility graphs.,Tamas Madl,2024,10.1109/embc53108.2024.10782024,"The benefits of meditation are increasingly recognized, and some forms are now used for clinical intervention. However, the electrophysiological correlates of meditative states are not yet well understood, and the limited predictive accuracy of known markers of meditation suggest that not all information relevant to meditation has been captured by previous work.Here, we convert electroencephalography (EEG) time series into scale-free networks using horizontal visibility graphs (HVGs), which are well-suited to distinguishing deterministic dynamical systems from stochastic systems, allowing them to model novel aspects of cortical oscillatory activity. Based on HVGs, we introduce and evaluate a general class of predictors, which can be used to augment existing features in contemplative neuroscience, and exhibit high predictive power for several types of meditation.We show the statistical significance of these network predictors - and their increased performance compared to popular spectral and non-linear features such as complexity or entropy - on data from highly skilled meditators, in a continuous setting applicable to real-time analysis and applications such as neurofeedback.",https://pubmed.ncbi.nlm.nih.gov/40039552/,https://pubmed.ncbi.nlm.nih.gov/40039552/,English,Include,,Network analysis of meditative states in highly skilled meditators using EEG and horizontal visibility graphs.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40039543,pubmed:40039543,PubMed,pubmed:40039543,Human Emotions Analysis and Recognition Using EEG Signals in Response to 360° Videos.,Haseeb Ur Rahman Abbasi;Zeeshan Rashid;Muhammad Majid;Syed Muhammad Anwar,2024,10.1109/embc53108.2024.10782298,"Emotion recognition (ER) technology is integral for developing innovative applications such as drowsiness detection and health monitoring that play a pivotal role in contemporary society. This study delves into ER using electroencephalography (EEG) within immersive virtual reality (VR) environments. Our proposed methodology has four main stages: data acquisition, pre-processing, feature extraction, and emotion classification. Acknowledging the limitations of existing 2D datasets, we introduce a groundbreaking 3D VR dataset to elevate the precision of emotion elicitation. Leveraging the Interaxon Muse headband for EEG recording and Oculus Quest 2 for VR stimuli, we meticulously recorded data from 40 participants, prioritizing subjects without reported mental illnesses. To ensure the robustness of our model, we employed a 10-fold cross-validation, revealing an average validation accuracy of 85.54%, with a noteworthy maximum accuracy of 90.20% in the best fold. Subsequently, the trained model demonstrated a commendable test accuracy of 82.03%, promising favorable outcomes.",https://pubmed.ncbi.nlm.nih.gov/40039543/,https://pubmed.ncbi.nlm.nih.gov/40039543/,English,Include,,Human Emotions Analysis and Recognition Using EEG Signals in Response to 360° Videos.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.45,cv_reported;small_sample_mentioned
pubmed:40039500,pubmed:40039500,PubMed,pubmed:40039500,Functional Connectivity Methods for Multi-Class Mental Workload Classification.,Arya Teymourlouei;Minsi Hu;Rodolphe Gentili;James Reggia,2024,10.1109/embc53108.2024.10782848,"Recently, significant attention has been drawn to the ability of network-based features to classify EEG signals reflecting varying levels of mental workload. Such features are based on methods of functional connectivity (FC), which quantify the statistical relationship between EEG electrode potentials. Here, we compare three FC-based feature extraction methods for the classification of mental workload from the Multi-Attribute Task Battery. The approaches used are weighted phase lag index (WPLI), imaginary coherence (IC), and layer entanglement (LE). WPLI and IC are popular methods for FC analysis. LE is a new approach which was introduced in recent literature. When classifying between three levels of workload, a support vector machine classifier achieved an 88% average (person-dependent) accuracy using all FC methods together, 89% using only the LE method, 67% with the IC method, and 61% with the WPLI method. When classifying between two levels of workload, these scores improve to 97%, 97%, 86%, and 81%, respectively. These results support and extend the findings of prior work and suggest that LE-based methods may enable accurate mental workload prediction which is suitable for passive brain-computer interfaces.",https://pubmed.ncbi.nlm.nih.gov/40039500/,https://pubmed.ncbi.nlm.nih.gov/40039500/,English,Include,,Functional Connectivity Methods for Multi-Class Mental Workload Classification.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40039490,pubmed:40039490,PubMed,pubmed:40039490,Long-short term memory autoencoder using delta with beta bands of EEG enables highly accurate prediction of seizure outcome in Infantile Epileptic Spasms Syndrome of unknown etiology.,Ryosuke Suzui;Jun Natsume;Tatsuki Saito;Koichi Fujiwara,2024,10.1109/embc53108.2024.10782809,"[Background] Infantile epileptic spasms syndrome (IESS) is a developmental epileptic encephalopathy in infants, which is often difficult to be predicted long-term seizure outcomes at the time of onsets. The aim of this study is to predict its long-term outcome by analyzing EEG data at the onset of IESS of unknown etiology. [Methods] The study included eighteen patients with IESS of unknown etiology. Thirteen patients in whom seizures disappeared after initial treatments were categorized into a good outcome group, and five patients with continuation or relapse of seizures were into a poor outcome group. We trained a machine learning (ML) model from clinical EEG data of patients in the good outcome group only utilizing an anomaly detection framework. The delta and the beta bands, constructing basis of hypsarrhythmia were extracted from scalp EEG data during sleep by bandpass filtering, and the phase of each band was used as features of the ML model. Long-short term memory autoencoder (LSTM-AE), which copes with anomaly detection with time series data, was adopted as the ML model. We tested its performance of long-term outcome prediction. This trial was repeated ten times randomly exchanging training, validation, and test datasets for precise performance evaluation. [Results] The trained LSTM-AE model achieved a sensitivity, specificity, and accuracy of 0.82 ± 0.08, 0.80 ± 0.10, and 0.81 ± 0.10, respectively, when patients the poor outcome group were detected, which may contribute to clinical decision. [Conclusion] The developed ML model enabled highly accurate prediction of seizure outcomes of IESS of unknown etiology from the EEG data at its onset.",https://pubmed.ncbi.nlm.nih.gov/40039490/,https://pubmed.ncbi.nlm.nih.gov/40039490/,English,Include,,Long-short term memory autoencoder using delta with beta bands of EEG enables highly accurate prediction of seizure outcome in Infantile Epileptic Spasms Syndrome of unknown etiology.,Include,,"ial was repeated ten times randomly exchanging training, validation, and test datasets for precise performance evaluation. [Results] The trained LSTM-AE model achieved a sensitivity, specificity, and accuracy of 0.82 ± 0.08, 0.80 ± 0.10, and 0.81 ± 0.10, respectively, when patients the poor outcome group were detected, which may contribute to clinical decision. [Conclusion] The developed ML model ",,0.95,0.6,
pubmed:40039466,pubmed:40039466,PubMed,pubmed:40039466,Multi-Modal Emotion Recognition Using EEG and Eye Tracking Features.,Paolo Iacono;Naimul Khan,2024,10.1109/embc53108.2024.10781843,"Multi-modal emotion recognition from various human physiological indicators has emerged as a large topic of interest, including the use of EEG, ECG, GSR and Eye Tracking features. This work introduced a simple CNN based multi-modal EEG and Eye Tracking emotion recognition model for the SEED V dataset. In contrast to other works on the SEED V dataset, different Differential Entropy time windows were tested for EEG feature extraction. EEG signals were arranged in a 2D image format to preserve spatial relationships between electrode placements on patients during the trials. The proposed model with a 1 second processing window for EEG features achieved state of the art results in Leave One Subject Out Validation, with a mean accuracy of 0.935 ± 0.038 on the SEED V dataset. A noticeable improvement was noted over the same multi-modal model using a 4 second processing window for EEG features, highlighting the importance of smaller time windows for EEG feature processing in emotion recognition problems.",https://pubmed.ncbi.nlm.nih.gov/40039466/,https://pubmed.ncbi.nlm.nih.gov/40039466/,English,Include,,Multi-Modal Emotion Recognition Using EEG and Eye Tracking Features.,Include,,"rode placements on patients during the trials. The proposed model with a 1 second processing window for EEG features achieved state of the art results in Leave One Subject Out Validation, with a mean accuracy of 0.935 ± 0.038 on the SEED V dataset. A noticeable improvement was noted over the same multi-modal model using a 4 second processing window for EEG features, highlighting the importance of ",,0.95,0.6,
pubmed:40039446,pubmed:40039446,PubMed,pubmed:40039446,Discrimination of Real and Deep Fake Videos using EEG Signals.,M Riyyan Khan;Hasan Mir;Fares Al Shargie;Usman Tariq;Abhinav Dhall;Shahzeb Naeem;M N Afzal Khan;Hasan Al Nashash,2024,10.1109/embc53108.2024.10781814,"Deepfake technology can create highly realistic fabricated videos, presenting serious ethical concerns and threats of misinformation. Reliably distinguishing deepfakes from genuine videos is therefore critical yet challenging. This study explored electroencephalography (EEG)-based deepfake detection by analyzing EEG responses in 10 participants viewing 100 videos (50 real, 50 deepfakes). Signals were recorded with a 64-channel system. Following standard preprocessing and artifact removal, data was analyzed using Pearson's correlation and features from the selected channels were extracted using wavelet packet decomposition (WPD) and fast Fourier transform (FFT). Five machine learning classifiers (support vector machine, k-nearest neighbors, etc.) were trained on these features to classify real versus deepfake videos. The WPD approach achieved a maximum accuracy of 94.16%, while the FFT method attained 98.25% accuracy using a k-nearest neighbors model. These EEG-based models demonstrate potential for passively detecting deepfakes, meriting further research.",https://pubmed.ncbi.nlm.nih.gov/40039446/,https://pubmed.ncbi.nlm.nih.gov/40039446/,English,Include,,Discrimination of Real and Deep Fake Videos using EEG Signals.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:40039435,pubmed:40039435,PubMed,pubmed:40039435,Mental Fatigue Classification with High-Density Diffuse Optical Tomography: A Feasibility Study.,Jianan Chen;Yunjia Xia;Alexander Thomas;Tom Carlson;Hubin Zhao,2024,10.1109/embc53108.2024.10782566,"High-Density Diffuse Optical Tomography (HD-DOT) presents as a promising tool for not only clinical use but also daily monitoring of mental states. This study employed wearable HD-DOT to evaluate mental fatigue, specifically examining the differences in functional near-infrared spectroscopy (fNIRS) data between states of low and high fatigue among healthy participants for data collection. Data processing involved filtering, channel selection, and dimensionality reduction through Uniform Manifold Approximation (UMAP) and Projection, followed by classification using Support Vector Machines (SVM). We developed two models to assess the accuracy and generalizability of our findings: one based on individually tailored models and another employing a leave-one-participant-out cross-validation strategy. We evaluated different kernel functions, resulting in various accuracy, F1 score, and Area Under the Curve (AUC) metrics. The study achieved an average accuracy of approximately 90% for participant-specific classifiers, underscoring the effectiveness of our approach to differentiate between low and high states of mental fatigue. Our analyses led to a robust model demonstrating high classification accuracy, proving its suitability and potential for real-time Brain-Computer Interface (BCI) applications.",https://pubmed.ncbi.nlm.nih.gov/40039435/,https://pubmed.ncbi.nlm.nih.gov/40039435/,English,Include,,Mental Fatigue Classification with High-Density Diffuse Optical Tomography: A Feasibility Study.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.45,cv_reported;small_sample_mentioned
pubmed:40039434,pubmed:40039434,PubMed,pubmed:40039434,"Balancing Spectral, Temporal and Spatial Information for EEG-based Alzheimer's Disease Classification.",Stephan Goerttler;Fei He;Min Wu,2024,10.1109/embc53108.2024.10782936,"The prospect of future treatment warrants the development of cost-effective screening for Alzheimer's disease (AD). A promising candidate in this regard is electroencephalography (EEG), as it is one of the most economic imaging modalities. Recent efforts in EEG analysis have shifted towards leveraging spatial information, employing novel frameworks such as graph signal processing or graph neural networks. Here, we investigate the importance of spatial information relative to spectral or temporal information by varying the proportion of each dimension for AD classification. To do so, we systematically test various dimension resolution configurations on two routine EEG datasets. Our findings show that spatial information is more important than temporal information and equally valuable as spectral information. On the larger second dataset, substituting spectral with spatial information even led to an increase of 1.1% in accuracy, which emphasises the importance of spatial information for EEG-based AD classification. We argue that our resolution-based feature extraction has the potential to improve AD classification specifically, and multivariate signal classification generally.Clinical relevance- This study proposes balancing the spectral, temporal and spatial feature resolution to improve EEGbased diagnosis of neurodegenerative diseases.",https://pubmed.ncbi.nlm.nih.gov/40039434/,https://pubmed.ncbi.nlm.nih.gov/40039434/,English,Include,,"Balancing Spectral, Temporal and Spatial Information for EEG-based Alzheimer's Disease Classification.",Include,," more important than temporal information and equally valuable as spectral information. On the larger second dataset, substituting spectral with spatial information even led to an increase of 1.1% in accuracy, which emphasises the importance of spatial information for EEG-based AD classification. We argue that our resolution-based feature extraction has the potential to improve AD classification s",,0.95,0.6,
pubmed:40039431,pubmed:40039431,PubMed,pubmed:40039431,Application of a Neural ODE to Classify Motion Control Strategy using EEG.,Liran Ziegelman;Manuel E Hernandez,2024,10.1109/embc53108.2024.10782326,"Speed-accuracy trade offs exist in a variety of functional tasks, which may require differences in control strategies in future neuroprosthetic devices. It is the goal of this work to evaluate the predictability of different motor control strategies during wrist rotation tasks. Participants were asked to perform a series of discrete wrist rotations. This motion data was clustered into segments of either speed or range of motion oriented control strategy, controlling for age cohort and motion type. Competing neural ordinary differential equation (NODE) and random forest (RF) models were evaluated to explore the feasibility of classifying control strategy using cortical data alone. In comparison to traditional ML techniques, such as RF models, the NODE model provided achieved comparable classification accuracy at a fraction of the time. Furthermore, the use of a single motor cluster or two frontal clusters provided similar accuracy to the full data from 4 clusters, which may due to increased information from these cortical areas. This study provided a promising initial demonstration of the benefits of NODE models for future brain-computer-interface applications that require near real-time classification.",https://pubmed.ncbi.nlm.nih.gov/40039431/,https://pubmed.ncbi.nlm.nih.gov/40039431/,English,Include,,Application of a Neural ODE to Classify Motion Control Strategy using EEG.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:40039415,pubmed:40039415,PubMed,pubmed:40039415,Advancing SSVEP-BCI Decoding: Cross-Subject Transfer Learning and Short Calibrated Approach with ELM-AE.,Christian Flores;Paolo Casas;Sarah Negreiros de Carvalho;Romis Attux,2024,10.1109/embc53108.2024.10782739,"The Steady-State Visually Evoked Potential (SSVEP) is a robust paradigm for developing a high-speed Brain-Computer Interface (BCI). However, one of the challenges of BCI is to face the variability of EEG signals between subjects to reduce or eliminate the time calibration process for a new subject (target subject). Some approaches propose linearly transforming; however, it limits the ability to capture complex and nonlinear relationships in data. This study presents a method for performing a Nonlinear Transformation (NLT) using an Extreme Learning Machine Autoencoder (ELM-AE) on SSVEP trials. To improve the NLT, it maps each trial from the existing subjects (source subjects) to one or a few templates from the target subject. This approach can enhance cross-subject recognition classification, reducing the calibration time for the target subject. Our results reported that, for one template, NLT and LST achieved 84.23% and 82.19% average recognition accuracy, respectively. Thus, our results reported that the recognition accuracy of NLT outperformed LST for all template sizes across all 35 subjects. These results demonstrated the feasibility of the NLT using one or a few templates for rapid calibration for the target subject.",https://pubmed.ncbi.nlm.nih.gov/40039415/,https://pubmed.ncbi.nlm.nih.gov/40039415/,English,Include,,Advancing SSVEP-BCI Decoding: Cross-Subject Transfer Learning and Short Calibrated Approach with ELM-AE.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40039400,pubmed:40039400,PubMed,pubmed:40039400,High-Frequency SSVEP-BCI Stimulation Frequency Optimization Based on BCI accuracy.,Sodai Kondo;Hisaya Tanaka,2024,10.1109/embc53108.2024.10782291,"This study investigates optimization of the stimulation frequency of blinking stimuli used for steady-state visual evoked potential (SSVEP) brain-computer interface (BCI) for individuals. Heare, we set the target BCI accuracy to 90%, and we propose and evaluate an efficient algorithm to search for stimulation frequencies that satisfy the accuracy target for each subject. The results of a four-input SSVEP-BCI operation experiment with various stimulation frequencies indicate that the experimental system obtained optimal stimulation frequency for the subject based on BCI accuracy. However, we found that the optimization time was greater for subjects who are not proficient at BCI operations, which caused subject fatigue.",https://pubmed.ncbi.nlm.nih.gov/40039400/,https://pubmed.ncbi.nlm.nih.gov/40039400/,English,Include,,High-Frequency SSVEP-BCI Stimulation Frequency Optimization Based on BCI accuracy.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40039376,pubmed:40039376,PubMed,pubmed:40039376,Interpretable SincNet-Based Spatiotemporal Neural Network for Seizure Prediction.,Baolian Shan;Haiqing Yu;Hanzhe Jiang;Yongzhi Huang;Minpeng Xu;Dong Ming,2024,10.1109/embc53108.2024.10781705,"Spatiotemporal convolutional neural networks (CNNs) have emerged as potent tools for seizure prediction (SP) using electroencephalogram (EEG) signals, probing spatiotemporal biomarkers in epileptic brains. Nevertheless, it poses significant challenges for clinical practice due to the poor interpretability of learned features and the numerous trainable parameters in existing CNNs. To improve the interpretability and performance, this study proposed an interpretable SincNet-based architecture for spatiotemporal CNNs, encompassing EEGNet-8,2, ShallowConvNet, DeepConvNet, and EEGWaveNet, enabling direct visualization of the bandpass temporal filter range using a sinc-convolution layer. Furthermore, we also constructed a visualization analysis method to demonstrate the crucial spatiotemporal features learned by the proposed optimal CNN. Results on the CHB-MIT dataset revealed that both ShallowConvNet and EEGWaveNet had significantly improved performance with more lightweight parameters. Notably, the architecture enabled ShallowConvNet to achieve an average accuracy of 87.2%, sensitivity of 88.3%, weighted F1-score of 87.1%, and AUC of 92.7% for 21 epilepsy patients. Besides, the visualization outcomes underscored the ability of the optimal model to extract statistically significant spatiospectral energy differences within high-frequency EEG bands for SP classification tasks.",https://pubmed.ncbi.nlm.nih.gov/40039376/,https://pubmed.ncbi.nlm.nih.gov/40039376/,English,Include,,Interpretable SincNet-Based Spatiotemporal Neural Network for Seizure Prediction.,Include,,"ataset revealed that both ShallowConvNet and EEGWaveNet had significantly improved performance with more lightweight parameters. Notably, the architecture enabled ShallowConvNet to achieve an average accuracy of 87.2%, sensitivity of 88.3%, weighted F1-score of 87.1%, and AUC of 92.7% for 21 epilepsy patients. Besides, the visualization outcomes underscored the ability of the optimal model to extr",,0.95,0.6,
pubmed:40039361,pubmed:40039361,PubMed,pubmed:40039361,fMRINet: Repurposing the EEGNet model to identify emotional arousal states in fMRI data.,Daniel Agostinho;Miguel Castelo-Branco;Marco Simoes,2024,10.1109/embc53108.2024.10782984,"In recent years, functional magnetic resonance imaging (fMRI) transformed our understanding of the intricate relationship between emotions and the brain. The precise classification of emotional states from fMRI data poses challenges for traditional machine learning methods dealing with high-dimensional data. The limitations of these conventional approaches have spurred a growing interest in exploring the potential of deep learning (DL) models. This study introduces a novel approach to classifying emotional arousal levels using fMRI data, specifically tailored for projects with limited data. The approach involves the adaptation of the EEGNet architecture, originally designed for the classification of electroencephalography (EEG) signals, to fMRI data. By mapping the fMRI signal into brain regions using a brain atlas, fMRINet is applied to the two-dimensional fMRI time series, achieving a promising performance in identifying emotional states in both typical and clinical participants (balanced accuracy between 70% and 72%). Our findings highlight the successful integration of the EEGNet architecture into fMRI data and contribute to the broader field of brain state classification.",https://pubmed.ncbi.nlm.nih.gov/40039361/,https://pubmed.ncbi.nlm.nih.gov/40039361/,English,Include,,fMRINet: Repurposing the EEGNet model to identify emotional arousal states in fMRI data.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:40039350,pubmed:40039350,PubMed,pubmed:40039350,Spike isolation from background signal in neonatal EEG data using an integrated independent component analysis method.,Mina Ezzati Asl;Josue D Rodriguez;Mercedes Cabrerizo;Anuj Jayakar;Armando Barreto;Malek Adjouadi,2024,10.1109/embc53108.2024.10782611,"Spike detection in epileptic neonates is a challenging task since the recorded electroencephalography (EEG) data are often fraught with artifacts and noise. This study aims to enhance the clarity of epileptic spikes by separating them from background activity using an integrated method based on the independent component analysis (ICA). We analyzed spikes of 12 epileptic neonates as marked in their EEG scalp recordings by a clinical expert. The proposed method makes use of the ICA method to isolate the source of the spikes and then apply a power frequency analysis and template matching to validate the performance of the ICA. Isolating a spike is achieved by choosing the component that should correspond to its defining characteristics, followed by signal reconstruction using that component. To evaluate the accuracy of our spike isolation method, we first check if the power spectrum of the separated spikes aligns with the typical power spectral density observed in neonates. Subsequently, we measured the degree of similarity between the extracted spike and a predefined spike template, comparing it against the original spike segment. With this integrated method, the results show the successful extraction of 29 out of the 37 marked spikes (i.e., 79 percent), which signifies that ICA can serve as a promising approach in the initial isolation process of spikes in EEG records of neonates. This could lead to further investigation into those subtle features or changes missed on those EEG records of the marked spikes that were not separated. Determining such features and subtle changes, if indeed inherent to spikes, could lead to the development of enhanced spike detection methods in neonates. It should be noted that in 5 out of the 37 epochs, we could not identify any independent component as a spike source, and 3 out of 32 remaining cases showed unsuccessful separation in validation, possibly due to the source not being statistically independent or being Gaussian in nature. In such cases, the expert clinician(s) could review or reconsider marking such spikes.",,https://pubmed.ncbi.nlm.nih.gov/40039350/,English,Exclude,Review/survey papers,Spike isolation from background signal in neonatal EEG data using an integrated independent component analysis method.,,,,,0.95,0.6,
pubmed:40039339,pubmed:40039339,PubMed,pubmed:40039339,Detection of Sleep Oxygen Desaturations from Electroencephalogram Signals.,Shashank Manjunath;Aarti Sathyanarayana,2024,10.1109/embc53108.2024.10781541,"In this work, we leverage machine learning techniques to identify potential biomarkers of oxygen desaturation during sleep exclusively from electroencephalogram (EEG) signals in pediatric patients with sleep apnea. Development of a machine learning technique which can successfully identify EEG signals from patients with sleep apnea as well as identify latent EEG signals which come from subjects who experience oxygen desaturations but do not themselves occur during oxygen desaturation events would provide a strong step towards developing a brain-based biomarker for sleep apnea in order to aid with easier diagnosis of this disease. We leverage a large corpus of data, and show that machine learning enables us to classify EEG signals as occurring during oxygen desaturations or not occurring during oxygen desaturations with an average 66.8% balanced accuracy. We furthermore investigate the ability of machine learning models to identify subjects who experience oxygen desaturations from EEG data that does not occur during oxygen desaturations. We conclude that there is a potential biomarker for oxygen desaturation in EEG data.",https://pubmed.ncbi.nlm.nih.gov/40039339/,https://pubmed.ncbi.nlm.nih.gov/40039339/,English,Include,,Detection of Sleep Oxygen Desaturations from Electroencephalogram Signals.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40039323,pubmed:40039323,PubMed,pubmed:40039323,Improving the Classification of Olfactory Brain-Computer Interface Responses by Combining EEG and EBG Signals.,Hubert Kasprzak;Nina Niewinska;Tomasz Komendzinski;Mihoko Otake-Matsuura;Tomasz M Rutkowski,2024,10.1109/embc53108.2024.10782826,"The sense of smell, or olfaction, can enhance brain-computer interfaces (BCIs). Different scents can be assigned to specific commands to allow users to interact with technology naturally, but challenges remain. Accurate odor delivery systems and robust algorithms for detecting and interpreting brain activity patterns are necessary. We propose combining electroencephalography (EEG) and electrobulbography (EBG) to improve classification accuracy. Our pilot study shows promising results for a new olfactory brain-computer interface (BCI) modality that combines common spatial pattern (CSP) filtration applied to EEG and EBG to classify responses to six scent stimuli in a classical oddball paradigm.",https://pubmed.ncbi.nlm.nih.gov/40039323/,https://pubmed.ncbi.nlm.nih.gov/40039323/,English,Include,,Improving the Classification of Olfactory Brain-Computer Interface Responses by Combining EEG and EBG Signals.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40039273,pubmed:40039273,PubMed,pubmed:40039273,A Novel Real-time Algorithm Based on Phase-Locked Data Alignment for Continuously Controlled SSVEP-BCI.,Hanzhe Jiang;Xiaolin Xiao;Jie Mei;Minpeng Xu;Kun Wang;Dong Ming,2024,10.1109/embc53108.2024.10782824,"Brain-computer interfaces (BCIs) based on steady-state visual evoked potential (SSVEP) show good performance. However, algorithms always decode segments of electroencephalogram (EEG) and can only satisfy discrete output instructions, which limit the real-time continuous control of the BCI system. This article proposes a novel algorithm for SSVEP-BCI that can translate continuous EEG into control commands, achieving real-time monitoring of user intentions. A phase synchronicity maximum strategy has been employed in this algorithm, which could capture a fixed-duration SSVEP epoch near any given moment, ensuring each trial is aligned with the phase of the potential corresponding template. Then, the algorithm utilized an update strategy of a small-step sliding window to recognize and output commands in approximately real-time. We constructed an SSVEP-BCI system with continuous stimulation and recruited nine subjects. The results showed that the algorithm proposed in this study efficiently decoded continuously evoked SSVEP signals. The BCI's online average accuracy and ITR were 92.03% and 143.38 bits/min, respectively. The proposed algorithm can decode SSVEP at any time theoretically, which improves command output density as well as maintains high recognition accuracy. This study provides novel methods for real-time control of external devices using SSVEP-BCIs and helps to develop BCIs that are more compatible with human control habits.",https://pubmed.ncbi.nlm.nih.gov/40039273/,https://pubmed.ncbi.nlm.nih.gov/40039273/,English,Include,,A Novel Real-time Algorithm Based on Phase-Locked Data Alignment for Continuously Controlled SSVEP-BCI.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40039264,pubmed:40039264,PubMed,pubmed:40039264,Cross-paradigm data alignment to improve the calibration of asynchronous BCI systems in EEG-based speech imagery.,Mingtao Li;Sio Hang Pun;Fei Chen,2024,10.1109/embc53108.2024.10781999,"The brain-computer interfaces (BCIs) based on speech imagery with asynchronous (self-paced) paradigms enable users to directly access and manipulate BCIs with more freedom. Compared with the indirect BCIs with traditional synchronous (cue-based) paradigms, the calibration time of asynchronous paradigms was much longer and with the unbalanced number of task states and idle states. This work aimed to improve the calibration of asynchronous BCI systems by applying a data alignment (DA) approach on cue-based and self-paced paradigms. The cue-based paradigm was regarded as the calibration paradigm and the self-paced paradigm was the testing paradigm. The data alignment approach based on the parallel transport mapped their features on the same tangent space. The logistic regression was used as the classifier to classify task states and idle states. The average result with DA was 7.52% higher than that without DA (baseline), which were 78.45% and 70.92%, respectively. Specially, the best classification accuracy was for 91.82% with DA, and the largest improvement in accuracy was 22.92%. These results suggest that it is practical to use a synchronous paradigm as calibration paradigm in asynchronous BCI systems and the data alignment approach has positive impacts on the classification of task states and idle states.",https://pubmed.ncbi.nlm.nih.gov/40039264/,https://pubmed.ncbi.nlm.nih.gov/40039264/,English,Include,,Cross-paradigm data alignment to improve the calibration of asynchronous BCI systems in EEG-based speech imagery.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40039262,pubmed:40039262,PubMed,pubmed:40039262,An Improved Neurosurgical Planning Method for Focal Epileptic Seizure Surgery using Stereo-EEG-Based Source Localization and Multimodal Imaging.,Thomas Hartigan;Lauren Byrne;Sarah Lavelle;Ali McDonnell;Kieron Sweeney;Richard B Reilly,2024,10.1109/embc53108.2024.10781654,"Refractory Focal Epilepsy can be treated by the surgical resection of the Seizure Onset Zone (SOZ), the region in the brain from which seizures originate. To remove the SOZ, precise localization must be performed to identify this region, and to minimize the risk of removing eloquent cortex. StereoEEG is a valuable method to localize the SOZ, by recording the propagation of epileptic signals using a series of implanted depth electrodes. This allows the origin of the seizure signals to be determined based on the time at which they are detected at known electrode contact coordinates along the implanted electrodes. The automation of the localization of the SOZ using stereo-EEG, CT and MRI data is becoming increasingly relevant in the neurosurgical literature, as it offers an opportunity for increased accuracy and efficiency. This study proposes a novel method to localize the SOZ by using multimodal image processing. The method allows a statistical representation of the SOZ to be constructed on the cortical surface model, by using a series of spatial transformations. In a clinical case of MRI-positive focal epilepsy, the proposed pipeline was able to correctly identify the SOZ whilst using electrophysiological input from distant electrodes with 80-90% of the pipeline's result being within the resection cavity. In an MRI-negative patient's result, 60-75% of the SOZ determination was also within the resective cavity. In both cases, the pipeline showed greater than 50% reduction in SOZ volume determination. Such precise localization may allow for smaller resection volumes to achieve seizure freedom and reduce neurological complications. This method may therefore offer a more accurate solution to SOZ localization with a reduced clinical workload.",https://pubmed.ncbi.nlm.nih.gov/40039262/,https://pubmed.ncbi.nlm.nih.gov/40039262/,English,Include,,An Improved Neurosurgical Planning Method for Focal Epileptic Seizure Surgery using Stereo-EEG-Based Source Localization and Multimodal Imaging.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40039208,pubmed:40039208,PubMed,pubmed:40039208,Motor Imagery Decoding from EEG under Visual Distraction via Feature Map Attention EEGNet.,Yiting Geng;Banghua Yang;Sixiong Ke;Liang Chang;Jiayang Zhang;Yanyan Zheng,2024,10.1109/embc53108.2024.10781898,"The investigation of motor imagery (MI)-based brain-computer interface (BCI) is vital to the domains of human-computer interaction and rehabilitation. Few existing studies on electroencephalogram(EEG) signals decoding based on MI consider any distractions. However, it is difficult for users to do a single MI task in real life, which is especially affected by visual distraction. In this paper, we aim to investigate the effects of visual distraction on MI decoding performance. We first design a noval MI paradigm under visual distraction and observe distinct patterns of event-related desynchronization (ERD) and event-related synchronization (ERS) in MI under visual distraction. Then, we propose a robust decoding method of MI under visual distraction from EEG signals by using the feature map attention EEGNet (named FMA-EEGNet) and use EEG data under conditions without and with distraction to compare the decoding performance of five methods (including the proposed method and other methods). The results demonstrate that FMA-EEGNet achieved mean accuracy of 89.1% and 82.2% without and with visual distraction, respectively, indicating superior performance compared to other methods while exhibiting minimal degradation in performance. This work contributes significantly to the advancement of practical applications in MI-BCI technology.",https://pubmed.ncbi.nlm.nih.gov/40039208/,https://pubmed.ncbi.nlm.nih.gov/40039208/,English,Include,,Motor Imagery Decoding from EEG under Visual Distraction via Feature Map Attention EEGNet.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40039205,pubmed:40039205,PubMed,pubmed:40039205,Complexity Analysis based on Parietal Fuzzy Entropy to Facilitate ADHD Diagnosis in Young Children.,I-Wen Huang;Yu-Ci Jheng;I-Chun Chen;Li-Wei Ko,2024,10.1109/embc53108.2024.10781919,"Attention deficit hyperactivity disorder (ADHD) is the most common condition affecting the development of neurons in children. Therefore, early and accurate diagnosis of ADHD in young children is of paramount importance. In this study, the 8-channel wireless wearable EEG measurement device was employed to record EEG data from 30 children diagnosed with ADHD and 30 typical development (TD) young children aged 4-7 years. The data was collected both during rest and while the children performed a Kiddie Continuous Performance Test (K-CPT). We extract relative power spectral density (PSD) unaffected by factors like skull resistance and thickness. Additionally, a range of complex entropy values based on the time domain were extracted. These included sample entropy (SaEn), permutation entropy (PeEn), singular value decomposition entropy (SvdEn), and fuzzy entropy (FuEn). We compare the performance of k-Nearest Neighbors (kNN), Support Vector Machine (SVM), and XGBoost, and utilized the sequential forward selection (SFS) feature selection method in the wrapper approach. Through this process, the study identified the most effective EEG data segments and feature subsets. The findings indicated that using a combination of resting and K-CPT EEG data yielded greater discriminability. Notably, the study found that extracting beta power from the right occipital lobe along with fuzzy entropy from the parietal lobe resulted in optimal accuracy of 90% in distinguishing between children with ADHD and TD children. These outcomes highlight the potential of relative PSD and complexity metrics to support the clinical diagnosis of early ADHD. Furthermore, these metrics may contain unique neurobiomarkers that could be valuable for devising early intervention strategies.",https://pubmed.ncbi.nlm.nih.gov/40039205/,https://pubmed.ncbi.nlm.nih.gov/40039205/,English,Include,,Complexity Analysis based on Parietal Fuzzy Entropy to Facilitate ADHD Diagnosis in Young Children.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40039178,pubmed:40039178,PubMed,pubmed:40039178,An Efficient Deep Transfer Learning Network for Characterization of Stroke Patients' Motor Execution from Multi-Channel EEG-Recordings.,Oluwarotimi Williams Samuel;Mojisola Grace Asogbon;Frank Kulwa;Alistair A McEwan;Sunday Timothy Aboyeji;Rami Khushaba;Peng Fang;Guanglin Li,2024,10.1109/embc53108.2024.10782368,"Recent advances in stroke rehabilitation technology have been focused on developing Intelligent Rehabilitation Robots (IRR) that can effectively engage post-stroke patients (PSP) in intuitive motor training for full function recovery. Most existing rehabilitation robots incorporate functionalities that are passive in nature, constraining PSP to predetermined trajectories that often deviate from patients' limb movement intentions, consequently hindering recovery. To resolve this issue, a robust deep-transfer learning driven network (DTLN) is developed to adequately characterize PSP's motion intention signatures from neural oscillations towards achieving intuitive and active training. Thus, we investigated and proposed the utilization of mu-frequency spectrum (muFS) based CWT approach for Scalograms construction, which serves as inputs to the DTLN model that characterizes multiple classes of PSP's motor execution signatures from multi-channel electroencephalography (EEG) recordings. Then, we evaluated the proposed method using EEG data from six PSP and compared the decoding results to those of related approaches under similar experimental settings. The proposed method resulted in a significant increment of 10.84 % - 13.19% decoding accuracy across stroke patients and better convergence in comparison to other methods. Additionally, the method exhibited distinct task separability for individual motor execution signature across patients. In conclusion, our method offers a consistently accurate decoding of motor tasks that could enable intuitively active robotic training in PSPs with impaired motor function.",https://pubmed.ncbi.nlm.nih.gov/40039178/,https://pubmed.ncbi.nlm.nih.gov/40039178/,English,Include,,An Efficient Deep Transfer Learning Network for Characterization of Stroke Patients' Motor Execution from Multi-Channel EEG-Recordings.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40039176,pubmed:40039176,PubMed,pubmed:40039176,A real-time HFO detection framework for localization of SOZ in iEEG recording of patients with epilepsy.,Behrang Fazli Besheli;Chandra Prakash Swamy;Amir Hossein Ayyoubi;Luciano R F Branco;Gregory A Worrell;Zhiyi Sha;Jay R Gavvala;Kai J Miller;Nuri F Ince,2024,10.1109/embc53108.2024.10781609,"Interictal High-frequency Oscillation (HFO) between 80-600 Hz in intracranial EEG (iEEG) is a promising biomarker of the epileptogenic zone in individuals with epilepsy. Numerous studies revealed that the resection of channels with a high rate of HFOs correlates with favorable surgical outcomes. Early feedback to clinicians regarding the distribution of HFOs during the iEEG recording, especially after the implantation of electrodes, would be helpful for clinical decisions. However, iEEG recording can easily get corrupted by various factors mimicking real HFOs. This study presents a real-time HFO detection framework within MATLAB/Simulink that exhibits robustness against such pseudo-HFOs. This detector is responsible for identifying the initial pool of candidate HFOs and transmitting them via user datagram protocol (UDP) to an external application. The external application contains a machine learning tool that is utilized for post-processing and isolating the real-HFOs. It is implemented in a graphical user interface (GUI) that provides visual feedback regarding the distribution and waveforms of HFOs. The entire processing pipeline was validated by randomly selecting 10-minute segments of interictal iEEG recordings from 10 subjects. It successfully identifies the seizure onset zone (SOZ) in these subjects, achieving an average accuracy of 65% using the detected Ripples and 74% using the detected events with both Ripples and Fast Ripples. Importantly, the spatio-temporal distribution of detected HFOs in real-time showed more than 98% spatio-temporal similarity index compared to offline analysis. Our framework proves to be an effective tool for the automatic identification of HFOs in real-time with the ability to promptly stream the HFO analysis results and provide early feedback regarding the probable SOZ regions to clinicians for surgical decision-making.",https://pubmed.ncbi.nlm.nih.gov/40039176/,https://pubmed.ncbi.nlm.nih.gov/40039176/,English,Include,,A real-time HFO detection framework for localization of SOZ in iEEG recording of patients with epilepsy.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40039164,pubmed:40039164,PubMed,pubmed:40039164,TAU-DI Net: A Multi-Scale Convolutional Network Combining Prob-Sparse Attention for EEG-based Depression Identification.,Jingdong Zhou;Chongyuan Lian;Xiaoyong Lan;Xue Shi;Lan Wang;Nan Yan;Yi Guo,2024,10.1109/embc53108.2024.10782219,"EEG-based detection of major depression disorder (MDD) plays a pivotal role in the subsequent treatment and recovery. With the rapid development of deep learning, CNN, LSTM, and attention-based models have been used for auxiliary diagnosis of MDD from EEG signals. However, these approaches either lack the utilization of pathological features of depression at the signal level or neglect handling redundant signal information within resting-state EEG. Considering these limitations, we propose a novel architecture based on an adaptive time-frequency distribution network. This method conducts the structure, which combines frequency-periodic transformation and multi-scale CNN to extract multi-frequency information representations from the most significant and least significant frequencies. Then, the method employs an adaptive weighted fusion of spatiotemporal representations across different frequencies and subsequently utilizes down-sampled Prob-Sparse Attention to distill reliable patterns within resting-state EEG. Experimental results demonstrate that our approach outperforms other models based on self-attention mechanisms and convolutional neural networks, achieving an optimal classification accuracy of 94.91%. The results show that adaptive methods based on different frequencies can produce better capabilities in processing EEG signals related to depression disorder.",https://pubmed.ncbi.nlm.nih.gov/40039164/,https://pubmed.ncbi.nlm.nih.gov/40039164/,English,Include,,TAU-DI Net: A Multi-Scale Convolutional Network Combining Prob-Sparse Attention for EEG-based Depression Identification.,Include,,"esting-state EEG. Experimental results demonstrate that our approach outperforms other models based on self-attention mechanisms and convolutional neural networks, achieving an optimal classification accuracy of 94.91%. The results show that adaptive methods based on different frequencies can produce better capabilities in processing EEG signals related to depression disorder.",,0.95,0.6,
pubmed:40039132,pubmed:40039132,PubMed,pubmed:40039132,Evaluating the Influence of Temporal Context on Automatic Mouse Sleep Staging through the Application of Human Models.,Javier Garcia Ciudad;Morten Morup;Birgitte Rahbek Kornum;Alexander Neergaard Zahid,2024,10.1109/embc53108.2024.10782771,"In human sleep staging models, augmenting the temporal context of the input to the range of tens of minutes has recently demonstrated performance improvement. In contrast, the temporal context of mouse sleep staging models is typically in the order of tens of seconds. While long-term time patterns are less clear in mouse sleep, increasing the temporal context further than that of the current mouse sleep staging models might still result in a performance increase, given that the current methods only model very short term patterns. In this study, we examine the influence of increasing the temporal context in mouse sleep staging up to 15 minutes in three mouse cohorts using two recent and high-performing human sleep staging models that account for long-term dependencies. These are compared to two prominent mouse sleep staging models that use a local context of 12 s and 20 s, respectively. An increase in context up to 28 s is observed to have a positive impact on sleep stage classification performance, especially in REM sleep. However, the impact is limited for longer context windows. One of the human sleep scoring models, L-SeqSleepNet, outperforms both mouse models in all cohorts. This suggests that mouse sleep staging can benefit from more temporal context than currently used.",,https://pubmed.ncbi.nlm.nih.gov/40039132/,English,Exclude,Not EEG-BCI focused,Evaluating the Influence of Temporal Context on Automatic Mouse Sleep Staging through the Application of Human Models.,,,,,0.9,0.6,
pubmed:40039126,pubmed:40039126,PubMed,pubmed:40039126,EEG Acquisition and Motor Imagery Classification for Robotic Control.,Hamza Amrani;Daniela Micucci;Marco Nalin;Paolo Napoletano;Ilario Rizzi,2024,10.1109/embc53108.2024.10782723,"The adoption of brain-computer interfaces (BCIs) has significantly increased in various application domains, particularly in the field of controlling robotic systems through motor imagery. The article contributes in two primary ways: 1) validating the effectiveness of using a minimally invasive electroencephalography (EEG) device combined with machine learning techniques to control fundamental movements in a robotic setting, and 2) demonstrating these findings practically through the construction of a robotic vehicle. In this vehicle, tasks involving motor imagery align directly with control commands for the vehicle. To validate our approach, we identified four-class and two-class classification tasks. The signals have been acquired from a portable EEG device equipped with eight dry electrodes. We employed sliding window strategies to segment the data, along with feature extraction using the Common Spatial Pattern (CSP) method. Classification modules were implemented based on Support Vector Machine (SVM) and K-Nearest Neighbors (KNN) models. The experimentation involved five participants, each with their own personalized model. While the accuracy of results in the four-class tasks is not notably high, the outcomes in binary classification tasks are promising, boasting an average accuracy of approximately 61%. Results suggest a promising potential for this approach in the realm of robot control, particularly when employing dry-electrode EEG devices.",https://pubmed.ncbi.nlm.nih.gov/40039126/,https://pubmed.ncbi.nlm.nih.gov/40039126/,English,Include,,EEG Acquisition and Motor Imagery Classification for Robotic Control.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:40039119,pubmed:40039119,PubMed,pubmed:40039119,Towards Optimising EEG Decoding using Post-hoc Explanations and Domain Knowledge.,Param Rajpura;Yogesh Kumar Meena,2024,10.1109/embc53108.2024.10781846,"Decoding Electoencephalography (EEG) during motor imagery is pivotal for the Brain-Computer Interface (BCI) system, influencing its overall performance significantly. As end-to-end data-driven learning methods advance, the challenge lies in balancing model complexity with the need for human interpretability and trust. Despite strides in EEG-based BCIs, challenges like artefacts and low signal-to-noise ratio emphasise the ongoing importance of model transparency. This work proposes using post-hoc explanations to interpret model outcomes and validate them against domain knowledge. Leveraging the GradCAM post-hoc explanation technique on the EEG motor movement/imagery dataset, this work demonstrates that relying solely on accuracy metrics may be inadequate to ensure BCI performance and acceptability. A model trained using all EEG channels of the dataset achieves 72.60% accuracy, while a model trained with motor-imagery/movement-relevant channel data has a statistically insignificant decrease of 1.75%. However, the relevant features for both are very different based on neurophysiological facts. This work demonstrates that integrating domain-specific knowledge with Explainable AI (XAI) techniques emerges as a promising paradigm for validating the neurophysiological basis of model outcomes in BCIs. Our results reveal the significance of neurophysiological validation in evaluating BCI performance, highlighting the potential risks of exclusively relying on performance metrics when selecting models for dependable and transparent BCIs.",https://pubmed.ncbi.nlm.nih.gov/40039119/,https://pubmed.ncbi.nlm.nih.gov/40039119/,English,Include,,Towards Optimising EEG Decoding using Post-hoc Explanations and Domain Knowledge.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40039113,pubmed:40039113,PubMed,pubmed:40039113,EEG-based Estimation of Cognitive Workload Across Multiple Tasks.,Anita Susan Mathews;Niraj Hirachan;Calvin Joseph;Maryam Ghahramani;Jehu Lopez-Aparicio;Raul Fernandez Rojas,2024,10.1109/embc53108.2024.10782830,"Key to the efficacy of working in high-risk environments is the reliable estimation of the human's cognitive state for improving safety and to maintain high performance longer. In this study, we developed an experimental protocol in which participants completed three cognitive tasks under two different levels (High, Low) of workload. We then evaluated the effect of the different cognitive activities on EEG signals and its accuracy in predicting respective cognitive load. The analysis was conducted using well-known machine learning algorithms such as SVM, RF, and KNN. An average accuracy of 82.75% was obtained through the proposed SVM model to identify the participant's cognitive workload level. The results obtained through this study indicated the efficacy of the EEG features in predicting the level of cognitive load irrespective of the activity. The proposed set of EEG features represents the cognitive indicators that form the basis for developments of augmented cognition systems in our future works.",https://pubmed.ncbi.nlm.nih.gov/40039113/,https://pubmed.ncbi.nlm.nih.gov/40039113/,English,Include,,EEG-based Estimation of Cognitive Workload Across Multiple Tasks.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:40039110,pubmed:40039110,PubMed,pubmed:40039110,Unsupervised Hybrid Deep Feature Encoder for Robust Feature Learning from Resting-State EEG Data.,Yuan Yue;Jeremiah D Deng;Tapabrata Chakraborti;Dirk De Ridder;Patrick Manning,2024,10.1109/embc53108.2024.10781741,"EEG classification is a challenging task due to the nonstationary nature of EEG data and the covariance shift induced by cross-subject variance. Recently, various machine learning and deep learning models have been developed to learn robust features for inter-subject EEG classification tasks. However, current existing models are designed based on active task-related EEG, with a lack of investigation into learning robust feature representation from resting-state EEG data. Given the differences in the nature of brain activities captured by resting-state and active task-related EEG, existing models might not be applicable to resting-state EEG. This study proposed an unsupervised hybrid deep feature encoder to learn robust feature representation in resting-state EEG data. It involves using a Variational Autoencoder (VAE) to learn latent feature representation, followed by a further feature selection conducted through a non-task-related sample-level proximity classification using K-means clustering. We demonstrate the efficiency of our proposed model through significantly improved classification accuracies compared to benchmark models, as well as the high between-subject separability manifested by the learned feature representation.",https://pubmed.ncbi.nlm.nih.gov/40039110/,https://pubmed.ncbi.nlm.nih.gov/40039110/,English,Include,,Unsupervised Hybrid Deep Feature Encoder for Robust Feature Learning from Resting-State EEG Data.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40039096,pubmed:40039096,PubMed,pubmed:40039096,Improving inner speech decoding by hybridisation of bimodal EEG and fMRI data.,Scott Wellington;Holly Wilson;Foteini Simistira Liwicki;Vibha Gupta;Rajkumar Saini;Kanjar De;Nosheen Abid;Sumit Rakesh;Johan Eriksson;Oliver Watts;Xi Chen;Damien Coyle;Mohammad Golbabaee;Michael J Proulx;Marcus Liwicki;Eamonn O'Neill;Benjamin Metcalfe,2024,10.1109/embc53108.2024.10781692,"Decoding inner speech from the brain via the hybridisation of fMRI and EEG data is explored to investigate the performance benefits over unimodal models. Two different fusion approaches are examined: concatenation of probability vectors from unimodal fMRI and EEG machine learning models, and data fusion with feature engineering. Same-task inner speech data are recorded from four participants, and different processing strategies are compared and contrasted to previously-employed hybridisation efforts. Data across participants are discovered to encode different underlying structures, which correlates to decoding performances between subject-dependent fusion models. For all participants, the performance of inner speech decoding models is shown to improve when pursuing bimodal fMRI-EEG fusion strategies, with an average increase of 6.025% accuracy on an 8-word classification task across two semantic categories.",https://pubmed.ncbi.nlm.nih.gov/40039096/,https://pubmed.ncbi.nlm.nih.gov/40039096/,English,Include,,Improving inner speech decoding by hybridisation of bimodal EEG and fMRI data.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:40039093,pubmed:40039093,PubMed,pubmed:40039093,Contrastive Self-supervised EEG Representation Learning for Emotion Classification.,Keya Hu;Ren-Jie Dai;Wen-Tao Chen;Hao-Long Yin;Bao-Liang Lu;Wei-Long Zheng,2024,10.1109/embc53108.2024.10781579,"Self-supervised learning provides an effective approach to leverage a large amount of unlabeled data. Numerous previous studies have indicated that applying self-supervision to physiological signals can yield better representations of the signals. In the paper, we aim to apply this method to the crucial field of emotion recognition. We perform the experiment with several state-of-the-art contrastive self-supervised methods to explore their effectiveness in pre-training feature encoders on raw electroencephalography (EEG) signals and fine-tuning the pre-trained encoders on the downstream emotion classification tasks. We attempt to vary the proportion of labeled data used during fine-tuning and find that the improvement from self-supervised methods is more pronounced when the proportion of labeled data is small. Additionally, we explore the transferability of the feature encoders pre-trained on various datasets and observe that most self-supervised methods exhibit a certain degree of transferability. Methods that effectively utilize the temporal information in EEG signals show superior stability, accuracy, and transferability.",https://pubmed.ncbi.nlm.nih.gov/40039093/,https://pubmed.ncbi.nlm.nih.gov/40039093/,English,Include,,Contrastive Self-supervised EEG Representation Learning for Emotion Classification.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40039083,pubmed:40039083,PubMed,pubmed:40039083,EEG Tensorization Enhances CNN-Based Outcome Classification in Comatose Patients Following a Cardiac Arrest.,R Teodoro Ors-Quixal;Samuel Ruiperez-Campillo;Francisco Castells-Ramon;Jose Millet,2024,10.1109/embc53108.2024.10782869,"Standard diagnostic methods for evaluating the severity of brain injuries resulting from cardiac arrest, such as the Glasgow Coma Scale, exhibit subjective biases that lead to potentially fatal misclassifications, where life-support systems are prematurely withdrawn from patients who might otherwise recover. This study utilizes an open dataset from the International Cardiac Arrest Research Consortium to develop and evaluate a 3D convolutional neural network (CNN) model for classifying outcomes in comatose patients after cardiac arrest. The electroencephalographic (EEG) signals from the dataset are preprocessed by resampling, filtering, and standardizing signal length (10 seconds) and channel count. The model's architecture comprises 3D convolutional neural networks with subsequent layers for vectorization, compression, and further automatic feature extraction. Evaluation metrics focus on the area under the receiver operating characteristic curve, confusion matrix, accuracy, and F1 score. Results show that the 3D-CNN model outperforms existing 2D-CNN models in classifying outcomes for comatose patients, exhibiting a higher area under the receiver operating characteristic curve.",https://pubmed.ncbi.nlm.nih.gov/40039083/,https://pubmed.ncbi.nlm.nih.gov/40039083/,English,Include,,EEG Tensorization Enhances CNN-Based Outcome Classification in Comatose Patients Following a Cardiac Arrest.,Include,,"h subsequent layers for vectorization, compression, and further automatic feature extraction. Evaluation metrics focus on the area under the receiver operating characteristic curve, confusion matrix, accuracy, and F1 score. Results show that the 3D-CNN model outperforms existing 2D-CNN models in classifying outcomes for comatose patients, exhibiting a higher area under the receiver operating chara",,0.95,0.6,
pubmed:40039082,pubmed:40039082,PubMed,pubmed:40039082,Detecting Deepfakes with Super-Resolution EEG.,Ramzi Al-Sharawi;Hamza Athar;M Riyyan Khan;Usman Tariq;Fares Al Shargie;Abhinav Dhall;Hasan Al Nashash,2024,10.1109/embc53108.2024.10782476,"Electroencephalogram (EEG) signals play a crucial role as biomarkers of brain activity, providing valuable insights into neural processes. The spatial resolution of EEG, determined by the number of channels, is essential for obtaining a comprehensive understanding of brain functions. However, low-resolution EEG systems pose a significant challenge in capturing detailed brain processes. In this paper we propose a deep autoencoder structure that essentially takes in the information from low resolution (LR) 32 channels of EEG and outputs a super-resolution (SR) 63 channel EEG signal. Our proposed approach, draws its inspiration from image super-resolution literature, and greatly improves on traditional interpolation approaches such as bilinear interpolation, with a 74.69% reduction in mean-squared error (MSE), 27.70% increase in correlation, and 25.19% increase in peak signal-to-noise (PSNR) ratio. Furthermore, the resulting LR, SR, and original high resolution (HR) signals were used within a Naive Bayes for deepfake classification; this yielded similar SR and HR classification results (61.13% and 62.21%, respectively), whereas the LR classification lagged behind both, with an average accuracy of 58.35%. This serves as a proof-of-concept for generating higher resolution EEG from low resolution data to channels as high as 63 with a simple autoencoder based structure, with application to deepfake detection.",https://pubmed.ncbi.nlm.nih.gov/40039082/,https://pubmed.ncbi.nlm.nih.gov/40039082/,English,Include,,Detecting Deepfakes with Super-Resolution EEG.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40039051,pubmed:40039051,PubMed,pubmed:40039051,Self-Supervised Transformer Model Training for a Sleep-EEG Foundation Model.,Mattson Ogg;William G Coon,2024,10.1109/embc53108.2024.10782281,"The American Academy of Sleep Medicine (AASM) recognizes five sleep/wake states (Wake, N1, N2, N3, REM), yet this classification schema provides only a high-level summary of sleep and likely overlooks important neurological or health information. New, data-driven approaches are needed to more deeply probe the information content of sleep signals. Here we present a self-supervised approach that learns the structure embedded in large quantities of neurophysiological sleep data. This masked transformer training procedure is inspired by high performing self-supervised methods developed for speech transcription. We show that self-supervised pre-training matches or outperforms supervised sleep stage classification, especially when labeled data or compute-power is limited. Perhaps more importantly, we also show that our pre-trained model is flexible and can be fine-tuned to perform well on new EEG recording montages not seen in training, and for new tasks including distinguishing individuals or quantifying ""brain age"" (a potential health biomarker). This suggests that modern methods can automatically learn information that is potentially overlooked by the 5-class sleep staging schema, laying the groundwork for new sleep scoring schemas and further data-driven exploration of sleep.",https://pubmed.ncbi.nlm.nih.gov/40039051/,https://pubmed.ncbi.nlm.nih.gov/40039051/,English,Include,,Self-Supervised Transformer Model Training for a Sleep-EEG Foundation Model.,Include,,rmation content of sleep signals. Here we present a self-supervised approach that learns the structure embedded in large quantities of neurophysiological sleep data. This masked transformer training procedure is inspired by high performing self-supervised methods developed for speech transcription. We show that self-supervised pre-training matches or outperforms supervised sleep stage classificati,,0.95,0.6,
pubmed:40039043,pubmed:40039043,PubMed,pubmed:40039043,Effective diagnosis of sleep disorders using EEG and EOG signals.,Ritika Jain;Ramakrishnan Angarai Ganesan,2024,10.1109/embc53108.2024.10782470,"This work focuses on the diagnosis of various sleep disorders such as insomnia, narcolepsy, periodic leg movement, nocturnal frontal lobe epilepsy, bruxism, REM behavior disorder, and sleep-disordered breathing. We utilize SVM for classifying each of the sleep disorders from healthy controls. The proposed approach is evaluated on the publicly available CAP dataset comprising 108 overnight recordings from healthy controls and patients with sleep disorders. A single feature called gridded distribution entropy derived from Poincaré plots of EEG signal provides 100% accuracy in distinguishing healthy controls from each pathology, except insomnia and PLM. With the EOG channel, we are able to classify these two groups as well with 100% accuracy, demonstrating the effectiveness of EOG in disambiguating insomnia and PLM from controls.Clinical relevance- Diagnosis of sleep disorders is important to facilitate appropriate treatment. It is challenging due to the diverse nature and inter-subject variation of the physiological symptoms. Automated sleep disorder detection can improve cost efficiency and reduce variability.",https://pubmed.ncbi.nlm.nih.gov/40039043/,https://pubmed.ncbi.nlm.nih.gov/40039043/,English,Include,,Effective diagnosis of sleep disorders using EEG and EOG signals.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40039033,pubmed:40039033,PubMed,pubmed:40039033,Diagnosis of schizophrenia using an extended multivariate autoregressive model for EEGs.,Ali Torabi;James Reilly;Duncan MacCrimmon,2024,10.1109/embc53108.2024.10782941,"Schizophrenia is a complex brain disorder that leads to an abnormal interpretation of reality. One of its reliable biological markers is the auditory evoked potential P300. The aim of the current paper is to classify healthy-control subjects from schizophrenic patients using EEG signals collected during an auditory oddball paradigm. The electroencephalogram (EEG) is modeled by a multivariate autoregressive (MVAR) model that takes into account the instantaneous causality between the EEG channels. After preprocessing, 19 channels of the recorded signals were divided into seven clusters based on their location. Next, the PCA technique was employed to obtain the first principal component inside each cluster. By imposing realistic constraints to estimate instantaneous effects between the variables, the instantaneous interactions matrix and, consequently, the extended multivariate autoregressive (eMVAR) model were estimated. Then, extended partial directed coherences (ePDCs) were extracted as connectivity features. The mRMR algorithm was utilized to reduce the feature dimension, and finally, the selected features were imported into a deep neural network for classification between healthy and schizophrenic states. The results showed that the eMVAR model outperformed the strictly causal model in classifying schizophrenic patients. With eMVAR modeling, an accuracy of 91.11% was obtained by using only four features. Furthermore, the most discriminative connectivity feature was ePDC from left posterior (LP) to (LP), and the most informative frequency band was the gamma sub-band. We have therefore presented evidence that the proposed approach enhances the characterization and diagnosis of schizophrenia.",https://pubmed.ncbi.nlm.nih.gov/40039033/,https://pubmed.ncbi.nlm.nih.gov/40039033/,English,Include,,Diagnosis of schizophrenia using an extended multivariate autoregressive model for EEGs.,Include,," classification between healthy and schizophrenic states. The results showed that the eMVAR model outperformed the strictly causal model in classifying schizophrenic patients. With eMVAR modeling, an accuracy of 91.11% was obtained by using only four features. Furthermore, the most discriminative connectivity feature was ePDC from left posterior (LP) to (LP), and the most informative frequency ban",,0.95,0.6,
pubmed:40039013,pubmed:40039013,PubMed,pubmed:40039013,Classification of Emerging Neural Activity from Planning to Grasp Execution using a Novel EEG-Based BCI Platform.,Anna Cetera;Ali Rabiee;Sima Ghafoori;Yalda Shahriari;Reza Abiri,2024,10.1109/embc53108.2024.10782523,"There have been different reports of developing Brain-Computer Interface (BCI) platforms to investigate the noninvasive electroencephalography (EEG) signals associated with plan-to-grasp tasks in humans. However, these reports were unable to clearly show evidence of emerging neural activity from the planning (observation) phase - dominated by the vision cortices - to grasp execution - dominated by the motor cortices. In this study, we developed a novel vision-based-grasping BCI platform that distinguishes different grip types (power and precision) through the phases of plan-to-grasp tasks using EEG signals. Using our platform and extracting features from Filter Bank Common Spatial Patterns (FBCSP), we show that frequency-band specific EEG contains discriminative spatial patterns present in both the observation and movement phases. Support Vector Machine (SVM) classification (power vs precision) yielded high accuracy percentages of 74% and 68% for the observation and movement phases in the alpha band, respectively.",https://pubmed.ncbi.nlm.nih.gov/40039013/,https://pubmed.ncbi.nlm.nih.gov/40039013/,English,Include,,Classification of Emerging Neural Activity from Planning to Grasp Execution using a Novel EEG-Based BCI Platform.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40038999,pubmed:40038999,PubMed,pubmed:40038999,Advancing Brain-Computer Interface Systems: Asynchronous Classification of Error Potentials.,Andrea Farabbi;Luca Mainardi,2024,10.1109/embc53108.2024.10782785,"This paper explores the paradigm shift in the classification of Error-Related Potentials (ErrP) in Brain-Computer Interfaces (BCIs) by introducing an asynchronous approach. Traditional synchronous methods, relying on precise temporal alignment between stimuli presentation and neural responses, face challenges in real-world scenarios with human response variability.The proposed asynchronous classification liberates BCI systems from strict temporal constraints, allowing for a more natural interaction paradigm. The study introduces an innovative ensemble method comprising Linear Discriminant Analysis (LDA) and EEGNet for asynchronous ErrP classification.The method is evaluated on EEG data from the BNCI Horizon 2020 dataset, demonstrating high balanced accuracy. While the introduction of EEGNet refines the classification, reducing false positives, challenges persist in achieving a balanced trade-off between precision and recall.The findings suggest the ensemble method's potential for practical applications, emphasizing the need for further refinement and exploration of advanced techniques in asynchronous ErrP classification.",https://pubmed.ncbi.nlm.nih.gov/40038999/,https://pubmed.ncbi.nlm.nih.gov/40038999/,English,Include,,Advancing Brain-Computer Interface Systems: Asynchronous Classification of Error Potentials.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40038985,pubmed:40038985,PubMed,pubmed:40038985,Utilizing Motor-Imagery Brain-Computer Interfaces for the Assessment of Developmental Coordination Disorder in Children.,Kuan-Yi Lee;Kong-Yi Chang;Hao-Che Hsu;Yu-Ting Tseng;Chun-Shu Wei;Shih-Syun Lin;Chun-Hsiang Chuang,2024,10.1109/embc53108.2024.10781534,"Developmental Coordination Disorder (DCD) is a neurodevelopmental disorder characterized by significant motor difficulties that affect daily life. Current assessment methods primarily focus on behavioral analysis, lacking in neuroscientific metrics for a comprehensive evaluation. This study introduced an electroencephalography-based motor imagery brain-computer interface classification system for evaluating children with DCD. A key of this system was the implementation of entropy-based data screening, which markedly enhanced classification performance. Notably, using mu band power in a support vector machine achieved an accuracy rate of 79.0%. These findings pave the way for developing a tool that could assist professionals in identifying children potentially affected by DCD.",https://pubmed.ncbi.nlm.nih.gov/40038985/,https://pubmed.ncbi.nlm.nih.gov/40038985/,English,Include,,Utilizing Motor-Imagery Brain-Computer Interfaces for the Assessment of Developmental Coordination Disorder in Children.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40038966,pubmed:40038966,PubMed,pubmed:40038966,EEG-based Emotion Recognition using Graph Attention Network with Dual-Branch Attention Module.,Cheng Li;Sio Hang Pun;Jia Wen Li;Fei Chen,2024,10.1109/embc53108.2024.10782334,"EEG reveals human brain activities for emotion and becomes an important aspect of affective computing. In this study, we developed a novel approach, namely DAM-GAT, which incorporated a dual-branch attention module (DAM) into a graph attention network (GAT) for EEG-based emotion recognition. This method used the GAT to capture the local features of emotional EEG signals. To enhance the important EEG features for emotion recognition, the proposed method also included a DAM that calculated weights considering both channel and frequency information. Additionally, the relationship between EEG channels was determined using the phase-locking value (PLV) connectivity of corresponding EEG signals. Based on the SEED datasets, the proposed approach provided an accuracy of up to 94.63% for emotion recognition, demonstrating its impressive performance compared with other existing methods.",https://pubmed.ncbi.nlm.nih.gov/40038966/,https://pubmed.ncbi.nlm.nih.gov/40038966/,English,Include,,EEG-based Emotion Recognition using Graph Attention Network with Dual-Branch Attention Module.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40038965,pubmed:40038965,PubMed,pubmed:40038965,Ranking the Importance of Spatiotemporal Windows of EEG Signals Results in a Better Alzheimer's Disease Prediction.,Ronen Taub;Yonatan Savir,2024,10.1109/embc53108.2024.10781589,"The integration of Electroencephalogram (EEG) measurements with machine learning holds the promise of enhancing diagnostic accuracy and providing personalized insights into the progression of neurodegenerative diseases (NDs) and Alzheimer's disease (AD) in particular. The complex nature of EEG signals, influenced by individual variability and noise, poses difficulties in interpreting the rich and dynamic embedded information, thus requiring algorithms capable of discerning meaningful patterns. In this work, we develop a novel approach for ranking the importance of spatiotemporal EEG information based on the Smart Aggregation Framework (SAF) framework in which each spatiotemporal window is weighted non-linearly using the Boltzmann distribution with a hyperparameter, analogous to temperature. We validate our model on a dataset that includes EEG recordings of 65 healthy and AD subjects. We rank the significant spatiotemporal windows for each subject and show that the features of the top-ranked windows provide significant separability between the AD and healthy subjects. We determine the most significant electrode and show that taking only the top two electrodes provides a better classification of the AD patients compared with taking all the electrodes or a random pair. Besides providing cutting-edge accuracy in classifying AD, our work provides an interpretability framework for ranking spatiotemporal information in EEG signals that can be harnessed to enhance the diagnostics of other neurodegenerative conditions.",https://pubmed.ncbi.nlm.nih.gov/40038965/,https://pubmed.ncbi.nlm.nih.gov/40038965/,English,Include,,Ranking the Importance of Spatiotemporal Windows of EEG Signals Results in a Better Alzheimer's Disease Prediction.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40038942,pubmed:40038942,PubMed,pubmed:40038942,Wavelet Analysis of Noninvasive EEG Signals Discriminates Complex and Natural Grasp Types.,Ali Rabiee;Sima Ghafoori;Anna Cetera;Yalda Shahriari;Reza Abiri,2024,10.1109/embc53108.2024.10782674,"This research aims to decode hand grasps from Electroencephalograms (EEGs) for dexterous neuroprosthetic development and Brain-Computer Interface (BCI) applications, especially for patients with motor disorders. Particularly, it focuses on distinguishing two complex natural power and precision grasps in addition to a neutral condition as a no-movement condition using a new EEG-based BCI platform and wavelet signal processing. Wavelet analysis involved generating time-frequency and topographic maps from wavelet power coefficients. Then, by using machine learning techniques with novel wavelet features, we achieved high average accuracies: 85.16% for multiclass, 95.37% for No-Movement vs Power, 95.40% for No-Movement vs Precision, and 88.07% for Power vs Precision, demonstrating the effectiveness of these features in EEG-based grasp differentiation. In contrast to previous studies, a critical part of our study was permutation feature importance analysis, which highlighted key features for grasp classification. It revealed that the most crucial brain activities during grasping occur in the motor cortex, within the alpha and beta frequency bands. These insights demonstrate the potential of wavelet features in real-time neuroprosthetic technology and BCI applications.",https://pubmed.ncbi.nlm.nih.gov/40038942/,https://pubmed.ncbi.nlm.nih.gov/40038942/,English,Include,,Wavelet Analysis of Noninvasive EEG Signals Discriminates Complex and Natural Grasp Types.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40038936,pubmed:40038936,PubMed,pubmed:40038936,Functional Graph Image Representation applied to EEG-based Mental Workload Classification.,Maria Sarkis;Mira Rizkallah;Said Moussaoui,2024,10.1109/embc53108.2024.10781733,"A lot of research has been lately dedicated to develop machine learning and statistical signal processing methods exploiting graph representations to solve inference and estimation problems. This is particularly relevant in the case of functional connectivity analysis from Electroencephalography (EEG) signals. However, the widely adopted functional connectivity metrics are hand-crafted, and thus suffer from the redundant and sometimes irrelevant information due to the volume conduction problem. Besides, the actual locations of the nodes (i.e. the electrodes) in the functional graph are often overlooked. In this work, we introduce an innovative approach leveraging the image representation of functional graphs learned from EEG signals under sparsity and structural constraints, where both the locations of the electrodes and a sparse functional connectivity learned from data are explicitly encoded. The resulting images are then fed to a convolutional neural network to extract meaningful latent features prior to inference. The proposed method is applied to Mental Workload (MW) classification. Experimental results on a public dataset demonstrate promising performance compared to state-of-the-art spatial filtering techniques and those based on hand-crafted functional connectivities.",https://pubmed.ncbi.nlm.nih.gov/40038936/,https://pubmed.ncbi.nlm.nih.gov/40038936/,English,Include,,Functional Graph Image Representation applied to EEG-based Mental Workload Classification.,Include,,A lot of research has been lately dedicated to develop machine learning and statistical signal processing methods exploiting graph representations to solve inference and estimation problems. This is particularly relevant in the case of functional connectivity analysis from Electroencephalography,,0.95,0.6,
pubmed:40031523,pubmed:40031523,PubMed,pubmed:40031523,SS-MSDA: Streamlined Sample-level Multi-source Domain Adaptation for EEG Emotion Recognition.,Jiaheng Wang;Zhenyu Wang;Tianheng Xu;Ting Zhou;Xi Zhao;Honglin Hu,2024,10.1109/embc53108.2024.10781531,"Affective EEG-based Brain-Computer Interface (BCI) offers extensive prospects. Yet, it grapples with notable challenges in consistently achieving accurate emotion recognition among new subjects. Mitigating this matter, Multi-Source Domain Adaptation (MSDA) has been advanced. However, they exhibit performance that falls short of expectations, necessitate complex preparations and lack solid theoretical underpinnings. Concerning these insufficiencies, we propose an innovative MSDA algorithm, effectively narrowing the Wasserstein Distance between identified subdomain and the target domain, thereby theoretically constraining the upper bound of emotion classification error. Compared with baseline model on the emotional EEG dataset SEED,SS-MSDA achieved an increase in recognition accuracy ranging from 1",https://pubmed.ncbi.nlm.nih.gov/40031523/,https://pubmed.ncbi.nlm.nih.gov/40031523/,English,Include,,SS-MSDA: Streamlined Sample-level Multi-source Domain Adaptation for EEG Emotion Recognition.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40031516,pubmed:40031516,PubMed,pubmed:40031516,HeteroEEG: A Dual-Branch Spatial-Spectral-Temporal Heterogeneous Graph Network for EEG Classification.,Zanhao Fu;Huaiyu Zhu;Ruohong Huan;Yi Zhang;Shuohui Chen;Yun Pan,2024,10.1109/embc53108.2024.10781679,"Given the non-Euclidean topology inherent in electroencephalogram (EEG) electrode configurations, graph-based approaches, particularly graph neural networks, have shown notable success across diverse EEG classification tasks. However, since the cerebral cortex lobes function individually and/or collaboratively across diverse tasks, there exist substantial differences between intra-lobe and inter-lobe brain intrinsic functional connectivity. Existing graph networks for EEG classification are based on homogeneous graphs, yet the nature of the cerebral cortex aligns more closely with a heterogeneous graph structure. To this end, we propose HeteroEEG for EEG classification, which to the best of our knowledge is the first to reframe the challenge of exploring EEG spatial information, especially decoupling different types of brain lobes and functional connections, as heterogeneous graph reasoning. Specifically, HeteroEEG is designed to be a dual-branch network aware of spatial, spectral, and temporal EEG features. Experimental results justify the superiority of HeteroEEG in pain and emotion recognition compared with other state-of-the-art studies. The heterogeneous graph construction of HeteroEEG may shed light on future graph-based EEG classification network design.",https://pubmed.ncbi.nlm.nih.gov/40031516/,https://pubmed.ncbi.nlm.nih.gov/40031516/,English,Include,,HeteroEEG: A Dual-Branch Spatial-Spectral-Temporal Heterogeneous Graph Network for EEG Classification.,Exclude,No performance metrics reported,No metrics found in full text,,0.9,0.6,
pubmed:40031514,pubmed:40031514,PubMed,pubmed:40031514,Bi-Stream Adaptation Network for Motor Imagery Decoding.,Zikai Wang;Ang Li;Zhenyu Wang;Ting Zhou;Tianheng Xu;Honglin Hu,2024,10.1109/embc53108.2024.10782480,"Neural activities in distinct brain regions variably contribute to the formation of motor imagery (MI). Utilizing the hidden contextual information can thereby enhance network performance by having a comprehensive understanding of MI. Besides, due to the non-stationarity of EEG, the global and local distributions of cross-session EEG from an individual vary in applications. Based on these ideas, a novel Bi-Stream Adaptation Network (BSAN) is proposed to generate multi-scale context dependencies and to bridge the cross-session discrepancies in MI classification. Specifically, a Bi-attention module is proposed to cultivate multi-scale temporal dependencies and figure out the predominant brain regions. After features extraction, a Bi-discriminator is trained to implement the task of domain adaptation both globally and locally. To validate the proposed BSAN, extensive experiments were conducted based on two public MI datasets. The results revealed that the proposed BSAN improved the performance and robustness of MI classification and outperformed several state-of-the-art methods.",https://pubmed.ncbi.nlm.nih.gov/40031514/,https://pubmed.ncbi.nlm.nih.gov/40031514/,English,Include,,Bi-Stream Adaptation Network for Motor Imagery Decoding.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40031513,pubmed:40031513,PubMed,pubmed:40031513,Narrowband-Enhanced Method for Improving Frequency Recognition in SSVEP-BCIs.,Ruxue Li;Xi Zhao;Zhenyu Wang;Guiying Xu;Honglin Hu;Ting Zhou;Tianheng Xu,2024,10.1109/embc53108.2024.10782374,"Steady-state visual evoked potential (SSVEP)-based brain-computer interfaces (BCI) provide a non-invasive and effective means for communication and control, which fundamentally rely on the feature of frequency information. However, filter banks in conventional spatial filter classification methods do not effectively utilize narrowband information. This study proposed a narrowband-enhanced filter bank canonical correlation analysis (NE-FBCCA) to integrate narrowband signal processing with a broadband filter bank analysis. By employing adaptive signal decomposition via multivariate fast iterative filtering (MvFIF), the specific component corresponding to the stimulus frequency can be strengthened separately. To validate the efficacy of this method, we conducted a performance evaluation using public SSVEP datasets. The results demonstrate a notable enhancement of reconstructed EEG signals in the signal-to-noise ratio (SNR) of stimulus frequency responses. Furthermore, there are significant improvements observed in classification accuracy and ITRs when compared to standard canonical correlation analysis (CCA) and filter bank CCA (FBCCA) approaches. This study provides a narrowband signal processing strategy for SSVEP responses and shows its potential to improve the performance of SSVEP-based BCI systems.",https://pubmed.ncbi.nlm.nih.gov/40031513/,https://pubmed.ncbi.nlm.nih.gov/40031513/,English,Include,,Narrowband-Enhanced Method for Improving Frequency Recognition in SSVEP-BCIs.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40031504,pubmed:40031504,PubMed,pubmed:40031504,A Method of Cross-Subject Transfer Learning for Ultra Short Time SSVEP Classification.,Hongzhuo Kang;Naqin Bao;Huanzi Liu;Chaoyi Dong;Dongyang Lei;Xiaoyan Chen,2024,10.1109/embc53108.2024.10782593,"The steady-state visual evoked potentials (SSVEP) based brain-computer interfaces (BCIs) require extensive training data for efficient classification, but existing algorithms struggle with ultra short time inputs (less than 0.2 seconds), limiting the feasibility of real-time systems. This paper proposes a novel method CSA-GSDANN consisting of CSA and GSDANN. GSDANN improves SSVEP feature extraction performance in ultra short time input scenarios by applying cross-subject transfer learning techniques, combining a Global Attention Mechanism (GAM) and an optimized SSVEPNet and pre-training method CSA selects the most suitable source subject based on accuracy and aligns it with the target subject to address the inter-subject variability. The proposed CSA-GSDANN method adopts a Domain Adversarial Neural Network (DANN) framework, which integrates an enhanced SSVEPNet algorithm with an attention mechanism to extract features from electroencephalogram (EEG) data within and across subjects. The extracted features undergo domain-adversarial transfer learning. The final stage involves frequency signal classification using a constrained convolutional network. The evaluation of the CSA-GSDANN method on the IMUT dataset containing 12 subjects shows significant improvements. A comparative analysis against eight mainstream deep learning and traditional algorithms demonstrates an average accuracy enhancement of 4.23% and an average Information Transfer Rate (ITR) improvement of 50.482 bits/min compared to state-of-the-art classification algorithms under short time (0.2s) EEG inputs, substantially improving SSVEP classification performance.",https://pubmed.ncbi.nlm.nih.gov/40031504/,https://pubmed.ncbi.nlm.nih.gov/40031504/,English,Include,,A Method of Cross-Subject Transfer Learning for Ultra Short Time SSVEP Classification.,Include,,"plying cross-subject transfer learning techniques, combining a Global Attention Mechanism (GAM) and an optimized SSVEPNet and pre-training method CSA selects the most suitable source subject based on accuracy and aligns it with the target subject to address the inter-subject variability. The proposed CSA-GSDANN method adopts a Domain Adversarial Neural Network (DANN) framework, which integrates an",,0.95,0.6,
pubmed:40031501,pubmed:40031501,PubMed,pubmed:40031501,A Dynamic Evaluation-Denoising Network for Motion Artifacts Removal from Single-Channel EEG.,Zhe Li;Kecheng Shi;Wenjiang Li;Fengjun Mu;Jingting Zhang;Rui Huang;Hong Cheng,2024,10.1109/embc53108.2024.10782860,"Brain-computer interfaces (BCIs) have gained significant attention in rehabilitation research as a critical step in investigating neural remodeling techniques. However, most existing methods usually overlook the randomness and diversity of motion artifacts, thereby lacking the desired generalization ability and denoising precision, which limits their practical application. To address these limitations, we propose a Dynamic Evaluation Denoising Network (DED-Net) that incorporates an evaluation model with cross-domain feature fusion for artifact detection and classification. Then dynamically selecting Bidirectional Long Short-Term Memory (Bi-LSTM) networks with varying parameters for artifact removal, which achieves superior performance compared to state-of-the-art methods. Our experiment on a semi-simulated dataset constructed by EEGdenoiseNET demonstrates that the performance of DED-Net is advanced over the state-of-the-art method, i.e., SDNet, in terms of the signal-to-noise rate (SNR) and correlation coefficient (CC). Using our method, SNR and CC are 6.0597 dB and 95.28%, respectively increasing by 20.48% and 3.15%. Experiments on real EEG data demonstrate the superior performance of the proposed method in reconstructing EEG signals, in terms of the intent recognition tasks, achieving a remarkable accuracy of 88.89%, outperforming other methods.",https://pubmed.ncbi.nlm.nih.gov/40031501/,https://pubmed.ncbi.nlm.nih.gov/40031501/,English,Include,,A Dynamic Evaluation-Denoising Network for Motion Artifacts Removal from Single-Channel EEG.,Include,,"48% and 3.15%. Experiments on real EEG data demonstrate the superior performance of the proposed method in reconstructing EEG signals, in terms of the intent recognition tasks, achieving a remarkable accuracy of 88.89%, outperforming other methods.",,0.95,0.6,
pubmed:40031491,pubmed:40031491,PubMed,pubmed:40031491,Cross-subject EEG-based Motor Imagery Recognition for Patient's Rehabilitation.,Yalan Ye;Xinxin Mu;Tongjie Pan;Yuxiang Li;Lin Wei;Xiaoli Fan;Lan Wei,2024,10.1109/embc53108.2024.10782932,"Motor imagery (MI), a kind of psychological representation without actual action, has garnered increasing attention in rehabilitation. However, the inherent differences between patients and healthy persons hinder rehabilitation by reducing the accuracy of cross-subject MI recognition. Although unsupervised domain adaptation (UDA) methods have mitigated individual differences, they still suffer from challenges in terms of selecting confusing source domains and accurately classifying MI samples at the boundary. To address these challenges, we propose a novel UDA framework with a causal graphical model and label similarity clustering. The causal graphical model is employed to estimate the similarity of EEG signals, enabling the causal selection to effectively avoid confusing healthy persons' data. In addition, label similarity clustering mechanism is utilized to establish a distinct boundary, thereby enhancing the classification accuracy. The experimental results demonstrate that our approach outperforms baseline 10.10% and 16.27% on BCI IV-2a&2b, separately. MI is expected to aid rehabilitation through precise recognition and active support.",https://pubmed.ncbi.nlm.nih.gov/40031491/,https://pubmed.ncbi.nlm.nih.gov/40031491/,English,Include,,Cross-subject EEG-based Motor Imagery Recognition for Patient's Rehabilitation.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40031490,pubmed:40031490,PubMed,pubmed:40031490,Intended Speech Classification with EEG Signals Based on a Temporal Attention Mechanism: A Study of Mandarin Vowels.,Xinyu Wang;Ying-Hui Lai;Fei Chen,2024,10.1109/embc53108.2024.10782383,"Speech brain-machine interfaces (BCIs) offer an effective means for patients with voice disorders to communicate, and research on decoding electroencephalography (EEG) signals related to intended speech can help to understand the mechanisms of language production in the brain. This study classified the intended speech EEG signals of four Chinese vowels, utilizing a dataset collected from 10 participants. A proposed TA-EEGNet model was employed, incorporating a temporal attention module. The model achieved an accuracy of 49.47%, surpassing other prevalent EEG classification models. The average accuracy in the binary classification of vowels was 69.83%. The vowels /u/ and /ü/ were classified with the lowest accuracy, suggesting difficulties in classifying vowels with similar articulatory movements based on intended speech EEG signals. Furthermore, the research analyzed the classification performance using data of different brain regions. The results showed that the auditory cortex, Broca's and Wernicke's areas, prefrontal cortex, and motor cortex outperformed the sensory cortex, indicating their contributions in the intended speech process of Mandarin vowels. Results also showed left hemisphere dominance. These findings contribute to the study of the neural mechanisms underlying speech production and articulatory movements, emphasizing the potential of speech BCIs to improve communication for people with speech disorders.",https://pubmed.ncbi.nlm.nih.gov/40031490/,https://pubmed.ncbi.nlm.nih.gov/40031490/,English,Include,,Intended Speech Classification with EEG Signals Based on a Temporal Attention Mechanism: A Study of Mandarin Vowels.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:40031483,pubmed:40031483,PubMed,pubmed:40031483,Channel Stacking: A Rapid Classification Method for Parkinson's Disease Based on EEG Data.,Mingliang Zhang;Timo Hamalainen;Fengyu Cong;Hang Liu,2024,10.1109/embc53108.2024.10782619,"This study introduces a technique known as ""channel stacking,"" aimed at comprehensively representing electroencephalogram signals to identify Parkinson's disease accurately. This method combines information from multiple channels to prepare input signals for the model, enabling the deep learning architecture to capture information across all channels efficiently. For classification, a ResNet18 network is employed. Notably, the model achieves an accuracy of 96.43% with just 90 seconds of data per subject. This performance is validated through Leave-One-Subject-Out Cross-Validation, effectively simulating real-world scenarios. The experimental results highlight the robust detection performance of the proposed method on clinical datasets.",https://pubmed.ncbi.nlm.nih.gov/40031483/,https://pubmed.ncbi.nlm.nih.gov/40031483/,English,Include,,Channel Stacking: A Rapid Classification Method for Parkinson's Disease Based on EEG Data.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.25,cv_reported
pubmed:40031482,pubmed:40031482,PubMed,pubmed:40031482,"From Word Embedding to Reading Embedding Using Large Language Model, EEG and Eye-tracking.",Yuhong Zhang;Shilai Yang;Gert Cauwenberghs;Tzyy-Ping Jung,2024,10.1109/embc53108.2024.10781627,"Reading comprehension, a fundamental cognitive ability essential for knowledge acquisition, is a complex skill, with a notable number of learners lacking proficiency in this domain. This study introduces innovative tasks for Brain-Computer Interface (BCI), predicting the relevance of words or tokens read by individuals to the target inference words. We use state-of-the-art Large Language Models (LLMs) to guide a new reading embedding representation in training. This representation, integrating EEG and eye-tracking biomarkers through an attention-based transformer encoder, achieved a mean 5-fold cross-validation accuracy of 68.7% across nine subjects using a balanced sample, with the highest single-subject accuracy reaching 71.2%. This study pioneers the integration of LLMs, EEG, and eye-tracking for predicting human reading comprehension at the word level. We fine-tune the pre-trained Bidirectional Encoder Representations from Transformers (BERT) model for word embedding, devoid of information about the reading tasks. Despite this absence of task-specific details, the model effortlessly attains an accuracy of 92.7%, thereby validating our findings from LLMs. This work represents a preliminary step toward developing tools to assist reading. The code and data are available in github.",https://pubmed.ncbi.nlm.nih.gov/40031482/,https://pubmed.ncbi.nlm.nih.gov/40031482/,English,Include,,"From Word Embedding to Reading Embedding Using Large Language Model, EEG and Eye-tracking.",Include,," reading embedding representation in training. This representation, integrating EEG and eye-tracking biomarkers through an attention-based transformer encoder, achieved a mean 5-fold cross-validation accuracy of 68.7% across nine subjects using a balanced sample, with the highest single-subject accuracy reaching 71.2%. This study pioneers the integration of LLMs, EEG, and eye-tracking for predicti",,0.95,0.25,cv_reported
pubmed:40031475,pubmed:40031475,PubMed,pubmed:40031475,EEG-Based Tension Recognition Annotated with Electrodermal Activity.,Wei Gu;Yun-Huan Li;Li-Ming Zhao;Wei-Long Zheng;Bao-Liang Lu,2024,10.1109/embc53108.2024.10782145,"The precise annotation of emotions is crucial for constructing emotion EEG datasets, where videos are the dominant emotion-inducing tools. However, existing annotation methodologies are often limited, assigning a uniform label to the entire video and neglecting subjects' emotional arousal variations during viewing. This paper proposes a novel approach to address this issue by integrating electrodermal activity (EDA), a psychophysiological marker of arousal, with EEG data. We introduce a new dataset that captures both tension and calmness, utilizing EDA to annotate EEG data with high and low arousal. The method is systematically tested in subject-specific paradigms, employing a suite of machine learning and deep learning algorithms. Our results demonstrate that models trained solely on highly induced EEG data, comprising 71.75% of the initial training set, yield equal or superior performance on test sets, regardless of their arousal levels. This underscores the potential of EDA in enhancing emotion recognition accuracy in EEG studies.",https://pubmed.ncbi.nlm.nih.gov/40031475/,https://pubmed.ncbi.nlm.nih.gov/40031475/,English,Include,,EEG-Based Tension Recognition Annotated with Electrodermal Activity.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40031471,pubmed:40031471,PubMed,pubmed:40031471,Electrical stimulation-based paradigm to enhance lower limb motor imagery: initial validation in stroke patients.,Zhuolan Gui;Yuan Liu;Shiyin Qiu;Yujian Zhang;Kailun Dong;Dong Ming,2024,10.1109/embc53108.2024.10782372,"Lower limb motor dysfunction is a prevalent complication of stroke that significantly impacts patients' quality of life. Current research indicates that motor imagery-based brain-computer interface (BCI-MI) training can assist stroke patients in enhancing motor function and reconstructing neural pathways. Nevertheless, 40% of stroke patients struggle with effective motor imagery (MI), leading to challenges in applying lower limb MI in clinical settings. Electrical stimulation (ES) has demonstrated the ability to induce muscle contractions, generating a kinesthetic illusion that effectively guides subjects in performing MI. However, the existing study lacks clarity regarding the effectiveness of the ES-MI paradigm in improving lower limb MI in stroke patients. To address this gap, we recruited seven stroke patients to participate in an experiment involving the ES-MI enhancement paradigm, aiming to validate its performance in stroke patients. The results revealed that the ES-MI paradigm augmented the activation of the motor cortex in the lower limb and reactivated dormant areas, suggesting that MI training based on the ES-MI paradigm holds promise for enhancing neural remodeling effects in stroke patients. Additionally, the paradigm enhanced the classification accuracy of SVM(+1.17%), KNN(+0.93%), RF(+7.13%), LDA(+5.29%), and EEGNet(+0.96%), indicating potential improvements in the efficiency and quality of human-robot interaction in brain-controlled lower limb rehabilitation robots.",https://pubmed.ncbi.nlm.nih.gov/40031471/,https://pubmed.ncbi.nlm.nih.gov/40031471/,English,Include,,Electrical stimulation-based paradigm to enhance lower limb motor imagery: initial validation in stroke patients.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40031469,pubmed:40031469,PubMed,pubmed:40031469,Enhancing Detection of SSVEP-based BCIs Using Adjacent Frequencies Fusion Method.,Wenhao Zhou;Xi Zhao;Ting Zhou;Zhenyu Wang;Tianheng Xu;Honglin Hu,2024,10.1109/embc53108.2024.10782332,"Brain-computer interfaces (BCIs) have emerged as transformative technologies, enabling direct communication between the human brain and external devices. Steady-state visual evoked potentials (SSVEP) have gained particular attention due to their potential in BCIs. Current decoding algorithms do not take advantage of the correlation coefficients of adjacent frequencies. We propose adjacent frequencies fusion filter bank canonical correlation analysis (AFF-FBCCA), which enhances accuracy and robustness by utilizing information from adjacent frequencies. This weighted fusion aims to capitalize on the inherent similarity between electroencephalogram (EEG) signals at closely spaced frequencies. The determination of weight coefficients, incorporating dynamic adjustments based on the time window, further contributes to the adaptability of AFF-FBCCA. The proposed method is validated using public benchmark datasets. The results show that AFF-FBCCA is always superior to standard FBCCA in terms of classification accuracy and information transfer rate (ITR) in all test time windows. This method maintains the advantage of training-free and provides a more accurate and user-friendly solution for SSVEP-based BCI.",https://pubmed.ncbi.nlm.nih.gov/40031469/,https://pubmed.ncbi.nlm.nih.gov/40031469/,English,Include,,Enhancing Detection of SSVEP-based BCIs Using Adjacent Frequencies Fusion Method.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40031464,pubmed:40031464,PubMed,pubmed:40031464,Adaptive Stepwise Feature Selection Approach for EEG-Based Epileptic Seizure Classification.,Sunday Timothy Aboyeji;Wenfang Zhou;Yuan Tao;Mingxing Zhu;Oluwarotimi Williams Samuel;Ijaz Ahmad;Guoru Zhao;Ji Yi;Michael Chi Fai Tong;Xin Wang;Yi Guo;Shixiong Chen,2024,10.1109/embc53108.2024.10782357,"Recent advancements in feature selection (FS) optimization algorithms have influenced the field of epileptic seizure classification. However, integrating these optimization algorithms into machine learning (ML) models often creates time complexity, limiting their clinical deployment. To address this issue, we propose an innovative adaptive stepwise FS method tailored for epileptic seizure detection (ESD). First, a discrete wavelet transform (DWT) was applied to the preprocessed signal to get three levels of the db4 wavelet family within the frequency range pertinent to epileptic seizure classification. Linear and nonlinear features are then extracted from each level of the DWT. The selected features are initially ranked using the minimum relevance, maximum redundancy (mRMR) FS technique. After that, a stepwise FS approach was applied to the ranked features to optimize the performance of Random Forest (RF), K-Nearest Neighbour (KNN), and Support Vector Machine (SVM) classifiers. The experiment was performed on a publicly accessible CHB-MIT dataset in a patient-independent approach. The model's performance was assessed using accuracy, sensitivity, and specificity. The results show an improved performance of the ML models with the integration of stepwise algorithm into the mRMR technique. Among the classifiers, RF exhibited superior performance with accuracy, sensitivity, and specificity of 87.69%, 91.53%, and 83.86%, respectively, when 12 features were selected. Our proposed stepwise feature selection method (PSFS) performs similarly to generalize forward feature selection (GFFS), with an average accuracy of 88.37% and 88.57%, respectively across selected features with less computation. This makes PSFS a very efficient and effective FS in epileptic seizure classification.",https://pubmed.ncbi.nlm.nih.gov/40031464/,https://pubmed.ncbi.nlm.nih.gov/40031464/,English,Include,,Adaptive Stepwise Feature Selection Approach for EEG-Based Epileptic Seizure Classification.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40031462,pubmed:40031462,PubMed,pubmed:40031462,A Novel SSVEP Modulation Method Utilizing VR-Based Binocular Vision.,Haifeng Liu;Zhengyu Wang;Ruxue Li;Xi Zhao;Tianheng Xu;Ting Zhou;Honglin Hu,2024,10.1109/embc53108.2024.10781783,"This paper presents a novel method for modulating steady-state visual evoked potentials (SSVEP) based on binocular vision in virtual reality (VR). The method involves displaying monocular frequencies in the left and right view of VR to encode nine binocular targets using only two frequencies. We constructed a VR-BCI system and validated the effectiveness of this binocular-encoded paradigm through the task-related component analysis (TRCA) algorithm, which is a supervised approach based on individual templates. The results showed a recognition accuracy of 79.05% and an information transfer rate (ITR) of 43.38 bits/min with a data length of 2 seconds. The electroencephalography (EEG) responses of the binocular combinations exhibited unique characteristics compared to traditional SSVEP, suggesting potential for further optimization in terms of performance. This proposed method reduces the frequency requirements for encoding SSVEP-speller and highlights the potential of VR-BCI in utilizing binocular characteristics, which could contribute to the practicality and high-speed implementation of SSVEP-based brain-computer interface (BCI) systems.",https://pubmed.ncbi.nlm.nih.gov/40031462/,https://pubmed.ncbi.nlm.nih.gov/40031462/,English,Include,,A Novel SSVEP Modulation Method Utilizing VR-Based Binocular Vision.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40031461,pubmed:40031461,PubMed,pubmed:40031461,Enhancing Word-Level Imagined Speech BCI Through Heterogeneous Transfer Learning.,Ang Li;Zhengyu Wang;Xi Zhao;Tianheng Xu;Ting Zhou;Honglin Hu,2024,10.1109/embc53108.2024.10782407,"In this study, we proposed a novel heterogeneous transfer learning approach named Focused Speech Feature Transfer Learning (FSFTL), aimed at enhancing the performance of electroencephalogram (EEG)-based word-level Imagined Speech (IS) Brain-Computer Interface (BCI). In IS BCI, the classification accuracy for imagining specific words is relatively low due to the inherent complexity in high-level feature variations. However, the binary classification accuracy for IS/rest is significantly higher. FSFTL leverages the refined feature focusing capability of the binary IS/Rest classification task to effectively locate relevant features for the word-level task. The feature extractor in the IS/Rest model demonstrates robust decoding ability for low-level IS features in EEG signals. We applied this high-performance yet low-resolution feature extractor to a public dataset for five-word IS task. The classifier was retrained to handle an increased number of classification categories, and the feature extractor was further fine-tuned to accommodate higher-level classification tasks. Before the experiment, we aligned the data from the two datasets to maintain the versatility of the feature extractor. Our proposed FSFTL approach was compared with existing EEG models, showing a significant improvement. The FSFTL approach outperformed the backbone strategy with a 6% increase in mean accuracy across all fifteen subjects. This study highlights the commonality of features in EEG data of IS and their transferability across various datasets and tasks, which is beneficial for improving the decoding ability of word-level IS BCI.",https://pubmed.ncbi.nlm.nih.gov/40031461/,https://pubmed.ncbi.nlm.nih.gov/40031461/,English,Include,,Enhancing Word-Level Imagined Speech BCI Through Heterogeneous Transfer Learning.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40031460,pubmed:40031460,PubMed,pubmed:40031460,CEBRA Method: Decoding Brain Activity for Advanced Brain-Computer Interface Technology.,Jingcheng Yang;Frank Kulwa;Xuanwei Liu;Yiqing Lu;Yufa Fu;Guanglin Li;Yaping Huai;Xin Zhang;Yongcheng Li,2024,10.1109/embc53108.2024.10782428,"The emerging neurorehabilitation technology, Brain-Computer Interface (BCI), provides a novel prospect for stroke recovery. However, decoding brain activity during the movement present substantial challenges, and feature extraction is crutial to build a better decoder. In this study the CEBRA method were employed to extract features first based on electroencephalogram(EEG) data during Motor Execution(ME) and Motor lmagery (Ml) tasks for 20 participants (including 10 stroke patients). The results revealed that, in MI tasks, CEBRA-RF (Random Forests) achieved an average classification accuracy of 91.33%, with an average F1-score of 91.19%, and CEBRA-SVM (Support Vector Machine) achieved an average classification accuracy of 91.32%, with an average F1-score of 90.83%. Compared to other conventional feature extraction methods, CEBRA shows significantly higher accuracy (t-test, p<0.01). However, in ME tasks, CEBRA-RF achieved an average classification accuracy of 75.67%, with an average F1-score of 75.39%, and CEBRA-SVM achieved an average classification accuracy of 76.13%, with an average F1-score of 75.80%. Nevertheless, no significant differences were observed compared to other feature extraction methods. These findings demonstrate the potential of CEBRA in decoding patients' brain activity. The results of this study hold promise in addressing the current challenges of low decoding accuracy in BCI systems, offering a new approach for designing BCI-assisted rehabilitation systems for stroke patients.",https://pubmed.ncbi.nlm.nih.gov/40031460/,https://pubmed.ncbi.nlm.nih.gov/40031460/,English,Include,,CEBRA Method: Decoding Brain Activity for Advanced Brain-Computer Interface Technology.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:40031456,pubmed:40031456,PubMed,pubmed:40031456,"An Attention-Based Hybrid Deep Learning Approach for Patient-Specific, Cross-Patient, and Patient-Independent Seizure Detection.",Ijaz Ahmad;Xin Wang;Lin Li;Zhenzhen Liu;Jun Huang;Sunday Timothy Aboyeji;Guanglin Li;Subhas Chandra Mukhopadhyay;Zhiyuan Liu;Guoru Zhao;Yi Guo;Shixiong Chen,2024,10.1109/embc53108.2024.10782346,"Automatic detection of epilepsy plays a crucial role in diagnosing and treatment of patients, while most current methods rely on patient-specific models and have shown promising results, which is not suitable for clinical application, especially when new patient data are used for diagnosis in EEG epileptic seizure detection (ESD). Therefore, the proposed study introduces a novel hybrid deep learning approach consisting of a one-dimensional convolutional neural network (1D CNN), a Multi-Long Short-Term Memory Network (MLSTM) with a multi-attention layer (MAT) for patient-specific, cross-patient, and patient-independent seizure detection. The 1D CNN model extracts spatial features, while the MLSTM extracts temporal features from segmented EEG data. Moreover, the MAT layer conducts feature fusion and identifies relevant patterns. Experiments conducted using the CHB-MIT EEG dataset confirm our method's superiority over other sibling and state-of-the-art methods by an average of 2% in classification accuracy, recall, specificity, and G.mean of using patient-specific, cross-patient, and patient-independent seizure detection, demonstrating a robust and effective framework in EEG ESD.",https://pubmed.ncbi.nlm.nih.gov/40031456/,https://pubmed.ncbi.nlm.nih.gov/40031456/,English,Include,,"An Attention-Based Hybrid Deep Learning Approach for Patient-Specific, Cross-Patient, and Patient-Independent Seizure Detection.",Include,,"dentifies relevant patterns. Experiments conducted using the CHB-MIT EEG dataset confirm our method's superiority over other sibling and state-of-the-art methods by an average of 2% in classification accuracy, recall, specificity, and G.mean of using patient-specific, cross-patient, and patient-independent seizure detection, demonstrating a robust and effective framework in EEG ESD.",,0.95,0.6,
pubmed:40031451,pubmed:40031451,PubMed,pubmed:40031451,EEG Emotion Recognition Based on 3D-CTransNet.,Hongtao Luo;Xi Zhao;Ting Zhou;Zhenyu Wang;Tianheng Xu;Honglin Hu,2024,10.1109/embc53108.2024.10782401,"Emotion recognition is of great significance for brain-computer interface and emotion computing, and EEG plays a key role in this field. However, the current design of brain computer interface deep learning model is faced with algorithmic or structural constraints, and it is difficult to recognize the complex features in EEG signals with long-term dynamic changes. To solve this issue, a hybrid CNN-Transformer structure using 3D data input is proposed and named 3D-CTransNet in this paper, which solves the problem of performance degradation of the traditional CNN-LSTM hybrid structure in the recognition of long sequence signals. At the same time, the self attention mechanism and parallel mode introduced by Transformer improve the recognition accuracy and processing speed. In addition, the 3D data feature map based on electrode position mapping effectively retains the spatial characteristics of EEG signals, which makes CNN better combine the time domain and spatial domain. Finally, the Valence-Arousal classification training of emotion is carried out on the public dataset DEAP, and the classification accuracy is 97.04%, which is about 5% higher than that of the hybrid CNN-LSTM model.",https://pubmed.ncbi.nlm.nih.gov/40031451/,https://pubmed.ncbi.nlm.nih.gov/40031451/,English,Include,,EEG Emotion Recognition Based on 3D-CTransNet.,Include,,"e traditional CNN-LSTM hybrid structure in the recognition of long sequence signals. At the same time, the self attention mechanism and parallel mode introduced by Transformer improve the recognition accuracy and processing speed. In addition, the 3D data feature map based on electrode position mapping effectively retains the spatial characteristics of EEG signals, which makes CNN better combine t",,0.95,0.6,
pubmed:40031447,pubmed:40031447,PubMed,pubmed:40031447,Random Subset Multi-domain Feature Extraction for Attentional State Recognition.,Guiying Xu;Zhenyu Wang;Honglin Hu;Xi Zhao;Ruxue Li;Ting Zhou;Tianheng Xu,2024,10.1109/embc53108.2024.10781618,"Existing attentional state recognition methods achieve good results by utilizing frequency domain features, but spatial information has not been fully considered. In this paper, a random subset multi-domain feature extraction method is proposed. To exploit the spatial information, the training data is first divided into several non-overlapping subsets, and independent Riemannian manifolds are constructed within each subset. Riemannian distances from the Riemannian means are extracted as the feature. Besides, frequency domain information is extracted using a filter bank while phase domain information is extracted using a Hilbert transform. Finally, Riemannian distances from Riemannian means are extracted from multi-domain EEG signals. The influence of different filter banks and various numbers of random subsets are validated in the experiments. The idea of the random subset is implemented in the minimum distance to the Riemannian mean method and the results show its effectiveness. The proposed method achieves superior results compared with existing methods in attentional state recognition with an accuracy of 92.25 ± 4.58%.",https://pubmed.ncbi.nlm.nih.gov/40031447/,https://pubmed.ncbi.nlm.nih.gov/40031447/,English,Include,,Random Subset Multi-domain Feature Extraction for Attentional State Recognition.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40030619,pubmed:40030619,PubMed,pubmed:40030619,A Systematic Review of Bimanual Motor Coordination in Brain-Computer Interface.,Poraneepan Tantawanich;Chatrin Phunruangsakao;Shin-Ichi Izumi;Mitsuhiro Hayashibe,2024,10.1109/tnsre.2024.3522168,"Advancements in neuroscience and artificial intelligence are propelling rapid progress in brain-computer interfaces (BCIs). These developments hold significant potential for decoding motion intentions from brain signals, enabling direct control commands without reliance on conventional neural pathways. Growing interest exists in decoding bimanual motor tasks, crucial for activities of daily living. This stems from the need to restore motor function, especially in individuals with deficits. This review aims to summarize neurological advancements in bimanual BCIs, encompassing neuroimaging techniques, experimental paradigms, and analysis algorithms. Thirty-six articles were reviewed, adhering to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. The literature search result revealed diverse experimental paradigms, protocols, and research directions, including enhancing the decoding accuracy, advancing versatile prosthesis robots, and enabling real-time applications. Notably, within BCI studies on bimanual movement coordination, a shared objective is to achieve naturalistic movement and practical applications with neurorehabilitation potential.",,https://pubmed.ncbi.nlm.nih.gov/40030619/,English,Exclude,Review/survey papers,A Systematic Review of Bimanual Motor Coordination in Brain-Computer Interface.,,,,,0.95,0.6,
pubmed:40030511,pubmed:40030511,PubMed,pubmed:40030511,Decoding Motor Excitability in TMS using EEG-Features: An Exploratory Machine Learning Approach.,Lisa Haxel;Oskari Ahola;Paolo Belardinelli;Maria Ermolova;Dania Humaidan;Jakob H Macke;Ulf Ziemann,2024,10.1109/tnsre.2024.3516393,"Brain state-dependent transcranial magnetic stimulation (TMS) holds promise for enhancing neuromodulatory effects by synchronizing stimulation with specific features of cortical oscillations derived from real-time electroencephalography (EEG). However, conventional approaches rely on open-loop systems with static stimulation parameters, assuming that pre-determined EEG features universally indicate high or low excitability states. This one-size-fits-all approach overlooks individual neurophysiological differences and the dynamic nature of brain states, potentially compromising therapeutic efficacy. We present a supervised machine learning framework that predicts individual motor excitability states from pre-stimulus EEG features. Our approach combines established biomarkers with a comprehensive set of spectral and connectivity measures, implementing multi-scale feature selection within a nested cross-validation scheme. Validation across multiple classifiers, feature sets, and experimental protocols in 50 healthy participants demonstrated a mean prediction accuracy of 71 ± 7%. Hierarchical clustering of top predictive EEG features revealed two distinct participant subgroups. The first subgroup, comprising approximately 50% of participants, showed predictive features predominantly in alpha and low-beta bands in sensorimotor regions of the stimulated hemisphere, aligning with traditional associations of motor excitability and the sensorimotor μ-rhythm. The second subgroup exhibited predictive features primarily in low and high gamma bands in parietal regions, suggesting that motor excitability is influenced by broader neural dynamics for these individuals. Our data-driven framework effectively identifies personalized motor excitability biomarkers, holding promise to optimize TMS interventions in clinical and research settings. Additionally, our approach provides a versatile platform for biomarker discovery and validation across diverse neuromodulation paradigms and brain signal classification tasks.",https://pubmed.ncbi.nlm.nih.gov/40030511/,https://pubmed.ncbi.nlm.nih.gov/40030511/,English,Include,,Decoding Motor Excitability in TMS using EEG-Features: An Exploratory Machine Learning Approach.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.45,cv_reported;small_sample_mentioned
pubmed:40030402,pubmed:40030402,PubMed,pubmed:40030402,Improving the Performance of Individually Calibrated SSVEP Classification by Rhythmic Entrainment Source Separation.,Wei Xu;Yufeng Ke;Dong Ming,2024,10.1109/tnsre.2024.3503772,"The supervised decoding algorithms of Steady-State Visual Evoked Potentials (SSVEP) have achieved remarkable performance with sufficient training data. However, these methods have typically failed to achieve acceptable performance in single-trial training scenarios. To address this challenge, we propose a method to enhance SSVEP classification performance using less training data by employing Rhythmic Entrainment Source Separation (RESS) to construct spatial filters. We evaluate RESS alongside other state-of-the-art methods using two distinct datasets to assess their effectiveness. Our results indicate that RESS significantly outperforms other advanced algorithms when trained with a single block of calibration data. Specifically, compared to task-related component analysis, the RESS-based method improves average classification accuracy by 49.81% and 59.06% on the two datasets using 1-second EEG segments. The RESS-based method can significantly improve SSVEP classification performance with limited training data. RESS holds promise for practical applications in SSVEP-based BCIs, offering a novel solution to reduce the calibration data requirements for individually calibrated systems.",https://pubmed.ncbi.nlm.nih.gov/40030402/,https://pubmed.ncbi.nlm.nih.gov/40030402/,English,Include,,Improving the Performance of Individually Calibrated SSVEP Classification by Rhythmic Entrainment Source Separation.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40030288,pubmed:40030288,PubMed,pubmed:40030288,Electrophysiological evidence on mirror therapy for promoting perceptuo-motor processes in stroke patients.,Li Ding;Dan Wang;Chengcheng Wu;Xu Wang;Jinyang Zhuang;Xiaoli Guo;Jie Jia,2024,10.1109/tnsre.2024.3503657,"Mirror therapy is proposed to enhance post-stroke awareness of the affected limb and mental ability, but convincing evidence on the perceptuo-motor processes is insufficient. In this study, we aimed to investigate the longitudinal effect of mirror therapy on limb perception and early motor processes in stroke patients using the hand mental rotation (HMR) task with both behavioral and electrophysiological evidence. Fifty stroke patients were randomly assigned to a mirror therapy group (MG, N = 25) or a conventional treatment group (CG, N = 25). Before and after 4-week intervention, the HMR task was performed, and its behavioral performance and EEG characteristics were measured and correlated with clinical outcomes. Behavioral analysis showed that enhanced accuracy of the HMR task, correlating with greater improvement in upper extremity motor function, was only observed in the MG. The ERD/ERS and brain network analysis revealed significant group differences in brain activation and local network metrics in the ipsilesional hemisphere during the preparation and execution of mental rotation while processing the affected hand stimuli. Specifically, the MG showed enhanced ipsilesional parietal ERD in the α (8-13 Hz) and β1 (13-20 Hz) bands, along with increased ipsilesional centroparietal nodal strength and betweenness centrality, which were cross-correlated. The results indicate the potential of long-term mirror therapy for promoting perceptuo-motor processes, facilitating visuospatial perception, and improving motor preparation and mental ability of the affected limb, thereby contributing to post-stroke recovery.",https://pubmed.ncbi.nlm.nih.gov/40030288/,https://pubmed.ncbi.nlm.nih.gov/40030288/,English,Include,,Electrophysiological evidence on mirror therapy for promoting perceptuo-motor processes in stroke patients.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40030248,pubmed:40030248,PubMed,pubmed:40030248,FACT-Net: a Frequency Adapter CNN with Temporal-periodicity Inception for Fast and Accurate MI-EEG Decoding.,Sixiong Ke;Banghua Yang;Yiyang Qin;Fenqi Rong;Jiayang Zhang;Yanyan Zheng,2024,10.1109/tnsre.2024.3499998,"Motor imagery brain-computer interface (MI-BCI) based on non-invasive electroencephalogram (EEG) signals is a typical paradigm of BCI. However, existing decoding methods face significant challenges in terms of signal decoding accuracy, real-time processing, and deployment. To overcome these challenges, we propose FACT-Net, an innovative deep-learning network for the fast and accurate decoding of MI-EEG signals. FACT-Net incorporates a Frequency Adapter (FA) module designed for processing the frequency features of MI-EEG data, as well as a Temporal-Periodicity Inception (TPI) module specifically for handling global periodic signals in MI. To evaluate the proposed model, we conduct the experiments on the cross-day dataset collected from 67 subjects and the BCIC-IV-2a dataset. The FACT-Net achieved an accuracy of 48.32% and 80.67% higher than the state-of-the-art (SOTA) approaches, demonstrating excellent performance in MI decoding. Additionally, it exhibits exceptional memory efficiency and inference time, indicating significant potential for practical applications. We anticipate that FACT-Net will set a new baseline for MI-EEG decoding. The code is available in https://github.com/Ktn1ga/EEG_FACT.",https://pubmed.ncbi.nlm.nih.gov/40030248/,https://pubmed.ncbi.nlm.nih.gov/40030248/,English,Include,,FACT-Net: a Frequency Adapter CNN with Temporal-periodicity Inception for Fast and Accurate MI-EEG Decoding.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40030247,pubmed:40030247,PubMed,pubmed:40030247,A Wearable Brain-Computer Interface with Fewer EEG Channels for Online Motor Imagery Detection.,Zuguang Rao;Junbiao Zhu;Zilin Lu;Rui Zhang;Kendi Li;Zijing Guan;Yuanqing Li,2024,10.1109/tnsre.2024.3502135,"Motor imagery-based brain-computer interfaces (MI-BCIs) have significant potential for neurorehabilitation and motor recovery. However, most BCI systems employ multi-channel electroencephalogram (EEG) recording devices, during which the pre-experimental preparation and post-experimental hair cleaning are time-consuming and inconvenient for stroke patients, and potentially affect their motivation for rehabilitation training. In this paper, we introduced a wearable MI-BCI system for online MI classification using a wireless headband device with four EEG channels to reduce setup time while enhancing portability. To validate the performance of the system in decoding MI-EEG signals, extensive experiments and comparisons were performed on sixty-six healthy subjects. Specifically, an offline and an online experiment with forty-six subjects were conducted, with the system achieving average offline and online accuracies of 85.21% and 76.54%, respectively. Furthermore, a comparison experiment involving another twenty subjects showed that the online performance of our headband device (77.84%) was comparable to that of a mature commercial Neuroscan device (76.50%). Compared to several existing portable systems, our wearable system achieved superior performance with fewer channels and was validated on a larger number of subjects. These results demonstrated that our wearable BCI system can reduce preparation time, enhance portability, and meet the classification performance requirements for BCI-based rehabilitation intervention, indicating its substantial potential for large-scale clinical applications in enhancing motor recovery of stroke patients.",https://pubmed.ncbi.nlm.nih.gov/40030247/,https://pubmed.ncbi.nlm.nih.gov/40030247/,English,Include,,A Wearable Brain-Computer Interface with Fewer EEG Channels for Online Motor Imagery Detection.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:40000200,pubmed:40000200,PubMed,pubmed:40000200;pubmed:39173486,[Fusion of electroencephalography multi-domain features and functional connectivity for early dementia recognition].,Wenwen Chang;Lei Zheng;Guanghui Yan;Renjie Lyu;Wenchao Nie;Bin Guo,2024,10.1016/j.compbiomed.2024.108993,"Dementia is a neurodegenerative disease closely related to brain network dysfunction. In this study, we assessed the interdependence between brain regions in patients with early-stage dementia based on phase-lock values, and constructed a functional brain network, selecting network feature parameters for metrics based on complex network analysis methods. At the same time, the entropy information characterizing the EEG signals in time domain, frequency domain and time-frequency domain, as well as the nonlinear dynamics features such as Hjorth and Hurst indexes were extracted, respectively. Based on the statistical analysis, the feature parameters with significant differences between different conditions were screened to construct feature vectors, and finally multiple machine learning algorithms were used to realize the recognition of early categories of dementia patients. The results showed that the fusion of multiple features performed well in the categorization of Alzheimer's disease, frontotemporal lobe dementia and healthy controls, especially in the identification of Alzheimer's disease and healthy controls, the accuracy of β-band reached 98%, which showed its effectiveness. This study provides new ideas for the early diagnosis of dementia and computer-assisted diagnostic methods. 痴呆症是一种与脑网络功能失调密切相关的神经退行性疾病。本研究基于相位锁值来评估早期痴呆症患者脑区间的相互依赖关系，并构建功能性脑网络，基于复杂网络分析方法选择网络特征参数进行度量。同时，分别提取表征脑电信号时域、频域和时频域特征的熵值信息，以及Hjorth和Hurst指标等非线性动力学特征。基于统计分析筛选在不同病症之间存在显著差异的特征参数构建特征向量，最后利用多种机器学习算法实现对痴呆症患者早期类别的识别。结果表明，多特征的融合在阿尔茨海默症、额颞叶痴呆与健康对照组的分类中表现优异，尤其在阿尔茨海默症与健康对照组的识别中，β频段的准确率达到98%，显示了方法的有效性。本研究为痴呆症早期诊断提供了新思路，也为计算机辅助诊断提方法供了参考。.",https://pubmed.ncbi.nlm.nih.gov/40000200/,https://pubmed.ncbi.nlm.nih.gov/40000200/,English,Include,,[Fusion of electroencephalography multi-domain features and functional connectivity for early dementia recognition].,Exclude,Duplicate study,Duplicate group,,0.99,0.6,
pubmed:40000198,pubmed:40000198,PubMed,pubmed:40000198,[Research on emotion recognition in electroencephalogram based on independent component analysis-recurrence plot and improved EfficientNet].,Guohong Feng;Xiao Zheng;Bin Zhang;Hongen Wang,2024,10.7507/1001-5515.202303010,"To accurately capture and effectively integrate the spatiotemporal features of electroencephalogram (EEG) signals for the purpose of improving the accuracy of EEG-based emotion recognition, this paper proposes a new method combining independent component analysis-recurrence plot with an improved EfficientNet version 2 (EfficientNetV2). First, independent component analysis is used to extract independent components containing spatial information from key channels of the EEG signals. These components are then converted into two-dimensional images using recurrence plot to better extract emotional features from the temporal information. Finally, the two-dimensional images are input into an improved EfficientNetV2, which incorporates a global attention mechanism and a triplet attention mechanism, and the emotion classification is output by the fully connected layer. To validate the effectiveness of the proposed method, this study conducts comparative experiments, channel selection experiments and ablation experiments based on the Shanghai Jiao Tong University Emotion Electroencephalogram Dataset (SEED). The results demonstrate that the average recognition accuracy of our method is 96.77%, which is significantly superior to existing methods, offering a novel perspective for research on EEG-based emotion recognition. 为精准捕获并有效融合脑电信号中的时空特征以提高脑电情绪识别精度，本文提出一种基于独立成分分析—递归图和改进的第2代高效能网络（EfficientNetV2）相结合的新方法。首先，采用独立成分分析从脑电信号的关键通道中提取包含空间信息的独立成分；然后，由递归图转换为二维图像以更好地提取时间信息中的情感特征；最后，将二维图像输入到引入全局注意力机制和三重注意力机制的EfficientNetV2中，由全连接层输出情感分类。为验证所提方法的有效性，本研究基于上海交通大学情绪脑电数据集（SEED）进行对比实验、通道选择实验和消融实验。研究结果显示，本文所提方法平均识别准确率为96.77%，显著优于现有其他方法，为脑电情绪识别研究提供了新的思路。.",https://pubmed.ncbi.nlm.nih.gov/40000198/,https://pubmed.ncbi.nlm.nih.gov/40000198/,English,Include,,[Research on emotion recognition in electroencephalogram based on independent component analysis-recurrence plot and improved EfficientNet].,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:40000196,pubmed:40000196,PubMed,pubmed:40000196,[Fontanel compensation for infant electroencephalography forward modeling method].,Ting Zhang;Yan Liu;Bo Peng;Siqi Zhang;Ying Hu;Weifeng Zhong;Yakang Dai,2024,10.1109/tmi.2016.2624634,"Magnetic resonance imaging (MRI)-based electroencephalography (EEG) forward modeling method has become prevalent in the field of EEG. However, due to the inability to obtain clear images of an infant's fontanel through MRI, the fontanelle information is often lacking in the EEG forward model, which affects accuracy of modeling in infants. To address this issue, we propose a novel method to achieve fontanel compensation for infant EEG forward modeling method. First, we employed imaging segmentation and meshing to the head MRIs, creating a fontanel-free model. Second, a projection-based surface reconstruction method was proposed, which utilized priori information on fontanel morphology and the fontanel-free head model to reconstruct the two-dimensional measured fontanel into a three-dimensional fontanel model to achieve fontanel-compensation modeling. Finally, we calculated a fontanel compensation-based EEG forward model for infants based on this model. Simulation results, based on a real head model, demonstrated that the compensation of fontanel had a potential to improve EEG forward modeling accuracy, particularly for the sources beneath the fontanel (relative difference measure larger than 0.05). Additional experimental results revealed that the uncertainty of the infant's skull conductivity had the widest impact range on the neural sources, and the absence of fontanel had the strongest impact on the neural sources below the fontanel. Overall, the proposed fontanel-compensated method showcases the potential to improve the modeling accuracy of EEG forward problem without relying on computed tomography (CT) acquisition, which is more in line with the requirements of practical application scenarios. 基于磁共振成像（MRI）的脑电正问题建模方法已在脑电领域被广泛应用。然而，婴儿囟门无法在MRI中清晰成像，所构建婴儿脑电正问题建模缺乏囟门信息，影响建模精度。为此，本文提出一种新的基于囟门补偿的婴儿脑电正问题建模方法。首先，基于头部MRI的图像分割和网格划分，构建无囟门头模型；然后，提出基于投影的网格重建方法，利用囟门的形态学先验信息和无囟门头模型将二维囟门测量重建为三维囟门模型，实现囟门补偿头模型构建；最后，该头模型被用于脑电正问题建模完成脑电正问题的囟门补偿。基于真实头模型的仿真结果表明，所提囟门补偿具有提升婴儿脑电正问题建模精度的潜力，对于囟门下方神经源的补偿效果尤为显著（拓扑误差RDM > 0.05）。进一步的实验结果表明，颅骨电导率的不确定性对建模的影响范围最广，囟门缺失对建模的影响强度最大。总体上，本文提出的基于形态学先验的囟门补偿方法展现出不依赖计算机断层扫描（CT）即可提升脑电正问题建模精度的潜力，更符合实际应用场景的需求。.",https://pubmed.ncbi.nlm.nih.gov/40000196/,https://pubmed.ncbi.nlm.nih.gov/40000196/,English,Include,,[Fontanel compensation for infant electroencephalography forward modeling method].,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39965789,pubmed:39965789,PubMed,pubmed:39965789,Comparison of machine learning algorithms for automatic prediction of Alzheimer disease.,Emrah Aslan;Yildirim Özüpak,2025,10.1097/jcma.0000000000001188,"Alzheimer disease is a progressive neurological disorder marked by irreversible memory loss and cognitive decline. Traditional diagnostic tools, such as intracranial volume assessments, electroencephalography (EEG) signals, and brain magnetic resonance imaging (MRI), have shown utility in detecting the disease. However, artificial intelligence (AI) offers promise for automating this process, potentially enhancing diagnostic accuracy and accessibility. In this study, various machine learning models were used to detect Alzheimer disease, including K-nearest neighbor regression, support vector machines (SVM), AdaBoost regression, and logistic regression. A neural network was constructed and validated using data from 150 participants in the University of Washington's Alzheimer's Disease Research Center (Open Access Imaging Studies Series [OASIS] dataset). Cross-validation was also performed on the Alzheimer Disease Neuroimaging Initiative (ADNI) dataset to assess the robustness of the models. Among the models tested, K-nearest neighbor regression achieved the highest accuracy, reaching 97.33%. The cross-validation on the ADNI dataset further confirmed the effectiveness of the models, demonstrating satisfactory results in screening and diagnosing Alzheimer disease in a community-based sample. The findings indicate that AI-based models, particularly K-nearest neighbor regression, provide promising accuracy for the early detection of Alzheimer disease. This approach has potential for further development into practical diagnostic tools that could be applied in clinical and community settings.",,https://pubmed.ncbi.nlm.nih.gov/39965789/,English,Exclude,Outside date range,Comparison of machine learning algorithms for automatic prediction of Alzheimer disease.,,,,,0.95,0.45,cv_reported;small_sample_mentioned
pubmed:39963515,pubmed:39963515,PubMed,pubmed:39963515,Specific endophenotypes in EEG microstates for methamphetamine use disorder.,Xurong Gao;Yun-Hsuan Chen;Ziyi Zeng;Wenyao Zheng;Chengpeng Chai;Hemmings Wu;Zhoule Zhu;Jie Yang;Lihua Zhong;Hua Shen;Mohamad Sawan,2024,10.1109/tcss.2021.3135425,"Electroencephalogram (EEG) microstates, which reflect large-scale resting-state networks of the brain, have been proposed as potential endophenotypes for methamphetamine use disorder (MUD). However, current endophenotypes lack refinement at the frequency band level, limiting their precision in identifying key frequency bands associated with MUD. In this study, we investigated EEG microstate dynamics across various frequency bands and different tasks, utilizing machine learning to classify MUD and healthy controls. During the resting state, the highest classification accuracy for detecting MUD was 85.5%, achieved using microstate parameters in the alpha band. Among these, the coverage of microstate class A contributed the most, suggesting it as the most promising endophenotype for specifying MUD. We accurately categorize the endophenotype of MUD into different sub-frequency bands, thereby providing reliable biomarkers.",https://pubmed.ncbi.nlm.nih.gov/39963515/,https://pubmed.ncbi.nlm.nih.gov/39963515/,English,Include,,Specific endophenotypes in EEG microstates for methamphetamine use disorder.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39962836,pubmed:39962836,PubMed,pubmed:39962836,A Novel State Space Model with Dynamic Graphic Neural Network for EEG Event Detection.,Xinying Li;Shengjie Yan;Yonglin Wu;Chenyun Dai;Yao Guo,2025,10.1142/s012906572550008x,"Electroencephalography (EEG) is a widely used physiological signal to obtain information of brain activity, and its automatic detection holds significant research importance, which saves doctors' time, improves detection efficiency and accuracy. However, current automatic detection studies face several challenges: large EEG data volumes require substantial time and space for data reading and model training; EEG's long-term dependencies test the temporal feature extraction capabilities of models; and the dynamic changes in brain activity and the non-Euclidean spatial structure between electrodes complicate the acquisition of spatial information. The proposed method uses range-EEG (rEEG) to extract time-frequency features from EEG to reduce data volume and resource consumption. Additionally, the next-generation state-space model Mamba is utilized as a temporal feature extractor to effectively capture the temporal information in EEG data. To address the limitations of state space models (SSMs) in spatial feature extraction, Mamba is combined with Dynamic Graph Neural Networks, creating an efficient model called DG-Mamba for EEG event detection. Testing on seizure detection and sleep stage classification tasks showed that the proposed method improved training speed by 10 times and reduced memory usage to less than one-seventh of the original data while maintaining superior performance. On the TUSZ dataset, DG-Mamba achieved an AUROC of 0.931 for seizure detection and in the sleep stage classification task, the proposed model surpassed all baselines.",,https://pubmed.ncbi.nlm.nih.gov/39962836/,English,Exclude,Outside date range,A Novel State Space Model with Dynamic Graphic Neural Network for EEG Event Detection.,,,,,0.95,0.6,
pubmed:39950750,pubmed:39950750,PubMed,pubmed:39950750,A combination of deep learning models and type-2 fuzzy for EEG motor imagery classification through spatiotemporal-frequency features.,Ensong Jiang;Tangsen Huang;Xiangdong Yin,2024,10.1080/03091902.2025.2463577,"Developing a robust and effective technique is crucial for interpreting a user's brainwave signals accurately in the realm of biomedical signal processing. The variability and uncertainty present in EEG patterns over time, compounded by noise, pose notable challenges, particularly in mental tasks like motor imagery. Introducing fuzzy components can enhance the system's ability to withstand noisy environments. The emergence of deep learning has significantly impacted artificial intelligence and data analysis, prompting extensive exploration into assessing and understanding brain signals. This work introduces a hybrid series architecture called FCLNET, which combines Compact-CNN to extract frequency and spatial features alongside the LSTM network for temporal feature extraction. The activation functions in the CNN architecture were implemented using type-2 fuzzy functions to tackle uncertainties. Hyperparameters of the FCLNET model are tuned by the Bayesian optimisation algorithm. The efficacy of this approach is assessed through the BCI Competition IV-2a database and the BCI Competition IV-1 database. By incorporating type-2 fuzzy activation functions and employing Bayesian optimisation for tuning, the proposed architecture indicates good classification accuracy compared to the literature. Outcomes showcase the exceptional achievements of the FCLNET model, suggesting that integrating fuzzy units into other classifiers could lead to advancements in motor imagery-based BCI systems.",https://pubmed.ncbi.nlm.nih.gov/39950750/,https://pubmed.ncbi.nlm.nih.gov/39950750/,English,Include,,A combination of deep learning models and type-2 fuzzy for EEG motor imagery classification through spatiotemporal-frequency features.,Include,,"abase and the BCI Competition IV-1 database. By incorporating type-2 fuzzy activation functions and employing Bayesian optimisation for tuning, the proposed architecture indicates good classification accuracy compared to the literature. Outcomes showcase the exceptional achievements of the FCLNET model, suggesting that integrating fuzzy units into other classifiers could lead to advancements in mo",,0.95,0.6,
pubmed:39949163,pubmed:39949163,PubMed,pubmed:39949163,Epileptic seizure detection in EEG signals via an enhanced hybrid CNN with an integrated attention mechanism.,Sakorn Mekruksavanich;Wikanda Phaphan;Anuchit Jitpattanakul,2025,10.3934/mbe.2025004,"Epileptic seizures, a prevalent neurological condition, necessitate precise and prompt identification for optimal care. Nevertheless, the intricate characteristics of electroencephalography (EEG) signals, noise, and the want for real-time analysis require enhancement in the creation of dependable detection approaches. Despite advances in machine learning and deep learning, capturing the intricate spatial and temporal patterns in EEG data remains challenging. This study introduced a novel deep learning framework combining a convolutional neural network (CNN), bidirectional gated recurrent unit (BiGRU), and convolutional block attention module (CBAM). The CNN extracts spatial features, the BiGRU captures long-term temporal dependencies, and the CBAM emphasizes critical spatial and temporal regions, creating a hybrid architecture optimized for EEG pattern recognition. Evaluation of a public EEG dataset revealed superior performance compared to existing methods. The model achieved 99.00% accuracy in binary classification, 96.20% in three-class tasks, 92.00% in four-class scenarios, and 89.00% in five-class classification. High sensitivity (89.00-99.00%) and specificity (89.63-99.00%) across all tasks highlighted the model's robust ability to identify diverse EEG patterns. This approach supports healthcare professionals in diagnosing epileptic seizures accurately and promptly, improving patient outcomes and quality of life.",,https://pubmed.ncbi.nlm.nih.gov/39949163/,English,Exclude,Outside date range,Epileptic seizure detection in EEG signals via an enhanced hybrid CNN with an integrated attention mechanism.,,,,,0.95,0.6,
pubmed:39936165,pubmed:39936165,PubMed,pubmed:39936165,Combining interictal intracranial EEG and fMRI to compute a dynamic resting-state index for surgical outcome validation.,Varina L Boerwinkle;Kristin M Gunnarsdottir;Bethany L Sussman;Sarah N Wyckoff;Emilio G Cediel;Belfin Robinson;William R Reuther;Aryan Kodali;Sridevi V Sarma,2024,10.1002/ana.22548,"Accurate localization of the seizure onset zone (SOZ) is critical for successful epilepsy surgery but remains challenging with current techniques. We developed a novel seizure onset network characterization tool that combines dynamic biomarkers of resting-state intracranial stereoelectroencephalography (rs-iEEG) and resting-state functional magnetic resonance imaging (rs-fMRI), vetted against surgical outcomes. This approach aims to reduce reliance on capturing seizures during invasive monitoring to pinpoint the SOZ. We computed the source-sink index (SSI) from rs-iEEG for all implanted regions and from rs-fMRI for regions identified as potential SOZs by noninvasive modalities. The SSI scores were evaluated in 17 pediatric drug-resistant epilepsy (DRE) patients (ages 3-15 years) by comparing outcomes classified as successful (Engel I or II) versus unsuccessful (Engel III or IV) at 1 year post-surgery. Of 30 reviewed patients, 17 met the inclusion criteria. The combined dynamic index (im-DNM) integrating rs-iEEG and rs-fMRI significantly differentiated good (Engel I-II) from poor (Engel III-IV) surgical outcomes, outperforming the predictive accuracy of individual biomarkers from either modality alone. The combined dynamic network model demonstrated superior predictive performance than standalone rs-fMRI or rs-iEEG indices. By leveraging interictal data from two complementary modalities, this combined approach has the potential to improve epilepsy surgical outcomes, increase surgical candidacy, and reduce the duration of invasive monitoring.",,https://pubmed.ncbi.nlm.nih.gov/39936165/,English,Exclude,Review/survey papers,Combining interictal intracranial EEG and fMRI to compute a dynamic resting-state index for surgical outcome validation.,,,,,0.95,0.6,
pubmed:39927238,pubmed:39927238,PubMed,pubmed:39927238,EEG-Based Alcohol Detection System for Driver Monitoring.,Molly Vassbotn;Iselin J Nordstrøm-Hauge;Andres Soler;Marta Molinas,2024,10.3233/jifs-169909,"Today, alcohol drinking frequently accompanies socialising as a routine activity in various groups of society. 84.0% of individuals aged 18 and above in the United States have drunk alcohol at some point in their life (National Institute on Alcohol Abuse & US, 2023). Similarly, 81.7% of Norwegians in the age group 16 to 79 have drunk alcohol in 2021 (Bye, 2018). Driving after the consumption of alcohol is a worldwide problem, causing a large number of deaths and injuries a year. This work proposes the first steps towards developing an electroencephalography (EEG)-based alcohol detector conceived with the idea to prevent people from driving under the influence of alcohol. This includes the design of an experimental protocol for EEG data collection, during which participants performed the Flanker task, and their blood alcohol concentration (BAC) was measured. The resulting data set consists of two sessions per participant, both while they are affected and not-affected by alcohol. Statistical analysis of the Flanker task indicated that participants were affected by alcohol and, therefore, their EEG signals were expected to be affected as well. The collected EEG signals were used as input for intra-subject and inter-subject models, both based on the EEGNet architecture. The intra-subject model obtained a mean classification accuracy of 90.7% and the inter-subject model a mean classification accuracy of 62.9%. The result suggest that alcohol can be detected with high accuracy when developing individual models and above the change accuracy when using a general model. Therefore, the work presented here could be used as the first steps towards the development of an EEG-based alcohol detector for drivers. Hoy en día, el consumo de alcohol frecuentemente acompaña la socialización como una actividad rutinaria en varios grupos de la sociedad. El 84.0% de las personas mayores de 18 años en los Estados Unidos han consumido alcohol en algún momento de sus vidas (National Institute on Alcohol Abuse & US, 2023). De manera similar, el 81.7% de los noruegos en el grupo de edad de 16 a 79 años consumieron alcohol en 2021 (Bye, 2018). Conducir después del consumo de alcohol es un problema mundial que causa un gran número de muertes y lesiones cada año. Este trabajo propone los primeros pasos hacia el desarrollo de un detector de alcohol basado en electroencefalografía (EEG), concebido con la idea de prevenir que las personas conduzcan bajo los efectos del alcohol. Esto incluye el diseño de un protocolo experimental para la recopilación de datos EEG, durante el cual los participantes realizaron la prueba de Flanker y se midió su concentración de alcohol en la sangre (BAC). El conjunto de datos resultante consta de dos sesiones por participante, tanto mientras estaban afectados como no afectados por el alcohol. El análisis estadístico de la prueba de Flanker indicó que los participantes estaban afectados por el alcohol y, por lo tanto, se esperaba que sus señales EEG también lo estuvieran. Las señales EEG recopiladas se utilizaron como entrada para modelos intra-participantes e inter-participantes, ambos basados en la arquitectura EEGNet. El modelo intra-participantes obtuvo una precisión media de clasificación del 90.7%, y el modelo inter-participantes una precisión media del 62.9%. Los resultados sugieren que el alcohol puede detectarse con alta precisión al desarrollar modelos individuales y con una precisión superior al azar al usar un modelo general. Por lo tanto, el trabajo presentado aquí podría servir como los primeros pasos hacia el desarrollo de un detector de alcohol basado en EEG para conductores.",https://pubmed.ncbi.nlm.nih.gov/39927238/,https://pubmed.ncbi.nlm.nih.gov/39927238/,English,Include,,EEG-Based Alcohol Detection System for Driver Monitoring.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39922654,pubmed:39922654,PubMed,pubmed:39922654,A robust method for parkinson's disease diagnosis: Combining electroencephalography signal features with reconstructed phase space images.,Farnaz Garehdaghi;Yashar Sarbaz,2025,10.1016/j.medengphy.2024.104276,"Parkinson's disease (PD) is a neurodegenerative disease. Since the diagnosis of the PD is mainly made based on the symptoms and after the disease progression, early diagnosis can play a crucial role in delaying the passage of the PD. There have been many methods focusing on disease diagnosis using electroencephalography (EEG) signals, where most of the proposed methods are data-dependent. Here, the study aims to propose a technique that, despite its high accuracy, is robust. Various features including fractal dimension, approximate entropy, largest Lyapunov exponent, and the energy of different frequency sub-bands were extracted from EEG signals. Multi-layer perceptron neural networks were used for classification based on these features. Additionally, 2D phase space images reconstructed from EEG signals were classified using convolutional neural networks. Finally, a combination of these features and images was used for classification using ResNets. During 10 rounds of training and testing, the mean accuracies were calculated for three cases: using only features, only images, and a combination of both. The mean accuracies were 84.67 %, 76.5 %, and 90.2 % respectively. The variances for each case were 35.6 %, 19.5 %, and 13.97 %. The lower variance when using a combination of features and images indicates a more accurate and robust classification.",,https://pubmed.ncbi.nlm.nih.gov/39922654/,English,Exclude,Outside date range,A robust method for parkinson's disease diagnosis: Combining electroencephalography signal features with reconstructed phase space images.,,,,,0.95,0.6,
pubmed:39922653,pubmed:39922653,PubMed,pubmed:39922653,A novel ECG-based approach for classifying psychiatric disorders: Leveraging wavelet scattering networks.,Hardik Telangore;Nishant Sharma;Manish Sharma;U Rajendra Acharya,2025,10.1016/j.medengphy.2024.104275,"Individuals with neuropsychiatric disorders experience both physical and mental difficulties, hindering their ability to live healthy lives and participate in daily activities. It is challenging to diagnose these disorders due to a lack of reliable diagnostic tests and the complex symptoms and treatments for various disorders. Generally, psychiatric disorders are identified manually by doctors using questionnaires, which may be prone to subjectivity and human errors. A few automated systems have recently been developed to identify these disorders using physiological signals, including electroencephalogram (EEG) and electrocardiogram (ECG) signals. Often, EEG signals are used to identify psychiatric disorders, but the EEG signals are nonlinear and non-stationary in nature and hence are relatively complex to analyze when compared to the ECG signals. The ECG signals in psychiatric patients are used due to the connection between the heart and brain. The proposed study is aimed at investigating the use of ECG signals for the automated identification of neuropsychiatric disorders, including bipolar disorder (BD), depression (DP), and schizophrenia (SZ). Generally, convolution neural networks (CNNs) have proven to be effective in accurately identifying psychological conditions. However, their application requires a large amount of data and technical expertise. The wavelet scattering network (WSN), a variant of CNNs, was introduced to overcome these limitations. The WSN is a network capable of accurately detecting unique patterns in the signal. The proposed research incorporated the WSN network and was conducted using a Psychiatric ECG Beat Dataset with a population of 233 subjects, of whom 198 were diagnosed with multiple psychiatric disorders, and 35 were control subjects. ECG signals from 3570 heartbeats were collected and analyzed using wavelet scattering-based feature extraction and machine learning techniques. The Fine K-Nearest Neighbor (FKNN) algorithm produced the best results with an average classification accuracy of 99.8% and a Kappa value of 0.996 using a ten-fold cross-validation. The model yielded an accuracy of 99.78%, 99.94%, 99.98%, and 100% for automated identification of BD, DP, SZ, and control subjects, respectively, with F1 scores and precision values close to 1. The proposed method could also help in the automated clinical detection of different psychiatric disorders.",,https://pubmed.ncbi.nlm.nih.gov/39922653/,English,Exclude,Outside date range,A novel ECG-based approach for classifying psychiatric disorders: Leveraging wavelet scattering networks.,,,,,0.95,0.25,cv_reported
pubmed:39917249,pubmed:39917249,PubMed,pubmed:39917249,The NARCOguide index - a novel parameter for monitoring depth of hypnosis during anaesthesia/sedation with propofol: A comparison study with the Narcotrend index.,Florian Hetzer;Stefan Horack;Gert Küchler;Jens Broscheit,2024,10.1097/ea9.0000000000000057,"The NARCOguide algorithm calculates an EEG-derived index to monitor the hypnotic component of anaesthesia. This study evaluates the accuracy of the index calculated by NARCOguide against the Narcotrend index as a reference. Secondly, the automatic detection of burst-suppression patterns as represented by the burst suppression ratio was compared. Comparative study to assess the agreement between two medical devices. At two study centres, patient data were collected from a total of 40 adults receiving general anaesthesia or sedation with propofol. Patients underwent either general anaesthesia for oral surgery with propofol/remifentanil/rocuronium (study centre 1) or light general anaesthesia/deep sedation with propofol alone for laryngoscopic upper airway exploration (study centre 2). In a posthoc analysis, the NARCOguide index was compared with the Narcotrend index. Comparison was made after averaging over 1 min at defined clinical markers using classic linear least squares regression and Bland-Altman plots. Precision and recall for the detection of burst suppression were determined using human scoring as a reference. Data analysis showed good agreement [Bland-Altman mean difference (MD) = -2.3; limits of agreement = -27.1, to +22.4;  The NARCOguide index can be used to monitor the hypnotic component of anaesthesia in patients undergoing general anaesthesia or sedation with propofol, with a performance similar to that of the Narcotrend index. Trial registration number: 18020, regulatory authority: Ethikkommission der bayerischen Landesärztekammer, chairman: Dr med. Gerald Quitterer, applicant: Dr Gert Küchler, date of approval: 12. Jun 2018, completion of data collection: 12 December 2018, study completion: 31 March 2022.",https://pubmed.ncbi.nlm.nih.gov/39917249/,https://pubmed.ncbi.nlm.nih.gov/39917249/,English,Include,,The NARCOguide index - a novel parameter for monitoring depth of hypnosis during anaesthesia/sedation with propofol: A comparison study with the Narcotrend index.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39911780,pubmed:39911780,PubMed,pubmed:39911780,Multimodal approach to public health interventions using EGG and mobile health technologies.,Xiao Zhang;Han Liu;Mingyang Sun;Shuangyi Feng,2024,10.1007/s12652-021-03439-8,"Public health interventions increasingly integrate multimodal data sources, such as Electroencephalogram (EEG) data, to enhance monitoring and predictive capabilities for mental health conditions. However, traditional models often face challenges with the complexity and high dimensionality of EEG signals. While recent advancements like Contrastive Language-lmage Pre-training(CLIP) models excel in cross-modal understanding, their application to EEG-based tasks remains limited due to the unique characteristics of EEG data. In response, we introduce PH-CLIP (Public Health Contrastive Language-lmage Pretraining), a novel framework that combines CLIP's representational power with a multi-scale fusion mechanism designed specifically for EEG data within mobile health technologies. PH-CLIP employs hierarchical feature extraction to capture the temporal dynamics of EEG signals, aligning them with contextually relevant textual descriptions for improved public health insights. Through a multi-scale fusion layer, PH-CLIP enhances interpretability and robustness in EEG embeddings, thereby supporting more accurate and scalable interventions across diverse public health applications. Experimental results indicate that PH-CLIP achieves significant improvements in EEG classification accuracy and mental health prediction efficiency compared to leading EEG analysis models. This framework positions PH-CLIP as a transformative tool in public health monitoring, with the potential to advance large-scale mental health interventions through integrative mobile health technologies.",https://pubmed.ncbi.nlm.nih.gov/39911780/,https://pubmed.ncbi.nlm.nih.gov/39911780/,English,Include,,Multimodal approach to public health interventions using EGG and mobile health technologies.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39911774,pubmed:39911774,PubMed,pubmed:39911774,Fusion Model Using Resting Neurophysiological Data to Help Mass Screening of Methamphetamine Use Disorder.,Chun-Chuan Chen;Meng-Chang Tsai;Eric Hsiao-Kuang Wu;Shao-Rong Sheng;Jia-Jeng Lee;Yung-En Lu;Shih-Ching Yeh,2025,10.1109/jtehm.2024.3522356,"Methamphetamine use disorder (MUD) is a substance use disorder. Because MUD has become more prevalent due to the COVID-19 pandemic, alternative ways to help the efficiency of mass screening of MUD are important. Previous studies used electroencephalogram (EEG), heart rate variability (HRV), and galvanic skin response (GSR) aberrations during the virtual reality (VR) induction of drug craving to accurately separate patients with MUD from the healthy controls. However, whether these abnormalities present without induction of drug-cue reactivity to enable separation between patients and healthy subjects remains unclear. Here, we propose a clinically comparable intelligent system using the fusion of 5-channel EEG, HRV, and GSR data during resting state to aid in detecting MUD. Forty-six patients with MUD and 26 healthy controls were recruited and machine learning methods were employed to systematically compare the classification results of different fusion models. The analytic results revealed that the fusion of HRV and GSR features leads to the most accurate separation rate of 79%. The use of EEG, HRV, and GSR features provides more robust information, leading to relatively similar and enhanced accuracy across different classifiers. In conclusion, we demonstrated that a clinically applicable intelligent system using resting-state EEG, ECG, and GSR features without the induction of drug cue reactivity enhances the detection of MUD. This system is easy to implement in the clinical setting and can save a lot of time on setting up and experimenting while maintaining excellent accuracy to assist in mass screening of MUD.",,https://pubmed.ncbi.nlm.nih.gov/39911774/,English,Exclude,Outside date range,Fusion Model Using Resting Neurophysiological Data to Help Mass Screening of Methamphetamine Use Disorder.,,,,,0.95,0.6,
pubmed:39911539,pubmed:39911539,PubMed,pubmed:39911539,Oscillating Mindfully: Using Machine Learning to Characterize Systems-Level Electrophysiological Activity During Focused Attention Meditation.,Noga Aviad;Oz Moskovich;Ophir Orenstein;Etam Benger;Arnaud Delorme;Amit Bernstein,2025,10.48550/arxiv.1705.07874,"There has been rapid growth of neuroelectrophysiological studies that aspire to uncover the ""black box"" of mindfulness and meditation. Reliance on traditional data analysis methods hinders understanding of the complex, nonlinear, multidimensional, and systemic nature of the functional neuroelectrophysiology of meditation states. Thus, to reveal the complex systemic neuroelectrophysiology of meditation, we applied a machine learning extreme gradient boosting classification algorithm and 4 complementary feature importance methods to extract systemic electroencephalography features characterizing mindful states from electroencephalography recorded during a focused attention meditation and a control mind-wandering state among 26 experienced meditators. The algorithm classified meditation versus mind-wandering states with 83% accuracy, with an area under the receiver operating characteristic curve of 79% and F1 score of 74%. Feature importance techniques identified 10 electroencephalography features associated with increased power and coherence of high-frequency oscillations during focused attention meditation relative to an instructed mind-wandering state. The findings help delineate the complex systemic oscillatory activity that characterizes meditation. There is fast-growing neuroscientific study aimed at uncovering the “black box” of mindfulness and meditation. We applied machine learning methods to characterize brain states from EEG recorded during a focused attention meditation and a control mind-wandering state among 26 experienced meditators. Machine learning was able to distinguish between these experimental meditation vs. mind-wandering states, as well as to identify and help characterize important electrophysiological features of these brain states. The findings help us to better understand the complex systemic brain activity characteristic of this form of meditation.",,https://pubmed.ncbi.nlm.nih.gov/39911539/,English,Exclude,Outside date range,Oscillating Mindfully: Using Machine Learning to Characterize Systems-Level Electrophysiological Activity During Focused Attention Meditation.,,,,,0.95,0.6,
pubmed:39897456,pubmed:39897456,PubMed,pubmed:39897456,Alzheimer's disease diagnosis using rhythmic power changes and phase differences: a low-density EEG study.,Juan Wang;Jiamei Zhao;Xiaoling Chen;Bowen Yin;Xiaoli Li;Ping Xie,2024,10.2174/1567205018666211001110824,"The future emergence of disease-modifying treatments for dementia highlights the urgent need to identify reliable and easily accessible tools for diagnosing Alzheimer's disease (AD). Electroencephalography (EEG) is a non-invasive and cost-effective technique commonly used in the study of neurodegenerative disorders. However, the specific alterations in EEG biomarkers associated with AD remain unclear when using a limited number of electrodes. We studied pathological characteristics of AD using low-density EEG data collected from 26 AD and 29 healthy controls (HC) during both eye closed (EC) and eye opened (EO) resting conditions. The analysis including power spectrum, phase lock value (PLV), and weighted lag phase index (wPLI) and power-to-power frequency coupling (theta/beta) analysis were applied to extract features in the delta, theta, alpha, and beta bands. During the EC condition, the AD group exhibited decreased alpha power compared to HC. Additionally, both analysis of PLV and wPLI in the theta band indicated that the alterations in the AD brain network predominantly involved in the frontal region with the opposite changes. Moreover, the AD group had increased frequency coupling in the frontal and central regions. Surprisingly, no group difference was found in the EO condition. Notably, decreased theta band functional connectivity within the fronto-central lobe and increased frequency coupling in frontal region were found in AD group from EC to EO. More importantly, the combination of EC and EO quantitative EEG features improved the inter-group classification accuracy when using support vector machine (SVM) in older adults with AD. These findings highlight the complementary nature of EC and EO conditions in assessing and differentiating AD cohorts. Our results underscore the potential of utilizing low-density EEG data from resting-state paradigms, combined with machine learning techniques, to improve the identification and classification of AD.",https://pubmed.ncbi.nlm.nih.gov/39897456/,https://pubmed.ncbi.nlm.nih.gov/39897456/,English,Include,,Alzheimer's disease diagnosis using rhythmic power changes and phase differences: a low-density EEG study.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39896395,pubmed:39896395,PubMed,pubmed:39896395,CIT-EmotionNet: convolution interactive transformer network for EEG emotion recognition.,Wei Lu;Lingnan Xia;Tien Ping Tan;Hua Ma,2024,10.1109/tai.2024.3406289,"Emotion recognition is a significant research problem in affective computing as it has a lot of potential areas of application. One of the approaches in emotion recognition uses electroencephalogram (EEG) signals to identify the emotion of a person. However, effectively using the global and local features of EEG signals to improve the performance of emotion recognition is still a challenge. In this study, we propose a novel Convolution Interactive Transformer Network for EEG Emotion Recognition, known as CIT-EmotionNet, which efficiently integrates the global and local features of EEG signals. We convert the raw EEG signals into spatial-spectral representations, which serve as the inputs into the model. The model integrates convolutional neural network (CNN) and Transformer within a single framework in a parallel manner. We propose a Convolution Interactive Transformer module, which facilitates the interaction and fusion of local and global features extracted by CNN and Transformer respectively, thereby improving the average accuracy of emotion recognition. The proposed CIT-EmotionNet outperforms state-of-the-art methods, achieving an average recognition accuracy of 98.57% and 92.09% on two publicly available datasets, SEED and SEED-IV, respectively.",https://pubmed.ncbi.nlm.nih.gov/39896395/,https://pubmed.ncbi.nlm.nih.gov/39896395/,English,Include,,CIT-EmotionNet: convolution interactive transformer network for EEG emotion recognition.,Include,,"se a Convolution Interactive Transformer module, which facilitates the interaction and fusion of local and global features extracted by CNN and Transformer respectively, thereby improving the average accuracy of emotion recognition. The proposed CIT-EmotionNet outperforms state-of-the-art methods, achieving an average recognition accuracy of 98.57% and 92.09% on two publicly available datasets, SE",,0.95,0.6,
pubmed:39895994,pubmed:39895994,PubMed,pubmed:39895994,Cross-modality fusion with EEG and text for enhanced emotion detection in English writing.,Jing Wang;Ci Zhang,2024,10.1109/tamd.2015.2431497,"Emotion detection in written text is critical for applications in human-computer interaction, affective computing, and personalized content recommendation. Traditional approaches to emotion detection primarily leverage textual features, using natural language processing techniques such as sentiment analysis, which, while effective, may miss subtle nuances of emotions. These methods often fall short in recognizing the complex, multimodal nature of human emotions, as they ignore physiological cues that could provide richer emotional insights. To address these limitations, this paper proposes Emotion Fusion-Transformer, a cross-modality fusion model that integrates EEG signals and textual data to enhance emotion detection in English writing. By utilizing the Transformer architecture, our model effectively captures contextual relationships within the text while concurrently processing EEG signals to extract underlying emotional states. Specifically, the Emotion Fusion-Transformer first preprocesses EEG data through signal transformation and filtering, followed by feature extraction that complements the textual embeddings. These modalities are fused within a unified Transformer framework, allowing for a holistic view of both the cognitive and physiological dimensions of emotion. Experimental results demonstrate that the proposed model significantly outperforms text-only and EEG-only approaches, with improvements in both accuracy and F1-score across diverse emotional categories. This model shows promise for enhancing affective computing applications by bridging the gap between physiological and textual emotion detection, enabling more nuanced and accurate emotion analysis in English writing.",https://pubmed.ncbi.nlm.nih.gov/39895994/,https://pubmed.ncbi.nlm.nih.gov/39895994/,English,Include,,Cross-modality fusion with EEG and text for enhanced emotion detection in English writing.,Include,," the cognitive and physiological dimensions of emotion. Experimental results demonstrate that the proposed model significantly outperforms text-only and EEG-only approaches, with improvements in both accuracy and F1-score across diverse emotional categories. This model shows promise for enhancing affective computing applications by bridging the gap between physiological and textual emotion detecti",,0.95,0.6,
pubmed:39886471,pubmed:39886471,PubMed,pubmed:39886471,The role of conscious attention in auditory statistical learning: Evidence from patients with impaired consciousness.,Lucas Benjamin;Di Zang;Ana Fló;Zengxin Qi;Pengpeng Su;Wenya Zhou;Liping Wang;Xuehai Wu;Peng Gui;Ghislaine Dehaene-Lambertz,2025,10.1101/2023.09.16.558075,"The need for attention to enable statistical learning is debated. Testing individuals with impaired consciousness offers valuable insight, but very few studies have been conducted due to the difficulties inherent in such studies. Here, we examined the ability of patients with varying levels of disorders of consciousness (DOC) to extract statistical regularities from an artificial language composed of randomly concatenated pseudowords by measuring frequency tagging in EEG. The objectives were firstly, to assess the automaticity of the segmentation process and the correlations between the level of covert consciousness and statistical learning capacities; secondly, to identify potential new diagnostic indicators. We observed that segmentation abilities were preserved in some minimally conscious patients, suggesting that auditory statistical learning is an inherently automatic low-level process. Due to significant inter-individual variability, word segmentation might not be robust enough for clinical use. In contrast, temporal accuracy of auditory syllable responses correlates strongly with coma severity.",,https://pubmed.ncbi.nlm.nih.gov/39886471/,English,Exclude,Outside date range,The role of conscious attention in auditory statistical learning: Evidence from patients with impaired consciousness.,,,,,0.95,0.6,
pubmed:39882377,pubmed:39882377,PubMed,pubmed:39882377;pubmed:39313602,A portable EEG signal acquisition system and a limited-electrode channel classification network for SSVEP.,Yunxiao Ma;Jinming Huang;Chuan Liu;Meiyu Shi,2024,10.1016/j.jneumeth.2013.07.018,"Brain-computer interfaces (BCIs) have garnered significant research attention, yet their complexity has hindered widespread adoption in daily life. Most current electroencephalography (EEG) systems rely on wet electrodes and numerous electrodes to enhance signal quality, making them impractical for everyday use. Portable and wearable devices offer a promising solution, but the limited number of electrodes in specific regions can lead to missing channels and reduced BCI performance. To overcome these challenges and enable better integration of BCI systems with external devices, this study developed an EEG signal acquisition platform (Gaitech BCI) based on the Robot Operating System (ROS) using a 10-channel dry electrode EEG device. Additionally, a multi-scale channel attention selection network based on the Squeeze-and-Excitation (SE) module (SEMSCS) is proposed to improve the classification performance of portable BCI devices with limited channels. Steady-state visual evoked potential (SSVEP) data were collected using the developed BCI system to evaluate both the system and network performance. Offline data from ten subjects were analyzed using within-subject and cross-subject experiments, along with ablation studies. The results demonstrated that the SEMSCS model achieved better classification performance than the comparative reference model, even with a limited number of channels. Additionally, the implementation of online experiments offers a rational solution for controlling external devices via BCI.",https://pubmed.ncbi.nlm.nih.gov/39882377/,https://pubmed.ncbi.nlm.nih.gov/39882377/,English,Include,,A portable EEG signal acquisition system and a limited-electrode channel classification network for SSVEP.,Exclude,Duplicate study,Duplicate group,,0.99,0.6,
pubmed:39867597,pubmed:39867597,PubMed,pubmed:39867597,Improving auditory attention decoding by classifying intracranial responses to glimpsed and masked acoustic events.,Vinay S Raghavan;James O'Sullivan;Jose Herrero;Stephan Bickel;Ashesh D Mehta;Nima Mesgarani,2024,10.1016/j.neuron.2012.12.037,"Listeners with hearing loss have trouble following a conversation in multitalker environments. While modern hearing aids can generally amplify speech, these devices are unable to tune into a target speaker without first knowing to which speaker a user aims to attend. Brain-controlled hearing aids have been proposed using auditory attention decoding (AAD) methods, but current methods use the same model to compare the speech stimulus and neural response, regardless of the dynamic overlap between talkers which is known to influence neural encoding. Here, we propose a novel framework that directly classifies event-related potentials (ERPs) evoked by glimpsed and masked acoustic events to determine whether the source of the event was attended. We present a system that identifies auditory events using the local maxima in the envelope rate of change, assesses the temporal masking of auditory events relative to competing speakers, and utilizes masking-specific ERP classifiers to determine if the source of the event was attended. Using intracranial electrophysiological recordings, we showed that high gamma ERPs from recording sites in auditory cortex can effectively decode the attention of subjects. This method of AAD provides higher accuracy, shorter switch times, and more stable decoding results compared with traditional correlational methods, permitting the quick and accurate detection of changes in a listener's attentional focus. This framework also holds unique potential for detecting instances of divided attention and inattention. Overall, we extend the scope of AAD algorithms by introducing the first linear, direct-classification method for determining a listener's attentional focus that leverages the latest research in multitalker speech perception. This work represents another step toward informing the development of effective and intuitive brain-controlled hearing assistive devices.",,https://pubmed.ncbi.nlm.nih.gov/39867597/,English,Exclude,Not EEG-BCI focused,Improving auditory attention decoding by classifying intracranial responses to glimpsed and masked acoustic events.,,,,,0.9,0.6,
pubmed:39867451,pubmed:39867451,PubMed,pubmed:39867451,Partial directed coherence analysis of resting-state EEG signals for alcohol use disorder detection using machine learning.,Ainul Khairiyah Mohd Nazri;Norashikin Yahya;Danish M Khan;Noor'Izni Zafirah Mohd Radzi;Nasreen Badruddin;Abdul Halim Abdul Latiff;Mohammed J Abdulaal,2024,10.3389/fnins.2021.651439,"Excessive alcohol consumption negatively impacts physical and psychiatric health, lifestyle, and societal interactions. Chronic alcohol abuse alters brain structure, leading to alcohol use disorder (AUD), a condition requiring early diagnosis for effective management. Current diagnostic methods, primarily reliant on subjective questionnaires, could benefit from objective measures. The study proposes a novel EEG-based classification approach, focusing on effective connectivity (EC) derived from resting-state EEG signals in combination with support vector machine (SVM) algorithms. EC estimation is performed using the partial directed coherence (PDC) technique. The analysis is conducted on an EEG dataset comprising 35 individuals with AUD and 35 healthy controls (HCs). The methodology evaluates the efficacy of connectivity features in distinguishing between AUD and HC and subsequently develops and assesses an EEG classification technique using EC matrices and SVM. The proposed methodology demonstrated promising performance, achieving a peak accuracy of 94.5% and an area under the curve (AUC) of 0.988, specifically using frequency bands 29, 36, 45, 46, and 52. Additionally, feature reduction techniques applied to the PDC adjacency matrices in the gamma band further improved classification outcomes. The SVM-based classification achieved an accuracy of 96.37 ± 0.45%, showcasing enhanced performance through the utilization of reduced PDC adjacency matrices. These results highlight the potential of the developed algorithm as a robust diagnostic tool for AUD detection, enhancing precision beyond subjective methods. Incorporating EC features derived from EEG signals can inform tailored treatment strategies, contributing to improved management of AUD.",https://pubmed.ncbi.nlm.nih.gov/39867451/,https://pubmed.ncbi.nlm.nih.gov/39867451/,English,Include,,Partial directed coherence analysis of resting-state EEG signals for alcohol use disorder detection using machine learning.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39867449,pubmed:39867449,PubMed,pubmed:39867449,"Who is WithMe? EEG features for attention in a visual task, with auditory and rhythmic support.",Renata Turkeš;Steven Mortier;Jorg De Winne;Dick Botteldooren;Paul Devos;Steven Latré;Tim Verdonck,2024,10.1016/j.neurobiolaging.2016.03.018,"The study of attention has been pivotal in advancing our comprehension of cognition. The goal of this study is to investigate which EEG data representations or features are most closely linked to attention, and to what extent they can handle the cross-subject variability. We explore the features obtained from the univariate time series from a single EEG channel, such as time domain features and recurrence plots, as well as representations obtained directly from the multivariate time series, such as global field power or functional brain networks. To address the cross-subject variability in EEG data, we also investigate persistent homology features that are robust to different types of noise. The performance of the different EEG representations is evaluated with the Support Vector Machine (SVM) accuracy on the WithMe data derived from a modified digit span experiment, and is benchmarked against baseline EEG-specific models, including a deep learning architecture known for effectively learning task-specific features. The raw EEG time series outperform each of the considered data representations, but can fall short in comparison with the black-box deep learning approach that learns the best features. The findings are limited to the WithMe experimental paradigm, highlighting the need for further studies on diverse tasks to provide a more comprehensive understanding of their utility in the analysis of EEG data.",https://pubmed.ncbi.nlm.nih.gov/39867449/,https://pubmed.ncbi.nlm.nih.gov/39867449/,English,Include,,"Who is WithMe? EEG features for attention in a visual task, with auditory and rhythmic support.",Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39851397,pubmed:39851397,PubMed,pubmed:39851397,Exploring Machine Learning Classification of Movement Phases in Hemiparetic Stroke Patients: A Controlled EEG-tDCS Study.,Rishishankar E Suresh;M S Zobaer;Matthew J Triano;Brian F Saway;Parneet Grewal;Nathan C Rowland,2024,10.3390/brainsci14090894,"Noninvasive brain stimulation (NIBS) can boost motor recovery after a stroke. Certain movement phases are more responsive to NIBS, so a system that auto-detects these phases would optimize stimulation timing. This study assessed the effectiveness of various machine learning models in identifying movement phases in hemiparetic individuals undergoing simultaneous NIBS and EEG recordings. We hypothesized that transcranial direct current stimulation (tDCS), a form of NIBS, would enhance EEG signals related to movement phases and improve classification accuracy compared to sham stimulation. EEG data from 10 chronic stroke patients and 11 healthy controls were recorded before, during, and after tDCS. Eight machine learning algorithms and five ensemble methods were used to classify two movement phases (hold posture and reaching) during each of these periods. Data preprocessing included z-score normalization and frequency band power binning. In chronic stroke participants who received active tDCS, the classification accuracy for hold vs. reach phases increased from pre-stimulation to the late intra-stimulation period (72.2% to 75.2%,  Machine learning algorithms showed enhanced movement phase classification during active tDCS in chronic stroke participants. These results suggest their feasibility for real-time movement detection in neurorehabilitation, including brain-computer interfaces for stroke recovery.",https://pubmed.ncbi.nlm.nih.gov/39851397/,https://pubmed.ncbi.nlm.nih.gov/39851397/,English,Include,,Exploring Machine Learning Classification of Movement Phases in Hemiparetic Stroke Patients: A Controlled EEG-tDCS Study.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39851395,pubmed:39851395,PubMed,pubmed:39851395,"A Task-Related EEG Microstate Clustering Algorithm Based on Spatial Patterns, Riemannian Distance, and a Deep Autoencoder.",Shihao Pan;Tongyuan Shen;Yongxiang Lian;Li Shi,2024,10.1109/eusipco.2015.7362879,"The segmentation of electroencephalography (EEG) signals into a limited number of microstates is of significant importance in the field of cognitive neuroscience. Currently, the microstate analysis algorithm based on global field power has demonstrated its efficacy in clustering resting-state EEG. The task-related EEG was extensively analyzed in the field of brain-computer interfaces (BCIs); however, its primary objective is classification rather than segmentation. We propose an innovative algorithm for analyzing task-related EEG microstates based on spatial patterns, Riemannian distance, and a modified deep autoencoder. The objective of this algorithm is to achieve unsupervised segmentation and clustering of task-related EEG signals. The proposed algorithm was validated through experiments conducted on simulated EEG data and two publicly available cognitive task datasets. The evaluation results and statistical tests demonstrate its robustness and efficiency in clustering task-related EEG microstates. The proposed unsupervised algorithm can autonomously discretize EEG signals into a finite number of microstates, thereby facilitating investigations into the temporal structures underlying cognitive processes.",https://pubmed.ncbi.nlm.nih.gov/39851395/,https://pubmed.ncbi.nlm.nih.gov/39851395/,English,Include,,"A Task-Related EEG Microstate Clustering Algorithm Based on Spatial Patterns, Riemannian Distance, and a Deep Autoencoder.",Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39851372,pubmed:39851372,PubMed,pubmed:39851372,Dynamic Neural Network States During Social and Non-Social Cueing in Virtual Reality Working Memory Tasks: A Leading Eigenvector Dynamics Analysis Approach.,Pinar Ozel,2024,10.3389/fnins.2019.00964,"This research investigates brain connectivity patterns in reaction to social and non-social stimuli within a virtual reality environment, emphasizing their impact on cognitive functions, specifically working memory. Employing the LEiDA framework with EEG data from 47 participants, I examined dynamic brain network states elicited by social avatars compared to non-social stick cues during a VR memory task. Through the integration of LEiDA with deep learning and graph theory analyses, unique connectivity patterns associated with cue type were discerned, underscoring the substantial influence of social cues on cognitive processes. LEiDA, conventionally utilized with fMRI, was creatively employed in EEG to detect swift alterations in brain network states, offering insights into cognitive processing dynamics. The findings indicate distinct neural states for social and non-social cues; notably, social cues correlated with a unique brain state characterized by increased connectivity within self-referential and memory-processing networks, implying greater cognitive engagement. Moreover, deep learning attained approximately 99% accuracy in differentiating cue contexts, highlighting the efficacy of prominent eigenvectors from LEiDA in EEG analysis. Analysis of graph theory also uncovered structural network disparities, signifying enhanced integration in contexts involving social cues. This multi-method approach elucidates the dynamic influence of social cues on brain connectivity and cognition, establishing a basis for VR-based cognitive rehabilitation and immersive learning, wherein social signals may significantly enhance cognitive function.",https://pubmed.ncbi.nlm.nih.gov/39851372/,https://pubmed.ncbi.nlm.nih.gov/39851372/,English,Include,,Dynamic Neural Network States During Social and Non-Social Cueing in Virtual Reality Working Memory Tasks: A Leading Eigenvector Dynamics Analysis Approach.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39851299,pubmed:39851299,PubMed,pubmed:39851299,Spatial Cognitive EEG Feature Extraction and Classification Based on MSSECNN and PCMI.,Xianglong Wan;Yue Sun;Yiduo Yao;Wan Zuha Wan Hasan;Dong Wen,2024,10.1016/j.conb.2018.07.009,"With the aging population rising, the decline in spatial cognitive ability has become a critical issue affecting the quality of life among the elderly. Electroencephalogram (EEG) signal analysis presents substantial potential in spatial cognitive assessments. However, conventional methods struggle to effectively classify spatial cognitive states, particularly in tasks requiring multi-class discrimination of pre- and post-training cognitive states. This study proposes a novel approach for EEG signal classification, utilizing Permutation Conditional Mutual Information (PCMI) for feature extraction and a Multi-Scale Squeezed Excitation Convolutional Neural Network (MSSECNN) model for classification. Specifically, the MSSECNN classifies spatial cognitive states into two classes-before and after cognitive training-based on EEG features. First, the PCMI extracts nonlinear spatial features, generating spatial feature matrices across different channels. SENet then adaptively weights these features, highlighting key channels. Finally, the MSCNN model captures local and global features using convolution kernels of varying sizes, enhancing classification accuracy and robustness. This study systematically validates the model using cognitive training data from a brain-controlled car and manually operated UAV tasks, with cognitive state assessments performed through spatial cognition games combined with EEG signals. The experimental findings demonstrate that the proposed model significantly outperforms traditional methods, offering superior classification accuracy, robustness, and feature extraction capabilities. The MSSECNN model's advantages in spatial cognitive state classification provide valuable technical support for early identification and intervention in cognitive decline.",https://pubmed.ncbi.nlm.nih.gov/39851299/,https://pubmed.ncbi.nlm.nih.gov/39851299/,English,Include,,Spatial Cognitive EEG Feature Extraction and Classification Based on MSSECNN and PCMI.,Include,,"Net then adaptively weights these features, highlighting key channels. Finally, the MSCNN model captures local and global features using convolution kernels of varying sizes, enhancing classification accuracy and robustness. This study systematically validates the model using cognitive training data from a brain-controlled car and manually operated UAV tasks, with cognitive state assessments perfo",,0.95,0.6,
pubmed:39850622,pubmed:39850622,PubMed,pubmed:39850622,ClinClip: a Multimodal Language Pre-training model integrating EEG data for enhanced English medical listening assessment.,Guangyu Sun,2024,10.1109/cvpr52688.2022.00836,"In the field of medical listening assessments,accurate transcription and effective cognitive load management are critical for enhancing healthcare delivery. Traditional speech recognition systems, while successful in general applications often struggle in medical contexts where the cognitive state of the listener plays a significant role. These conventional methods typically rely on audio-only inputs and lack the ability to account for the listener's cognitive load, leading to reduced accuracy and effectiveness in complex medical environments. To address these limitations, this study introduces ClinClip, a novel multimodal model that integrates EEG signals with audio data through a transformer-based architecture. ClinClip is designed to dynamically adjust to the cognitive state of the listener, thereby improving transcription accuracy and robustness in medical settings. The model leverages cognitive-enhanced strategies, including EEG-based modulation and hierarchical fusion of multimodal data, to overcome the challenges faced by traditional methods. Experiments conducted on four datasets-EEGEyeNet, DEAP, PhyAAt, and eSports Sensors-demonstrate that ClinClip significantly outperforms six state-of-the-art models in both Word Error Rate (WER) and Cognitive Modulation Efficiency (CME). These results underscore the model's effectiveness in handling complex medical audio scenarios and highlight its potential to improve the accuracy of medical listening assessments. By addressing the cognitive aspects of the listening process. ClinClip contributes to more reliable and effective healthcare delivery, offering a substantial advancement over traditional speech recognition approaches.",https://pubmed.ncbi.nlm.nih.gov/39850622/,https://pubmed.ncbi.nlm.nih.gov/39850622/,English,Include,,ClinClip: a Multimodal Language Pre-training model integrating EEG data for enhanced English medical listening assessment.,Include,,"ve state of the listener plays a significant role. These conventional methods typically rely on audio-only inputs and lack the ability to account for the listener's cognitive load, leading to reduced accuracy and effectiveness in complex medical environments. To address these limitations, this study introduces ClinClip, a novel multimodal model that integrates EEG signals with audio data through a",,0.95,0.6,
pubmed:39850073,pubmed:39850073,PubMed,pubmed:39850073,Single-channel attention classification algorithm based on robust Kalman filtering and norm-constrained ELM.,Jing He;Zijun Huang;Yunde Li;Jiangfeng Shi;Yehang Chen;Chengliang Jiang;Jin Feng,2024,10.1007/s00500-022-07745-x,"Attention classification based on EEG signals is crucial for brain-computer interface (BCI) applications. However, noise interference and real-time signal fluctuations hinder accuracy, especially in portable single-channel devices. This study proposes a robust Kalman filtering method combined with a norm-constrained extreme learning machine (ELM) to address these challenges. The proposed method integrates Discrete Wavelet Transformation (DWT) and Independent Component Analysis (ICA) for noise removal, followed by a robust Kalman filter enhanced with convex optimization to preserve critical EEG components. The norm-constrained ELM employs L1/L2 regularization to improve generalization and classification performance. Experimental data were collected using a Schulte Grid paradigm and TGAM sensors, along with publicly available datasets for validation. The robust Kalman filter demonstrated superior denoising performance, achieving an average AUC of 0.8167 and a maximum AUC of 0.8678 on self-collected datasets, and an average AUC of 0.8344 with a maximum of 0.8950 on public datasets. The method outperformed traditional Kalman filtering, LMS adaptive filtering, and TGAM's eSense algorithm in both noise reduction and attention classification accuracy. The study highlights the effectiveness of combining advanced signal processing and machine learning techniques to improve the robustness and generalization of EEG-based attention classification. Limitations include the small sample size and limited demographic diversity, suggesting future research should expand participant groups and explore broader applications, such as mental health monitoring and neurofeedback.",https://pubmed.ncbi.nlm.nih.gov/39850073/,https://pubmed.ncbi.nlm.nih.gov/39850073/,English,Include,,Single-channel attention classification algorithm based on robust Kalman filtering and norm-constrained ELM.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39845868,pubmed:39845868,PubMed,pubmed:39845868,Which type of feedback-Positive or negative- reinforces decision recall? An EEG study.,Michela Balconi;Laura Angioletti;Roberta A Allegretta,2024,10.3389/fnins.2022.1011475,"This study examines the impact of positive and negative feedback on recall of past decisions, focusing on behavioral performance and electrophysiological (EEG) responses. Participants completed a decision-making task involving 10 real-life scenarios, each followed by immediate positive or negative feedback. In a recall phase, participants' accuracy (ACC), errors (ERRs), and response times (RTs) were recorded alongside EEG data to analyze brain activity patterns related to recall. Results indicate that accurately recalled decisions with positive feedback had slower RTs, suggesting an attentional bias toward positive information that could increase cognitive load during memory retrieval. A lack of difference in recall accuracy implies that social stimuli and situational goals may influence the positivity bias. EEG data showed distinct patterns: lower alpha band activity in frontal regions (AF7, AF8) for both correct and incorrect decisions recall, reflecting focused attention and cognitive control. Correctly recalled decisions with negative feedback showed higher delta activity, often linked to aversive processing, while incorrect recalls with negative feedback showed higher beta and gamma activity. A theta band feedback-dependent modulation in electrode activity showed higher values for decisions with negative feedback, suggesting memory suppression. These findings suggest that recalling decisions linked to self-threatening feedback may require greater cognitive effort, as seen in increased beta and gamma activity, which may indicate motivational processing and selective memory suppression. This study provides insights into the neural mechanisms of feedback-based memory recall, showing how feedback valence affects not only behavioral outcomes but also the cognitive and emotional processes involved in decision recall.",https://pubmed.ncbi.nlm.nih.gov/39845868/,https://pubmed.ncbi.nlm.nih.gov/39845868/,English,Include,,Which type of feedback-Positive or negative- reinforces decision recall? An EEG study.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39845093,pubmed:39845093,PubMed,pubmed:39845093,Multimodal consumer choice prediction using EEG signals and eye tracking.,Syed Muhammad Usman;Shehzad Khalid;Aimen Tanveer;Ali Shariq Imran;Muhammad Zubair,2024,10.1007/s11042-017-4580-6,"Marketing plays a vital role in the success of a business, driving customer engagement, brand recognition, and revenue growth. Neuromarketing adds depth to this by employing insights into consumer behavior through brain activity and emotional responses to create more effective marketing strategies. Electroencephalogram (EEG) has typically been utilized by researchers for neuromarketing, whereas Eye Tracking (ET) has remained unexplored. To address this gap, we propose a novel multimodal approach to predict consumer choices by integrating EEG and ET data. Noise from EEG signals is mitigated using a bandpass filter, Artifact Subspace Reconstruction (ASR), and Fast Orthogonal Regression for Classification and Estimation (FORCE). Class imbalance is handled by employing the Synthetic Minority Over-sampling Technique (SMOTE). Handcrafted features, including statistical and wavelet features, and automated features from Convolutional Neural Network and Long Short-Term Memory (CNN-LSTM), have been extracted and concatenated to generate a feature space representation. For ET data, preprocessing involved interpolation, gaze plots, and SMOTE, followed by feature extraction using LeNet-5 and handcrafted features like fixations and saccades. Multimodal feature space representation was generated by performing feature-level fusion for EEG and ET, which was later fed into a meta-learner-based ensemble classifier with three base classifiers, including Random Forest, Extended Gradient Boosting, and Gradient Boosting, and Random Forest as the meta-classifier, to perform classification between buy vs. not buy. The performance of the proposed approach is evaluated using a variety of performance metrics, including accuracy, precision, recall, and F1 score. Our model demonstrated superior performance compared to competitors by achieving 84.01% accuracy in predicting consumer choices and 83% precision in identifying positive consumer preferences.",https://pubmed.ncbi.nlm.nih.gov/39845093/,https://pubmed.ncbi.nlm.nih.gov/39845093/,English,Include,,Multimodal consumer choice prediction using EEG signals and eye tracking.,Include,,"g, and Random Forest as the meta-classifier, to perform classification between buy vs. not buy. The performance of the proposed approach is evaluated using a variety of performance metrics, including accuracy, precision, recall, and F1 score. Our model demonstrated superior performance compared to competitors by achieving 84.01% accuracy in predicting consumer choices and 83% precision in identify",,0.95,0.6,
pubmed:39844854,pubmed:39844854,PubMed,pubmed:39844854,ID3RSNet: cross-subject driver drowsiness detection from raw single-channel EEG with an interpretable residual shrinkage network.,Xiao Feng;Zhongyuan Guo;Sam Kwong,2024,10.1109/cvpr.2016.319,"Accurate monitoring of drowsy driving through electroencephalography (EEG) can effectively reduce traffic accidents. Developing a calibration-free drowsiness detection system with single-channel EEG alone is very challenging due to the non-stationarity of EEG signals, the heterogeneity among different individuals, and the relatively parsimonious compared to multi-channel EEG. Although deep learning-based approaches can effectively decode EEG signals, most deep learning models lack interpretability due to their black-box nature. To address these issues, we propose a novel interpretable residual shrinkage network, namely, ID3RSNet, for cross-subject driver drowsiness detection using single-channel EEG signals. First, a base feature extractor is employed to extract the essential features of EEG frequencies; to enhance the discriminative feature learning ability, the residual shrinkage building unit with attention mechanism is adopted to perform adaptive feature recalibration and soft threshold denoising inside the residual network is further applied to achieve automatic feature extraction. In addition, a fully connected layer with weight freezing is utilized to effectively suppress the negative influence of neurons on the model classification. With the global average pooling (GAP) layer incorporated in the residual shrinkage network structure, we introduce an EEG-based Class Activation Map (ECAM) interpretable method to enable visualization analysis of sample-wise learned patterns to effectively explain the model decision. Extensive experimental results demonstrate that the proposed method achieves the superior classification performance and has found neurophysiologically reliable evidence of classification.",https://pubmed.ncbi.nlm.nih.gov/39844854/,https://pubmed.ncbi.nlm.nih.gov/39844854/,English,Include,,ID3RSNet: cross-subject driver drowsiness detection from raw single-channel EEG with an interpretable residual shrinkage network.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39840233,pubmed:39840233,PubMed,pubmed:39840233,Directional Spatial and Spectral Attention Network (DSSA Net) for EEG-based emotion recognition.,Jiyao Liu;Lang He;Haifeng Chen;Dongmei Jiang,2024,10.3390/s24113464,"Significant strides have been made in emotion recognition from Electroencephalography (EEG) signals. However, effectively modeling the diverse spatial, spectral, and temporal features of multi-channel brain signals remains a challenge. This paper proposes a novel framework, the Directional Spatial and Spectral Attention Network (DSSA Net), which enhances emotion recognition accuracy by capturing critical spatial-spectral-temporal features from EEG signals. The framework consists of three modules: Positional Attention (PA), Spectral Attention (SA), and Temporal Attention (TA). The PA module includes Vertical Attention (VA) and Horizontal Attention (HA) branches, designed to detect active brain regions from different orientations. Experimental results on three benchmark EEG datasets demonstrate that DSSA Net outperforms most competitive methods. On the SEED and SEED-IV datasets, it achieves accuracies of 96.61% and 85.07% for subject-dependent emotion recognition, respectively, and 87.03% and 75.86% for subject-independent recognition. On the DEAP dataset, it attains accuracies of 94.97% for valence and 94.73% for arousal. These results showcase the framework's ability to leverage both spatial and spectral differences across brain hemispheres and regions, enhancing classification accuracy for emotion recognition.",https://pubmed.ncbi.nlm.nih.gov/39840233/,https://pubmed.ncbi.nlm.nih.gov/39840233/,English,Include,,Directional Spatial and Spectral Attention Network (DSSA Net) for EEG-based emotion recognition.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39840131,pubmed:39840131,PubMed,pubmed:39840131,A novel non-invasive EEG-SSVEP diagnostic tool for color vision deficiency in individuals with locked-in syndrome.,Ghada N AlEssa;Saleh I Alzahrani,2024,10.1155/2010/702357,"Color vision deficiency (CVD), a common visual impairment, affects individuals' ability to differentiate between various colors due to malfunctioning or absent color photoreceptors in the retina. Currently available diagnostic tests require a behavioral response, rendering them unsuitable for individuals with limited physical and communication abilities, such as those with locked-in syndrome. This study introduces a novel, non-invasive method that employs brain signals, specifically Steady-State Visually Evoked Potentials (SSVEPs), along with Ishihara plates to diagnose CVD. This method aims to provide an alternative diagnostic tool that addresses the limitations of current tests. Electroencephalography (EEG) recordings were obtained from 16 subjects, including 5 with CVD (specifically Deuteranomaly), using channels O1, O2, Pz, and Cz. The subjects were exposed to visual stimuli at frequencies of 15 Hz and 18 Hz to assess the proposed method. The subjects focused on specific visual stimuli in response to questions related to the Ishihara plates. Their responses were analyzed to determine the presence of CVD. Feature extraction was performed using Power Spectral Density (PSD), Canonical Correlation Analysis (CCA), and a combined PSD + CCA, followed by classification to categorize subjects into two classes: normal vision and CVD. The results indicate that the proposed method effectively diagnoses CVD in individuals with limited communication abilities. The classification accuracy of SSVEP exceeded 75% across the three classifiers: Decision Tree (DT), K-Nearest Neighbors (KNN), and Support Vector Machine (SVM). The SVM classifier demonstrated higher accuracy compared to the other classifiers, exceeding 90%. These observations suggest that the SVM classifier, utilizing the combined feature set of PSD + CCA, may be the most effective in this classification task. These findings demonstrate that the proposed method is an accurate and reliable diagnostic tool for CVD, particularly for individuals unable to communicate.",https://pubmed.ncbi.nlm.nih.gov/39840131/,https://pubmed.ncbi.nlm.nih.gov/39840131/,English,Include,,A novel non-invasive EEG-SSVEP diagnostic tool for color vision deficiency in individuals with locked-in syndrome.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39840009,pubmed:39840009,PubMed,pubmed:39840009,Preliminary evaluation of the FastCAP for users of the Nurotron cochlear implant.,Xue-Ying Yang;Sui Huang;Qian-Jie Fu;John Galvin;Bing Chen;Ji-Sheng Liu;Duo-Duo Tao,2024,10.1055/s-0040-1718701,"Electrically evoked compound action potential (ECAP) can be used to measure the auditory nerve's response to electrical stimulation in cochlear implant (CI) users. In the Nurotron CI system, extracting the ECAP waveform from the stimulus artifact is time-consuming. We developed a new paradigm (""FastCAP"") for use with Nurotron CI devices. In electrically evoked compound action potential in fast mode (FastCAP), N recordings are averaged directly on the CI hardware before data transmission, significantly reducing data transmission time. FastCAPs and ECAPs were measured across five electrodes and four stimulation levels per electrode. The FastCAP stimulation rate (33.3 Hz) is also faster than the ECAP rate (2.5 Hz). Results showed strong correlations between ECAPs and FastCAPs for N1 latency ( This preliminary evaluation suggests that the FastCAP could be an effective clinical tool to optimize CI processor settings (e.g., threshold stimulation levels) in users of the Nurotron CI device.",,https://pubmed.ncbi.nlm.nih.gov/39840009/,English,Exclude,Not EEG-BCI focused,Preliminary evaluation of the FastCAP for users of the Nurotron cochlear implant.,,,,,0.9,0.6,
pubmed:39834619,pubmed:39834619,PubMed,pubmed:39834619,An EEG-based framework for automated discrimination of conversion to Alzheimer's disease in patients with amnestic mild cognitive impairment: an 18-month longitudinal study.,Yingfeng Ge;Jianan Yin;Caie Chen;Shuo Yang;Yuduan Han;Chonglong Ding;Jiaming Zheng;Yifan Zheng;Jinxin Zhang,2024,10.3389/fncom.2021.698386,"As a clinical precursor to Alzheimer's disease (AD), amnestic mild cognitive impairment (aMCI) bears a considerably heightened risk of transitioning to AD compared to cognitively normal elders. Early prediction of whether aMCI will progress to AD is of paramount importance, as it can provide pivotal guidance for subsequent clinical interventions in an early and effective manner. A total of 107 aMCI cases were enrolled and their electroencephalogram (EEG) data were collected at the time of the initial diagnosis. During 18-month follow-up period, 42 individuals progressed to AD (PMCI), while 65 remained in the aMCI stage (SMCI). Spectral, nonlinear, and functional connectivity features were extracted from the EEG data, subjected to feature selection and dimensionality reduction, and then fed into various machine learning classifiers for discrimination. The performance of each model was assessed using 10-fold cross-validation and evaluated in terms of accuracy (ACC), area under the curve (AUC), sensitivity (SEN), specificity (SPE), positive predictive value (PPV), and F1-score. Compared to SMCI patients, PMCI patients exhibit a trend of ""high to low"" frequency shift, decreased complexity, and a disconnection phenomenon in EEG signals. An epoch-based classification procedure, utilizing the extracted EEG features and  Aiming to explore the EEG biomarkers with predictive value for AD in the early stages of aMCI, the proposed discriminant framework provided robust longitudinal evidence for the trajectory of the aMCI cases, aiding in the achievement of early diagnosis and proactive intervention.",https://pubmed.ncbi.nlm.nih.gov/39834619/,https://pubmed.ncbi.nlm.nih.gov/39834619/,English,Include,,An EEG-based framework for automated discrimination of conversion to Alzheimer's disease in patients with amnestic mild cognitive impairment: an 18-month longitudinal study.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.25,cv_reported
pubmed:39830198,pubmed:39830198,PubMed,pubmed:39830198,Global glucose metabolism rate as diagnostic marker for disorder of consciousness of patients: quantitative FDG-PET study.,Dongsheng Liu;Nan Wang;Ming Song;Xiaoke Chai;Qiheng He;Tianqing Cao;Dawei Kong;Zhuhuan Song;Guangming Zhang;Lei Liu;Xiaosong Wang;Guoqiang Chen;Shaoya Yin;Yi Yang;Jizong Zhao,2024,10.1212/wnl.0b013e31823fcd61,"This study was to employ 18F-flurodeoxyglucose (FDG-PET) to evaluate the resting-state brain glucose metabolism in a sample of 46 patients diagnosed with disorders of consciousness (DoC). The aim was to identify objective quantitative metabolic indicators and predictors that could potentially indicate the level of awareness in these patients. A cohort of 46 patients underwent Coma Recovery Scale-Revised (CRS-R) assessments in order to distinguish between the minimally conscious state (MCS) and the unresponsive wakefulness syndrome (UWS). Additionally, resting-state FDG-PET data were acquired from both the patient group and a control group consisting of 10 healthy individuals. The FDG-PET data underwent reorientation, spatial normalization to a stereotaxic space, and smoothing. The normalization procedure utilized a customized template following the methodology outlined by Phillips et al. Mean cortical metabolism of the overall sample was utilized for distinguishing between UWS and MCS, as well as for predicting the outcome at a 1-year follow-up through the application of receiver operating characteristic (ROC) analysis. We used Global Glucose Metabolism as the Diagnostic Marker. A one-way ANOVA revealed that there was a statistically significant difference in cortical metabolic index between two groups ( Our findings demonstrate that conscious awareness requires a minimum of 41% of normal cortical activity, as indicated by metabolic rates.",,https://pubmed.ncbi.nlm.nih.gov/39830198/,English,Exclude,Not EEG-BCI focused,Global glucose metabolism rate as diagnostic marker for disorder of consciousness of patients: quantitative FDG-PET study.,,,,,0.9,0.6,
pubmed:39829439,pubmed:39829439,PubMed,pubmed:39829439,Leveraging deep learning for robust EEG analysis in mental health monitoring.,Zixiang Liu;Juan Zhao,2024,10.1109/icbaie56435.2022.9985881,"Mental health monitoring utilizing EEG analysis has garnered notable interest due to the non-invasive characteristics and rich temporal information encoded in EEG signals, which are indicative of cognitive and emotional conditions. Conventional methods for EEG-based mental health evaluation often depend on manually crafted features or basic machine learning approaches, like support vector classifiers or superficial neural networks. Despite the potential of these approaches, they often fall short in capturing the intricate spatiotemporal relationships within EEG data, leading to lower classification accuracy and poor adaptability across various populations and mental health scenarios. To overcome these limitations, we introduce the EEG Mind-Transformer, an innovative deep learning architecture composed of a Dynamic Temporal Graph Attention Mechanism (DT-GAM), a Hierarchical Graph Representation and Analysis (HGRA) module, and a Spatial-Temporal Fusion Module (STFM). The DT-GAM is designed to dynamically extract temporal dependencies within EEG data, while the HGRA models the brain's hierarchical structure to capture both localized and global interactions among different brain regions. The STFM synthesizes spatial and temporal elements, generating a comprehensive representation of EEG signals. Our empirical results confirm that the EEG Mind-Transformer significantly surpasses conventional approaches, achieving an accuracy of 92.5%, a recall of 91.3%, an F1-score of 90.8%, and an AUC of 94.2% across several datasets. These findings underline the model's robustness and its generalizability to diverse mental health conditions. Moreover, the EEG Mind-Transformer not only pushes the boundaries of state-of-the-art EEG-based mental health monitoring but also offers meaningful insights into the underlying brain functions associated with mental disorders, solidifying its value for both research and clinical settings.",https://pubmed.ncbi.nlm.nih.gov/39829439/,https://pubmed.ncbi.nlm.nih.gov/39829439/,English,Include,,Leveraging deep learning for robust EEG analysis in mental health monitoring.,Include,," superficial neural networks. Despite the potential of these approaches, they often fall short in capturing the intricate spatiotemporal relationships within EEG data, leading to lower classification accuracy and poor adaptability across various populations and mental health scenarios. To overcome these limitations, we introduce the EEG Mind-Transformer, an innovative deep learning architecture co",,0.95,0.6,
pubmed:39811472,pubmed:39811472,PubMed,pubmed:39811472,Enhancing prosthetic hand control: A synergistic multi-channel electroencephalogram.,Pooya Chanu Maibam;Dingyi Pei;Parthan Olikkal;Ramana Kumar Vinjamuri;Nayan M Kakoty,2024,10.1017/wtc.2024.13,"Electromyogram (EMG) has been a fundamental approach for prosthetic hand control. However it is limited by the functionality of residual muscles and muscle fatigue. Currently, exploring temporal shifts in brain networks and accurately classifying noninvasive electroencephalogram (EEG) for prosthetic hand control remains challenging. In this manuscript, it is hypothesized that the coordinated and synchronized temporal patterns within the brain network, termed as brain synergy, contain valuable information to decode hand movements. 32-channel EEGs were acquired from 10 healthy participants during hand grasp and open. Synergistic spatial distribution pattern and power spectra of brain activity were investigated using independent component analysis of EEG. Out of 32 EEG channels, 15 channels spanning the frontal, central and parietal regions were strategically selected based on the synergy of spatial distribution pattern and power spectrum of independent components. Time-domain and synergistic features were extracted from the selected 15 EEG channels. These features were employed to train a Bayesian optimizer-based support vector machine (SVM). The optimized SVM classifier could achieve an average testing accuracy of 94.39 .84% using synergistic features. The paired ",https://pubmed.ncbi.nlm.nih.gov/39811472/,https://pubmed.ncbi.nlm.nih.gov/39811472/,English,Include,,Enhancing prosthetic hand control: A synergistic multi-channel electroencephalogram.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39807512,pubmed:39807512,PubMed,pubmed:39807512,Sleep stages classification based on feature extraction from music of brain.,Hamidreza Jalali;Majid Pouladian;Ali Motie Nasrabadi;Azin Movahed,2025,10.1016/j.heliyon.2024.e41147,"Sleep stages classification one of the essential factors concerning sleep disorder diagnoses, which can contribute to many functional disease treatments or prevent the primary cognitive risks in daily activities. In this study, A novel method of mapping EEG signals to music is proposed to classify sleep stages. A total of 4.752 selected 1-min sleep records extracted from the capsleep database are applied as the statistical population for this assessment. In this process, first, the tempo and scale parameters are extracted from the signal according to the rules of music, and next by applying them and changing the dominant frequency of the pre-processed single-channel EEG signal, a sequence of musical notes is produced. A total of 19 features are extracted from the sequence of notes and fed into feature reduction algorithms; the selected features are applied to a two-stage classification structure: 1) the classification of 5 classes (merging S1 and REM-S2-S3-S4-W) is made with an accuracy of 89.5 % (Cap sleep database), 85.9 % (Sleep-EDF database), 86.5 % (Sleep-EDF expanded database), and 2) the classification of 2 classes (S1 vs. REM) is made with an accuracy of 90.1 % (Cap sleep database),88.9 % (Sleep-EDF database), 90.1 % (Sleep-EDF expanded database). The overall percentage of correct classification for 6 sleep stages are 88.13 %, 84.3 % and 86.1 % for those databases, respectively. The other objective of this study is to present a new single-channel EEG sonification method, The classification accuracy obtained is higher or comparable to contemporary methods. This shows the efficiency of our proposed method.",,https://pubmed.ncbi.nlm.nih.gov/39807512/,English,Exclude,Outside date range,Sleep stages classification based on feature extraction from music of brain.,,,,,0.95,0.6,
pubmed:39796911,pubmed:39796911,PubMed,pubmed:39796911,Performance Improvement with Reduced Number of Channels in Motor Imagery BCI System.,Ali Özkahraman;Tamer Ölmez;Zümray Dokur,2024,10.3389/fnins.2013.00267,"Classifying Motor Imaging (MI) Electroencephalogram (EEG) signals is of vital importance for Brain-Computer Interface (BCI) systems, but challenges remain. A key challenge is to reduce the number of channels to improve flexibility, portability, and computational efficiency, especially in multi-class scenarios where more channels are needed for accurate classification. This study demonstrates that combining Electrooculogram (EOG) channels with a reduced set of EEG channels is more effective than relying on a large number of EEG channels alone. EOG channels provide useful information for MI signal classification, countering the notion that they only introduce eye-related noise. The study uses advanced deep learning techniques, including multiple 1D convolution blocks and depthwise-separable convolutions, to optimize classification accuracy. The findings in this study are tested on two datasets: dataset 1, the BCI Competition IV Dataset IIa (4-class MI), and dataset 2, the Weibo dataset (7-class MI). The performance for dataset 1, utilizing 3 EEG and 3 EOG channels (6 channels total), is of 83% accuracy, while dataset 2, with 3 EEG and 2 EOG channels (5 channels total), achieves an accuracy of 61%, demonstrating the effectiveness of the proposed channel reduction method and deep learning model.",https://pubmed.ncbi.nlm.nih.gov/39796911/,https://pubmed.ncbi.nlm.nih.gov/39796911/,English,Include,,Performance Improvement with Reduced Number of Channels in Motor Imagery BCI System.,Include,,"that they only introduce eye-related noise. The study uses advanced deep learning techniques, including multiple 1D convolution blocks and depthwise-separable convolutions, to optimize classification accuracy. The findings in this study are tested on two datasets: dataset 1, the BCI Competition IV Dataset IIa (4-class MI), and dataset 2, the Weibo dataset (7-class MI). The performance for dataset ",,0.95,0.6,
pubmed:39796844,pubmed:39796844,PubMed,pubmed:39796844,Exploring Task-Related EEG for Cross-Subject Early Alzheimer's Disease Susceptibility Prediction in Middle-Aged Adults Using Multitaper Spectral Analysis.,Ziyang Li;Hong Wang;Jianing Song;Jiale Gong,2024,10.1152/jn.00041.2021,"The early prediction of Alzheimer's disease (AD) risk in healthy individuals remains a significant challenge. This study investigates the feasibility of task-state EEG signals for improving detection accuracy. Electroencephalogram (EEG) data were collected from the Multi-Source Interference Task (MSIT) and Sternberg Memory Task (STMT). Time-frequency features were extracted using the Multitaper method, followed by multidimensional reduction techniques. Subspace features (F24 and F216) were selected via ",https://pubmed.ncbi.nlm.nih.gov/39796844/,https://pubmed.ncbi.nlm.nih.gov/39796844/,English,Include,,Exploring Task-Related EEG for Cross-Subject Early Alzheimer's Disease Susceptibility Prediction in Middle-Aged Adults Using Multitaper Spectral Analysis.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39796842,pubmed:39796842,PubMed,pubmed:39796842,Epilepsy Prediction and Detection Using Attention-CssCDBN with Dual-Task Learning.,Weizheng Qiao;Xiaojun Bi;Lu Han;Yulin Zhang,2024,10.3390/brainsci14080839,"Epilepsy is a group of neurological disorders characterized by epileptic seizures, and it affects tens of millions of people worldwide. Currently, the most effective diagnostic method employs the monitoring of brain activity through electroencephalogram (EEG). However, it is critical to predict epileptic seizures in patients prior to their onset, allowing for the administration of preventive medications before the seizure occurs. As a pivotal application of artificial intelligence in medical treatment, learning the features of EEGs for epilepsy prediction and detection remains a challenging problem, primarily due to the presence of intra-class and inter-class variations in EEG signals. In this study, we propose the spatio-temporal EEGNet, which integrates contractive slab and spike convolutional deep belief network (CssCDBN) with a self-attention architecture, augmented by dual-task learning to address this issue. Initially, our model was designed to extract high-order and deep representations from EEG spectrum images, enabling the simultaneous capture of spatial and temporal information. Furthermore, EEG-based verification aids in reducing intra-class variation by considering the time correlation of the EEG during the fine-tuning stage, resulting in easier inference and training. The results demonstrate the notable efficacy of our proposed method. Our method achieved a sensitivity of 98.5%, a false-positive rate (FPR) of 0.041, a prediction time of 50.92 min during the epilepsy prediction task, and an accuracy of 94.1% during the epilepsy detection task, demonstrating significant improvements over current state-of-the-art methods.",https://pubmed.ncbi.nlm.nih.gov/39796842/,https://pubmed.ncbi.nlm.nih.gov/39796842/,English,Include,,Epilepsy Prediction and Detection Using Attention-CssCDBN with Dual-Task Learning.,Include,,"e notable efficacy of our proposed method. Our method achieved a sensitivity of 98.5%, a false-positive rate (FPR) of 0.041, a prediction time of 50.92 min during the epilepsy prediction task, and an accuracy of 94.1% during the epilepsy detection task, demonstrating significant improvements over current state-of-the-art methods.",,0.95,0.6,
pubmed:39796823,pubmed:39796823,PubMed,pubmed:39796823,A Novel Real-Time Threshold Algorithm for Closed-Loop Epilepsy Detection and Stimulation System.,Liang-Hung Wang;Zhen-Nan Zhang;Chao-Xin Xie;Hao Jiang;Tao Yang;Qi-Peng Ran;Ming-Hui Fan;I-Chun Kuo;Zne-Jung Lee;Jian-Bo Chen;Tsung-Yi Chen;Shih-Lun Chen;Patricia Angela R Abu,2024,10.1016/j.compbiomed.2022.105366,"Epilepsy, as a common brain disease, causes great pain and stress to patients around the world. At present, the main treatment methods are drug, surgical, and electrical stimulation therapies. Electrical stimulation has recently emerged as an alternative treatment for reducing symptomatic seizures. This study proposes a novel closed-loop epilepsy detection system and stimulation control chip. A time-domain detection algorithm based on amplitude, slope, line length, and signal energy characteristics is introduced. A new threshold calculation method is proposed; that is, the threshold is updated by means of the mean and standard deviation of four consecutive eigenvalues through parameter combination. Once a seizure is detected, the system begins to control the stimulation of a two-phase pulse current with an amplitude and frequency of 34 μA and 200 Hz, respectively. The system is physically designed on the basis of the UMC 55 nm process and verified by a field programmable gate array verification board. This research is conducted through innovative algorithms to reduce power consumption and the area of the circuit. It can maintain a high accuracy of more than 90% and perform seizure detection every 64 ms. It is expected to provide a new treatment for patients with epilepsy.",,https://pubmed.ncbi.nlm.nih.gov/39796823/,English,Exclude,Not EEG-BCI focused,A Novel Real-Time Threshold Algorithm for Closed-Loop Epilepsy Detection and Stimulation System.,,,,,0.9,0.6,
pubmed:39781056,pubmed:39781056,PubMed,pubmed:39781056,A high performance heterogeneous hardware architecture for brain computer interface.,Zhengbo Cai;Penghai Li;Longlong Cheng;Ding Yuan;Mingji Li;Hongji Li,2025,10.3389/fnhum.2018.00187/full,"Brain-computer interface (BCI) has been widely used in human-computer interaction. The introduction of artificial intelligence has further improved the performance of BCI system. In recent years, the development of BCI has gradually shifted from personal computers to embedded devices, which boasts lower power consumption and smaller size, but at the cost of limited device resources and computing speed, thus can hardly improve the support of complex algorithms. This paper proposes a heterogeneous BCI architecture based on ARM + FPGA, enabling real-time processing of electroencephalogram (EEG) signals. Adopting data quantization, layer fusion and data augmentation to optimize the compact neural network model EEGNet, and design dedicated hardware engines to accelerate the network. Experimental results show that the system achieves 93.3% classification accuracy for steady-state visual evoked potential signals, with a time delay of 0.2 ms per trail, and a power consumption of approximately (1.91 W). That is 31.5 times faster acceleration is realized at the cost of only 0.7% lower accuracy compared with the conventional processor. The results show that the BCI architecture proposed in this study has strong practicability and high research significance.",,https://pubmed.ncbi.nlm.nih.gov/39781056/,English,Exclude,Outside date range,A high performance heterogeneous hardware architecture for brain computer interface.,,,,,0.95,0.6,
pubmed:39781053,pubmed:39781053,PubMed,pubmed:39781053,Driver fatigue recognition using limited amount of individual electroencephalogram.,Pukyeong Seo;Hyun Kim;Kyung Hwan Kim,2025,10.1007/s13534-024-00431-x,"This study aims to create a fatigue recognition system that utilizes electroencephalogram (EEG) signals to assess a driver's physiological and mental state, with the goal of minimizing the risk of road accidents by detecting driver fatigue regardless of physical cues or vehicle attributes. A fatigue state recognition system was developed using transfer learning applied to partial ensemble averaged EEG power spectral density (PSD). The study utilized layer-wise relevance propagation (LRP) analysis to identify critical cortical regions and frequency bands for effective fatigue discrimination. A total of 21 participants were included in the study, and data augmentation techniques were used to enhance the system's classification accuracy. The results indicate a significant improvement in classification accuracy, particularly with the application of data augmentation. The classification accuracies were 99.2 ± 2.3% for the training data, 97.9 ± 3.1% for the validation data, and 96.9 ± 3.3% for the test data. This study advances the development of personalized EEG-based fatigue monitoring systems that have the potential to improve road safety and reduce accidents. The findings highlight the utility of EEG signals in detecting fatigue and the benefits of data augmentation in improving system performance. Further research is recommended to optimize data augmentation strategies and enhance the scalability and efficiency of the system. The online version contains supplementary material available at 10.1007/s13534-024-00431-x.",,https://pubmed.ncbi.nlm.nih.gov/39781053/,English,Exclude,Outside date range,Driver fatigue recognition using limited amount of individual electroencephalogram.,,,,,0.95,0.8,small_sample_mentioned
pubmed:39776784,pubmed:39776784,PubMed,pubmed:39776784,A Bayesian dynamic stopping method for evoked response brain-computer interfacing.,Sara Ahmadi;Peter Desain;Jordy Thielen,2024,10.1109/tbme.2008.919128,"As brain-computer interfacing (BCI) systems transition fromassistive technology to more diverse applications, their speed, reliability, and user experience become increasingly important. Dynamic stopping methods enhance BCI system speed by deciding at any moment whether to output a result or wait for more information. Such approach leverages trial variance, allowing good trials to be detected earlier, thereby speeding up the process without significantly compromising accuracy. Existing dynamic stopping algorithms typically optimize measures such as symbols per minute (SPM) and information transfer rate (ITR). However, these metrics may not accurately reflect system performance for specific applications or user types. Moreover, many methods depend on arbitrary thresholds or parameters that require extensive training data. We propose a model-based approach that takes advantage of the analytical knowledge that we have about the underlying classification model. By using a risk minimization approach, our model allows precise control over the types of errors and the balance between precision and speed. This adaptability makes it ideal for customizing BCI systems to meet the diverse needs of various applications. We validate our proposed method on a publicly available dataset, comparing it with established static and dynamic stopping methods. Our results demonstrate that our approach offers a broad range of accuracy-speed trade-offs and achieves higher precision than baseline stopping methods.",https://pubmed.ncbi.nlm.nih.gov/39776784/,https://pubmed.ncbi.nlm.nih.gov/39776784/,English,Include,,A Bayesian dynamic stopping method for evoked response brain-computer interfacing.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39771907,pubmed:39771907,PubMed,pubmed:39771907,Attention-Based PSO-LSTM for Emotion Estimation Using EEG.,Hayato Oka;Keiko Ono;Adamidis Panagiotis,2024,10.3390/s20236727,"Recent advances in emotion recognition through Artificial Intelligence (AI) have demonstrated potential applications in various fields (e.g., healthcare, advertising, and driving technology), with electroencephalogram (EEG)-based approaches demonstrating superior accuracy compared to facial or vocal methods due to their resistance to intentional manipulation. This study presents a novel approach to enhance EEG-based emotion estimation accuracy by emphasizing temporal features and efficient parameter space exploration. We propose a model combining Long Short-Term Memory (LSTM) with an attention mechanism to highlight temporal features in EEG data while optimizing LSTM parameters through Particle Swarm Optimization (PSO). The attention mechanism assigned weights to LSTM hidden states, and PSO dynamically optimizes the vital parameters, including units, batch size, and dropout rate. Using the DEAP and SEED datasets, which serve as benchmark datasets for emotion estimation research using EEG, we evaluate the model's performance. For the DEAP dataset, we conduct a four-class classification of combinations of high and low valence and arousal states. We perform a three-class classification of negative, neutral, and positive emotions for the SEED dataset. The proposed model achieves an accuracy of 0.9409 on the DEAP dataset, surpassing the previous state-of-the-art accuracy of 0.9100 reported by Lin et al. The model attains an accuracy of 0.9732 on the SEED dataset, recording one of the highest accuracies among the related research. These results demonstrate that integrating the attention mechanism with PSO significantly improves the accuracy of EEG-based emotion estimation, contributing to the advancement of emotion recognition technology.",https://pubmed.ncbi.nlm.nih.gov/39771907/,https://pubmed.ncbi.nlm.nih.gov/39771907/,English,Include,,Attention-Based PSO-LSTM for Emotion Estimation Using EEG.,Include,,"igence (AI) have demonstrated potential applications in various fields (e.g., healthcare, advertising, and driving technology), with electroencephalogram (EEG)-based approaches demonstrating superior accuracy compared to facial or vocal methods due to their resistance to intentional manipulation. This study presents a novel approach to enhance EEG-based emotion estimation accuracy by emphasizing t",,0.95,0.6,
pubmed:39771903,pubmed:39771903,PubMed,pubmed:39771903,Systematic Review of EEG-Based Imagined Speech Classification Methods.,Salwa Alzahrani;Haneen Banjar;Rsha Mirza,2024,10.1038/s41597-022-01147-2,"This systematic review examines EEG-based imagined speech classification, emphasizing directional words essential for development in the brain-computer interface (BCI). This study employed a structured methodology to analyze approaches using public datasets, ensuring systematic evaluation and validation of results. This review highlights the feature extraction techniques that are pivotal to classification performance. These include deep learning, adaptive optimization, and frequency-specific decomposition, which enhance accuracy and robustness. Classification methods were explored by comparing traditional machine learning with deep learning and emphasizing the role of brain lateralization in imagined speech for effective recognition and classification. This study discusses the challenges of generalizability and scalability in imagined speech recognition, focusing on subject-independent approaches and multiclass scalability. Performance benchmarking across various datasets and methodologies revealed varied classification accuracies, reflecting the complexity and variability of EEG signals. This review concludes that challenges remain despite progress, particularly in classifying directional words. Future research directions include improved signal processing techniques, advanced neural network architectures, and more personalized, adaptive BCI systems. This review is critical for future efforts to develop practical communication tools for individuals with speech and motor impairments using EEG-based BCIs.",,https://pubmed.ncbi.nlm.nih.gov/39771903/,English,Exclude,Review/survey papers,Systematic Review of EEG-Based Imagined Speech Classification Methods.,,,,,0.95,0.6,
pubmed:39771880,pubmed:39771880,PubMed,pubmed:39771880,Multivariate Modelling and Prediction of High-Frequency Sensor-Based Cerebral Physiologic Signals: Narrative Review of Machine Learning Methodologies.,Nuray Vakitbilir;Abrar Islam;Alwyn Gomez;Kevin Y Stein;Logan Froese;Tobias Bergmann;Amanjyot Singh Sainbhi;Davis McClarty;Rahul Raj;Frederick A Zeiler,2024,10.1016/j.jneumeth.2021.109282,"Monitoring cerebral oxygenation and metabolism, using a combination of invasive and non-invasive sensors, is vital due to frequent disruptions in hemodynamic regulation across various diseases. These sensors generate continuous high-frequency data streams, including intracranial pressure (ICP) and cerebral perfusion pressure (CPP), providing real-time insights into cerebral function. Analyzing these signals is crucial for understanding complex brain processes, identifying subtle patterns, and detecting anomalies. Computational models play an essential role in linking sensor-derived signals to the underlying physiological state of the brain. Multivariate machine learning models have proven particularly effective in this domain, capturing intricate relationships among multiple variables simultaneously and enabling the accurate modeling of cerebral physiologic signals. These models facilitate the development of advanced diagnostic and prognostic tools, promote patient-specific interventions, and improve therapeutic outcomes. Additionally, machine learning models offer great flexibility, allowing different models to be combined synergistically to address complex challenges in sensor-based data analysis. Ensemble learning techniques, which aggregate predictions from diverse models, further enhance predictive accuracy and robustness. This review explores the use of multivariate machine learning models in cerebral physiology as a whole, with an emphasis on sensor-derived signals related to hemodynamics, cerebral oxygenation, metabolism, and other modalities such as electroencephalography (EEG) and functional near-infrared spectroscopy (fNIRS) where applicable. It will detail the operational principles, mathematical foundations, and clinical implications of these models, providing a deeper understanding of their significance in monitoring cerebral function.",,https://pubmed.ncbi.nlm.nih.gov/39771880/,English,Exclude,Review/survey papers,Multivariate Modelling and Prediction of High-Frequency Sensor-Based Cerebral Physiologic Signals: Narrative Review of Machine Learning Methodologies.,,,,,0.95,0.6,
pubmed:39771862,pubmed:39771862,PubMed,pubmed:39771862,Enhancing Deep-Learning Classification for Remote Motor Imagery Rehabilitation Using Multi-Subject Transfer Learning in IoT Environment.,Joharah Khabti;Saad AlAhmadi;Adel Soudani,2024,10.3390/s22239547,"One of the most promising applications for electroencephalogram (EEG)-based brain-computer interfaces (BCIs) is motor rehabilitation through motor imagery (MI) tasks. However, current MI training requires physical attendance, while remote MI training can be applied anywhere, facilitating flexible rehabilitation. Providing remote MI training raises challenges to ensuring an accurate recognition of MI tasks by healthcare providers, in addition to managing computation and communication costs. The MI tasks are recognized through EEG signal processing and classification, which can drain sensor energy due to the complexity of the data and the presence of redundant information, often influenced by subject-dependent factors. To address these challenges, we propose in this paper a multi-subject transfer-learning approach for an efficient MI training framework in remote rehabilitation within an IoT environment. For efficient implementation, we propose an IoT architecture that includes cloud/edge computing as a solution to enhance the system's efficiency and reduce the use of network resources. Furthermore, deep-learning classification with and without channel selection is applied in the cloud, while multi-subject transfer-learning classification is utilized at the edge node. Various transfer-learning strategies, including different epochs, freezing layers, and data divisions, were employed to improve accuracy and efficiency. To validate this framework, we used the BCI IV 2a dataset, focusing on subjects 7, 8, and 9 as targets. The results demonstrated that our approach significantly enhanced the average accuracy in both multi-subject and single-subject transfer-learning classification. In three-subject transfer-learning classification, the FCNNA model achieved up to 79.77% accuracy without channel selection and 76.90% with channel selection. For two-subject and single-subject transfer learning, the application of transfer learning improved the average accuracy by up to 6.55% and 12.19%, respectively, compared to classification without transfer learning. This framework offers a promising solution for remote MI rehabilitation, providing both accurate task recognition and efficient resource usage.",https://pubmed.ncbi.nlm.nih.gov/39771862/,https://pubmed.ncbi.nlm.nih.gov/39771862/,English,Include,,Enhancing Deep-Learning Classification for Remote Motor Imagery Rehabilitation Using Multi-Subject Transfer Learning in IoT Environment.,Include,,"-subject transfer-learning classification is utilized at the edge node. Various transfer-learning strategies, including different epochs, freezing layers, and data divisions, were employed to improve accuracy and efficiency. To validate this framework, we used the BCI IV 2a dataset, focusing on subjects 7, 8, and 9 as targets. The results demonstrated that our approach significantly enhanced the a",,0.95,0.6,
pubmed:39771843,pubmed:39771843,PubMed,pubmed:39771843;pubmed:39686319,Comparison of EEG Signal Spectral Characteristics Obtained with Consumer- and Research-Grade Devices.,Dmitry Mikhaylov;Muhammad Saeed;Mohamed Husain Alhosani;Yasser F Al Wahedi,2024,10.1109/tits.2023.3348517,"Electroencephalography (EEG) has emerged as a pivotal tool in both research and clinical practice due to its non-invasive nature, cost-effectiveness, and ability to provide real-time monitoring of brain activity. Wearable EEG technology opens new avenues for consumer applications, such as mental health monitoring, neurofeedback training, and brain-computer interfaces. However, there is still much to verify and re-examine regarding the functionality of these devices and the quality of the signal they capture, particularly as the field evolves rapidly. In this study, we recorded the resting-state brain activity of healthy volunteers via three consumer-grade EEG devices, namely PSBD Headband Pro, PSBD Headphones Lite, and Muse S Gen 2, and compared the spectral characteristics of the signal obtained with that recorded via the research-grade Brain Product amplifier (BP) with the mirroring montages. The results showed that all devices exhibited higher mean power in the low-frequency bands, which are characteristic of dry-electrode technology. PSBD Headband proved to match BP most precisely among the other examined devices. PSBD Headphones displayed a moderate correspondence with BP and signal quality issues in the central group of electrodes. Muse demonstrated the poorest signal quality, with extremely low alignment with BP. Overall, this study underscores the importance of considering device-specific design constraints and emphasizes the need for further validation to ensure the reliability and accuracy of wearable EEG devices.",https://pubmed.ncbi.nlm.nih.gov/39771843/,https://pubmed.ncbi.nlm.nih.gov/39771843/,English,Include,,Comparison of EEG Signal Spectral Characteristics Obtained with Consumer- and Research-Grade Devices.,Exclude,Duplicate study,Duplicate group,,0.99,0.6,
pubmed:39771785,pubmed:39771785,PubMed,pubmed:39771785,Improving the Performance of Electrotactile Brain-Computer Interface Using Machine Learning Methods on Multi-Channel Features of Somatosensory Event-Related Potentials.,Marija Novičić;Olivera Djordjević;Vera Miler-Jerković;Ljubica Konstantinović;Andrej M Savić,2024,10.1155/2021/6694310,"Traditional tactile brain-computer interfaces (BCIs), particularly those based on steady-state somatosensory-evoked potentials, face challenges such as lower accuracy, reduced bit rates, and the need for spatially distant stimulation points. In contrast, using transient electrical stimuli offers a promising alternative for generating tactile BCI control signals: somatosensory event-related potentials (sERPs). This study aimed to optimize the performance of a novel electrotactile BCI by employing advanced feature extraction and machine learning techniques on sERP signals for the classification of users' selective tactile attention. The experimental protocol involved ten healthy subjects performing a tactile attention task, with EEG signals recorded from five EEG channels over the sensory-motor cortex. We employed sequential forward selection (SFS) of features from temporal sERP waveforms of all EEG channels. We systematically tested classification performance using machine learning algorithms, including logistic regression, k-nearest neighbors, support vector machines, random forests, and artificial neural networks. We explored the effects of the number of stimuli required to obtain sERP features for classification and their influence on accuracy and information transfer rate. Our approach indicated significant improvements in classification accuracy compared to previous studies. We demonstrated that the number of stimuli for sERP generation can be reduced while increasing the information transfer rate without a statistically significant decrease in classification accuracy. In the case of the support vector machine classifier, we achieved a mean accuracy over 90% for 10 electrical stimuli, while for 6 stimuli, the accuracy decreased by less than 7%, and the information transfer rate increased by 60%. This research advances methods for tactile BCI control based on event-related potentials. This work is significant since tactile stimulation is an understudied modality for BCI control, and electrically induced sERPs are the least studied control signals in reactive BCIs. Exploring and optimizing the parameters of sERP elicitation, as well as feature extraction and classification methods, is crucial for addressing the accuracy versus speed trade-off in various assistive BCI applications where the tactile modality may have added value.",https://pubmed.ncbi.nlm.nih.gov/39771785/,https://pubmed.ncbi.nlm.nih.gov/39771785/,English,Include,,Improving the Performance of Electrotactile Brain-Computer Interface Using Machine Learning Methods on Multi-Channel Features of Somatosensory Event-Related Potentials.,Include,,"Traditional tactile brain-computer interfaces (BCIs), particularly those based on steady-state somatosensory-evoked potentials, face challenges such as lower accuracy, reduced bit rates, and the need for spatially distant stimulation points. In contrast, using transient electrical stimuli offers a promising alternative for generating tactile BCI control si",,0.95,0.6,
pubmed:39771656,pubmed:39771656,PubMed,pubmed:39771656,Unlocking Security for Comprehensive Electroencephalogram-Based User Authentication Systems.,Adnan Elahi Khan Khalil;Jesus Arturo Perez-Diaz;Jose Antonio Cantoral-Ceballos;Javier M Antelis,2024,10.1007/s11571-021-09664-3,"With recent significant advancements in artificial intelligence, the necessity for more reliable recognition systems has rapidly increased to safeguard individual assets. The use of brain signals for authentication has gained substantial interest within the scientific community over the past decade. Most previous efforts have focused on identifying distinctive information within electroencephalogram (EEG) recordings. In this study, an EEG-based user authentication scheme is presented, employing a multi-layer perceptron feedforward neural network (MLP FFNN). The scheme utilizes P300 potentials derived from EEG signals, focusing on the user's intent to select specific characters. This approach involves two phases: user identification and user authentication. Both phases utilize EEG recordings of brain signals, data preprocessing, a database to store and manage these recordings for efficient retrieval and organization, and feature extraction using mutual information (MI) from selected EEG data segments, specifically targeting power spectral density (PSD) across five frequency bands. The user identification phase employs multi-class classifiers to predict the identity of a user from a set of enrolled users. The user authentication phase associates the predicted user identities with user labels using probability assessments, verifying the claimed identity as either genuine or an impostor. This scheme combines EEG data segments with user mapping, confidence calculations, and claimed user verification for robust authentication. It also accommodates new users by transforming EEG data into feature vectors without the need for retraining. The model extracts selected features to identify users and to classify the input based on these features to authenticate the user. The experiments show that the proposed scheme can achieve 97% accuracy in EEG-based user identification and authentication.",https://pubmed.ncbi.nlm.nih.gov/39771656/,https://pubmed.ncbi.nlm.nih.gov/39771656/,English,Include,,Unlocking Security for Comprehensive Electroencephalogram-Based User Authentication Systems.,Include,,ining. The model extracts selected features to identify users and to classify the input based on these features to authenticate the user. The experiments show that the proposed scheme can achieve 97% accuracy in EEG-based user identification and authentication.,,0.95,0.6,
pubmed:39771620,pubmed:39771620,PubMed,pubmed:39771620,Model-Based Electroencephalogram Instantaneous Frequency Tracking: Application in Automated Sleep-Wake Stage Classification.,Masoud Nateghi;Mahdi Rahbar Alam;Hossein Amiri;Samaneh Nasiri;Reza Sameni,2024,10.1152/jappl.1959.14.2.247,"Understanding sleep stages is crucial for diagnosing sleep disorders, developing treatments, and studying sleep's impact on overall health. With the growing availability of affordable brain monitoring devices, the volume of collected brain data has increased significantly. However, analyzing these data, particularly when using the gold standard multi-lead electroencephalogram (EEG), remains resource-intensive and time-consuming. To address this challenge, automated brain monitoring has emerged as a crucial solution for cost-effective and efficient EEG data analysis. A critical component of sleep analysis is detecting transitions between wakefulness and sleep states. These transitions offer valuable insights into sleep quality and quantity, essential for diagnosing sleep disorders, designing effective interventions, enhancing overall health and well-being, and studying sleep's effects on cognitive function, mood, and physical performance. This study presents a novel EEG feature extraction pipeline for the accurate classification of various wake and sleep stages. We propose a noise-robust model-based Kalman filtering (KF) approach to track changes in a time-varying auto-regressive model (TVAR) applied to EEG data during different wake and sleep stages. Our approach involves extracting features, including instantaneous frequency and instantaneous power from EEG, and implementing a two-step classifier for sleep staging. The first step classifies data into wake, REM, and non-REM categories, while the second step further classifies non-REM data into N1, N2, and N3 stages. Evaluation on the extended Sleep-EDF dataset (Sleep-EDFx), with 153 EEG recordings from 78 subjects, demonstrated compelling results with classifiers including Logistic Regression, Support Vector Machines, Extreme Gradient Boosting (XGBoost), and Light Gradient Boosting Machine (LGBM). The best performance was achieved with the LGBM and XGBoost classifiers, yielding an overall accuracy of over 77%, a macro-averaged F1 score of 0.69, and a Cohen's kappa of 0.68, highlighting the efficacy of the proposed method with a remarkably compact and interpretable feature set.",https://pubmed.ncbi.nlm.nih.gov/39771620/,https://pubmed.ncbi.nlm.nih.gov/39771620/,English,Include,,Model-Based Electroencephalogram Instantaneous Frequency Tracking: Application in Automated Sleep-Wake Stage Classification.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39768069,pubmed:39768069,PubMed,pubmed:39768069,Analyzing the Impact of Binaural Beats on Anxiety Levels by a New Method Based on Denoised Harmonic Subtraction and Transient Temporal Feature Extraction.,Devika Rankhambe;Bharati Sanjay Ainapure;Bhargav Appasani;Avireni Srinivasulu;Nicu Bizon,2024,10.1007/s11042-022-12874-4,"Anxiety is a widespread mental health issue, and binaural beats have been explored as a potential non-invasive treatment. EEG data reveal changes in neural oscillation and connectivity linked to anxiety reduction; however, harmonics introduced during signal acquisition and processing often distort these findings. Existing methods struggle to effectively reduce harmonics and capture the fine-grained temporal dynamics of EEG signals, leading to inaccurate feature extraction. Hence, a novel Denoised Harmonic Subtraction and Transient Temporal Feature Extraction is proposed to improve the analysis of the impact of binaural beats on anxiety levels. Initially, a novel Wiener Fused Convo Filter is introduced to capture spatial features and eliminate linear noise in EEG signals. Next, an Intrinsic Harmonic Subtraction Network is employed, utilizing the Attentive Weighted Least Mean Square (AW-LMS) algorithm to capture nonlinear summation and resonant coupling effects, effectively eliminating the misinterpretation of brain rhythms. To address the challenge of fine-grained temporal dynamics, an Embedded Transfo XL Recurrent Network is introduced to detect and extract relevant parameters associated with transient events in EEG data. Finally, EEG data undergo harmonic reduction and temporal feature extraction before classification with a cross-correlated Markov Deep Q-Network (DQN). This facilitates anxiety level classification into normal, mild, moderate, and severe categories. The model demonstrated a high accuracy of 95.6%, precision of 90%, sensitivity of 93.2%, and specificity of 96% in classifying anxiety levels, outperforming previous models. This integrated approach enhances EEG signal processing, enabling reliable anxiety classification and offering valuable insights for therapeutic interventions.",https://pubmed.ncbi.nlm.nih.gov/39768069/,https://pubmed.ncbi.nlm.nih.gov/39768069/,English,Include,,Analyzing the Impact of Binaural Beats on Anxiety Levels by a New Method Based on Denoised Harmonic Subtraction and Transient Temporal Feature Extraction.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39768034,pubmed:39768034,PubMed,pubmed:39768034,Selective Auditory Attention Detection Using Combined Transformer and Convolutional Graph Neural Networks.,Masoud Geravanchizadeh;Amir Shaygan Asl;Sebelan Danishvar,2024,10.1213/ane.0000000000002864,"Attention is one of many human cognitive functions that are essential in everyday life. Given our limited processing capacity, attention helps us focus only on what matters. Focusing attention on one speaker in an environment with many speakers is a critical ability of the human auditory system. This paper proposes a new end-to-end method based on the combined transformer and graph convolutional neural network (TraGCNN) that can effectively detect auditory attention from electroencephalograms (EEGs). This approach eliminates the need for manual feature extraction, which is often time-consuming and subjective. Here, the first EEG signals are converted to graphs. We then extract attention information from these graphs using spatial and temporal approaches. Finally, our models are trained with these data. Our model can detect auditory attention in both the spatial and temporal domains. Here, the EEG input is first processed by transformer layers to obtain a sequential representation of EEG based on attention onsets. Then, a family of graph convolutional layers is used to find the most active electrodes using the spatial position of electrodes. Finally, the corresponding EEG features of active electrodes are fed into the graph attention layers to detect auditory attention. The Fuglsang 2020 dataset is used in the experiments to train and test the proposed and baseline systems. The new TraGCNN approach, as compared with state-of-the-art attention classification methods from the literature, yields the highest performance in terms of accuracy (80.12%) as a classification metric. Additionally, the proposed model results in higher performance than our previously graph-based model for different lengths of EEG segments. The new TraGCNN approach is advantageous because attenuation detection is achieved from EEG signals of subjects without requiring speech stimuli, as is the case with conventional auditory attention detection methods. Furthermore, examining the proposed model for different lengths of EEG segments shows that the model is faster than our previous graph-based detection method in terms of computational complexity. The findings of this study have important implications for the understanding and assessment of auditory attention, which is crucial for many applications, such as brain-computer interface (BCI) systems, speech separation, and neuro-steered hearing aid development.",https://pubmed.ncbi.nlm.nih.gov/39768034/,https://pubmed.ncbi.nlm.nih.gov/39768034/,English,Include,,Selective Auditory Attention Detection Using Combined Transformer and Convolutional Graph Neural Networks.,Include,,"nd test the proposed and baseline systems. The new TraGCNN approach, as compared with state-of-the-art attention classification methods from the literature, yields the highest performance in terms of accuracy (80.12%) as a classification metric. Additionally, the proposed model results in higher performance than our previously graph-based model for different lengths of EEG segments. The new TraGCN",,0.95,0.6,
pubmed:39766488,pubmed:39766488,PubMed,pubmed:39766488,Emotion Recognition Model of EEG Signals Based on Double Attention Mechanism.,Yahong Ma;Zhentao Huang;Yuyao Yang;Shanwen Zhang;Qi Dong;Rongrong Wang;Liangliang Hu,2024,10.1016/j.jad.2022.09.054,"Emotions play a crucial role in people's lives, profoundly affecting their cognition, decision-making, and interpersonal communication. Emotion recognition based on brain signals has become a significant challenge in the fields of affective computing and human-computer interaction. Addressing the issue of inaccurate feature extraction and low accuracy of existing deep learning models in emotion recognition, this paper proposes a multi-channel automatic classification model for emotion EEG signals named DACB, which is based on dual attention mechanisms, convolutional neural networks, and bidirectional long short-term memory networks. DACB extracts features in both temporal and spatial dimensions, incorporating not only convolutional neural networks but also SE attention mechanism modules for learning the importance of different channel features, thereby enhancing the network's performance. DACB also introduces dot product attention mechanisms to learn the importance of spatial and temporal features, effectively improving the model's accuracy. The accuracy of this method in single-shot validation tests on the SEED-IV and DREAMER (Valence-Arousal-Dominance three-classification) datasets is 99.96% and 87.52%, 90.06%, and 89.05%, respectively. In 10-fold cross-validation tests, the accuracy is 99.73% and 84.26%, 85.40%, and 85.02%, outperforming other models. This demonstrates that the DACB model achieves high accuracy in emotion classification tasks, demonstrating outstanding performance and generalization ability and providing new directions for future research in EEG signal recognition.",https://pubmed.ncbi.nlm.nih.gov/39766488/,https://pubmed.ncbi.nlm.nih.gov/39766488/,English,Include,,Emotion Recognition Model of EEG Signals Based on Double Attention Mechanism.,Include,,"ecognition based on brain signals has become a significant challenge in the fields of affective computing and human-computer interaction. Addressing the issue of inaccurate feature extraction and low accuracy of existing deep learning models in emotion recognition, this paper proposes a multi-channel automatic classification model for emotion EEG signals named DACB, which is based on dual attentio",,0.95,0.25,cv_reported
pubmed:39766471,pubmed:39766471,PubMed,pubmed:39766471,The Effect of Processing Techniques on the Classification Accuracy of Brain-Computer Interface Systems.,András Adolf;Csaba Márton Köllőd;Gergely Márton;Ward Fadel;István Ulbert,2024,10.1002/exp.20230146,,https://pubmed.ncbi.nlm.nih.gov/39766471/,https://pubmed.ncbi.nlm.nih.gov/39766471/,English,Include,,The Effect of Processing Techniques on the Classification Accuracy of Brain-Computer Interface Systems.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39766410,pubmed:39766410,PubMed,pubmed:39766410,Emotion Classification from Electroencephalographic Signals Using Machine Learning.,Jesus Arturo Mendivil Sauceda;Bogart Yail Marquez;José Jaime Esqueda Elizondo,2024,10.1016/j.neucom.2023.126262,"Emotions significantly influence decision-making, social interactions, and medical outcomes. Leveraging emotion recognition through Electroencephalography (EEG) signals offers potential advancements in personalized medicine, adaptive technologies, and mental health diagnostics. This study aimed to evaluate the performance of three neural network architectures-ShallowFBCSPNet, Deep4Net, and EEGNetv4-for emotion classification using the SEED-V dataset. The SEED-V dataset comprises EEG recordings from 16 individuals exposed to 15 emotion-eliciting video clips per session, targeting happiness, sadness, disgust, neutrality, and fear. EEG data were preprocessed with a bandpass filter, segmented by emotional episodes, and split into training (80%) and testing (20%) sets. Three neural networks were trained and evaluated to classify emotions from the EEG signals. ShallowFBCSPNet achieved the highest accuracy at 39.13%, followed by Deep4Net (38.26%) and EEGNetv4 (25.22%). However, significant misclassification issues were observed, such as EEGNetv4 predicting all instances as ""Disgust"" or ""Neutral"" depending on the configuration. Compared to state-of-the-art methods, such as ResNet18 combined with differential entropy, which achieved 95.61% accuracy on the same dataset, the tested models demonstrated substantial limitations. Our results highlight the challenges of generalizing across emotional states using raw EEG signals, emphasizing the need for advanced preprocessing and feature-extraction techniques. Despite these limitations, this study provides valuable insights into the potential and constraints of neural networks for EEG-based emotion recognition, paving the way for future advancements in the field.",https://pubmed.ncbi.nlm.nih.gov/39766410/,https://pubmed.ncbi.nlm.nih.gov/39766410/,English,Include,,Emotion Classification from Electroencephalographic Signals Using Machine Learning.,Include,,"tional episodes, and split into training (80%) and testing (20%) sets. Three neural networks were trained and evaluated to classify emotions from the EEG signals. ShallowFBCSPNet achieved the highest accuracy at 39.13%, followed by Deep4Net (38.26%) and EEGNetv4 (25.22%). However, significant misclassification issues were observed, such as EEGNetv4 predicting all instances as ""Disgust"" or ""Neutral",,0.95,0.6,
pubmed:39766400,pubmed:39766400,PubMed,pubmed:39766400,Comparative Analysis of Single-Channel and Multi-Channel Classification of Sleep Stages Across Four Different Data Sets.,Xingjian Zhang;Gewen He;Tingyu Shang;Fangfang Fan,2024,10.1088/2057-1976/ac2aee,,,https://pubmed.ncbi.nlm.nih.gov/39766400/,English,Exclude,Not EEG-BCI focused,Comparative Analysis of Single-Channel and Multi-Channel Classification of Sleep Stages Across Four Different Data Sets.,,,,,0.9,0.6,
pubmed:39764990,pubmed:39764990,PubMed,pubmed:39764990,Network-based biomarkers in background electroencephalography in childhood epilepsies-A scoping review and narrative synthesis.,Kay Meiklejohn;Leandro Junges;John R Terry;Alison Whight;Rohit Shankar;Wessel Woldman,2025,10.1016/j.seizure.2024.11.011,"Brain network analysis is an emerging field of research that could lead to the development, testing and validation of novel biomarkers for epilepsy. This could shorten the diagnostic uncertainty period, improve treatment, decrease seizure risk and lead to better management. This scoping review summarises the current state of electroencephalogram (EEG)-based network abnormalities for childhood epilepsies. The review assesses the overall robustness, potential generalisability, strengths, and limitations of the methodological frameworks of the identified research studies. PRISMA guidelines for Scoping Reviews and the PICO framework was used to guide this review. Studies that evaluated candidate network-based features from EEG in children were retrieved from four international indexing databases (Cochrane Central / Embase / MEDLINE/ PsycINFO). Each selected study design, intervention characteristics, methodological design, potential limitations, and key findings were analysed. Of 2,959 studies retrieved, nine were included. Studies used a group-level based comparison (e.g. based on a statistical test) or a classification-based method (e.g. based on a statistical model, such as a decision tree). A common limitation was the small sample-sizes (limiting further subgroup or confounder analysis) and the overall heterogeneity in epilepsy syndromes and age groups. The heterogeneity of included studies (e.g. study design, statistical framework, outcome metrics) highlights the need for future studies to adhere to standardised frameworks (e.g. STARD) in order to develop standardised and robust methodologies. This would enable rigorous comparisons between studies, which is critical in assessing the potential of network-based approaches in developing novel biomarkers for childhood epilepsies.",,https://pubmed.ncbi.nlm.nih.gov/39764990/,English,Exclude,Outside date range,Network-based biomarkers in background electroencephalography in childhood epilepsies-A scoping review and narrative synthesis.,,,,,0.95,0.6,
pubmed:39759760,pubmed:39759760,PubMed,pubmed:39759760,hvEEGNet: a novel deep learning model for high-fidelity EEG reconstruction.,Giulia Cisotto;Alberto Zancanaro;Italo F Zoppis;Sara L Manzoni,2024,10.1371/journal.pone.0162657,"Modeling multi-channel electroencephalographic (EEG) time-series is a challenging tasks, even for the most recent deep learning approaches. Particularly, in this work, we targeted our efforts to the high-fidelity reconstruction of this type of data, as this is of key relevance for several applications such as classification, anomaly detection, automatic labeling, and brain-computer interfaces. We analyzed the most recent works finding that high-fidelity reconstruction is seriously challenged by the complex dynamics of the EEG signals and the large inter-subject variability. So far, previous works provided good results in either high-fidelity reconstruction of single-channel signals, or poor-quality reconstruction of multi-channel datasets. Therefore, in this paper, we present a novel deep learning model, called hvEEGNet, designed as a hierarchical variational autoencoder and trained with a new loss function. We tested it on the benchmark Dataset 2a (including 22-channel EEG data from 9 subjects). We show that it is able to reconstruct all EEG channels with high-fidelity, fastly (in a few tens of epochs), and with high consistency across different subjects. We also investigated the relationship between reconstruction fidelity and the training duration and, using hvEEGNet as an anomaly detector, we spotted some data in the benchmark dataset that are corrupted and never highlighted before. Thus, hvEEGNet could be very useful in several applications where automatic labeling of large EEG dataset is needed and time-consuming. At the same time, this work opens new fundamental research questions about (1) the effectiveness of deep learning models training (for EEG data) and (2) the need for a systematic characterization of the input EEG data to ensure robust modeling.",https://pubmed.ncbi.nlm.nih.gov/39759760/,https://pubmed.ncbi.nlm.nih.gov/39759760/,English,Include,,hvEEGNet: a novel deep learning model for high-fidelity EEG reconstruction.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39759080,pubmed:39759080,PubMed,pubmed:39759080,MP: A steady-state visual evoked potential dataset based on multiple paradigms.,Xi Zhao;Shencheng Xu;Kexing Geng;Ting Zhou;Tianheng Xu;Zhenyu Wang;Shilun Feng;Honglin Hu,2024,10.1016/j.isci.2024.111030,"In the field of steady-state visual evoked potential (SSVEP), stimulus paradigms are regularly arranged or mimic the style of a keyboard with the same size. However, stimulation paradigms have important effects on the performance of SSVEP systems, which correlate with the electroencephalogram (EEG) signal amplitude and recognition accuracy. This paper provides MP dataset that was acquired using a 12-target BCI speller. MP dataset contains 9-channel EEG signals from the occipital region of 24 subjects under 5 stimulation paradigms with different stimulus sizes and arrangements. Stimuli were encoded using joint frequency and phase modulation (JFPM) method. Subjects completed an offline prompted spelling task using a speller under 5 paradigms. Each experiment contains 8 blocks, and each block contains 12 trials. Designers can use this dataset to test the performance of algorithms considering ""stimulus size"" and ""stimulus arrangement"". EEG data showed SSVEP features through amplitude-frequency analysis. FBCCA and TRCA confirmed its suitability.",https://pubmed.ncbi.nlm.nih.gov/39759080/,https://pubmed.ncbi.nlm.nih.gov/39759080/,English,Include,,MP: A steady-state visual evoked potential dataset based on multiple paradigms.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39758128,pubmed:39758128,PubMed,pubmed:39758128,"Biologically inspired heterogeneous learning for accurate, efficient and low-latency neural network.",Bo Wang;Yuxuan Zhang;Hongjue Li;Hongkun Dou;Yuchen Guo;Yue Deng,2025,10.1038/s41586-019-1506-7,"The pursuit of artificial neural networks that mirror the accuracy, efficiency and low latency of biological neural networks remains a cornerstone of artificial intelligence (AI) research. Here, we incorporated recent neuroscientific findings of self-inhibiting autapse and neuron heterogeneity for innovating a spiking neural network (SNN) with enhanced learning and memorizing capacities. A bi-level programming paradigm was formulated to respectively learn neuron-level biophysical variables and network-level synapse weights for nested heterogeneous learning. We successfully demonstrated that our biologically inspired neuron model could reproduce neural statistics at both individual and group levels, contributing to the effective decoding of brain-computer interface data. Furthermore, the heterogeneous SNN showed higher accuracy (1%-10% improvement), superior efficiency (maximal 17.83-fold reduction in energy) and lower latency (maximal 5-fold improvement) in performing several AI tasks. For the first time, we benchmarked SNN for conducting cell type identification from scRNA-seq data. The proposed model correctly identified very rare cell types associated with severe brain diseases where typical SNNs failed.",,https://pubmed.ncbi.nlm.nih.gov/39758128/,English,Exclude,Outside date range,"Biologically inspired heterogeneous learning for accurate, efficient and low-latency neural network.",,,,,0.95,0.6,
pubmed:39758095,pubmed:39758095,PubMed,pubmed:39758095,EEG-powered cerebral transformer for athletic performance.,Qikai Sun,2024,10.1109/tpami.2024.3442811,"In recent years, with advancements in wearable devices and biosignal analysis technologies, sports performance analysis has become an increasingly popular research field, particularly due to the growing demand for real-time monitoring of athletes' conditions in sports training and competitive events. Traditional methods of sports performance analysis typically rely on video data or sensor data for motion recognition. However, unimodal data often fails to fully capture the neural state of athletes, leading to limitations in accuracy and real-time performance when dealing with complex movement patterns. Moreover, these methods struggle with multimodal data fusion, making it difficult to fully leverage the deep information from electroencephalogram (EEG) signals. To address these challenges, this paper proposes a ""Cerebral Transformer"" model based on EEG signals and video data. By employing an adaptive attention mechanism and cross-modal fusion, the model effectively combines EEG signals and video streams to achieve precise recognition and analysis of athletes' movements. The model's effectiveness was validated through experiments on four datasets: SEED, DEAP, eSports Sensors, and MODA. The results show that the proposed model outperforms existing mainstream methods in terms of accuracy, recall, and F1 score, while also demonstrating high computational efficiency. The significance of this study lies in providing a more comprehensive and efficient solution for sports performance analysis. Through cross-modal data fusion, it not only improves the accuracy of complex movement recognition but also provides technical support for monitoring athletes' neural states, offering important applications in sports training and medical rehabilitation.",https://pubmed.ncbi.nlm.nih.gov/39758095/,https://pubmed.ncbi.nlm.nih.gov/39758095/,English,Include,,EEG-powered cerebral transformer for athletic performance.,Include,,"ts performance analysis typically rely on video data or sensor data for motion recognition. However, unimodal data often fails to fully capture the neural state of athletes, leading to limitations in accuracy and real-time performance when dealing with complex movement patterns. Moreover, these methods struggle with multimodal data fusion, making it difficult to fully leverage the deep information",,0.95,0.6,
pubmed:39752571,pubmed:39752571,PubMed,pubmed:39752571,The American Clinical Neurophysiology Society Guideline on Indications for Continuous Electroencephalography Monitoring in Neonates.,Courtney J Wusthoff;Adam L Numis;Ronit M Pressler;Catherine J Chu;Shavonne Massey;Robert R Clancy;Sylvie Nguyen;Cecil D Hahn;Mark S Scher;Betsy Pilon;Donald T King;Hong-Nei Wong;Tammy N Tsuchida;James J Riviello;Renée A Shellhaas,2025,10.1097/wnp.0000000000001120,"Continuous EEG (cEEG) monitoring is increasingly used in the management of neonates with seizures. There remains debate on what clinically relevant information can be gained from cEEG in neonates with suspected seizures, at high risk for seizures, or with definite seizures, as well as the use of cEEG for prognosis in a variety of conditions. In this guideline, we address these questions using American Clinical Neurophysiology Society structured methodology for clinical guideline development. A working group was formed from American Clinical Neurophysiology Society membership with expertise in neonatal cEEG and a set of priority questions developed. We performed literature searches in PubMed and EMBASE to identify relevant studies. Evidence tables were compiled from extracted data and quality assessments performed. A modification of the GRADE process was used to evaluate the body of evidence and draft recommendations. Our working group identified six priority questions to evaluate the accuracy of cEEG for neonatal seizure diagnosis and the formulation of prognosis. An initial literature search yielded 18,167 results, which were distilled to a set of 217 articles. Overall, the quality of evidence for most priority questions was rated as very low and we provided conditional recommendations based on published literature and expert consensus. For each priority question, we also considered the benefits and harms of cEEG, with relative harms considered to be far less than the potential benefits across recommendations. We present evidence-based clinical guidelines regarding indications for cEEG monitoring in neonates. Considering resource utilization and feasibility, when cEEG monitoring results have a likelihood of altering clinical decision making, the authors felt the resource investment was justifiable.",,https://pubmed.ncbi.nlm.nih.gov/39752571/,English,Exclude,Outside date range,The American Clinical Neurophysiology Society Guideline on Indications for Continuous Electroencephalography Monitoring in Neonates.,,,,,0.95,0.6,
pubmed:39744723,pubmed:39744723,PubMed,pubmed:39744723,Multimodal sleep staging network based on obstructive sleep apnea.,Jingxin Fan;Mingfu Zhao;Li Huang;Bin Tang;Lurui Wang;Zhong He;Xiaoling Peng,2024,10.1016/j.cmpb.2022.106806,"Automatic sleep staging is essential for assessing sleep quality and diagnosing sleep disorders. While previous research has achieved high classification performance, most current sleep staging networks have only been validated in healthy populations, ignoring the impact of Obstructive Sleep Apnea (OSA) on sleep stage classification. In addition, it remains challenging to effectively improve the fine-grained detection of polysomnography (PSG) and capture multi-scale transitions between sleep stages. Therefore, a more widely applicable network is needed for sleep staging. This paper introduces MSDC-SSNet, a novel deep learning network for automatic sleep stage classification. MSDC-SSNet transforms two channels of electroencephalogram (EEG) and one channel of electrooculogram (EOG) signals into time-frequency representations to obtain feature sequences at different temporal and frequency scales. An improved Transformer encoder architecture ensures temporal consistency and effectively captures long-term dependencies in EEG and EOG signals. The Multi-Scale Feature Extraction Module (MFEM) employs convolutional layers with varying dilation rates to capture spatial patterns from fine to coarse granularity. It adaptively fuses the weights of features to enhance the robustness of the model. Finally, multiple channel data are integrated to address the heterogeneity between different modalities effectively and alleviate the impact of OSA on sleep stages. We evaluated MSDC-SSNet on three public datasets and our collection of PSG records of 17 OSA patients. It achieved an accuracy of 80.4% on the OSA dataset. It also outperformed the state-of-the-art methods in terms of accuracy, F1 score, and Cohen's Kappa coefficient on the remaining three datasets. The MSDC-SSRNet multi-channel sleep staging architecture proposed in this study enhances widespread system applicability by supplementing inter-channel features. It employs multi-scale attention to extract transition rules between sleep stages and effectively integrates multimodal information. Our method address the limitations of single-channel approaches, enhancing interpretability for clinical applications.",https://pubmed.ncbi.nlm.nih.gov/39744723/,https://pubmed.ncbi.nlm.nih.gov/39744723/,English,Include,,Multimodal sleep staging network based on obstructive sleep apnea.,Include,,"different modalities effectively and alleviate the impact of OSA on sleep stages. We evaluated MSDC-SSNet on three public datasets and our collection of PSG records of 17 OSA patients. It achieved an accuracy of 80.4% on the OSA dataset. It also outperformed the state-of-the-art methods in terms of accuracy, F1 score, and Cohen's Kappa coefficient on the remaining three datasets. The MSDC-SSRNet m",,0.95,0.6,
pubmed:39742538,pubmed:39742538,PubMed,pubmed:39742538,Emotion recognition using multi-scale EEG features through graph convolutional attention network.,Liwen Cao;Wenfeng Zhao;Biao Sun,2025,10.1016/j.neunet.2024.107060,"Emotion recognition via electroencephalogram (EEG) signals holds significant promise across various domains, including the detection of emotions in patients with consciousness disorders, assisting in the diagnosis of depression, and assessing cognitive load. This process is critically important in the development and research of brain-computer interfaces, where precise and efficient recognition of emotions is paramount. In this work, we introduce a novel approach for emotion recognition employing multi-scale EEG features, denominated as the Dynamic Spatial-Spectral-Temporal Network (DSSTNet). DSSTNet includes three main parts, the first is spatial features extractor, which converts EEG signal into graph structure data, and uses graph convolutional network (GCN) to dynamically optimize the adjacency matrix during the training process to obtain the spatial features between the channels. Next, band attention module is composed of semi-global pooling, localized cross-band interaction and adaptive weighting, which further extracts frequency information. Finally, through the temporal features extractor, the deep temporal information is extracted by stacking several one-dimensional convolutional layers. In addition, in order to improve the performance of emotion recognition and filter valid channels, we add a ℓ",,https://pubmed.ncbi.nlm.nih.gov/39742538/,English,Exclude,Outside date range,Emotion recognition using multi-scale EEG features through graph convolutional attention network.,,,,,0.95,0.6,
pubmed:39741785,pubmed:39741785,PubMed,pubmed:39741785,Domain adaptation spatial feature perception neural network for cross-subject EEG emotion recognition.,Wei Lu;Xiaobo Zhang;Lingnan Xia;Hua Ma;Tien-Ping Tan,2024,10.48550/arxiv.2304.10755,"Emotion recognition is a critical research topic within affective computing, with potential applications across various domains. Currently, EEG-based emotion recognition, utilizing deep learning frameworks, has been effectively applied and achieved commendable performance. However, existing deep learning-based models face challenges in capturing both the spatial activity features and spatial topology features of EEG signals simultaneously. To address this challenge, a ",,https://pubmed.ncbi.nlm.nih.gov/39741785/,English,Exclude,Not classification-focused,Domain adaptation spatial feature perception neural network for cross-subject EEG emotion recognition.,,,,,0.85,0.6,
pubmed:39741784,pubmed:39741784,PubMed,pubmed:39741784,EEG channel and feature investigation in binary and multiple motor imagery task predictions.,Murside Degirmenci;Yilmaz Kemal Yuce;Matjaž Perc;Yalcin Isler,2024,10.1016/j.neunet.2019.02.009,"Motor Imagery (MI) Electroencephalography (EEG) signals are non-stationary and dynamic physiological signals which have low signal-to-noise ratio. Hence, it is difficult to achieve high classification accuracy. Although various machine learning methods have already proven useful to that effect, the use of many features and ineffective EEG channels often leads to a complex structure of classifier algorithms. State-of-the-art studies were interested in improving classification performance with complex feature extraction and classification methods by neglecting detailed EEG channel and feature investigation in predicting MI tasks from EEGs. Here, we investigate the effects of the statistically significant feature selection method on four different feature domains (time-domain, frequency-domain, time-frequency domain, and non-linear domain) and their two different combinations to reduce the number of features and classify MI-EEG features by comparing low-dimensional matrices with well-known machine learning algorithms. Our main goal is not to find the best classifier performance but to perform feature and channel investigation in MI task classification. Therefore, the detailed investigation of the effect of EEG channels and features is implemented using a statistically significant feature distribution on 22 EEG channels for each feature set separately. We used the BCI Competition IV Dataset IIa and 288 samples per person. A total of 1,364 MI-EEG features were analyzed in this study. We tested nine distinct classifiers: Decision tree, Discriminant analysis, Logistic regression, Naive Bayes, Support vector machine, k-Nearest neighbor, Ensemble learning, Neural networks, and Kernel approximation. Among all feature sets considered, classifications performed with non-linear and combined feature sets resulted in a maximum accuracy of 63.04% and 47.36% for binary and multiple MI task predictions, respectively. The ensemble learning classifier achieved the maximum accuracy in almost all feature sets for binary and multiple MI task classifications. Our research thus shows that the statistically significant feature-based feature selection method significantly improves the classification performance with fewer features in almost all feature sets, enabling detailed and effective EEG channel and feature investigation.",https://pubmed.ncbi.nlm.nih.gov/39741784/,https://pubmed.ncbi.nlm.nih.gov/39741784/,English,Include,,EEG channel and feature investigation in binary and multiple motor imagery task predictions.,Include,,"otor Imagery (MI) Electroencephalography (EEG) signals are non-stationary and dynamic physiological signals which have low signal-to-noise ratio. Hence, it is difficult to achieve high classification accuracy. Although various machine learning methods have already proven useful to that effect, the use of many features and ineffective EEG channels often leads to a complex structure of classifier al",,0.95,0.6,
pubmed:39741250,pubmed:39741250,PubMed,pubmed:39741250,Adaptive deep feature representation learning for cross-subject EEG decoding.,Shuang Liang;Linzhe Li;Wei Zu;Wei Feng;Wenlong Hang,2024,10.1186/s12859-024-06024-w,"The collection of substantial amounts of electroencephalogram (EEG) data is typically time-consuming and labor-intensive, which adversely impacts the development of decoding models with strong generalizability, particularly when the available data is limited. Utilizing sufficient EEG data from other subjects to aid in modeling the target subject presents a potential solution, commonly referred to as domain adaptation. Most current domain adaptation techniques for EEG decoding primarily focus on learning shared feature representations through domain alignment strategies. Since the domain shift cannot be completely removed, target EEG samples located near the edge of clusters are also susceptible to misclassification. We propose a novel adaptive deep feature representation (ADFR) framework to improve the cross-subject EEG classification performance through learning transferable EEG feature representations. Specifically, we first minimize the distribution discrepancy between the source and target domains by employing maximum mean discrepancy (MMD) regularization, which aids in learning the shared feature representations. We then utilize the instance-based discriminative feature learning (IDFL) regularization to make the learned feature representations more discriminative. Finally, the entropy minimization (EM) regularization is further integrated to adjust the classifier to pass through the low-density region between clusters. The synergistic learning between above regularizations during the training process enhances EEG decoding performance across subjects. The effectiveness of the ADFR framework was evaluated on two public motor imagery (MI)-based EEG datasets: BCI Competition III dataset 4a and BCI Competition IV dataset 2a. In terms of average accuracy, ADFR achieved improvements of 3.0% and 2.1%, respectively, over the state-of-the-art methods on these datasets. The promising results highlight the effectiveness of the ADFR algorithm for EEG decoding and show its potential for practical applications.",https://pubmed.ncbi.nlm.nih.gov/39741250/,https://pubmed.ncbi.nlm.nih.gov/39741250/,English,Include,,Adaptive deep feature representation learning for cross-subject EEG decoding.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39741130,pubmed:39741130,PubMed,pubmed:39741130,"Virtual reality-assisted prediction of adult ADHD based on eye tracking, EEG, actigraphy and behavioral indices: a machine learning analysis of independent training and test samples.",Annika Wiebe;Benjamin Selaskowski;Martha Paskin;Laura Asché;Julian Pakos;Behrem Aslan;Silke Lux;Alexandra Philipsen;Niclas Braun,2024,10.1038/s41398-024-03217-y,"Given the heterogeneous nature of attention-deficit/hyperactivity disorder (ADHD) and the absence of established biomarkers, accurate diagnosis and effective treatment remain a challenge in clinical practice. This study investigates the predictive utility of multimodal data, including eye tracking, EEG, actigraphy, and behavioral indices, in differentiating adults with ADHD from healthy individuals. Using a support vector machine model, we analyzed independent training (n = 50) and test (n = 36) samples from two clinically controlled studies. In both studies, participants performed an attention task (continuous performance task) in a virtual reality seminar room while encountering virtual distractions. Task performance, head movements, gaze behavior, EEG, and current self-reported inattention, hyperactivity, and impulsivity were simultaneously recorded and used for model training. Our final model based on the optimal number of features (maximal relevance minimal redundancy criterion) achieved a promising classification accuracy of 81% in the independent test set. Notably, the extracted EEG-based features had no significant contribution to this prediction and therefore were not included in the final model. Our results suggest the potential of applying ecologically valid virtual reality environments and integrating different data modalities for enhancing robustness of ADHD diagnosis.",https://pubmed.ncbi.nlm.nih.gov/39741130/,https://pubmed.ncbi.nlm.nih.gov/39741130/,English,Include,,"Virtual reality-assisted prediction of adult ADHD based on eye tracking, EEG, actigraphy and behavioral indices: a machine learning analysis of independent training and test samples.",Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.55,external_test_reported;small_sample_mentioned
pubmed:39735964,pubmed:39735964,PubMed,pubmed:39735964,Motion Cognitive Decoding of Cross-Subject Motor Imagery Guided on Different Visual Stimulus Materials.,Tian-Jian Luo;Jing Li;Rui Li;Xiang Zhang;Shen-Rui Wu;Hua Peng,2024,10.31083/j.jin2312218,"Motor imagery (MI) plays an important role in brain-computer interfaces, especially in evoking event-related desynchronization and synchronization (ERD/S) rhythms in electroencephalogram (EEG) signals. However, the procedure for performing a MI task for a single subject is subjective, making it difficult to determine the actual situation of an individual's MI task and resulting in significant individual EEG response variations during motion cognitive decoding. To explore this issue, we designed three visual stimuli (arrow, human, and robot), each of which was used to present three MI tasks (left arm, right arm, and feet), and evaluated differences in brain response in terms of ERD/S rhythms. To compare subject-specific variations of different visual stimuli, a novel cross-subject MI-EEG classification method was proposed for the three visual stimuli. The proposed method employed a covariance matrix centroid alignment for preprocessing of EEG samples, followed by a model agnostic meta-learning method for cross-subject MI-EEG classification. The experimental results showed that robot stimulus materials were better than arrow or human stimulus materials, with an optimal cross-subject motion cognitive decoding accuracy of 79.04%. Moreover, the proposed method produced robust classification of cross-subject MI-EEG signal decoding, showing superior results to conventional methods on collected EEG signals.",https://pubmed.ncbi.nlm.nih.gov/39735964/,https://pubmed.ncbi.nlm.nih.gov/39735964/,English,Include,,Motion Cognitive Decoding of Cross-Subject Motor Imagery Guided on Different Visual Stimulus Materials.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39733864,pubmed:39733864,PubMed,pubmed:39733864,A novel way to use cross-validation to measure connectivity by machine learning allows epilepsy surgery outcome prediction.,Karla Ivankovic;Alessandro Principe;Justo Montoya-Gálvez;Linus Manubens-Gil;Riccardo Zucca;Pablo Villoslada;Mara Dierssen;Rodrigo Rocamora,2025,10.1016/j.neuroimage.2024.120990,"The rate of success of epilepsy surgery, ensuring seizure-freedom, is limited by the lack of epileptogenicity biomarkers. Previous evidence supports the critical role of functional connectivity during seizure generation to characterize the epileptogenic network (EN). However, EN dynamics is highly variable across patients, hindering the development of diagnostic biomarkers. Without relying on specific connectivity variables, we focused on a general hypothesis that the EN undergoes the greatest magnitude of connectivity change during seizure generation, compared to other brain networks. To test this hypothesis, we developed a novel method for quantifying connectivity change between network states and applied it to identify surgical resection areas. A network state was represented by random snapshots of connectivity within a defined time interval of an intracranial EEG recording. A binary classifier was applied to classify two network states. The classifier generalization performance estimated by cross-validation was employed as a continuous measure of connectivity change. The algorithm generated a network by iteratively adding nodes until the connectivity change magnitude decreased. The resulting network was compared to the surgical resection, and the overlap score was used to predict post-surgical outcomes. The framework was evaluated in a consecutive cohort of 21 patients with a post-surgical follow-up of minimum 3 years. The best overlap between connectivity change networks and resections was obtained at the transition from pre-seizure to seizure (surgical outcome prediction ROC-AUC=90.3 %). However, all patients except one were correctly classified when considering the most informative time intervals. Time intervals proportional to seizure length were more informative than the almost universally used fixed intervals. This study demonstrates that connectivity can be successfully classified with a machine learning analysis and provide information for distinguishing a separate epileptogenic functional network. In summary, the connectivity change analysis could accurately identify epileptogenic networks validated by surgery outcome classification. Connectivity change magnitude at seizure transition could potentially serve as an EN biomarker. The tool provided by this study may aid surgical decision-making.",,https://pubmed.ncbi.nlm.nih.gov/39733864/,English,Exclude,Outside date range,A novel way to use cross-validation to measure connectivity by machine learning allows epilepsy surgery outcome prediction.,,,,,0.95,0.25,cv_reported
pubmed:39733823,pubmed:39733823,PubMed,pubmed:39733823,Media multitasking enhances individuals' anticipatory brain functions.,Jie Zhang;Han Song;Can Xu;Shiwei Liu;Zhijie Zhang,2025,10.1016/j.neuroscience.2024.12.051,"Media multitasking has become pervasive in our daily lives, yet its impact on cognitive abilities remains contentious, with more evidence supporting adverse effects (scattered attention hypothesis) than benefits (trained attention hypothesis). Recent studies have increasingly focused on the training effects of behavioral training on anticipatory brain functions, which involve cognitive and motor preparation before stimulus onset, assessed using event-related potentials (ERPs). This study investigated whether media multitasking enhances anticipatory brain functions and how task difficulty influences this relationship. Participants performed a response discrimination task where they detected targets among distractors, with salient and nonsalient targets manipulating task difficulty. Behavioral results indicated faster response times and comparable accuracy in heavy media multitaskers (HMM) compared to light media multitaskers (LMM) across both salient and nonsalient conditions, suggesting that media multitasking can expedite responses without sacrificing accuracy. The larger Bereitschaftspotential (BP) amplitude observed in HMM compared to LMM reflects heightened motor preparation in HMM, consistent with their quicker responses. The larger prefrontal negativity (pN) and P3 amplitudes in the nonsalient condition for HMM indicate increased cognitive preparation before stimulus onset and heightened attention control after stimulus onset. Our results suggest that HMM can flexibly adjust resource allocation based on task demands to maintain their response speed advantage. These findings suggest that LMM may possess a relatively steady acceleration/brake system, whereas HMM exhibit a more adaptable system capable of responding flexibly to diverse situations. Overall, these results underscore the training effects of media multitasking on anticipatory brain functions, supporting the trained attention hypothesis.",,https://pubmed.ncbi.nlm.nih.gov/39733823/,English,Exclude,Outside date range,Media multitasking enhances individuals' anticipatory brain functions.,,,,,0.95,0.8,small_sample_mentioned
pubmed:39733703,pubmed:39733703,PubMed,pubmed:39733703,Multi-modal cross-domain self-supervised pre-training for fMRI and EEG fusion.,Xinxu Wei;Kanhao Zhao;Yong Jiao;Nancy B Carlisle;Hua Xie;Gregory A Fonzo;Yu Zhang,2025,10.1016/j.neunet.2024.107066,"Neuroimaging techniques including functional magnetic resonance imaging (fMRI) and electroencephalogram (EEG) have shown promise in detecting functional abnormalities in various brain disorders. However, existing studies often focus on a single domain or modality, neglecting the valuable complementary information offered by multiple domains from both fMRI and EEG, which is crucial for a comprehensive representation of disorder pathology. This limitation poses a challenge in effectively leveraging the synergistic information derived from these modalities. To address this, we propose a Multi-modal Cross-domain Self-supervised Pre-training Model (MCSP), a novel approach that leverages self-supervised learning to synergize multi-modal information across spatial, temporal, and spectral domains. Our model employs cross-domain self-supervised loss that bridges domain differences by implementing domain-specific data augmentation and contrastive loss, enhancing feature discrimination. Furthermore, MCSP introduces cross-modal self-supervised loss to capitalize on the complementary information of fMRI and EEG, facilitating knowledge distillation within domains and maximizing cross-modal feature convergence. We constructed a large-scale pre-training dataset and pretrained MCSP model by leveraging proposed self-supervised paradigms to fully harness multimodal neuroimaging data. Through comprehensive experiments, we have demonstrated the superior performance and generalizability of our model on multiple classification tasks. Our study contributes a significant advancement in the fusion of fMRI and EEG, marking a novel integration of cross-domain features, which enriches the existing landscape of neuroimaging research, particularly within the context of mental disorder studies.",,https://pubmed.ncbi.nlm.nih.gov/39733703/,English,Exclude,Outside date range,Multi-modal cross-domain self-supervised pre-training for fMRI and EEG fusion.,,,,,0.95,0.6,
pubmed:39733023,pubmed:39733023,PubMed,pubmed:39733023,EEG-based emotion recognition using multi-scale dynamic CNN and gated transformer.,Zhuoling Cheng;Xuekui Bu;Qingnan Wang;Tao Yang;Jihui Tu,2024,10.1038/s41598-024-82705-z,"Emotions play a crucial role in human thoughts, cognitive processes, and decision-making. EEG has become a widely utilized tool in emotion recognition due to its high temporal resolution, real-time monitoring capabilities, portability, and cost-effectiveness. In this paper, we propose a novel end-to-end emotion recognition method from EEG signals, called MSDCGTNet, which is based on the Multi-Scale Dynamic 1D CNN and the Gated Transformer. First, the Multi-Scale Dynamic CNN is used to extract complex spatial and spectral features from raw EEG signals, which not only avoids information loss but also reduces computational costs associated with the time-frequency conversion of signals. Then, the Gated Transformer Encoder is utilized to capture global dependencies of EEG signals. This encoder focuses on specific regions of the input sequence while reducing computational resources through parallel processing with the improved multi-head self-attention mechanisms. Third, the Temporal Convolution Network is used to extract temporal features from the EEG signals. Finally, the extracted abstract features are fed into a classification module for emotion recognition. The proposed method was evaluated on three publicly available datasets: DEAP, SEED, and SEED_IV. Experimental results demonstrate the high accuracy and efficiency of the proposed method for emotion recognition. This approach proves to be robust and suitable for various practical applications. By addressing challenges posed by existing methods, the proposed method provides a valuable and effective solution for the field of Brain-Computer Interface (BCI).",https://pubmed.ncbi.nlm.nih.gov/39733023/,https://pubmed.ncbi.nlm.nih.gov/39733023/,English,Include,,EEG-based emotion recognition using multi-scale dynamic CNN and gated transformer.,Include,,"re fed into a classification module for emotion recognition. The proposed method was evaluated on three publicly available datasets: DEAP, SEED, and SEED_IV. Experimental results demonstrate the high accuracy and efficiency of the proposed method for emotion recognition. This approach proves to be robust and suitable for various practical applications. By addressing challenges posed by existing me",,0.95,0.6,
pubmed:39732802,pubmed:39732802,PubMed,pubmed:39732802,Decoding of pain during heel lancing in human neonates with EEG signal and machine learning approach.,Reyhane Shafiee;Mohammad Reza Daliri,2024,10.1038/s41598-024-82631-0,"Currently, pain assessment using electroencephalogram signals and machine learning methods in clinical studies is of great importance, especially for those who cannot express their pain. Since newborns are among the high-risk group and always experience pain at the beginning of birth, in this research, the severity of newborns has been investigated and evaluated. Other studies related to the annoyance of newborns have used the EEG signal of newborns alone; therefore, in this study, the intensity of newborn pain was measured using the electroencephalogram signal of 107 infants who were stimulated by the heel lance in three levels: no pain, low pain and moderate pain were recorded as a single trial and evaluated. The support vector machine (SVM), K-Nearest Neighbors (KNN) and Ensemble bagging classifiers were trained using the K-fold cross-validation method and features of the brain's time-frequency domain. The results were obtained with accuracies of 72.8 ± 2, 84.4 ± 1.3 and 82.9 ± 1.6%, respectively. Also, in examining the problem of distinguishing pain and no pain, the electroencephalogram signal of 74 infants was evaluated, and similar to the three-class mode, with the 10-fold validation method, we reached the highest accuracy of 100% in Bagging classifier and 98.6 ± 0.1 accuracy in KNN and SVM classifiers.",https://pubmed.ncbi.nlm.nih.gov/39732802/,https://pubmed.ncbi.nlm.nih.gov/39732802/,English,Include,,Decoding of pain during heel lancing in human neonates with EEG signal and machine learning approach.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.25,cv_reported
pubmed:39731320,pubmed:39731320,PubMed,pubmed:39731320,Acoustic Exaggeration Enhances Speech Discrimination in Young Autistic Children.,Luodi Yu;Lizhi Ban;Aiwen Yi;Jing Xin;Suping Li;Suiping Wang;Laurent Mottron,2025,10.1016/j.ijdevneu.2004.05.001,"Child-directed speech (CDS), which amplifies acoustic and social features of speech during interactions with young children, promotes typical phonetic and language development. In autism, both behavioral and brain data indicate reduced sensitivity to human speech, which predicts absent, decreased, or atypical benefits of exaggerated speech signals such as CDS. This study investigates the impact of exaggerated fundamental frequency (F0) and voice-onset time on the neural processing of speech sounds in 22 Chinese-speaking autistic children aged 2-7 years old with a history of speech delays, compared with 25 typically developing (TD) peers. Electroencephalography (EEG) data were collected during passive listening to exaggerated and non-exaggerated syllables. A time-resolved multivariate pattern analysis (MVPA) was used to evaluate the potential effects of acoustic exaggeration on syllable discrimination in terms of neural decoding accuracy. For non-exaggerated syllables, neither the autism nor the TD group achieved above-chance decoding accuracy. In contrast, for exaggerated syllables, both groups achieved above-chance decoding, indicating significant syllable discrimination, with no difference in accuracy between the autism and TD groups. However, the temporal generalization patterns in the MVPA results revealed distinct neural mechanisms supporting syllable discrimination between the groups. Although the TD group demonstrated a left-hemisphere advantage for decoding and generalization, the autism group displayed similar decoding patterns between hemispheres. These findings highlight the potential of selective acoustic exaggeration to support speech learning in autistic children, underscoring the importance of tailored, sensory-based interventions.",,https://pubmed.ncbi.nlm.nih.gov/39731320/,English,Exclude,Outside date range,Acoustic Exaggeration Enhances Speech Discrimination in Young Autistic Children.,,,,,0.95,0.6,
pubmed:39730694,pubmed:39730694,PubMed,pubmed:39730694,Quantitative electroencephalography predicts postoperative delirium in adult cardiac surgical patients from a prospective observational study.,Zhibao Guo;Wang Wan;Wenxue Liu;Ling Liu;Yi Yang;Congshan Yang;Xingran Cui,2024,10.1038/s41598-024-82422-7,"The diagnostic and prognostic value of quantitative electroencephalogram (qEEG) in the the onset of postoperative delirium (POD) remains an area of inquiry. We aim to determine whether qEEG could assist in the diagnosis of early POD in cardiac surgery patients. We prospectively studied a cohort of cardiac surgery patients undergoing qEEG for evaluation of altered mental status. Delirium was assessed with the Confusion Assessment Method for the intensive care unit (CAM-ICU). The qEEG were interpreted by clinician, and reports were reviewed to identify features such as amplitude-integrated EEG (aEEG), relative band energy in ɑ/β/θ/δ frequencies, α variability and spectral entropy. The raw EEG was also preprocessed offline for nonlinear analysis including Multi-scale Entropy analysis (MSE) and Detrended Fluctuation Analysis (DFA). Linear regression was performed to quantify associations among EEG findings, delirium, and clinical outcomes. Receiver operating characteristic (ROC) analysis was used to assess the accuracy of the qEEG as POD prediction index. Meanwhile, a comprehensive comparison of dynamic complexity across time scales and DFA exponent α was conducted between the non-delirium and delirium groups. Among those recruited initially (n = 64), 60 patients were evaluated and 29 patients (48.3%) met delirium criteria. When comparing delirious and non-delirious participants, significant differences were found in terms of age (p = 0.03), APACHE II scores (p = 0.004), lactate (p = 0.03), and hospital days (p = 0.048). Multivariate regression analysis revealed that the first quartile (Q1) and fourth quartile (Q4) of peak or valley value of F3-P3/F4-P4 derivation (for example, Q1 of peak value for F3-P3 derivation: OR 12.4, 95% CI 1.72-89.76, p = 0.012) showed a higher association with the incidence of POD. ROC analysis demonstrated qEEG could predict POD with high sensitivity and specificity, yielding an overall good accuracy. For instance, the peak value of F3-P3 derivation (the area under the curve of 0.81), as a predictor of POD showed a sensitivity of 90% and specificity pf 72% (p < 0.001). Furthermore, the MSE curves indicated that the non-delirium group exhibited higher complexity values at fine scales, while the delirium group had significantly higher complexity at coarse scales. The DFA comparison results revealed that long-term fractal exponent alpha2 values were higher in delirium patients than in non-delirium patients, with significant differences observed at the F4-P4 electrodes (p = 0.04). The qEEG can reliably predict delirium after heart cardiac surgery. It is helpful for clinicians to early diagnose and manage these patients.Trial registration: Clinical Trials.gov Identifier, NCT03351985. Registered 1 December 2017.",,https://pubmed.ncbi.nlm.nih.gov/39730694/,English,Exclude,Review/survey papers,Quantitative electroencephalography predicts postoperative delirium in adult cardiac surgical patients from a prospective observational study.,,,,,0.95,0.8,small_sample_mentioned
pubmed:39730640,pubmed:39730640,PubMed,pubmed:39730640,Acute effects of different physical activity on executive function and regulation role of beta oscillation in sedentary youth frontal region.,Yifan Lv;Xiaosheng Dong;Tingting Sun;Shan Jiang;Yue Gao;Jiaxin Liang;Songhan Hu;Haohan Yu;Xiao Hou,2024,10.1038/s41598-024-81538-0,"Chronic sedentary behavior can have a negative impact on the executive function (EF) of young people. While physical activity (PA) has been shown to improve this phenomenon, the effects of different types of PA on EF vary. In this study, we compared the effects of moderate-intensity continuous training (MICT) (60-70% HRmax, 30 min), body weight training (BWT) (2 sets tabata, 20 min), and mind-body exercise (MBE) (2 sets Yang style shadowboxing, 20 min) on EF in 59 sedentary youth (n = 59, age = 20.36 ± 1.78, BMI = 24.91 ± 1.82, P>0.05) to identify the optimal dose of PA for improving EF. Metrics related to the EF task paradigm included stop signal, electroencephalogram (EEG), event-related potential (ERP), P300, N200, error-related negativity (ERN), and error positivity (Pe). error positivity (Pe), and β-wave in frontal lobe; training monitoring, including heart rate (HR), rating of perceived exertion (RPE), feeling scale (FS), and dual-mode model (DMM); load assessment, including Edward's TRIMP (TRIMP) and session-RPE (s-RPE). The study results indicate that BWT significantly improved accuracy in terms of EF (F = 16.84, P = 0.0381) and was comparable to MICT in terms of shortening reaction time (F = 58.03, P = 0.0217; F = 75.49, P = 0.0178). Regarding ERP, BWT reduced the amplitude values of N200 compared to ERN (F = 44.35, P = 0.0351; F = 48.68, P = 0.0317), increased P300 compared to Pe (F = 97.72, P<0.01; F = 29.56, P = 0.0189), and shortened P300 latency (F = 1.84, P = 0.0406). In contrast, MICT was only effective for P300 with Pe (F = 66.59, P = 0.0194; F = 21.04, P = 0.0342) and shortened N200 latency (F = 27.29, P = 0.0411). The increase in total amplitude and β-oscillation in terms of EEG was proportional to the exercise intensity, with the difference between MICT and BWT being present at 5-20 Hz, and MBE at 10-15 Hz. Regarding training load, the order of HR, RPE, TRIMP, and s-RPE was BWT > MICT > MBE (F = 202.69; F = 114.69; F = 114.69; P = 0.0342). The latency of N200 was also shortened (F = 27.29, P = 0.0411). The results showed that PA improves EF in sedentary youth, although BWT works best, it leads to a decrease in motor perception. Initially, MICT was scheduled alongside MBE and later replaced with BWT. This may help establish an exercise habit while improving EF.",https://pubmed.ncbi.nlm.nih.gov/39730640/,https://pubmed.ncbi.nlm.nih.gov/39730640/,English,Include,,Acute effects of different physical activity on executive function and regulation role of beta oscillation in sedentary youth frontal region.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39729859,pubmed:39729859,PubMed,pubmed:39729859,"Neural markers of error processing relate to task performance, but not to substance-related risks and problems and externalizing problems in adolescence and emerging adulthood.",Olga D Boer;Thea Wiker;Shervin H Bukhari;Rikka Kjelkenes;Clara M F Timpe;Irene Voldsbekk;Knut Skaug;Rune Boen;Valerie Karl;Torgeir Moberget;Lars T Westlye;Ingmar H A Franken;Hanan El Marroun;Rene J Huster;Christian K Tamnes,2025,10.1007/s00702-008-0165-x,"Detecting errors and adapting behavior accordingly constitutes an integral aspect of cognition. Previous studies have linked neural correlates of error processing (e.g., error-related negativity (ERN) and error-related positivity (Pe)) to task performance and broader behavioral constructs, but few studies examined how these associations manifest in adolescence. In this study, we examined neural error processing markers and their behavioral associations in an adolescent/emerging adult sample (N = 143, M",,https://pubmed.ncbi.nlm.nih.gov/39729859/,English,Exclude,Outside date range,"Neural markers of error processing relate to task performance, but not to substance-related risks and problems and externalizing problems in adolescence and emerging adulthood.",,,,,0.95,0.6,
pubmed:39729407,pubmed:39729407,PubMed,pubmed:39729407,Therapeutic dose prediction of α5-GABA receptor modulation from simulated EEG of depression severity.,Alexandre Guet-McCreight;Frank Mazza;Thomas D Prevot;Etienne Sibille;Etay Hay,2024,10.1007/s10548-019-00710-2,"Treatment for major depressive disorder (depression) often has partial efficacy and a large portion of patients are treatment resistant. Recent studies implicate reduced somatostatin (SST) interneuron inhibition in depression, and new pharmacology boosting this inhibition via positive allosteric modulators of α5-GABAA receptors (α5-PAM) offers a promising effective treatment. However, testing the effect of α5-PAM on human brain activity is limited, meriting the use of detailed simulations. We utilized our previous detailed computational models of human depression microcircuits with reduced SST interneuron inhibition and α5-PAM effects, to simulate EEG of individual microcircuits across depression severity and α5-PAM doses. We developed machine learning models that predicted optimal dose from EEG with high accuracy and recovered microcircuit activity and EEG. This study provides dose prediction models for α5-PAM administration based on EEG biomarkers of depression severity. Given limitations in doing the above in the living human brain, the results and tools we developed will facilitate translation of α5-PAM treatment to clinical use.",https://pubmed.ncbi.nlm.nih.gov/39729407/,https://pubmed.ncbi.nlm.nih.gov/39729407/,English,Include,,Therapeutic dose prediction of α5-GABA receptor modulation from simulated EEG of depression severity.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39727765,pubmed:39727765,PubMed,pubmed:39727765,An Ensemble Deep Learning Approach for EEG-Based Emotion Recognition Using Multi-Class CSP.,Behzad Yousefipour;Vahid Rajabpour;Hamidreza Abdoljabbari;Sobhan Sheykhivand;Sebelan Danishvar,2024,10.1016/j.glmedi.2024.100099,"In recent years, significant advancements have been made in the field of brain-computer interfaces (BCIs), particularly in the area of emotion recognition using EEG signals. The majority of earlier research in this field has missed the spatial-temporal characteristics of EEG signals, which are critical for accurate emotion recognition. In this study, a novel approach is presented for classifying emotions into three categories, positive, negative, and neutral, using a custom-collected dataset. The dataset used in this study was specifically collected for this purpose from 16 participants, comprising EEG recordings corresponding to the three emotional states induced by musical stimuli. A multi-class Common Spatial Pattern (MCCSP) technique was employed for the processing stage of the EEG signals. These processed signals were then fed into an ensemble model comprising three autoencoders with Convolutional Neural Network (CNN) layers. A classification accuracy of 99.44 ± 0.39% for the three emotional classes was achieved by the proposed method. This performance surpasses previous studies, demonstrating the effectiveness of the approach. The high accuracy indicates that the method could be a promising candidate for future BCI applications, providing a reliable means of emotion detection.",https://pubmed.ncbi.nlm.nih.gov/39727765/,https://pubmed.ncbi.nlm.nih.gov/39727765/,English,Include,,An Ensemble Deep Learning Approach for EEG-Based Emotion Recognition Using Multi-Class CSP.,Include,,"or the processing stage of the EEG signals. These processed signals were then fed into an ensemble model comprising three autoencoders with Convolutional Neural Network (CNN) layers. A classification accuracy of 99.44 ± 0.39% for the three emotional classes was achieved by the proposed method. This performance surpasses previous studies, demonstrating the effectiveness of the approach. The high ac",,0.95,0.8,small_sample_mentioned
pubmed:39726882,pubmed:39726882,PubMed,pubmed:39726882,An Unsupervised Feature Extraction Method based on CLSTM-AE for Accurate P300 Classification in Brain-Computer Interface Systems.,Ramin Afrah;Zahra Amini;Rahele Kafieh,2024,10.3390/s20195576,"The P300 signal, an endogenous component of event-related potentials, is extracted from an electroencephalography signal and employed in Brain-computer Interface (BCI) devices. The current study aimed to address challenges in extracting useful features from P300 components and detecting P300 through a hybrid unsupervised manner based on Convolutional Neural Network (CNN) and Long Short-term Memory (LSTM). In this cross-sectional study, CNN as a useful method for the P300 classification task emphasizes spatial characteristics of data. However, CNN and LSTM networks are combined to modify the classification system by extracting both spatial and temporal features. Then, the CNN-LSTM network was trained in an unsupervised learning method based on an autoencoder to improve Signal-to-noise Ratio (SNR) by extracting main components from latent space. To deal with imbalanced data, an Adaptive Synthetic Sampling Approach (ADASYN) is used and augmented without any duplication. The trained model, tested on the BCI competition III dataset, including two normal subjects, with an accuracy of 95% and 94% for subjects A and B in P300 detection, respectively. CNN-LSTM, was embedded into an autoencoder and introduced to simultaneously extract spatial and temporal features and manage the computational complexity of the method. Further, ADASYN as an augmentation method was proposed to deal with the imbalanced nature of data, which not only maintained feature space as before but also preserved anatomical features of P300. High-quality results highlight the suitable efficiency of the proposed method.",https://pubmed.ncbi.nlm.nih.gov/39726882/,https://pubmed.ncbi.nlm.nih.gov/39726882/,English,Include,,An Unsupervised Feature Extraction Method based on CLSTM-AE for Accurate P300 Classification in Brain-Computer Interface Systems.,Include,,"a, an Adaptive Synthetic Sampling Approach (ADASYN) is used and augmented without any duplication. The trained model, tested on the BCI competition III dataset, including two normal subjects, with an accuracy of 95% and 94% for subjects A and B in P300 detection, respectively. CNN-LSTM, was embedded into an autoencoder and introduced to simultaneously extract spatial and temporal features and mana",,0.95,0.6,
pubmed:39726001,pubmed:39726001,PubMed,pubmed:39726001,Unraveling EEG correlates of unimanual finger movements: insights from non-repetitive flexion and extension tasks.,Qiang Sun;Eva Calvo Merino;Liuyin Yang;Marc M Van Hulle,2024,10.1186/s12984-024-01533-4,"The loss of finger control in individuals with neuromuscular disorders significantly impacts their quality of life. Electroencephalography (EEG)-based brain-computer interfaces that actuate neuroprostheses directly via decoded motor intentions can help restore lost finger mobility. However, the extent to which finger movements exhibit distinct and decodable EEG correlates remains unresolved. This study aims to investigate the EEG correlates of unimanual, non-repetitive finger flexion and extension. Sixteen healthy, right-handed participants completed multiple sessions of right-hand finger movement experiments. These included five individual (Thumb, Index, Middle, Ring, and Pinky) and four coordinated (Pinch, Point, ThumbsUp, and Fist) finger flexions and extensions, along with a rest condition (None). High-density EEG and finger trajectories were simultaneously recorded and analyzed. We examined low-frequency (0.3-3 Hz) time series and movement-related cortical potentials (MRCPs), and event-related desynchronization/synchronization (ERD/S) in the alpha- (8-13 Hz) and beta (13-30 Hz) bands. A clustering approach based on Riemannian distances was used to chart similarities between the broadband EEG responses (0.3-70 Hz) to the different finger scenarios. The contribution of different state-of-the-art features was identified across sub-bands, from low-frequency to low gamma (30-70 Hz), and an ensemble approach was used to pairwise classify single-trial finger movements and rest. A significant decrease in EEG amplitude in the low-frequency time series was observed in the contralateral frontal-central regions during finger flexion and extension. Distinct MRCP patterns were found in the pre-, ongoing-, and post-movement stages. Additionally, strong ERD was detected in the contralateral central brain regions in both alpha and beta bands during finger flexion and extension, with the beta band showing a stronger rebound (ERS) post-movement. Within the finger movement repertoire, the Thumb was most distinctive, followed by the Fist. Decoding results indicated that low-frequency time-domain amplitude better differentiates finger movements, while alpha and beta band power and Riemannian features better detect movement versus rest. Combining these features yielded over 80% finger movement detection accuracy, while pairwise classification accuracy exceeded 60% for the Thumb versus the other fingers. Our findings confirm that non-repetitive finger movements, whether individual or coordinated, can be precisely detected from EEG. However, differentiating between specific movements is challenging due to highly overlapping neural correlates in time, spectral, and spatial domains. Nonetheless, certain finger movements, such as those involving the Thumb, exhibit distinct EEG responses, making them prime candidates for dexterous finger neuroprostheses.",https://pubmed.ncbi.nlm.nih.gov/39726001/,https://pubmed.ncbi.nlm.nih.gov/39726001/,English,Include,,Unraveling EEG correlates of unimanual finger movements: insights from non-repetitive flexion and extension tasks.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39725813,pubmed:39725813,PubMed,pubmed:39725813,Entropy of difference works similarly to permutation entropy for the assessment of anesthesia and sleep EEG despite the lower computational effort.,Alexander Edthofer;Dina Ettel;Gerhard Schneider;Andreas Körner;Matthias Kreuzer,2025,10.1007/s10877-024-01258-8,"EEG monitoring during anesthesia or for diagnosing sleep disorders is a common standard. Different approaches for measuring the important information of this biosignal are used. The most often and efficient one for entropic parameters is permutation entropy as it can distinguish the vigilance states in the different settings. Due to high calculation times, it has mostly been used for low orders, although it shows good results even for higher orders. Entropy of difference has a similar way of extracting information from the EEG as permutation entropy. Both parameters and different algorithms for encoding the associated patterns in the signal are described. The runtimes of both entropic measures are compared, not only for the needed encoding but also for calculating the value itself. The mutual information that both parameters extract is measured with the AUC for a linear discriminant analysis classifier. Entropy of difference shows a smaller calculation time than permutation entropy. The reduction is much larger for higher orders, some of them can even only be computed with the entropy of difference. The distinguishing of the vigilance states between both measures is similar as the AUC values for the classification do not differ significantly. As the runtimes for the entropy of difference are smaller than for the permutation entropy, even though the performance stays the same, we state the entropy of difference could be a useful method for analyzing EEG data. Higher orders of entropic features may also be investigated better and more easily.",,https://pubmed.ncbi.nlm.nih.gov/39725813/,English,Exclude,Outside date range,Entropy of difference works similarly to permutation entropy for the assessment of anesthesia and sleep EEG despite the lower computational effort.,,,,,0.95,0.6,
pubmed:39725763,pubmed:39725763,PubMed,pubmed:39725763,Performance investigation of MVMD-MSI algorithm in frequency recognition for SSVEP-based brain-computer interface and its application in robotic arm control.,Rongrong Fu;Shaoxiong Niu;Xiaolei Feng;Ye Shi;Chengcheng Jia;Jing Zhao;Guilin Wen,2025,10.1109/tase.2021.3054741,"This study focuses on improving the performance of steady-state visual evoked potential (SSVEP) in brain-computer interfaces (BCIs) for robotic control systems. The challenge lies in effectively reducing the impact of artifacts on raw data to enhance the performance both in quality and reliability. The proposed MVMD-MSI algorithm combines the advantages of multivariate variational mode decomposition (MVMD) and multivariate synchronization index (MSI). Compared to widely used algorithms, the novelty of this method is its capability of decomposing nonlinear and non-stationary EEG signals into intrinsic mode functions (IMF) across different frequency bands with the best center frequency and bandwidth. Therefore, SSVEP decoding performance can be improved by this method, and the effectiveness of MVMD-MSI is evaluated by the robot with 6 degrees-of-freedom. Offline experiments were conducted to optimize the algorithm's parameters, resulting in significant improvements. Additionally, the algorithm showed good performance even with fewer channels and shorter data lengths. In online experiments, the algorithm achieved an average accuracy of 98.31% at 1.8 s, confirming its feasibility and effectiveness for real-time SSVEP BCI-based robotic arm applications. The MVMD-MSI algorithm, as proposed, represents a significant advancement in SSVEP analysis for robotic control systems. It enhances decoding performance and shows promise for practical application in this field.",,https://pubmed.ncbi.nlm.nih.gov/39725763/,English,Exclude,Outside date range,Performance investigation of MVMD-MSI algorithm in frequency recognition for SSVEP-based brain-computer interface and its application in robotic arm control.,,,,,0.95,0.6,
pubmed:39725001,pubmed:39725001,PubMed,pubmed:39725001,The role of delta phase for temporal predictions investigated with bilateral parietal tACS.,Rebecca Burke;Alexander Maÿe;Jonas Misselhorn;Marina Fiene;Felix J Engelhardt;Till R Schneider;Andreas K Engel,2025,10.1016/j.brs.2024.12.1476,"Previous research has shown that temporal prediction processes are associated with phase resets of low-frequency delta oscillations in a network of parietal, sensory and frontal areas during non-rhythmic sensory stimulation. Transcranial alternating current stimulation (tACS) modulates perceptually relevant brain oscillations in a frequency and phase-specific manner, allowing the assessment of their functional qualities in certain cognitive functions like temporal prediction. We addressed the relation between oscillatory activity and temporal prediction by using tACS to manipulate brain activity in a sinusoidal manner. This enables the investigation of the relevance of low-frequency oscillations' phase for temporal prediction. Delta tACS was applied over the left and right parietal cortex in two separate unimodal and crossmodal temporal prediction experiments. Participants judged either the visual or the tactile reappearance of a uniformly moving visual stimulus, which shortly disappeared behind an occluder. tACS was applied with six different phase shifts relative to sensory stimulation in both experiments. Additionally, a computational model was developed and analysed to elucidate oscillation-based functional principles for the generation of temporal predictions. Only in the unimodal experiment, the application of delta tACS resulted in a phase-dependent modulation of temporal prediction performance. By considering the effect of sustained tACS in the computational model, we demonstrate that the entrained dynamics can phase-specifically modulate temporal prediction accuracy. Our results suggest that delta oscillatory phase contributes to unimodal temporal prediction. Crossmodal prediction may involve a broader brain network or cross-frequency interactions, extending beyond parietal delta phase and the scope of our current stimulation design.",,https://pubmed.ncbi.nlm.nih.gov/39725001/,English,Exclude,Outside date range,The role of delta phase for temporal predictions investigated with bilateral parietal tACS.,,,,,0.95,0.8,small_sample_mentioned
pubmed:39724534,pubmed:39724534,PubMed,pubmed:39724534,Accuracy of a Rapid-Response EEG's Automated Seizure-Burden Estimator: AccuRASE Study.,Zubeda B Sheikh;Monica B Dhakar;Michael W K Fong;Wei Fang;Neishay Ayub;Janine Molino;Hiba A Haider;Brandon Foreman;Emily Gilmore;Moshe Mizrahi;Ioannis Karakis;Sarah E Schmitt;Gamaleldin Osman;Ji Yeoun Yoo;Lawrence J Hirsch,2025,10.1212/wnl.0000000000210234,"The use of rapid response EEG (rr-EEG) has recently expanded in limited-resource settings and as a supplement to conventional EEG to rapidly detect and treat nonconvulsive status epilepticus. The study objective was to test the accuracy of an rr-EEG's automated seizure burden estimator (ASBE). This is a retrospective observational study using multiple blinded reviewers. All consecutive clinical rr-EEG procedures performed between November 2019 and February 2021 at Yale New Haven Hospital, one affiliated community hospital, and one affiliated inner-city regional hospital were included. Three reviewers blindly reviewed each EEG. The reference standard was 2/3 agreement. The co-primary outcome measures were the negative predictive value (NPV) of the ASBE for the detection of electrographic status epilepticus (ESE) or possible ESE (ESE/pESE) (to be used as a screening method to exclude ESE without the need for urgent expert review) and the positive predictive value (PPV, to be used for immediate treatment without requiring urgent expert review). These were assessed using a variety of seizure burden cutoffs determined by the algorithm (>1%, >10%, >20%, >50%, and >90%). In the first 2 hours, a >10% burden cutoff detected 86% (95% CI 42%-100%) of studies with ESE alone and 88% (68%-97%) with ESE/pESE; this >10% cutoff had a NPV of 99% (97%-100%) for ESE and 98% (95%-100%) for ESE/pESE. The specificity at this threshold was 79% (73%-84%) for ESE and 84% (79%-89%) for ESE/pESE, but the PPV was low at 11% (4%-23%) for ESE and 39% (26%-53%) for ESE/pESE. A >90% burden cutoff was 97% (94%-99%) specific for detecting ESE (PPV 33% [7%-70%]) and 99% (97%-100%) specific for detecting ESE/pESE [PPV 78% (40%-97%)], although the sensitivity dropped significantly to 29% (13%-51%) for ESE/pESE and 43% (10%-82%) for ESE at the >90% threshold. The ASBE has high specificity at >90% seizure burden threshold for detecting ESE and ESE/pESE, with good PPV for ESE/pESE, though with only low-to-moderate sensitivity; at this threshold, it can be used to help triage patients for immediate treatment/transfer, urgent expert review, and additional CEEG. A >10% threshold has a high sensitivity, detecting approximately 85% of patients with ESE; at this lower cutoff, it can be used as a screening tool to exclude ESE with >95% NPV. This study provides Class II evidence that ASBE software can reliably exclude ESE (98% negative predictive value using a <10% burden cutoff) without expert review in most patients requiring rapid response EEG.",,https://pubmed.ncbi.nlm.nih.gov/39724534/,English,Exclude,Outside date range,Accuracy of a Rapid-Response EEG's Automated Seizure-Burden Estimator: AccuRASE Study.,,,,,0.95,0.6,
pubmed:39721414,pubmed:39721414,PubMed,pubmed:39721414,Enhancing multiple sclerosis diagnosis: A comparative study of electroencephalogram signal processing and entropy methods.,Umut Aslan;Mehmet Feyzi Akşahin,2025,10.1016/j.compbiomed.2024.109615,"As one of the most common neurodegenerative diseases, Multiple sclerosis (MS) is a chronic immune-driven disorder that affects the central nervous system (CNS). Due to the variety of symptoms, accurately diagnosing MS demands rigorous attention to differential diagnosis, as various disorders can closely mimic its clinical and paraclinical features. Although MR imaging techniques are gold standards in diagnosing MS, the feasibility of advanced Electroencephalogram (EEG) signal processing methods is discussed in this study to detect patients with MS disorder. EEG signals from 50 individuals were evaluated through entropy-based methods. Sixteen distinct entropy methods were employed to extract features, which were used to train several machine-learning algorithms for classifying MS patients. Furthermore, each entropy method was individually evaluated to identify the most effective approach for MS diagnosis. A regional analysis of the EEG channels was conducted to determine the most informative regions for classification. The results indicated that the proposed method outperformed previous studies and achieved highly effective results in the classification of MS patients.",,https://pubmed.ncbi.nlm.nih.gov/39721414/,English,Exclude,Outside date range,Enhancing multiple sclerosis diagnosis: A comparative study of electroencephalogram signal processing and entropy methods.,,,,,0.95,0.6,
pubmed:39721149,pubmed:39721149,PubMed,pubmed:39721149;pubmed:39640690,EEG-based brain age prediction in infants-toddlers: Implications for early detection of neurodevelopmental disorders.,Winko W An;Aprotim C Bhowmik;Charles A Nelson;Carol L Wilkinson,2025,10.1186/1744-9081-7-30,"The infant brain undergoes rapid developmental changes in the first three years of life. Understanding these changes through the prediction of chronological age using neuroimaging can provide insights into typical and atypical brain development. We utilized 938 resting-state EEG recordings from 457 typically developing infants, 2 to 38 months old, to develop age prediction models. The multilayer perceptron model demonstrated the highest accuracy with an R",,https://pubmed.ncbi.nlm.nih.gov/39721149/,English,Exclude,Outside date range,EEG-based brain age prediction in infants-toddlers: Implications for early detection of neurodevelopmental disorders.,,,,,0.95,0.6,
pubmed:39720668,pubmed:39720668,PubMed,pubmed:39720668,3D convolutional neural network based on spatial-spectral feature pictures learning for decoding motor imagery EEG signal.,Xiaoguang Li;Yaqi Chu;Xuejian Wu,2024,10.1016/j.bspc.2022.103825,"Non-invasive brain-computer interfaces (BCI) hold great promise in the field of neurorehabilitation. They are easy to use and do not require surgery, particularly in the area of motor imagery electroencephalography (EEG). However, motor imagery EEG signals often have a low signal-to-noise ratio and limited spatial and temporal resolution. Traditional deep neural networks typically only focus on the spatial and temporal features of EEG, resulting in relatively low decoding and accuracy rates for motor imagery tasks. To address these challenges, this paper proposes a 3D Convolutional Neural Network (P-3DCNN) decoding method that jointly learns spatial-frequency feature maps from the frequency and spatial domains of the EEG signals. First, the Welch method is used to calculate the frequency band power spectrum of the EEG, and a 2D matrix representing the spatial topology distribution of the electrodes is constructed. These spatial-frequency representations are then generated through cubic interpolation of the temporal EEG data. Next, the paper designs a 3DCNN network with 1D and 2D convolutional layers in series to optimize the convolutional kernel parameters and effectively learn the spatial-frequency features of the EEG. Batch normalization and dropout are also applied to improve the training speed and classification performance of the network. Finally, through experiments, the proposed method is compared to various classic machine learning and deep learning techniques. The results show an average decoding accuracy rate of 86.69%, surpassing other advanced networks. This demonstrates the effectiveness of our approach in decoding motor imagery EEG and offers valuable insights for the development of BCI.",https://pubmed.ncbi.nlm.nih.gov/39720668/,https://pubmed.ncbi.nlm.nih.gov/39720668/,English,Include,,3D convolutional neural network based on spatial-spectral feature pictures learning for decoding motor imagery EEG signal.,Include,,"to-noise ratio and limited spatial and temporal resolution. Traditional deep neural networks typically only focus on the spatial and temporal features of EEG, resulting in relatively low decoding and accuracy rates for motor imagery tasks. To address these challenges, this paper proposes a 3D Convolutional Neural Network (P-3DCNN) decoding method that jointly learns spatial-frequency feature maps ",,0.95,0.6,
pubmed:39720230,pubmed:39720230,PubMed,pubmed:39720230,STAFNet: an adaptive multi-feature learning network via spatiotemporal fusion for EEG-based emotion recognition.,Fo Hu;Kailun He;Mengyuan Qian;Xiaofeng Liu;Zukang Qiao;Lekai Zhang;Junlong Xiong,2024,10.1109/tnsre.2023.3323432,"Emotion recognition using electroencephalography (EEG) is a key aspect of brain-computer interface research. Achieving precision requires effectively extracting and integrating both spatial and temporal features. However, many studies focus on a single dimension, neglecting the interplay and complementarity of multi-feature information, and the importance of fully integrating spatial and temporal dynamics to enhance performance. We propose the Spatiotemporal Adaptive Fusion Network (STAFNet), a novel framework combining adaptive graph convolution and temporal transformers to enhance the accuracy and robustness of EEG-based emotion recognition. The model includes an adaptive graph convolutional module to capture brain connectivity patterns through spatial dynamic evolution and a multi-structured transformer fusion module to integrate latent correlations between spatial and temporal features for emotion classification. Extensive experiments were conducted on the SEED and SEED-IV datasets to evaluate the performance of STAFNet. The model achieved accuracies of 97.89% and 93.64%, respectively, outperforming state-of-the-art methods. Interpretability analyses, including confusion matrices and t-SNE visualizations, were employed to examine the influence of different emotions on the model's recognition performance. Furthermore, an investigation of varying GCN layer depths demonstrated that STAFNet effectively mitigates the over-smoothing issue in deeper GCN architectures. In summary, the findings validate the effectiveness of STAFNet in EEG-based emotion recognition. The results emphasize the critical role of spatiotemporal feature extraction and introduce an innovative framework for feature fusion, advancing the state of the art in emotion recognition.",https://pubmed.ncbi.nlm.nih.gov/39720230/,https://pubmed.ncbi.nlm.nih.gov/39720230/,English,Include,,STAFNet: an adaptive multi-feature learning network via spatiotemporal fusion for EEG-based emotion recognition.,Include,,"poral dynamics to enhance performance. We propose the Spatiotemporal Adaptive Fusion Network (STAFNet), a novel framework combining adaptive graph convolution and temporal transformers to enhance the accuracy and robustness of EEG-based emotion recognition. The model includes an adaptive graph convolutional module to capture brain connectivity patterns through spatial dynamic evolution and a multi",,0.95,0.6,
pubmed:39720022,pubmed:39720022,PubMed,pubmed:39720022;pubmed:39268152,A comparative study of wavelet families for schizophrenia detection.,E Sathiya;T D Rao;T Sunil Kumar,2024,10.3389/fninf.2018.00095,"Schizophrenia (SZ) is a chronic mental disorder, affecting approximately 1% of the global population, it is believed to result from various environmental factors, with psychological factors potentially influencing its onset and progression. Discrete wavelet transform (DWT)-based approaches are effective in SZ detection. In this report, we aim to investigate the effect of wavelet and decomposition levels in SZ detection. In our study, we analyzed the early detection of SZ using DWT across various decomposition levels, ranging from 1 to 5, with different mother wavelets. The electroencephalogram (EEG) signals are processed using DWT, which decomposes them into multiple frequency bands, yielding approximation and detail coefficients at each level. Statistical features are then extracted from these coefficients. The computed feature vector is then fed into a classifier to distinguish between SZ and healthy controls (HC). Our approach achieves the highest classification accuracy of 100% on a publicly available dataset, outperforming existing state-of-the-art methods.",https://pubmed.ncbi.nlm.nih.gov/39720022/,https://pubmed.ncbi.nlm.nih.gov/39720022/,English,Include,,A comparative study of wavelet families for schizophrenia detection.,Exclude,Duplicate study,Duplicate group,,0.99,0.6,
pubmed:39719815,pubmed:39719815,PubMed,pubmed:39719815,Auditory working memory in noise in cochlear implant users: Insights from behavioural and neuronal measures.,Loes Beckers;Birgit Philips;Wendy Huinck;Emmanuel Mylanus;Andreas Büchner;Andrej Kral,2025,10.1016/j.heares.2024.109167,"We investigated auditory working-memory using behavioural measures and electroencephalography (EEG) in adult Cochlear Implant (CI) users with varying degrees of CI performance. 24 adult CI listeners (age: M = 61.38, SD = 12.45) performed the Sternberg auditory-digit-in-working-memory task during which EEG, accuracy, and promptness were captured. Participants were presented with 2, 4, or 6 digits at Signal-to-Noise Ratios (SNR) of 0, +5 and +10dB. They had to identify a probe stimulus as present in the preceding sequence. ANOVA models were used to compare conditions. ANOVA revealed that increasing memory load (ML) led to decreased task performance and CI performance interacted with ML and SNR. Centro-parietal alpha power increased during memory encoding but did not differ between conditions. Frontal alpha power was positively correlated with accuracy in conditions most affected by SNR (r = 0.57, r = 0.52) and theta power in conditions most affected by ML (r = 0.55, r = 0.57). While parietal alpha power is modulated by the task, it is frontal alpha that relates quantitatively to sensory aspects of processing (noise) and frontal theta to memory load in this group of CI listeners. These results suggest that alpha and theta show distinct relationships to behaviour, providing additional insight into neurocognitive (auditory working-memory) processes in CI users.",,https://pubmed.ncbi.nlm.nih.gov/39719815/,English,Exclude,Outside date range,Auditory working memory in noise in cochlear implant users: Insights from behavioural and neuronal measures.,,,,,0.95,0.8,small_sample_mentioned
pubmed:39719536,pubmed:39719536,PubMed,pubmed:39719536,The N400 component reflecting semantic and repetition priming of visual scenes is suppressed during the attentional blink.,Courtney Guida;Minwoo J B Kim;Olivia A Stibolt;Alyssa Lompado;James E Hoffman,2025,10.3758/s13414-024-02997-1,"In the attentional blink paradigm, participants attempt to identify two targets appearing in a rapidly presented stream of distractors. Report accuracy is typically high for the first target (T1) while identification of the second target (T2) is impaired when it follows within about 200-400 ms of T1. An important question is whether T2 is processed to a semantic level even when participants are unaware of its identity. We examined this issue in three studies that used natural scenes as stimuli and the N400 component of the event-related potential (ERP) as a measure of semantic priming. In the first experiment, the prime (e.g., a doghouse in a yard) was presented at the beginning of the trial and a test picture that was related (e.g., a dog standing in the kitchen) or unrelated (e.g., a coffee mug on a table) appeared as T2. In the second experiment, the prime was presented as T2 and the test picture appeared at the end of the picture sequence. In both experiments, we found robust semantic priming when participants were aware of the identity of the blinked picture and an absence of priming when they were unaware. In Experiment 3, we used identity priming to assess whether earlier representations preceding semantics were preserved, and again found that priming critically depended on awareness of the prime's identity. These results suggest that semantic priming in scenes, as measured with the N400, is a higher-level process that critically depends on attention and awareness.",,https://pubmed.ncbi.nlm.nih.gov/39719536/,English,Exclude,Outside date range,The N400 component reflecting semantic and repetition priming of visual scenes is suppressed during the attentional blink.,,,,,0.95,0.8,small_sample_mentioned
pubmed:39719191,pubmed:39719191,PubMed,pubmed:39719191,"Decoding thoughts, encoding ethics: A narrative review of the BCI-AI revolution.",Thorsten Rudroff,2025,10.1016/j.brainres.2024.149423,"This narrative review aims to analyze mechanisms underlying Brain-Computer Interface (BCI) and Artificial Intelligence (AI) integration, evaluate recent advances in signal acquisition and processing techniques, and assess AI-enhanced neural decoding strategies. The review identifies critical research gaps and examines emerging solutions across multiple domains of BCI-AI integration. A narrative review was conducted using major biomedical and scientific databases including PubMed, Web of Science, IEEE Xplore, and Scopus (2014-2024). Literature was analyzed to identify key developments in BCI-AI integration, with particular emphasis on recent advances (2019-2024). The review process involved thematic analysis of selected publications focusing on practical applications, technical innovations, and emerging challenges. Recent advances demonstrate significant improvements in BCI-AI systems: 1) High-density electrode arrays achieve spatial resolution up to 5 mm, with stable recordings over 15 months; 2) Deep learning decoders show 40 % improvement in information transfer rates compared to traditional methods; 3) Adaptive algorithms maintain >90 % success rates in motor control tasks over 200-day periods without recalibration; 4) Novel closed-loop optimization frameworks reduce user training time by 55 % while improving accuracy. Latest developments in flexible neural interfaces and self-supervised learning approaches show promise in addressing long-term stability and cross-user generalization challenges. BCI-AI integration shows remarkable progress in improving signal quality, decoding accuracy, and user adaptation. While challenges remain in long-term stability and user training, advances in adaptive algorithms and feedback mechanisms demonstrate the technology's growing viability for clinical applications. Recent innovations in electrode technology, AI architectures, and closed-loop systems, combined with emerging standardization frameworks, suggest accelerating progress toward widespread therapeutic use and human augmentation applications.",,https://pubmed.ncbi.nlm.nih.gov/39719191/,English,Exclude,Outside date range,"Decoding thoughts, encoding ethics: A narrative review of the BCI-AI revolution.",,,,,0.95,0.6,
pubmed:39718409,pubmed:39718409,PubMed,pubmed:39718409,An attention-based motor imagery brain-computer interface system for lower limb exoskeletons.,Xinzhi Ma;Weihai Chen;Zhongcai Pei;Jing Zhang,2024,10.1063/5.0243337,"Lower-limb exoskeletons have become increasingly popular in rehabilitation to help patients with disabilities regain mobility and independence. Brain-computer interface (BCI) offers a natural control method for these exoskeletons, allowing users to operate them through their electroencephalogram (EEG) signals. However, the limited EEG decoding performance of the BCI system restricts its application for lower limb exoskeletons. To address this challenge, we propose an attention-based motor imagery BCI system for lower limb exoskeletons. The decoding module of the proposed BCI system combines the convolutional neural network (CNN) with a lightweight attention module. The CNN aims to extract meaningful features from EEG signals, while the lightweight attention module aims to capture global dependencies among these features. The experiments are divided into offline and online experiments. The offline experiment is conducted to evaluate the effectiveness of different decoding methods, while the online experiment is conducted on a customized lower limb exoskeleton to evaluate the proposed BCI system. Eight subjects are recruited for the experiments. The experimental results demonstrate the great classification performance of the decoding method and validate the feasibility of the proposed BCI system. Our approach establishes a promising BCI system for the lower limb exoskeleton and is expected to achieve a more effective and user-friendly rehabilitation process.",https://pubmed.ncbi.nlm.nih.gov/39718409/,https://pubmed.ncbi.nlm.nih.gov/39718409/,English,Include,,An attention-based motor imagery brain-computer interface system for lower limb exoskeletons.,Include,,he feasibility of the proposed BCI system. Our approach establishes a promising BCI system for the lower limb exoskeleton and is expected to achieve a more effective and user-friendly rehabilitation process.,,0.95,0.6,
pubmed:39716930,pubmed:39716930,PubMed,pubmed:39716930,Pre-implantation Scalp EEG Can Predict VNS Efficacy in Children.,Tereza Jurková;Jan Chládek;Irena Doležalová;Štefania Aulická;Jan Chrastina;Tomáš Zeman;Ondřej Horák;Eva Koriťáková;Milan Brázdil,2025,10.1177/15500594241308594,,,https://pubmed.ncbi.nlm.nih.gov/39716930/,English,Exclude,Outside date range,Pre-implantation Scalp EEG Can Predict VNS Efficacy in Children.,,,,,0.95,0.6,
pubmed:39716573,pubmed:39716573,PubMed,pubmed:39716573,Personalized whole-brain activity patterns predict human corticospinal tract activation in real-time.,Uttara U Khatri;Kristen Pulliam;Muskan Manesiya;Melanie Vieyra Cortez;José Del R Millán;Sara J Hussain,2025,10.1161/strokeaha.120.028932/asset/84d0f374-af12-4345-b4d7-365069e9de73/assets/images/large/strokeaha.120.028932.fig04.jpg,"Transcranial magnetic stimulation (TMS) interventions could feasibly treat stroke-related motor impairments, but their effects are highly variable. Brain state-dependent TMS approaches are a promising solution to this problem, but inter-individual variation in lesion location and oscillatory dynamics can make translating them to the poststroke brain challenging. Personalized brain state-dependent approaches specifically designed to address these challenges are needed. As a first step towards this goal, we tested a novel machine learning-based EEG-TMS system that identifies personalized brain activity patterns reflecting strong and weak corticospinal tract (CST) activation (strong and weak CST states) in healthy adults in real-time. Participants completed a single-session study that included the acquisition of a TMS-EEG-EMG training dataset, personalized classifier training, and real-time EEG-informed single-pulse TMS during classifier-predicted personalized CST states. MEP amplitudes elicited in real-time during classifier-predicted personalized strong CST states were significantly larger than those elicited during corresponding weak and random CST states. MEP amplitudes elicited in real-time during classifier-predicted personalized strong CST states were also significantly less variable than those elicited during corresponding weak CST states. Personalized CST states lasted for ∼1-2 s at a time and ∼1 s elapsed between consecutive similar states. Individual participants exhibited unique differences in spectro-spatial EEG patterns between classifier-predicted personalized strong and weak CST states. Our results show for the first time that personalized whole-brain EEG activity patterns predict CST activation in real-time in healthy humans. These findings represent a pivotal step towards using personalized brain state-dependent TMS interventions to promote poststroke CST function.",,https://pubmed.ncbi.nlm.nih.gov/39716573/,English,Exclude,Outside date range,Personalized whole-brain activity patterns predict human corticospinal tract activation in real-time.,,,,,0.95,0.8,small_sample_mentioned
pubmed:39714017,pubmed:39714017,PubMed,pubmed:39714017,The emergence of visual category representations in infants' brains.,Xiaoqian Yan;Sarah Shi Tung;Bella Fascendini;Yulan Diana Chen;Anthony M Norcia;Kalanit Grill-Spector,2024,10.1111/1467-8624.00022,"Organizing the continuous stream of visual input into categories like places or faces is important for everyday function and social interactions. However, it is unknown when neural representations of these and other visual categories emerge. Here, we used steady-state evoked potential electroencephalography to measure cortical responses in infants at 3-4 months, 4-6 months, 6-8 months, and 12-15 months, when they viewed controlled, gray-level images of faces, limbs, corridors, characters, and cars. We found that distinct responses to these categories emerge at different ages. Reliable brain responses to faces emerge first, at 4-6 months, followed by limbs and places around 6-8 months. Between 6 and 15 months response patterns become more distinct, such that a classifier can decode what an infant is looking at from their brain responses. These findings have important implications for assessing typical and atypical cortical development as they not only suggest that category representations are learned, but also that representations of categories that may have innate substrates emerge at different times during infancy.",https://pubmed.ncbi.nlm.nih.gov/39714017/,https://pubmed.ncbi.nlm.nih.gov/39714017/,English,Include,,The emergence of visual category representations in infants' brains.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39712669,pubmed:39712669,PubMed,pubmed:39712669,AI-driven approaches for automatic detection of sleep apnea/hypopnea based on human physiological signals: a review.,Dandan Peng;Le Sun;Qian Zhou;Yanchun Zhang,2025,10.1007/s13755-024-00320-8,"Sleep apnea/hypopnea is a sleep disorder characterized by repeated pauses in breathing which could induce a series of health problems such as cardiovascular disease (CVD) and even sudden death. Polysomnography (PSG) is the most common way to diagnose sleep apnea/hypopnea. Considering that PSG data acquisition is complex and the diagnosis of sleep apnea/hypopnea requires manual scoring, it is very time-consuming and highly professional. With the development of wearable devices and AI techniques, more and more works have been focused on building machine and deep learning models that use single or multi-modal physiological signals to achieve automated detection of sleep apnea/hypopnea. This paper provides a comprehensive review of automatic sleep apnea/hypopnea detection methods based on AI-based techniques in recent years. We summarize the general process used by existing works with a flow chart, which mainly includes data acquisition, raw signal pre-processing, model construction, event classification, and evaluation, since few papers consider these. Additionally, the commonly used public database and pre-processing methods are also reviewed in this paper. After that, we separately summarize the existing methods related to different modal physiological signals including nasal airflow, pulse oxygen saturation (SpO",,https://pubmed.ncbi.nlm.nih.gov/39712669/,English,Exclude,Outside date range,AI-driven approaches for automatic detection of sleep apnea/hypopnea based on human physiological signals: a review.,,,,,0.95,0.6,
pubmed:39712322,pubmed:39712322,PubMed,pubmed:39712322,Deep Learning-Based Visual Complexity Analysis of Electroencephalography Time-Frequency Images: Can It Localize the Epileptogenic Zone in the Brain?,Navaneethakrishna Makaram;Sarvagya Gupta;Matthew Pesce;Jeffrey Bolton;Scellig Stone;Daniel Haehn;Marc Pomplun;Christos Papadelis;Phillip Pearl;Alexander Rotenberg;Patricia Ellen Grant;Eleonora Tamilia,2023,10.3390/a16120567,"In drug-resistant epilepsy, a visual inspection of intracranial electroencephalography (iEEG) signals is often needed to localize the epileptogenic zone (EZ) and guide neurosurgery. The visual assessment of iEEG time-frequency (TF) images is an alternative to signal inspection, but subtle variations may escape the human eye. Here, we propose a deep learning-based metric of visual complexity to interpret TF images extracted from iEEG data and aim to assess its ability to identify the EZ in the brain. We analyzed interictal iEEG data from 1928 contacts recorded from 20 children with drug-resistant epilepsy who became seizure-free after neurosurgery. We localized each iEEG contact in the MRI, created TF images (1-70 Hz) for each contact, and used a pre-trained VGG16 network to measure their visual complexity by extracting unsupervised activation energy (UAE) from 13 convolutional layers. We identified points of interest in the brain using the UAE values via patient- and layer-specific thresholds (based on extreme value distribution) and using a support vector machine classifier. Results show that contacts inside the seizure onset zone exhibit lower UAE than outside, with larger differences in deep layers (L10, L12, and L13: ",https://pubmed.ncbi.nlm.nih.gov/39712322/,https://pubmed.ncbi.nlm.nih.gov/39712322/,English,Include,,Deep Learning-Based Visual Complexity Analysis of Electroencephalography Time-Frequency Images: Can It Localize the Epileptogenic Zone in the Brain?,Exclude,No performance metrics reported,No metrics found in full text,,0.9,0.6,
pubmed:39712143,pubmed:39712143,PubMed,pubmed:39712143,A novel dual-step transfer framework based on domain selection and feature alignment for motor imagery decoding.,Guanglian Bai;Jing Jin;Ren Xu;Xingyu Wang;Andrzej Cichocki,2024,10.1007/s11571-023-10053-1,"In brain-computer interfaces (BCIs) based on motor imagery (MI), reducing calibration time is gradually becoming an urgent issue in practical applications. Recently, transfer learning (TL) has demonstrated its effectiveness in reducing calibration time in MI-BCI. However, the different data distribution of subjects greatly affects the application effect of TL in MI-BCI. Therefore, this paper combines data alignment, source domain selection, and feature alignment into the MI-TL. We propose a novel dual-step transfer framework based on source domain selection and feature alignment. First, the source and target domains are aligned using a pre-calibration strategy (PS), and then a sequential reverse selection method is proposed to match the optimal source domain for each target domain with the designed dual model selection strategy. We use filter bank regularization common space pattern (FBRCSP) to obtain more features and introduce manifold embedded distribution alignment (MEDA) to correct the prediction results of the support vector machine (SVM). The experimental results on two competition public datasets (BCI competition IV Dataset 1 and Dataset 2a) and our dataset show that the average classification accuracy of the proposed framework is higher than the baseline method (no domain selection and no feature alignment), which reaches 84.12%, 79.91%, and 78.45%, respectively. And the computational cost is reduced by half compared with the baseline method.",https://pubmed.ncbi.nlm.nih.gov/39712143/,https://pubmed.ncbi.nlm.nih.gov/39712143/,English,Include,,A novel dual-step transfer framework based on domain selection and feature alignment for motor imagery decoding.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39712134,pubmed:39712134,PubMed,pubmed:39712134,Decoding of movement-related cortical potentials at different speeds.,Jing Zhang;Cheng Shen;Weihai Chen;Xinzhi Ma;Zilin Liang;Yue Zhang,2024,10.1007/s11571-024-10164-3,"The decoding of electroencephalogram (EEG) signals, especially motion-related cortical potentials (MRCP), is vital for the early detection of motor intent before movement execution. To enhance the decoding accuracy of MRCP and promote the application of early motion intention in active rehabilitation training, we propose a method for decoding MRCP signals. Specifically, an experimental paradigm is designed for the efficient capture of MRCP signals. Moreover, a feature extraction method based on differentiation is proposed to effectively characterize action variability. Six subjects were recruited to validate the effectiveness of the decoding method. Experiments such as fixed-window classification, sliding-window detection, and asynchronous analysis demonstrate that the method can detect motion intention 316 milliseconds before action execution and is capable of continuously detecting both rapid and slow movements.",https://pubmed.ncbi.nlm.nih.gov/39712134/,https://pubmed.ncbi.nlm.nih.gov/39712134/,English,Include,,Decoding of movement-related cortical potentials at different speeds.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39712133,pubmed:39712133,PubMed,pubmed:39712133,A bimodal deep learning network based on CNN for fine motor imagery.,Chenyao Wu;Yu Wang;Shuang Qiu;Huiguang He,2024,10.1007/s11571-024-10159-0,"Motor imagery (MI) is an important brain-computer interface (BCI) paradigm. The traditional MI paradigm (imagining different limbs) limits the intuitive control of the outer devices, while fine MI paradigm (imagining different joint movements from the same limb) can control the mechanical arm without cognitive disconnection. However, the decoding performance of fine MI limits its application. Electroencephalogram (EEG) and functional near-infrared spectroscopy (fNIRS) are widely used in BCI systems because of their portability and easy operation. In this study, a fine MI paradigm including four classes (hand, wrist, shoulder and rest) was designed, and the data of EEG-fNIRS bimodal brain activity was collected from 12 subjects. Event-related desynchronization (ERD) from EEG signals shows a contralateral dominant phenomenon, and there is difference between the ERD of the four classes. For fNIRS signal in the time dimension, the time periods with significant difference can be observed in the activation patterns of four MI tasks. Spatially, the signal peak based brain topographic map also shows difference of these four MI tasks. The EEG signal and fNIRS signal of these four classes are distinguishable. In this study, a bimodal fusion network is proposed to improve the fine MI tasks decoding performance. The features of these two modalities are extracted separately by two feature extractors based on convolutional neural networks (CNN). The recognition performance was significantly improved by the bimodal method proposed in this study, compared with the performance of the single-modal network. The proposed method outperformed all comparison methods, and achieved a four-class accuracy of 58.96%. This paper demonstrates the feasibility of EEG and fNIRS bimodal BCI systems for fine MI, and shows the effectiveness of the proposed bimodal fusion method. This research is supposed to support fine MI-based BCI systems with theories and techniques.",https://pubmed.ncbi.nlm.nih.gov/39712133/,https://pubmed.ncbi.nlm.nih.gov/39712133/,English,Include,,A bimodal deep learning network based on CNN for fine motor imagery.,Include,,"ly improved by the bimodal method proposed in this study, compared with the performance of the single-modal network. The proposed method outperformed all comparison methods, and achieved a four-class accuracy of 58.96%. This paper demonstrates the feasibility of EEG and fNIRS bimodal BCI systems for fine MI, and shows the effectiveness of the proposed bimodal fusion method. This research is suppos",,0.95,0.6,
pubmed:39712131,pubmed:39712131,PubMed,pubmed:39712131,STGAT-CS: spatio-temporal-graph attention network based channel selection for MI-based BCI.,Ming Meng;Bin Xu;Yuliang Ma;Yunyuan Gao;Zhizeng Luo,2024,10.1007/s11571-024-10154-5,"Brain-computer interface (BCI) based on the motor imagery paradigm typically utilizes multi-channel electroencephalogram (EEG) to ensure accurate capture of physiological phenomena. However, excessive channels often contain redundant information and noise, which can significantly degrade BCI performance. Although there have been numerous studies on EEG channel selection, most of them require manual feature extraction, and the extracted features are difficult to fully represent the effective information of EEG signals. In this paper, we propose a spatio-temporal-graph attention network for channel selection (STGAT-CS) of EEG signals. We consider the EEG channels and their inter-channel connectivity as a graph and treat the channel selection problem as a node classification problem on the graph. We leverage the multi-head attention mechanism of graph attention network to dynamically capture topological relationships between nodes and update node features accordingly. Additionally, we introduce one-dimensional convolution to automatically extract temporal features from each channel in the original EEG signal, thereby obtaining more comprehensive spatiotemporal characteristics. In the classification tasks of the BCI Competition III Dataset IVa and BCI Competition IV Dataset I, STGAT-CS achieved average accuracies of 91.5% and 85.4% respectively, demonstrating the effectiveness of the proposed method.",https://pubmed.ncbi.nlm.nih.gov/39712131/,https://pubmed.ncbi.nlm.nih.gov/39712131/,English,Include,,STGAT-CS: spatio-temporal-graph attention network based channel selection for MI-based BCI.,Exclude,No performance metrics reported,No metrics found in full text,,0.9,0.6,
pubmed:39712128,pubmed:39712128,PubMed,pubmed:39712128,Assessing the influence of latency variability on EEG classifiers - a case study of face repetition priming.,Yilin Li;Werner Sommer;Liang Tian;Changsong Zhou,2024,10.1007/s11571-024-10181-2,"Data-driven strategies have been widely used to distinguish experimental effects on single-trial EEG signals. However, how latency variability, such as within-condition jitter or latency shifts between conditions, affects the performance of EEG classifiers has not been well investigated. Without explicitly considering and disentangling such attributes of single trials, neural network-based classifiers have limitations in measuring their contributions. Inspired by domain knowledge of subcomponent latency and amplitude from traditional cognitive neuroscience, this study applies a stepwise latency correction method on single trials to control for their contributions to classifier behavior. As a case study demonstrating the value of this method, we measure repetition priming effects of faces, which induce large reaction time differences, latency shifts, and amplitude effects in averaged event-related potentials. The results show that within-condition jitter negatively impacts classifier performance, but between-condition latency shifts improve accuracy, whereas genuine amplitude differences have no significant influence. While demonstrated in the case of priming effects, this methodology can be generalized to experiments involving many kinds of time-varying signals to account for the contributions of latency variability to classifier performance. The online version contains supplementary material available at 10.1007/s11571-024-10181-2.",https://pubmed.ncbi.nlm.nih.gov/39712128/,https://pubmed.ncbi.nlm.nih.gov/39712128/,English,Include,,Assessing the influence of latency variability on EEG classifiers - a case study of face repetition priming.,Include,,"ifts, and amplitude effects in averaged event-related potentials. The results show that within-condition jitter negatively impacts classifier performance, but between-condition latency shifts improve accuracy, whereas genuine amplitude differences have no significant influence. While demonstrated in the case of priming effects, this methodology can be generalized to experiments involving many kind",,0.95,0.6,
pubmed:39712125,pubmed:39712125,PubMed,pubmed:39712125,A cross-attention swin transformer network for EEG-based subject-independent cognitive load assessment.,Zhongrui Li;Rongkai Zhang;Li Tong;Ying Zeng;Yuanlong Gao;Kai Yang;Bin Yan,2024,10.1007/s11571-024-10160-7,"EEG signals play a crucial role in assessing cognitive load, which is a key element in ensuring the secure operation of human-computer interaction systems. However, the variability of EEG signals across different subjects poses a challenge in applying the pre-trained cognitive load assessment model to new subjects. Moreover, previous domain adaptation research has primarily focused on developing complex network architectures to learn more domain-invariant features, overlooking the noise introduced by pseudo-labels and the challenges posed by domain migration problems. Therefore, this study proposes a novel cross-attention swin-transformer network for cross-subject cognitive load assessment, which achieves inter-domain feature alignment through parameter sharing in cross attention mechanism without using pseudo-labels, and utilizes maximum mean discrepancy (MMD) to measure the difference between the feature distributions of the source and target domains, further promoting feature alignment between domains. This method aims to leverage the advantages of cross-attention mechanism and MMD to better mitigate individual differences among subjects in cross-subject cognitive workload assessment. To validate the classification performance of the proposed network, two datasets of image recognition task and N-back task were employed for testing. Results show that, the proposed model outperformed advanced methods with cross-subject classification results of 88.13% and 81.27% on the on local and public datasets. The ablation experiment results reveal that using either the cross-attention mechanism or the MMD strategy alone improves cross-subject classification performance by 2.11% and 2.95% on the local dataset, respectively. Furthermore, the results of the EEG features distribution differences between all subjects before and after network training showed a significant reduction in feature distribution differences between subjects, further confirming the network's effectiveness in minimizing inter-subject differences. The online version contains supplementary material available at 10.1007/s11571-024-10160-7.",https://pubmed.ncbi.nlm.nih.gov/39712125/,https://pubmed.ncbi.nlm.nih.gov/39712125/,English,Include,,A cross-attention swin transformer network for EEG-based subject-independent cognitive load assessment.,Exclude,No performance metrics reported,No metrics found in full text,,0.9,0.6,
pubmed:39712122,pubmed:39712122,PubMed,pubmed:39712122,MSHANet: a multi-scale residual network with hybrid attention for motor imagery EEG decoding.,Mengfan Li;Jundi Li;Xiao Zheng;Jiahao Ge;Guizhi Xu,2024,10.1007/s11571-024-10127-8,"EEG decoding plays a crucial role in the development of motor imagery brain-computer interface. Deep learning has great potential to automatically extract EEG features for end-to-end decoding. Currently, the deep learning is faced with the chanllenge of decoding from a large amount of time-variant EEG to retain a stable peroformance with different sessions. This study proposes a multi-scale residual network with hybrid attention (MSHANet) to decode four motor imagery classes. The MSHANet combines a multi-head attention and squeeze-and-excitation attention to hybridly focus on important information of the EEG features; and applies a multi-scale residual block to extracts rich EEG features, sharing part of the block parameters to extract common features. Compared with seven state-of-the-art methods, the MSHANet exhits the best accuracy on BCI Competition IV 2a with an accuracy of 83.18% for session- specific task and 80.09% for cross-session task. Thus, the proposed MSHANet decodes the time-varying EEG robustly and can save the time cost of MI-BCI, which is beneficial for long-term use.",https://pubmed.ncbi.nlm.nih.gov/39712122/,https://pubmed.ncbi.nlm.nih.gov/39712122/,English,Include,,MSHANet: a multi-scale residual network with hybrid attention for motor imagery EEG decoding.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39712121,pubmed:39712121,PubMed,pubmed:39712121,Advances in brain-computer interface for decoding speech imagery from EEG signals: a systematic review.,Nimra Rahman;Danish Mahmood Khan;Komal Masroor;Mehak Arshad;Amna Rafiq;Syeda Maham Fahim,2024,10.1007/s11571-024-10167-0,"Numerous individuals encounter challenges in verbal communication due to various factors, including physical disabilities, neurological disorders, and strokes. In response to this pressing need, technology has actively pursued solutions to bridge the communication gap, recognizing the inherent difficulties faced in verbal communication, particularly in contexts where traditional methods may be inadequate. Electroencephalogram (EEG) has emerged as a primary non-invasive method for measuring brain activity, offering valuable insights from a cognitive neurodevelopmental perspective. It forms the basis for Brain-Computer Interfaces (BCIs) that provide a communication channel for individuals with neurological impairments, thereby empowering them to express themselves effectively. EEG-based BCIs, especially those adapted to decode imagined speech from EEG signals, represent a significant advancement in enabling individuals with speech disabilities to communicate through text or synthesized speech. By utilizing cognitive neurodevelopmental insights, researchers have been able to develop innovative approaches for interpreting EEG signals and translating them into meaningful communication outputs. To aid researchers in effectively addressing this complex challenge, this review article synthesizes key findings from state-of-the-art significant studies. It investigates into the methodologies employed by various researchers, including preprocessing techniques, feature extraction methods, and classification algorithms utilizing Deep Learning and Machine Learning approaches and their integration. Furthermore, the review outlines the potential avenues for future research, with the goal of advancing the practical implementation of EEG-based BCI systems for decoding imagined speech from a cognitive neurodevelopmental perspective.",,https://pubmed.ncbi.nlm.nih.gov/39712121/,English,Exclude,Review/survey papers,Advances in brain-computer interface for decoding speech imagery from EEG signals: a systematic review.,,,,,0.95,0.6,
pubmed:39712118,pubmed:39712118,PubMed,pubmed:39712118,EEG-based deception detection using weighted dual perspective visibility graph analysis.,Ali Rahimi Saryazdi;Farnaz Ghassemi;Zahra Tabanfar;Sheida Ansarinasab;Fahimeh Nazarimehr;Sajad Jafari,2024,10.1007/s11571-024-10163-4,"Deception detection is a critical aspect across various domains. Integrating advanced signal processing techniques, particularly in neuroscientific studies, has opened new avenues for exploring deception at a deeper level. This study uses electroencephalogram (EEG) signals from a balanced cohort of 22 participants, consisting of both males and females, aged between 22 and 29, engaged in a visual task for instructed deception. We propose a novel approach in the realm of deception detection utilizing the Weighted Dual Perspective Visibility Graph (WDPVG) method to decode instructed deception by converting average epochs from each EEG channel into a complex network. Six graph-based features, including average and deviation of strength, weighted clustering coefficient, weighted clustering coefficient entropy, average weighted shortest path length, and modularity, are extracted, comprehensively representing the underlying brain dynamics associated with deception. Subsequently, these features are employed for classification using three distinct algorithms: K Nearest Neighbors (KNN), Support Vector Machine (SVM), and Decision Tree (DT). Experimental results reveal promising accuracy rates for KNN (66.64%), SVM (86.25%), and DT (82.46%). Furthermore, the features distributions of EEG networks are analyzed across different brain lobes, comparing truth-telling and lying modes. These analyses reveal the frontal and parietal lobes' potential in distinguishing between truth and deception, highlighting their active role during deceptive behavior. The findings demonstrate the WDPVG method's effectiveness in decoding deception from EEG signals, offering insights into the neural basis of deceptive behavior. This research could enhance the understanding of neuroscience and deception detection, providing a framework for future real-world applications.",https://pubmed.ncbi.nlm.nih.gov/39712118/,https://pubmed.ncbi.nlm.nih.gov/39712118/,English,Include,,EEG-based deception detection using weighted dual perspective visibility graph analysis.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39712116,pubmed:39712116,PubMed,pubmed:39712116,Coherence-based channel selection and Riemannian geometry features for magnetoencephalography decoding.,Chao Tang;Tianyi Gao;Gang Wang;Badong Chen,2024,10.1007/s11571-024-10085-1,"Magnetoencephalography (MEG) records the extremely weak magnetic fields on the surface of the scalp through highly sensitive sensors. Multi-channel MEG data provide higher spatial and temporal resolution when measuring brain activities, and can be applied for brain-computer interfaces as well. However, a large number of channels leads to high computational complexity and can potentially impact decoding accuracy. To improve the accuracy of MEG decoding, this paper proposes a new coherence-based channel selection method that effectively identifies task-relevant channels, reducing the presence of noisy and redundant information. Riemannian geometry is then used to extract effective features from selected channels of MEG data. Finally, MEG decoding is achieved by training a support vector machine classifier with the Radial Basis Function kernel. Experiments were conducted on two public MEG datasets to validate the effectiveness of the proposed method. The results from Dataset 1 show that Riemannian geometry achieves higher classification accuracy (compared to common spatial patterns and power spectral density) in the single-subject visual decoding task. Moreover, coherence-based channel selection significantly (",https://pubmed.ncbi.nlm.nih.gov/39712116/,https://pubmed.ncbi.nlm.nih.gov/39712116/,English,Include,,Coherence-based channel selection and Riemannian geometry features for magnetoencephalography decoding.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39712110,pubmed:39712110,PubMed,pubmed:39712110,Predicting an EEG-Based hypnotic time estimation with non-linear kernels of support vector machine algorithm.,Hoda Taghilou;Mazaher Rezaei;Alireza Valizadeh;Touraj Hashemi Nosratabad;Mohammad Ali Nazari,2024,10.1007/s11571-024-10088-y,"Our ability to measure time is vital for daily life, technology use, and even mental health; however, separating pure time perception from other mental processes (like emotions) is a research challenge requiring precise tests to isolate and understand brain activity solely related to time estimation. To address this challenge, we designed an experiment utilizing hypnosis alongside electroencephalography (EEG) to assess differences in time estimation, namely underestimation and overestimation. Hypnotic induction is designed to reduce awareness and meta-awareness, facilitating a detachment from the immediate environment. This reduced information processing load minimizes the need for elaborate internal thought during hypnosis, further simplifying the cognitive landscape. To predict time perception based on brain activity during extended durations (5 min), we employed artificial intelligence techniques. Utilizing Support Vector Machines (SVMs) with both radial basis function (RBF) and polynomial kernels, we assessed their effectiveness in classifying time perception-related brain patterns. We evaluated various feature combinations and different algorithms to identify the most accurate configuration. Our analysis revealed an impressive 80.9% classification accuracy for time perception detection using the RBF kernel, demonstrating the potential of AI in decoding this complex cognitive function.",https://pubmed.ncbi.nlm.nih.gov/39712110/,https://pubmed.ncbi.nlm.nih.gov/39712110/,English,Include,,Predicting an EEG-Based hypnotic time estimation with non-linear kernels of support vector machine algorithm.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39712091,pubmed:39712091,PubMed,pubmed:39712091,EEG-based classification of Alzheimer's disease and frontotemporal dementia: a comprehensive analysis of discriminative features.,Mehran Rostamikia;Yashar Sarbaz;Somaye Makouei,2024,10.1007/s11571-024-10152-7,"Alzheimer's disease (AD) and frontotemporal dementia (FTD) are two main types of dementia. These diseases have similar symptoms, and they both may be considered as AD. Early detection of dementia and differential diagnosis between AD and FTD can lead to more effective management of the disease and contributes to the advancement of knowledge and potential treatments. In this approach, several features were extracted from electroencephalogram (EEG) signals of 36 subjects diagnosed with AD, 23 FTD subjects, and 29 healthy controls (HC). Mann-Whitney U-test and t-test methods were employed for the selection of the best discriminative features. The Fp1 channel for FTD patients exhibited the most significant differences compared to AD. In addition, connectivity features in the delta and alpha subbands indicated promising discrimination among these two groups. Moreover, for dementia diagnosis (AD + FTD vs. HC), central brain regions including Cz and Pz channels proved to be determining for the extracted features. Finally, four machine learning (ML) algorithms were utilized for the classification purpose. For differentiating between AD and FTD, and dementia diagnosis, an accuracy of 87.8% and 93.5% were achieved respectively, using the tenfold cross-validation technique and employing support vector machines (SVM) as the classifier.",https://pubmed.ncbi.nlm.nih.gov/39712091/,https://pubmed.ncbi.nlm.nih.gov/39712091/,English,Include,,EEG-based classification of Alzheimer's disease and frontotemporal dementia: a comprehensive analysis of discriminative features.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.25,cv_reported
pubmed:39712087,pubmed:39712087,PubMed,pubmed:39712087,Time-frequency-space transformer EEG decoding for spinal cord injury.,Fangzhou Xu;Ming Liu;Xinyi Chen;Yihao Yan;Jinzhao Zhao;Yanbing Liu;Jiaqi Zhao;Shaopeng Pang;Sen Yin;Jiancai Leng;Yang Zhang,2024,10.1007/s11571-024-10135-8,"Transformer neural networks based on multi-head self-attention are effective in several fields. To capture brain activity on electroencephalographic (EEG) signals and construct an effective pattern recognition model, this paper explores the multi-channel deep feature decoding method utilizing the self-attention mechanism. By integrating inter-channel features with intra-channel features, the self-attention mechanism generates a deep feature vector that encompasses information from all brain activities. In this paper, a time-frequency-spatial domain analysis of motor imagery (MI) based EEG signals from spinal cord injury patients is performed to construct a transformer neural network-based MI classification model. The proposed algorithm is named time-frequency-spatial transformer. The time-frequency and spatial domain feature vectors extracted from the EEG signals are input into the transformer neural network for multiple self-attention depth feature encoding, a peak classification accuracy of 93.56% is attained through the fully connected layer. By constructing the attention matrix brain network, it can be inferred that the channel connections constructed by the attention heads have similarities to the brain networks constructed by the EEG raw signals. The experimental results reveal that the self-attention coefficient brain network holds significant potential for brain activity analysis. The self-attention coefficient brain network can better illustrate correlated connections and show sample differences. Attention coefficient brain networks can provide a more discriminative approach for analyzing brain activity in clinical settings.",https://pubmed.ncbi.nlm.nih.gov/39712087/,https://pubmed.ncbi.nlm.nih.gov/39712087/,English,Include,,Time-frequency-space transformer EEG decoding for spinal cord injury.,Include,,"ime-frequency and spatial domain feature vectors extracted from the EEG signals are input into the transformer neural network for multiple self-attention depth feature encoding, a peak classification accuracy of 93.56% is attained through the fully connected layer. By constructing the attention matrix brain network, it can be inferred that the channel connections constructed by the attention heads",,0.95,0.6,
pubmed:39708531,pubmed:39708531,PubMed,pubmed:39708531,Time-Frequency functional connectivity alterations in Alzheimer's disease and frontotemporal dementia: An EEG analysis using machine learning.,Huang Zheng;Han Xiao;Yinan Zhang;Haozhe Jia;Xing Ma;Yiqun Gan,2025,10.1016/j.clinph.2024.12.008,"Alzheimer's disease (AD) and frontotemporal dementia (FTD) are prevalent neurodegenerative diseases characterized by altered brain functional connectivity (FC), affecting over 100 million people worldwide. This study aims to identify distinct FC patterns as potential biomarkers for differential diagnosis. Resting-state EEG data from 36 AD patients, 23 FTD patients, and 29 healthy controls were analyzed using time-frequency and bandpass filtering FC metrics. These metrics were estimated through Pearson's correlations, mutual information, and phase lag index, and served as input features in a support vector machine (SVM) with Leave-One-Out Cross-Validation for group classification. Both AD and FTD exhibited significantly decreased FC in the theta band within the frontal lobe and increased FC in the beta band in the posterior regions. Additionally, a decreased FC in central regions at theta band was observed uniquely in AD, but not in FTD. SVM classification accuracies reached 95% for AD and 86% for FTD. High classification accuracies underscore the potential of these FC alterations as reliable biomarkers for AD and FTD. This is the first study to integrate time-frequency and bandpass filtering FC metrics to reveal brain network alterations in AD and FTD, providing new insights for diagnostics and neurodegenerative pathologies.",,https://pubmed.ncbi.nlm.nih.gov/39708531/,English,Exclude,Outside date range,Time-Frequency functional connectivity alterations in Alzheimer's disease and frontotemporal dementia: An EEG analysis using machine learning.,,,,,0.95,0.25,cv_reported
pubmed:39708497,pubmed:39708497,PubMed,pubmed:39708497,DCSENets: Interpretable deep learning for patient-independent seizure classification using enhanced EEG-based spectrogram visualization.,Sunday Timothy Aboyeji;Ijaz Ahmad;Xin Wang;Yan Chen;Chen Yao;Guanglin Li;Michael Chi Fai Tong;Alice K Y Siu;Guoru Zhao;Shixiong Chen,2025,10.1016/j.compbiomed.2024.109558,"Neurologists often face challenges in identifying epileptic activities within multichannel EEG recordings, requiring extensive hours of analysis. Computer-aided diagnosis systems have been proposed to reduce manual inspection of EEG signals by neurologists. However, direct analysis of EEG signals is difficult due to their complex and dynamic nature, with variation across multiple patients. Therefore, researchers have proposed the short-time Fourier transform (STFT) to capture dynamic events indicative of seizures through time-varying frequency representation of EEG signals. However, tradeoffs between time and frequency resolution limited the spectrogram's interpretability and affected clinical deployment. Hence, this study proposes extracting high-resolution channels via a novel STFT spectrogram construction algorithm encompassing taper functions for seizure diagnosis. Initially, we extracted seizure and non-seizure segments from each channel of selected patients in the CHB-MIT dataset. Next, we systematically apply taper functions like Hann and Gaussian windows to minimize the edge effect during the construction of spectrogram images. Finally, we employ Dilated Convolutional Squeeze and Excitation Networks (DCSENets) through leave-one-patient-out cross-validation (LOPOCV) to perform patient-independent seizure classification. The proposed DCSENets achieve an average accuracy of 87.20±11.48% and 87.29±10.48% with Hann and Gaussian taper functions, respectively, and 86.85±11.56% without the taper function. Most patients with high performances indicate similarity in train-test sample distribution using the Kolmogorov-Smirnov test at 0.01<p≤0.05 or p>0.05. Furthermore, the Grad CAM deep visual explainer integration enhances the interpretability of the deep learning model's decision-making process. Consequently, neurologists are provided not only with enhanced visualized spectrograms but also a transparent model for improved seizure diagnosis.",,https://pubmed.ncbi.nlm.nih.gov/39708497/,English,Exclude,Outside date range,DCSENets: Interpretable deep learning for patient-independent seizure classification using enhanced EEG-based spectrogram visualization.,,,,,0.95,0.25,cv_reported
pubmed:39707986,pubmed:39707986,PubMed,pubmed:39707986,Crucial rhythms and subnetworks for emotion processing extracted by an interpretable deep learning framework from EEG networks.,Peiyang Li;Ruiting Lin;Weijie Huang;Hao Tang;Ke Liu;Nan Qiu;Peng Xu;Yin Tian;Cunbo Li,2024,10.1093/cercor/bhae477,"Electroencephalogram (EEG) brain networks describe the driving and synchronous relationships among multiple brain regions and can be used to identify different emotional states. However, methods for extracting interpretable structural features from brain networks are still lacking. In the current study, a novel deep learning structure comprising both an attention mechanism and a domain adversarial strategy is proposed to extract discriminant and interpretable features from brain networks. Specifically, the attention mechanism enhances the contribution of crucial rhythms and subnetworks for emotion recognition, whereas the domain-adversarial module improves the generalization performance of our proposed model for cross-subject tasks. We validated the effectiveness of the proposed method for subject-independent emotion recognition tasks with the SJTU Emotion EEG Dataset (SEED) and the EEGs recorded in our laboratory. The experimental results showed that the proposed method can effectively improve the classification accuracy of different emotions compared with commonly used methods such as domain adversarial neural networks. On the basis of the extracted network features, we also revealed crucial rhythms and subnetwork structures for emotion processing, which are consistent with those found in previous studies. Our proposed method not only improves the classification performance of brain networks but also provides a novel tool for revealing emotion processing mechanisms.",https://pubmed.ncbi.nlm.nih.gov/39707986/,https://pubmed.ncbi.nlm.nih.gov/39707986/,English,Include,,Crucial rhythms and subnetworks for emotion processing extracted by an interpretable deep learning framework from EEG networks.,Include,,"recognition tasks with the SJTU Emotion EEG Dataset (SEED) and the EEGs recorded in our laboratory. The experimental results showed that the proposed method can effectively improve the classification accuracy of different emotions compared with commonly used methods such as domain adversarial neural networks. On the basis of the extracted network features, we also revealed crucial rhythms and subn",,0.95,0.6,
pubmed:39705614,pubmed:39705614,PubMed,pubmed:39705614,Child Neurology: Neurophysiologic and Anatomical Correlates in Startle Epilepsy: A Comprehensive SEEG Investigation for Successful Resective Surgery.,Junhyung Kim;Min-Jee Kim;Mi-Sun Yum;Tae-Sung Ko;Seok Ho Hong,2025,10.1212/wnl.0000000000210178,"Startle epilepsy, characterized by startle-provoked epileptic seizures, was historically recognized as one of the reflex epilepsies but currently lacks classification as a specific epileptic syndrome because of insufficient characterization. This study presents an institutional experience and review of relevant literature focusing on the neurophysiologic and anatomical aspects of startle epilepsy. We describe a pediatric patient with an underlying structural etiology of left frontal encephalomalacia who continued to experience disabling seizures despite multiple antiseizure medications and previous palliative surgery. A comprehensive presurgical evaluation using SEEG led to the resection of the left supplementary motor area and adjacent middle cingulate cortex, resulting in successful seizure remission. A literature review on the surgical treatment of startle epilepsy revealed consistent reports of successful seizure remission through neocortical resection of the supplementary motor area and/or cingulate region. This case study and literature review highlights startle epilepsy as a distinct form of epilepsy with identifiable neurophysiologic and anatomical characteristics. Our observations emphasize the potential of resective surgery as a viable treatment option for startle epilepsy and underscore the importance of neurophysiologic monitoring in guiding surgical interventions.",,https://pubmed.ncbi.nlm.nih.gov/39705614/,English,Exclude,Outside date range,Child Neurology: Neurophysiologic and Anatomical Correlates in Startle Epilepsy: A Comprehensive SEEG Investigation for Successful Resective Surgery.,,,,,0.95,0.6,
pubmed:39704838,pubmed:39704838,PubMed,pubmed:39704838,The effect of workload on mind-wandering of drilling operators measured by electroencephalography (EEG).,Su Hao;Xie Ruiying;Xu Lifei;Wang Jian;Jiang Jiaxin;Fan Siping;Wang Xiaoqin;Qing Xin;Liu Lu;Zhang Yufeng,2024,10.1016/j.psep.2017.01.005,"Mind wandering can cause workers to overlook safety hazards and delay making accurate operational decisions, ultimately raising the potential for accidents. However, there is relatively little research on the physiological characteristics of drilling workers during mind wandering. The aim of this investigation was to tackle the constraints of previous studies and to establish a more comprehensive theoretical framework and practical guidance for safety management. To this end, the phenomenon of workload on mind wandering among drillers during the drilling process was investigated in depth. It focused on drilling site workers, using SART paradigm tasks and EEG devices to track cognitive states under various loads, exploring how they affect mind wandering and EEG mechanisms. Fifty workers participated, observing drilling images to judge accidents. Results showed workload influenced cognitive processes such as mind wandering occurrence, reaction time, accuracy, and brain connectivity. High workload increased reaction time, decreased accuracy, raised mind wandering frequency, altered theta, beta, and gamma waves, and reduced cerebral synchronisation and engagement. Workload affected employees' mind wandering, sensations, focus, and work status, with a positive correlation between workload and mind wandering, potentially harming work performance and safety. Analyzing EEG data helps identify mind wandering and develop intervention measures. In depth research on these features not only helps identify employee mind wandering, but also promotes the development of more precise and personalized intervention measures.",https://pubmed.ncbi.nlm.nih.gov/39704838/,https://pubmed.ncbi.nlm.nih.gov/39704838/,English,Include,,The effect of workload on mind-wandering of drilling operators measured by electroencephalography (EEG).,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39704293,pubmed:39704293,PubMed,pubmed:39704293,Community-onset pediatric status epilepticus: Barriers to care and outcomes in a real-world setting.,Anna Fetta;Luca Bergonzini;Arianna Dondi;Laura Maria Beatrice Belotti;Federica Sperandeo;Caterina Gambi;Anna Bratta;Rossana Romano;Angelo Russo;Maria Cristina Mondardini;Luca Vignatelli;Marcello Lanari;Duccio Maria Cordelli,2025,10.5001/omj.2010.92,"Status epilepticus (SE) is a neurological emergency in childhood, often leading to neuronal damage and long-term outcomes. The study aims to identify barriers in the pre-hospital and in-hospital management of community-onset pediatric SE and to evaluate the effectiveness of pediatric scores on outcomes prediction. This monocentric observational retrospective cohort study included patients treated for community-onset pediatric SE in a tertiary care hospital between 2010 and 2021. Data were extracted following Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) guidelines. Inclusion criteria were community-onset SE (according to the International League Against Epilepsy [ILAE] Task Force on SE Classification), admission to the pediatric emergency department (PED), age: 1 month to 18 years. Pre-hospital, in-hospital management and outcomes were analyzed. Pediatric scores for prediction of clinical worsening (Pediatric Early Warning Score - PEWS) and SE outcome (Status Epilepticus in Pediatric patients Severity Score - STEPSS; Pre-status Epilepticus PCPCS, background Electroencephalographic abnormalities, Drug refractoriness, Semiology and critical Sickness Score - PEDSS) were retrospectively assessed for their accuracy in predicting short-term and long-term outcomes. A total of 103 consecutive episodes of SE were included. Out-of-hospital rescue medications administration occurred in 54.4% of cases and was associated with higher SE resolution rate before PED admission (48.2% vs 27.6%, p = .033). Longer in-PED time to treatment was observed in case of delay to PED referral (r = 0.268, p = .048) or non-red triage labels (12 vs 5 min, p = 0.032), and was associated with longer in-PED duration of SE (r = 0.645, p < .001). Longer SE duration was observed in episodes leading to hospitalization compared to those discharged (50 vs 16 min, p < .001). In-PED electroencephalography (EEG) recordings were available in 39.8% of events. Predictive scores varied in accuracy, with PEWS ≥5 showing high sensitivity for intensive care unit (ICU) admission but low specificity. No patients died, 6.3% of SE was refractory. Effective pre-hospital administration of rescue medications and prompt PED management are crucial to reduce SE duration and improve outcomes. Predictive scores can aid in assessment of the severity and prognosis of SE; their utility is still not defined. Identifying and addressing actionable care barriers in SE management pathways is essential to enhance patient outcomes in pediatric SE.",,https://pubmed.ncbi.nlm.nih.gov/39704293/,English,Exclude,Outside date range,Community-onset pediatric status epilepticus: Barriers to care and outcomes in a real-world setting.,,,,,0.95,0.6,
pubmed:39703669,pubmed:39703669,PubMed,pubmed:39703669,A motor imagery classification model based on hybrid brain-computer interface and multitask learning of electroencephalographic and electromyographic deep features.,Yingyu Cao;Shaowei Gao;Huixian Yu;Zhenxi Zhao;Dawei Zang;Chun Wang,2024,10.1109/51.844386,"Extracting deep features from participants' bioelectric signals and constructing models are key research directions in motor imagery (MI) classification tasks. In this study, we constructed a multimodal multitask hybrid brain-computer interface net (2M-hBCINet) based on deep features of electroencephalogram (EEG) and electromyography (EMG) to effectively accomplish motor imagery classification tasks. The model first used a variational autoencoder (VAE) network for unsupervised learning of EEG and EMG signals to extract their deep features, and subsequently applied the channel attention mechanism (CAM) to select these deep features and highlight the advantageous features and minimize the disadvantageous ones. Moreover, in this study, multitask learning (MTL) was applied to train the 2M-hBCINet model, incorporating the primary task that is the MI classification task, and auxiliary tasks including EEG reconstruction task, EMG reconstruction task, and a feature metric learning task, each with distinct loss functions to enhance the performance of each task. Finally, we designed module ablation experiments, multitask learning comparison experiments, multi-frequency band comparison experiments, and muscle fatigue experiments. Using leave-one-out cross-validation(LOOCV), the accuracy and effectiveness of each module of the 2M-hBCINet model were validated using the self-made MI-EEMG dataset and the public datasets WAY-EEG-GAL and ESEMIT. The results indicated that compared to comparative models, the 2M-hBCINet model demonstrated good performance and achieved the best results across different frequency bands and under muscle fatigue conditions. The 2M-hBCINet model constructed based on EMG and EEG data innovatively in this study demonstrated excellent performance and strong generalization in the MI classification task. As an excellent end-to-end model, 2M-hBCINet can be generalized to be used in EEG-related fields such as anomaly detection and emotion analysis.",https://pubmed.ncbi.nlm.nih.gov/39703669/,https://pubmed.ncbi.nlm.nih.gov/39703669/,English,Include,,A motor imagery classification model based on hybrid brain-computer interface and multitask learning of electroencephalographic and electromyographic deep features.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.45,cv_reported;small_sample_mentioned
pubmed:39703101,pubmed:39703101,PubMed,pubmed:39703101,Cognitive Remediation in Patients With Bipolar Disorder: A Randomized Trial by Sequential tDCS and Navigated rTMS Targeting the Primary Visual Cortex.,Hetong Zhou;Minmin Wang;Ting Xu;Xiaomei Zhang;Xudong Zhao;Lili Tang;Pengfei Zhao;Dandan Wang;Jianbo Lai;Fei Wang;Shaomin Zhang;Shaohua Hu,2024,10.1111/cns.70179,"Non-invasive brain stimulation (NIBS), such as transcranial direct current stimulation (tDCS) and repetitive transcranial magnetic stimulation (rTMS), has emerged as a promising alternative in the precise treatment of clinical symptoms, such as the cognitive impairment of bipolar disorder (BD). Optimizing the neurocognitive effects by combining tDCS and rTMS to strengthen the clinical outcome is a challenging research issue. In this randomized, controlled trial, we first combined tDCS and neuronavigated rTMS targeting the V1 region to explore the efficacy on neurocognitive function in BD patients with depressive episodes. Eligible individuals (n = 105) were assigned into three groups, Group A (active tDCS-active rTMS), Group B (sham tDCS-active rTMS), and Group C (active tDCS-sham rTMS). All participants received 3-week treatment in which every participant received 15 sessions of stimulation through the study, 5 sessions every week, with tDCS treatment followed by neuronavigated rTMS every session. We evaluated the cognitive, emotional, and safety outcomes at week-0 (w0, baseline), week-3 (w3, immediately post-treatment), and week-8 (w8, follow-up period). The THINC-integrated tool (THINC-it), 17-item Hamilton Depression Rating Scale, and Young Mania Rating Scale were applied for evaluating the cognitive function and emotional state, respectively. Data were analyzed by repeated measure ANOVA and paired t-test. Eventually, 32 patients in Group A, 27 in Group B, and 23 in Group C completed the entire treatment. Compared to Groups B and C, Group A showed greater improvement in Symbol Check items (Time and Accuracy) at W3 and Symbol Check Accuracy at W8 (p < 0.01). The W0-W3 analysis indicated a significant improvement in depressive symptoms in both Group A and Group B (p < 0.01). Additionally, neuroimaging data revealed increased activity in the calcarine sulcus in Group A, suggesting potential neuroplastic changes in the visual cortex following the electromagnetic stimulation. These findings provide preliminary evidence that the combination of navigated rTMS with tDCS targeting V1 region may serve as a potential treatment strategy for improving cognitive impairment and depressive symptoms in BD patients. Clinical Trial Registry number: NCT05596461.",,https://pubmed.ncbi.nlm.nih.gov/39703101/,English,Exclude,Not EEG-BCI focused,Cognitive Remediation in Patients With Bipolar Disorder: A Randomized Trial by Sequential tDCS and Navigated rTMS Targeting the Primary Visual Cortex.,,,,,0.9,0.8,small_sample_mentioned
pubmed:39700689,pubmed:39700689,PubMed,pubmed:39700689,Multimodal autism detection: Deep hybrid model with improved feature level fusion.,S Vidivelli;P Padmakumari;P Shanthi,2025,10.1016/j.cmpb.2024.108492,"Social communication difficulties are a characteristic of autism spectrum disorder (ASD), a neurodevelopmental condition. The earlier method of diagnosing autism largely relied on error-prone behavioral observation of symptoms. More intelligence approaches are in progress to diagnose the disorder, which still demands improvement in prediction accuracy. Furthermore, computer-aided design systems based on machine learning algorithms are extremely time-consuming and difficult to design. This study used deep learning techniques to develop a novel autism detection model in order to overcome these problems. Preprocessing, Features extraction, Improved Feature level Fusion, and Detection are the phases of the suggested autism detection methodology. First, both input modalities will be preprocessed so they are ready for the next stages to be processed. In this case, the facial picture is preprocessed utilizing the Gabor filtering technique, while the input EEG data is preprocessed through Wiener filtering. Subsequently, features are extracted from the modalities, from the EEG signal data, features like Common Spatial Pattern (CSP), Improved Singular Spectrum Entropy, and correlation dimension, are extracted. From the face image, features like the Improved Active Appearance model, Gray-Level Co-occurrence matrix (GLCM) features and Proposed Shape Local Binary Texture (SLBT), as well are retrieved. Following extraction, enhanced feature-level fusion is performed to fuse the features. Ultimately, the combined features are fed into the hybrid model to complete the diagnosis. Models such as Convolutional Neural Networks (CNN) and Bidirectional Gated Recurrent Units (Bi-GRU) are part of the hybrid model. The suggested MADDHM model achieved an accuracy of about 91.03 % regarding EEG and 91.67 % regarding face analysis meanwhile, SVM=87.49 %, DNN=88.59 %, Bi-GRU=90.02 %, LSTM=87.49 % and CNN=82.02 %. As a result, the suggested methodology provides encouraging outcomes and opens up possibilities for early autism detection. The development of such models is not only a technical achievement but also a step forward in providing timely interventions for individuals with ASD.",,https://pubmed.ncbi.nlm.nih.gov/39700689/,English,Exclude,Outside date range,Multimodal autism detection: Deep hybrid model with improved feature level fusion.,,,,,0.95,0.6,
pubmed:39696383,pubmed:39696383,PubMed,pubmed:39696383,The benefit of inhibitory control training for insomnia with short sleep duration phenotype: a pilot randomized trial.,Haobo Zhang;Zhangwei Lv;Hanfei Chen;Zijie Tang;Xu Lei,2024,10.1186/s12916-024-03813-1,"Two phenotypes of insomnia disorder (ID) have been identified based on objective total sleep duration (TST): one with short sleep duration (ISSD) and another with normal sleep duration (INSD). Recent proposals suggested that insomnia with objective short-sleep duration (TST < 7 h) is associated with impaired inhibitory function, leading to a dysregulation of cortical inhibition, which may underlie its prevalence. This study investigated the status of impaired response inhibition in these two phenotypes and examined the potential different effect of response inhibition training on these two phenotypes. Twenty-two healthy controls (HC) and eighty-one patients with ID were recruited, with IDs further categorized into ISSD and INSD (with TST ≥ 7 h). Clinical behavior measures, including the Pittsburgh Sleep Quality Index (PSQI), Insomnia Severity Index (ISI), Pre-sleep Arousal Scale (PSAS), objective sleep characteristics assessed by all-night sleep electroencephalography, and the accuracy of NoGo trials in the Go/NoGo task were compared among the three groups. Subsequently, within each ID phenotype, participants were divided into training and blank control sub-groups. The two training sub-groups completed Adaptive Go/NoGo training task (Through adaptive difficulty adjustment, the task trains participants' inhibitory control) 15 times over 3 weeks, and all IDs were assessed using sleep-related subjective and objective measures and Go/NoGo task before and after the intervention. ISSD patients exhibited significantly longer sleep latency (p = 0.003) compared to HC, while wakefulness duration (p = 0.004) and light sleep duration (p < 0.001) were shorter than INSD. No significant differences in objective sleep characteristics were observed between INSD and HC. Following adaptive training, the ISSD training sub-group showed decreased scores in PSQI (p = 0.039) and ISI (p = 0.053) compared to their blank control sub-group. In the INSD groups, both training and blank control sub-groups demonstrated reductions in PSQI (p < 0.001), ISI (p < 0.001), and the cognitive arousal sub-dimension of the PSAS scores (p = 0.003) in the post-session test. Impaired response inhibition is a characteristic of ISSD, potentially indicating dysfunctional cortical inhibition, whereas INSD pathogenesis may be related to cognitive-emotional arousal. Response inhibition training effectively alleviates sleep problems in ISSD. These findings provide new insights for developing precise intervention strategies in ID. The study was prospectively registered on May 30, 2024, in Chinese Clinical Trials registry (ChiCTR2400085063).",https://pubmed.ncbi.nlm.nih.gov/39696383/,https://pubmed.ncbi.nlm.nih.gov/39696383/,English,Include,,The benefit of inhibitory control training for insomnia with short sleep duration phenotype: a pilot randomized trial.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39695125,pubmed:39695125,PubMed,pubmed:39695125,A finer-grained high altitude EEG dataset for hypoxia levels assessment.,Yingjun Si;Yu Zhang;Xi Zhang;Sicong Liu;Honghao Zhang;Hui Yang,2024,10.1038/s41597-024-04102-5,"The study reports on a high-altitude EEG dataset comprising 64-channel EEG signals from 23 subjects, aiming at achieving a finer-grained assessment of hypoxia levels. Four hypoxia levels were induced by creating a gradient of oxygen partial pressure through changes in altitude and external hypoxia stimulation. The dataset was collected in a hypoxic chamber that simulates altitude changes, allowing for a refined classification of different hypoxia levels based on ranges of oxygen saturation. The total recorded EEG data amounts to approximately 10.25 hours. Validation results indicate that the four hypoxia levels can be effectively recognized using EEG signals. Compared to binary classification, our fine-grained dataset allows for more precise detection of hypoxia levels. This dataset is anticipated to have significant research and practical value in developing accurate methods for identifying hypoxia levels. As a valuable and standardized resource, it will enable extensive analysis and comparison for researchers in the field of high-altitude hypoxia.",https://pubmed.ncbi.nlm.nih.gov/39695125/,https://pubmed.ncbi.nlm.nih.gov/39695125/,English,Include,,A finer-grained high altitude EEG dataset for hypoxia levels assessment.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39694051,pubmed:39694051,PubMed,pubmed:39694051,Exploring how first- and third-person narrative modulates neural activation during a social cognition task. An event-related potentials (ERPs) study.,Daniela Altavilla;Ines Adornetti;Valentina Deriu;Alessandra Chiera;Francesco Ferretti,2024,10.1080/17470919.2024.2441524,"Several studies showed a positive effect of stories on Theory of Mind (ToM) performance. The aim of the present exploratory study was to investigate whether and how a specific aspect of narrative, i.e., character perspective, modulates the brain activation in response to a ToM task and improve the accuracy. Fifty participants were divided in three groups based on the text assigned: first-person perspective group (1 G; ",,https://pubmed.ncbi.nlm.nih.gov/39694051/,English,Exclude,Not EEG-BCI focused,Exploring how first- and third-person narrative modulates neural activation during a social cognition task. An event-related potentials (ERPs) study.,,,,,0.9,0.8,small_sample_mentioned
pubmed:39693766,pubmed:39693766,PubMed,pubmed:39693766,A method for dynamically adjusting the difficulty of rehabilitation training tasks driven by attention level.,Raojing Chen;Jian Lv;Ligang Qiang;Xiang Liu,2024,10.1088/1741-2552/ada0e9,"Enhancements in the rehabilitation of motor and cognitive functions are significantly attainable through proactive patient engagement. The difficulty of rehabilitation tasks and the environment in which they are conducted directly impact patient motivation. Consequently, this study introduces a dynamic difficulty adjustment method for rehabilitation training tasks based on attention levels, designed to adjust task difficulty in real-time and augment the focus of participants on their training tasks. &#xD;Approach: EEG signals from participants were harnessed to train an attention classification model, enabling the acquisition of real-time attention level signals. Task difficulty levels were adjusted based on the fluctuating attention levels. A cohort of 30 participants was engaged to evaluate: (1) the impact on engagement when attention levels are utilized as dynamic difficulty 18 triggers; (2) the influence of various task environments on concentration. The experiment was assessed through EEG signals and questionnaire data, with frequency domain analysis conducted on EEG signals to calculate concentration values and statistical analysis performed on additional data. &#xD;Main Results: The findings reveal that within an identical virtual reality (VR) environment, leveraging attention levels as triggers for difficulty adjustment markedly improves participants' task concentration. Compared to 2D environments, VR environments substantially enhance participants' sense of immersion, interest, and flow state, albeit with increased physical exertion during training. The integration of VR and attention level feedback is deemed the most effective strategy. &#xD;Significance: These exploratory insights indicate that the proposed method paves a novel path for boosting patient engagement in rehabilitation. Immersive rehabilitation training, driven by attention levels, promises a more effective and captivating patient experience. This study advances the field by offering data-driven, personalized rehabilitation approaches, potentially culminating in superior patient outcomes and enhanced quality of life.",https://pubmed.ncbi.nlm.nih.gov/39693766/,https://pubmed.ncbi.nlm.nih.gov/39693766/,English,Include,,A method for dynamically adjusting the difficulty of rehabilitation training tasks driven by attention level.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39693763,pubmed:39693763,PubMed,pubmed:39693763,Multi-dimensional hybrid bilinear CNN-LSTM models for epileptic seizure detection and prediction using EEG signals.,Shan Liu;Jiang Wang;Shanshan Li;Lihui Cai,2024,10.1088/1741-2552/ada0e5,"Automatic detection and prediction of epilepsy are crucial for improving patient care and quality of life. However, existing methods typically focus on single-dimensional information and often confuse the periodic and aperiodic components in electrophysiological signals. We propose a novel deep learning framework that integrates temporal, spatial, and frequency information of EEG signals, in which periodic and aperiodic components are separated in the frequency domain. Specifically, we calculated the periodic and aperiodic components in single channel and the synchronization index of each component between channels. A self-attention mechanism is employed to filter single-channel features by selectively focusing on the most distinguishing features. Then, a hybrid bilinear deep learning network is utilized to capture the spatiotemporal features by combining a convolutional neural network (CNN) and a long short-term memory (LSTM) network. Finally, a bilinear pooling layer is employed to extract second-order features based on interactions between these spatiotemporal features. The model achieves exceptional performance，with a detection accuracy of 98.84% on the CHB-MIT dataset, and a prediction accuracy of 98.44% on CHB-MIT and 97.65% on the Kaggle dataset, both with an false positive rate (FPR) of 0.02. This work paves the way for developing real-time, wearable epilepsy prediction devices to improve patient care.",https://pubmed.ncbi.nlm.nih.gov/39693763/,https://pubmed.ncbi.nlm.nih.gov/39693763/,English,Include,,Multi-dimensional hybrid bilinear CNN-LSTM models for epileptic seizure detection and prediction using EEG signals.,Include,,"Finally, a bilinear pooling layer is employed to extract second-order features based on interactions between these spatiotemporal features. The model achieves exceptional performance，with a detection accuracy of 98.84% on the CHB-MIT dataset, and a prediction accuracy of 98.44% on CHB-MIT and 97.65% on the Kaggle dataset, both with an false positive rate (FPR) of 0.02. This work paves the way for ",,0.95,0.6,
pubmed:39693734,pubmed:39693734,PubMed,pubmed:39693734,"Simultaneous encoding of speed, distance, and direction in discrete reaching: an EEG study.",Nitikorn Srisrisawang;Gernot R Müller-Putz,2024,10.1088/1741-2552/ada0ea,,,https://pubmed.ncbi.nlm.nih.gov/39693734/,English,Exclude,Not classification-focused,"Simultaneous encoding of speed, distance, and direction in discrete reaching: an EEG study.",,,,,0.85,0.6,
pubmed:39693131,pubmed:39693131,PubMed,pubmed:39693131,The Effect of Left Temporal EEG Neurofeedback Training on Cerebral Cortical Activity and Precision Cognitive-Motor Performance.,Li-Chuan Lo;Bradley D Hatfield;Kiersten Janjigian;Yung-Shun Wang;Dong-Yang Fong;Tsung-Min Hung,2025,10.1080/02701367.2024.2441149,,,https://pubmed.ncbi.nlm.nih.gov/39693131/,English,Exclude,Outside date range,The Effect of Left Temporal EEG Neurofeedback Training on Cerebral Cortical Activity and Precision Cognitive-Motor Performance.,,,,,0.95,0.6,
pubmed:39692757,pubmed:39692757,PubMed,pubmed:39692757,Brain-Computer Interfaces Using Flexible Electronics: An a-IGZO Front-End for Active ECoG Electrodes.,Kyle van Oosterhout;Ashley Chilundo;Mariana P Branco;Erik J Aarnoutse;Martijn Timmermans;Marco Fattori;Nick F Ramsey;Eugenio Cantatore,2025,10.1002/advs.202408576,"Brain-computer interfaces (BCIs) are evolving toward higher electrode count and fully implantable solutions, which require extremely low power densities (<15mW cm",,https://pubmed.ncbi.nlm.nih.gov/39692757/,English,Exclude,Outside date range,Brain-Computer Interfaces Using Flexible Electronics: An a-IGZO Front-End for Active ECoG Electrodes.,,,,,0.95,0.6,
pubmed:39691819,pubmed:39691819,PubMed,pubmed:39691819,EEG-based action anticipation in human-robot interaction: a comparative pilot study.,Rodrigo Vieira;Plinio Moreno;Athanasios Vourvopoulos,2024,10.1109/tbme.2013.2294203,"As robots become integral to various sectors, improving human-robot collaboration is crucial, particularly in anticipating human actions to enhance safety and efficiency. Electroencephalographic (EEG) signals offer a promising solution, as they can detect brain activity preceding movement by over a second, enabling predictive capabilities in robots. This study explores how EEG can be used for action anticipation in human-robot interaction (HRI), leveraging its high temporal resolution and modern deep learning techniques. We evaluated multiple Deep Learning classification models on a motor imagery (MI) dataset, achieving up to 80.90% accuracy. These results were further validated in a pilot experiment, where actions were accurately predicted several hundred milliseconds before execution. This research demonstrates the potential of combining EEG with deep learning to enhance real-time collaborative tasks, paving the way for safer and more efficient human-robot interactions.",https://pubmed.ncbi.nlm.nih.gov/39691819/,https://pubmed.ncbi.nlm.nih.gov/39691819/,English,Include,,EEG-based action anticipation in human-robot interaction: a comparative pilot study.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39691581,pubmed:39691581,PubMed,pubmed:39691581,Explainable fNIRS-based pain decoding under pharmacological conditions via deep transfer learning approach.,Aykut Eken;Murat Yüce;Gülnaz Yükselen;Sinem Burcu Erdoğan,2024,10.1016/j.aca.2012.11.007,"Assessment of pain and its clinical diagnosis rely on subjective methods which become even more complicated under analgesic drug administrations. We aim to propose a deep learning (DL)-based transfer learning (TL) methodology for objective classification of functional near-infrared spectroscopy (fNIRS)-derived cortical oxygenated hemoglobin responses to painful and non-painful stimuli presented under different timings post-analgesic and placebo drug administration. A publicly available fNIRS dataset obtained during painful/non-painful stimuli was used. Separate fNIRS scans were taken under the same protocol before drug (morphine and placebo) administration and at three different timings (30, 60, and 90 min) post-administration. Data from pre-drug fNIRS scans were utilized for constructing a base DL model. Knowledge generated from the pre-drug model was transferred to six distinct post-drug conditions by following a TL approach. The DeepSHAP method was utilized to unveil the contribution weights of nine regions of interest for each of the pre-drug and post-drug decoding models. Accuracy, sensitivity, specificity, and area under curve (AUC) metrics of the pre-drug model were above 90%, whereas each of the post-drug models demonstrated a performance above 90% for the same metrics. Post-placebo models had higher decoding accuracy than post-morphine models. Knowledge obtained from a pre-drug base model could be successfully utilized to build pain decoding models for six distinct brain states that were scanned at three different timings after either analgesic or placebo drug administration. The contribution of different cortical regions to classification performance varied across the post-drug models. The proposed DL-based TL methodology may remove the necessity to build DL models for data collected at clinical or daily life conditions for which obtaining training data is not practical or building a new decoding model will have a computational cost. Unveiling the explanation power of different cortical regions may aid the design of more computationally efficient fNIRS-based brain-computer interface (BCI) system designs that target other application areas.",https://pubmed.ncbi.nlm.nih.gov/39691581/,https://pubmed.ncbi.nlm.nih.gov/39691581/,English,Include,,Explainable fNIRS-based pain decoding under pharmacological conditions via deep transfer learning approach.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39686227,pubmed:39686227,PubMed,pubmed:39686227,An Empirical Model-Based Algorithm for Removing Motion-Caused Artifacts in Motor Imagery EEG Data for Classification Using an Optimized CNN Model.,Rajesh Kannan Megalingam;Kariparambil Sudheesh Sankardas;Sakthiprasad Kuttankulangara Manoharan,2024,10.1109/access.2019.2939623,"Electroencephalography (EEG) is a non-invasive technique with high temporal resolution and cost-effective, portable, and easy-to-use features. Motor imagery EEG (MI-EEG) data classification is one of the key applications within brain-computer interface (BCI) systems, utilizing EEG signals from motor imagery tasks. BCI is very useful for people with severe mobility issues like quadriplegics, spinal cord injury patients, stroke patients, etc., giving them the freedom to a certain extent to perform activities without the need for a caretaker, like driving a wheelchair. However, motion artifacts can significantly affect the quality of EEG recordings. The conventional EEG enhancement algorithms are effective in removing ocular and muscle artifacts for a stationary subject but not as effective when the subject is in motion, e.g., a wheelchair user. In this research study, we propose an empirical error model-based artifact removal approach for the cross-subject classification of motor imagery (MI) EEG data using a modified CNN-based deep learning algorithm, designed to assist wheelchair users with severe mobility issues. The classification method applies to real tasks with measured EEG data, focusing on accurately interpreting motor imagery signals for practical application. The empirical error model evolved from the inertial sensor-based acceleration data of the subject in motion, the weight of the wheelchair, the weight of the subject, and the surface friction of the terrain under the wheelchair. Three different wheelchairs and five different terrains, including road, brick, concrete, carpet, and marble, are used for artifact data recording. After evaluating and benchmarking the proposed CNN and empirical model, the classification accuracy achieved is 94.04% for distinguishing between four specific classes: left, right, front, and back. This accuracy demonstrates the model's effectiveness compared to other state-of-the-art techniques. The comparative results show that the proposed approach is a potentially effective way to raise the decoding efficiency of motor imagery BCI.",https://pubmed.ncbi.nlm.nih.gov/39686227/,https://pubmed.ncbi.nlm.nih.gov/39686227/,English,Include,,An Empirical Model-Based Algorithm for Removing Motion-Caused Artifacts in Motor Imagery EEG Data for Classification Using an Optimized CNN Model.,Include,,"fferent terrains, including road, brick, concrete, carpet, and marble, are used for artifact data recording. After evaluating and benchmarking the proposed CNN and empirical model, the classification accuracy achieved is 94.04% for distinguishing between four specific classes: left, right, front, and back. This accuracy demonstrates the model's effectiveness compared to other state-of-the-art tech",,0.95,0.6,
pubmed:39686148,pubmed:39686148,PubMed,pubmed:39686148,MACNet: A Multidimensional Attention-Based Convolutional Neural Network for Lower-Limb Motor Imagery Classification.,Ling-Long Li;Guang-Zhong Cao;Yue-Peng Zhang;Wan-Chen Li;Fang Cui,2024,10.1109/tcyb.2024.3390805,"Decoding lower-limb motor imagery (MI) is highly important in brain-computer interfaces (BCIs) and rehabilitation engineering. However, it is challenging to classify lower-limb MI from electroencephalogram (EEG) signals, because lower-limb motions (LLMs) including MI are excessively close to physiological representations in the human brain and generate low-quality EEG signals. To address this challenge, this paper proposes a multidimensional attention-based convolutional neural network (CNN), termed MACNet, which is specifically designed for lower-limb MI classification. MACNet integrates a temporal refining module and an attention-enhanced convolutional module by leveraging the local and global feature representation abilities of CNNs and attention mechanisms. The temporal refining module adaptively investigates critical information from each electrode channel to refine EEG signals along the temporal dimension. The attention-enhanced convolutional module extracts temporal and spatial features while refining the feature maps across the channel and spatial dimensions. Owing to the scarcity of public datasets available for lower-limb MI, a specified lower-limb MI dataset involving four routine LLMs is built, consisting of 10 subjects over 20 sessions. Comparison experiments and ablation studies are conducted on this dataset and a public BCI Competition IV 2a EEG dataset. The experimental results show that MACNet achieves state-of-the-art performance and outperforms alternative models for the subject-specific mode. Visualization analysis reveals the excellent feature learning capabilities of MACNet and the potential relationship between lower-limb MI and brain activity. The effectiveness and generalizability of MACNet are verified.",https://pubmed.ncbi.nlm.nih.gov/39686148/,https://pubmed.ncbi.nlm.nih.gov/39686148/,English,Include,,MACNet: A Multidimensional Attention-Based Convolutional Neural Network for Lower-Limb Motor Imagery Classification.,Exclude,No performance metrics reported,No metrics found in full text,,0.9,0.6,
pubmed:39686066,pubmed:39686066,PubMed,pubmed:39686066,An Identification Method for Road Hypnosis Based on the Fusion of Human Life Parameters.,Bin Wang;Jingheng Wang;Xiaoyuan Wang;Longfei Chen;Chenyang Jiao;Han Zhang;Yi Liu,2024,10.1016/j.patrec.2007.10.002,"A driver in road hypnosis has two different types of characteristics. One is the external characteristics, which are distinct and can be directly observed. The other is internal characteristics, which are indistinctive and cannot be directly observed. The eye movement characteristic, as a distinct external characteristic, is one of the typical characteristics of road hypnosis identification. The electroencephalogram (EEG) characteristic, as an internal feature, is a golden parameter of drivers' life identification. This paper proposes an identification method for road hypnosis based on the fusion of human life parameters. Eye movement data and EEG data are collected through vehicle driving experiments and virtual driving experiments. The collected data are preprocessed with principal component analysis (PCA) and independent component analysis (ICA), respectively. Eye movement data can be trained with a self-attention model (SAM), and the EEG data can be trained with the deep belief network (DBN). The road hypnosis identification model can be constructed by combining the two trained models with the stacking method. Repeated Random Subsampling Cross-Validation (RRSCV) is used to validate models. The results show that road hypnosis can be effectively recognized using the constructed model. This study is of great significance to reveal the essential characteristics and mechanisms of road hypnosis. The effectiveness and accuracy of road hypnosis identification can also be improved through this study.",https://pubmed.ncbi.nlm.nih.gov/39686066/,https://pubmed.ncbi.nlm.nih.gov/39686066/,English,Include,,An Identification Method for Road Hypnosis Based on the Fusion of Human Life Parameters.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.25,cv_reported
pubmed:39686027,pubmed:39686027,PubMed,pubmed:39686027,A Closed-Loop Ear-Worn Wearable EEG System with Real-Time Passive Electrode Skin Impedance Measurement for Early Autism Detection.,Muhammad Sheeraz;Abdul Rehman Aslam;Emmanuel Mic Drakakis;Hadi Heidari;Muhammad Awais Bin Altaf;Wala Saadeh,2024,10.1016/j.snb.2018.08.155,"Autism spectrum disorder (ASD) is a chronic neurological disorder with the severity directly linked to the diagnosis age. The severity can be reduced if diagnosis and intervention are early (age < 2 years). This work presents a novel ear-worn wearable EEG system designed to aid in the early detection of ASD. Conventional EEG systems often suffer from bulky, wired electrodes, high power consumption, and a lack of real-time electrode-skin interface (ESI) impedance monitoring. To address these limitations, our system incorporates continuous, long-term EEG recording, on-chip machine learning for real-time ASD prediction, and a passive ESI evaluation system. The passive ESI methodology evaluates impedance using the root mean square voltage of the output signal, considering factors like pressure, electrode surface area, material, gel thickness, and duration. The on-chip machine learning processor, implemented in 180 nm CMOS, occupies a minimal 2.52 mm² of active area while consuming only 0.87 µJ of energy per classification. The performance of this ML processor is validated using the Old Dominion University ASD dataset.",https://pubmed.ncbi.nlm.nih.gov/39686027/,https://pubmed.ncbi.nlm.nih.gov/39686027/,English,Include,,A Closed-Loop Ear-Worn Wearable EEG System with Real-Time Passive Electrode Skin Impedance Measurement for Early Autism Detection.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39682605,pubmed:39682605,PubMed,pubmed:39682605,Schizophrenia Detection and Classification: A Systematic Review of the Last Decade.,Arghyasree Saha;Seungmin Park;Zong Woo Geem;Pawan Kumar Singh,2024,10.1007/s11042-020-09183-z,"Artificial Intelligence (AI) in healthcare employs advanced algorithms to analyze complex and large-scale datasets, mimicking aspects of human cognition. By automating decision-making processes based on predefined thresholds, AI enhances the accuracy and reliability of healthcare data analysis, reducing the need for human intervention. Schizophrenia (SZ), a chronic mental health disorder affecting millions globally, is characterized by symptoms such as auditory hallucinations, paranoia, and disruptions in thought, behavior, and perception. The SZ symptoms can significantly impair daily functioning, underscoring the need for advanced diagnostic tools. This systematic review has been conducted following the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) 2020 guidelines and examines peer-reviewed studies from the last decade (2015-2024) on AI applications in SZ detection as well as classification. The review protocol has been registered in the International Prospective Register of Systematic Reviews (PROSPERO) under registration number: CRD42024612364. Research has been sourced from multiple databases and screened using predefined inclusion criteria. The review evaluates the use of both Machine Learning (ML) and Deep Learning (DL) methods across multiple modalities, including Electroencephalography (EEG), Structural Magnetic Resonance Imaging (sMRI), and Functional Magnetic Resonance Imaging (fMRI). The key aspects reviewed include datasets, preprocessing techniques, and AI models. The review identifies significant advancements in AI methods for SZ diagnosis, particularly in the efficacy of ML and DL models for feature extraction, classification, and multi-modal data integration. It highlights state-of-the-art AI techniques and synthesizes insights into their potential to improve diagnostic outcomes. Additionally, the analysis underscores common challenges, including dataset limitations, variability in preprocessing approaches, and the need for more interpretable models. This study provides a comprehensive evaluation of AI-based methods in SZ prognosis, emphasizing the strengths and limitations of current approaches. By identifying unresolved gaps, it offers valuable directions for future research in the application of AI for SZ detection and diagnosis.",,https://pubmed.ncbi.nlm.nih.gov/39682605/,English,Exclude,Review/survey papers,Schizophrenia Detection and Classification: A Systematic Review of the Last Decade.,,,,,0.95,0.6,
pubmed:39682574,pubmed:39682574,PubMed,pubmed:39682574;pubmed:39516226,ChMinMaxPat: Investigations on Violence and Stress Detection Using EEG Signals.,Omer Bektas;Serkan Kirik;Irem Tasci;Rena Hajiyeva;Emrah Aydemir;Sengul Dogan;Turker Tuncer,2024,10.1038/s41598-024-78222-8,"Electroencephalography (EEG) signals, often termed the letters of the brain, are one of the most cost-effective methods for gathering valuable information about brain activity. This study presents a new explainable feature engineering (XFE) model designed to classify EEG data for violence detection. The primary objective is to assess the classification capability of the proposed XFE model, which uses a next-generation feature extractor, and to obtain interpretable findings for EEG-based violence and stress detection. In this research, two distinct EEG signal datasets were used to obtain classification and explainable results. The recommended XFE model utilizes a channel-based minimum and maximum pattern (ChMinMaxPat) feature extraction function, which generates 15 distinct feature vectors from EEG data. Cumulative weight-based neighborhood component analysis (CWNCA) is employed to select the most informative features from these vectors. Classification is performed by applying an iterative and ensemble t-algorithm-based k-nearest neighbors (tkNN) classifier to each feature vector. Information fusion is achieved through iterative majority voting (IMV), which consolidates the 15 tkNN classification results. Finally, the Directed Lobish (DLob) symbolic language generates interpretable outputs by leveraging the identities of the selected features. Together, the tkNN classifier, IMV-based information fusion, and DLob-based explainable feature extraction transform the model into a self-organizing explainable feature engineering (SOXFE) framework. The ChMinMaxPat-based model achieved over 70% accuracy on both datasets with leave-one-record-out (LORO) cross-validation (CV) and over 90% accuracy with 10-fold CV. For each dataset, 15 DLob strings were generated, providing explainable outputs based on these symbolic representations. The ChMinMaxPat-based SOXFE model demonstrates high classification accuracy and interpretability in detecting violence and stress from EEG signals. This model contributes to both feature engineering and neuroscience by enabling explainable EEG classification, underscoring the potential importance of EEG analysis in clinical and forensic applications.",https://pubmed.ncbi.nlm.nih.gov/39682574/,https://pubmed.ncbi.nlm.nih.gov/39682574/,English,Include,,ChMinMaxPat: Investigations on Violence and Stress Detection Using EEG Signals.,Exclude,Duplicate study,Duplicate group,,0.99,0.25,cv_reported
pubmed:39682565,pubmed:39682565,PubMed,pubmed:39682565,SLA-MLP: Enhancing Sleep Stage Analysis from EEG Signals Using Multilayer Perceptron Networks.,Farah Mohammad;Khulood Mohammed Al Mansoor,2024,10.1016/j.bspc.2023.105631,,,https://pubmed.ncbi.nlm.nih.gov/39682565/,English,Exclude,Not classification-focused,SLA-MLP: Enhancing Sleep Stage Analysis from EEG Signals Using Multilayer Perceptron Networks.,,,,,0.85,0.6,
pubmed:39681925,pubmed:39681925,PubMed,pubmed:39681925,Development and application of the Demands for Population Health Interventions (Depth) framework for categorising the agentic demands of population health interventions.,Kate Garrott;David Ogilvie;Jenna Panter;Mark Petticrew;Amanda Sowden;Catrin P Jones;Campbell Foubister;Emma R Lawlor;Erika Ikeda;Richard Patterson;Dolly van Tulleken;Roxanne Armstrong-Moore;Gokulan Vethanayakam;Lorna Bo;Martin White;Jean Adams,2024,10.1186/s44263-024-00043-8,"The 'agentic demand' of population health interventions (PHIs) refers to the capacity, resources and freedom to act that interventions demand of their recipients to benefit, which have a socio-economical pattern. Highly agentic interventions, e.g. information campaigns, rely on recipients noticing and responding to the intervention and thus might affect intervention effectiveness and equity. The absence of an adequate framework to classify agentic demands limits the fields' ability to systematically explore these associations. We systematically developed the Demands for Population Health Interventions (Depth) framework using an iterative approach: (1) developing the Depth framework by systematically identifying examples of PHIs aiming to promote healthier diets and physical activity, coding of intervention actors and actions and synthesising the data to develop the framework; (2) testing the Depth framework in online workshops with academic and policy experts and a quantitative reliability assessment. We applied the final framework in a proof-of-concept review, extracting studies from three existing equity-focused systematic reviews on framework category, overall effectiveness and differential socioeconomic effects and visualised the findings in harvest plots. The Depth framework identifies three constructs influencing agentic demand: exposure - initial contact with intervention (two levels), mechanism of action - how the intervention enables or discourages behaviour (five levels) and engagement - recipient response (two levels). When combined, these constructs form a matrix of 20 possible classifications. In the proof-of-concept review, we classified all components of 31 interventions according to the Depth framework. Intervention components were concentrated in a small number of Depth classifications; Depth classification appeared to be related to intervention equity but not effectiveness. This framework holds potential for future research, policy and practice, facilitating the design, selection and evaluation of interventions and evidence synthesis.",,https://pubmed.ncbi.nlm.nih.gov/39681925/,English,Exclude,Review/survey papers,Development and application of the Demands for Population Health Interventions (Depth) framework for categorising the agentic demands of population health interventions.,,,,,0.95,0.6,
pubmed:39680203,pubmed:39680203,PubMed,pubmed:39680203,Recognition memory decline is associated with the progression to prodromal Alzheimer's disease in asymptomatic at-risk individuals.,Filipa Raposo Pereira;Maximilien Chaumon;Bruno Dubois;Hovagim Bakardjian;Mahsa Bahrami;Marie-Odile Habert;Katia Andrade;Nadjia Younsi;Valentina La Corte;Nathalie George,2024,10.1111/1469-8986.3720127,"Episodic memory (EM) alterations are a hallmark of Alzheimer's disease (AD). We assessed EM longitudinally in cognitively normal elders at-risk for AD (with subjective memory complaints), as a function of amyloid-β (Aβ) burden, neurodegeneration (N), and progression to prodromal AD. We stratified 264 INSIGHT-preAD study subjects in controls (Aβ-/N-), stable/N- or N + (Aβ +), and progressors/N- or N + (Aβ +) groups (progressors were included only until AD-diagnosis). We used linear mixed-effect models with Aβ and N status, or progression to AD as factors, to analyze behavioral performance in an old/new word-recognition task based on the free and cued selective reminding test (FCSRT). The controls and stable/N- groups showed near-ceiling accuracy and RT improvement across follow-up. The stable/N + group showed accuracy reduction and no RT improvement, i.e., Aβ + /N + cumulative effect. The progressors showed a marked performance decline. EM alterations may constitute early preclinical markers of progression to prodromal AD, while individuals are cognitively normal according to neuropsychological standards.",,https://pubmed.ncbi.nlm.nih.gov/39680203/,English,Exclude,Not EEG-BCI focused,Recognition memory decline is associated with the progression to prodromal Alzheimer's disease in asymptomatic at-risk individuals.,,,,,0.9,0.6,
pubmed:39678727,pubmed:39678727,PubMed,pubmed:39678727,The design and implementation of multi-character classification scheme based on EEG signals of visual imagery.,Hongguang Pan;Wei Song;Li Li;Xuebin Qin,2024,10.1007/s11571-024-10087-z,"In visual-imagery-based brain-computer interface (VI-BCI), there are problems of singleness of imagination task and insufficient description of feature information, which seriously hinder the development and application of VI-BCI technology in the field of restoring communication. In this paper, we design and optimize a multi-character classification scheme based on electroencephalogram (EEG) signals of visual imagery (VI), which is used to classify 29 characters including 26 lowercase English letters and three punctuation marks. Firstly, a new paradigm of randomly presenting characters and including preparation stage is designed to acquire EEG signals and construct a multi-character dataset, which can eliminate the influence between VI tasks. Secondly, tensor data is obtained by the Morlet wavelet transform, and a feature extraction algorithm based on tensor-uncorrelated multilinear principal component analysis is used to extract high-quality features. Finally, three classifiers, namely support vector machine, K-nearest neighbor, and extreme learning machine, are employed for classifying multi-character, and the results are compared. The experimental results demonstrate that, the proposed scheme effectively extracts character features with minimal redundancy, weak correlation, and strong representation capability, and successfully achieves an average classification accuracy 97.59% for 29 characters, surpassing existing research in terms of both accuracy and quantity of classification. The present study designs a new paradigm for acquiring EEG signals of VI, and combines the Morlet wavelet transform and UMPCA algorithm to extract the character features, enabling multi-character classification in various classifiers. This research paves a novel pathway for establishing direct brain-to-world communication.",https://pubmed.ncbi.nlm.nih.gov/39678727/,https://pubmed.ncbi.nlm.nih.gov/39678727/,English,Include,,The design and implementation of multi-character classification scheme based on EEG signals of visual imagery.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39678725,pubmed:39678725,PubMed,pubmed:39678725,An improved CapsNet based on data augmentation for driver vigilance estimation with forehead single-channel EEG.,Huizhou Yang;Jingwen Huang;Yifei Yu;Zhigang Sun;Shouyi Zhang;Yunfei Liu;Han Liu;Lijuan Xia,2024,10.1007/s11571-024-10105-0,"Various studies have shown that it is necessary to estimate the drivers' vigilance to reduce the occurrence of traffic accidents. Most existing EEG-based vigilance estimation studies have been performed on intra-subject and multi-channel signals, and these methods are too costly and complicated to implement in practice. Hence, aiming at the problem of cross-subject vigilance estimation of single-channel EEG signals, an estimation algorithm based on capsule network (CapsNet) is proposed. Firstly, we propose a new construction method of the input feature maps to fit the characteristics of CapsNet to improve the algorithm accuracy. Meanwhile, the self-attention mechanism is incorporated in the algorithm to focus on the key information in feature maps. Secondly, we propose substituting the traditional multi-channel signals with the single-channel signals to improve the utility of algorithm. Thirdly, since the single-channel signals carry fewer dimensions of the information compared to the multi-channel signals, we use the conditional generative adversarial network to improve the accuracy of single-channel signals by increasing the amount of data. The proposed algorithm is verified on the SEED-VIG, and Root-mean-square-error (RMSE) and Pearson Correlation Coefficient (PCC) are used as the evaluation metrics. The results show that the proposed algorithm improves the computing speed while the RMSE is reduced by 3%, and the PCC is improved by 12% compared to the mainstream algorithm. Experiment results prove the feasibility of using forehead single-channel EEG signals for cross-subject vigilance estimation and offering the possibility of lightweight EEG vigilance estimation devices for practical applications.",https://pubmed.ncbi.nlm.nih.gov/39678725/,https://pubmed.ncbi.nlm.nih.gov/39678725/,English,Include,,An improved CapsNet based on data augmentation for driver vigilance estimation with forehead single-channel EEG.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39678724,pubmed:39678724,PubMed,pubmed:39678724,SST-CRAM: spatial-spectral-temporal based convolutional recurrent neural network with lightweight attention mechanism for EEG emotion recognition.,Yingxiao Qiao;Qian Zhao,2024,10.1007/s11571-024-10114-z,"Through emotion recognition with EEG signals, brain responses can be analyzed to monitor and identify individual emotional states. The success of emotion recognition relies on comprehensive emotion information extracted from EEG signals and the constructed emotion identification model. In this work, we proposed an innovative approach, called spatial-spectral-temporal-based convolutional recurrent neural network (CRNN) with lightweight attention mechanism (SST-CRAM). Firstly, we combined power spectral density (PSD) with differential entropy (DE) features to construct four-dimensional (4D) EEG feature maps and obtain more spatial, spectral, and temporal information. Additional, with a spatial interpolation algorithm, the utilization of the obtained valuable information was enhanced. Next, the constructed 4D EEG feature map was input into the convolutional neural network (CNN) integrated with convolutional block attention module (CBAM) and efficient channel attention module (ECA-Net) for extracting spatial and spectral features. CNN was used to learn spatial and spectral information and CBAM was employed to prioritize global information and obtain detailed and accurate features. ECA-Net was also used to further highlight key brain regions and frequency bands. Finally, a bidirectional long short-term memory (LSTM) network was used to explore the temporal correlation of EEG feature maps for comprehensive feature extraction. To assess the performance of our model, we tested it on the publicly available DEAP dataset. Our model demonstrated excellent performance and achieved high accuracy (98.63% for arousal classification and 98.66% for valence classification). These results indicated that SST-CRAM could fully utilize spatial, spectral, and temporal information to improve the emotion recognition performance.",https://pubmed.ncbi.nlm.nih.gov/39678724/,https://pubmed.ncbi.nlm.nih.gov/39678724/,English,Include,,SST-CRAM: spatial-spectral-temporal based convolutional recurrent neural network with lightweight attention mechanism for EEG emotion recognition.,Include,," maps for comprehensive feature extraction. To assess the performance of our model, we tested it on the publicly available DEAP dataset. Our model demonstrated excellent performance and achieved high accuracy (98.63% for arousal classification and 98.66% for valence classification). These results indicated that SST-CRAM could fully utilize spatial, spectral, and temporal information to improve the",,0.95,0.6,
pubmed:39677824,pubmed:39677824,PubMed,pubmed:39677824,Impaired Attention in Children with Obstructive Sleep Apnea: A Preliminary Study of Behavior Combined with Neuroelectrophysiology.,Yunxiao Wu;Changming Wang;Yingchao Jiang;Ya Zhang;Li Zheng;Xiao-Lin Ning;Zhifei Xu,2024,10.1046/j.1365-2869.2002.00289.x,"To investigate how attention is affected in children with obstructive sleep apnea (OSA) using the attention network test (ANT) combined with event-related potential (ERP) and time-frequency analysis. Eighty-seven children aged 6-11 years with symptoms of snoring or mouth breathing during sleep were recruited from the Sleep Center of Beijing Children's Hospital from May to July, 2023. All participants completed the Mini-mental State Examination and Attention Deficit Hyperactivity Disorder rating scale. We acquired 32-lead electroencephalography (EEG) data while participants performed the ANT, followed by Polysomnography. Of the 87 children, 21 had no OSA, 49 had mild OSA, and 17 had moderate to severe (MS) OSA. Each group had similar questionnaire scores, similar response time and accuracy for the different ANT conditions. There are alterations in the processing of three separate components of the attentional network in children with OSA. The amplitude of the N3 component at the F Attention impairment was observed as a reduced N3 in the frontal area in the MS OSA group, which was correlated with the OAHI. However, questionnaire and behavioral performance did not differ significantly between groups. These findings suggest that the N3 amplitude is a sensitive neuroelectrophysiological marker of OSA-related cognitive impairment.",https://pubmed.ncbi.nlm.nih.gov/39677824/,https://pubmed.ncbi.nlm.nih.gov/39677824/,English,Include,,Impaired Attention in Children with Obstructive Sleep Apnea: A Preliminary Study of Behavior Combined with Neuroelectrophysiology.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39676578,pubmed:39676578,PubMed,pubmed:39676578,The interaction between luminance polarity grouping and symmetry axes on the ERP responses to symmetry.,Benjamin Dering;Damien Wright;Elena Gheorghiu,2024,10.1111/nyas.13667,"Symmetry is a salient visual feature in the natural world, yet the perception of symmetry may be influenced by how natural lighting conditions (e.g., shading) fall on the object relative to its symmetry axis. Here, we investigate how symmetry detection may interact with luminance polarity grouping, and whether this modulates neural responses to symmetry, as evidenced by the Sustained Posterior Negativity (SPN) component of Event-Related Potentials (ERPs). Stimuli were dot patterns arranged either symmetrically (reflection, rotation, translation) or quasi-randomly, and by luminance polarity about a grouping axis (i.e., black dots on one side and white dots on the other). We varied the relative angular separation between the symmetry and polarity-grouping axes: 0, 30, 60, 90 deg. Participants performed a two interval-forced-choice (2IFC) task indicating which interval contained the symmetrical pattern. We found that accuracy for the 0 deg polarity-grouped condition was higher compared to the single-polarity condition for rotation and translation (but not reflection symmetry), and higher than all other angular difference (30, 60, 90) conditions for all symmetry types. The SPN was found to be separated topographically into an early and late component, with the early SPN being sensitive to luminance polarity grouping at parietal-occipital electrodes, and the late SPN sensitive to symmetry over central electrodes. The increase in relative angular differences between luminance polarity and symmetry axes highlighted changes between cardinal (0, 90 deg) and other (30, 60 deg) angles. Critically, we found a polarity-grouping effect in the SPN time window for noise only patterns, which was related to symmetry type, suggesting a task/ symmetry pattern influence on SPN processes. We conclude that luminance polarity grouping can facilitate symmetry perception when symmetry is not readily salient, as evidenced by polarity sensitivity of early SPN, yet it can also inhibit neural and behavioral responses when luminance polarity and symmetry axes are not aligned.",,https://pubmed.ncbi.nlm.nih.gov/39676578/,English,Exclude,Not EEG-BCI focused,The interaction between luminance polarity grouping and symmetry axes on the ERP responses to symmetry.,,,,,0.9,0.8,small_sample_mentioned
pubmed:39673992,pubmed:39673992,PubMed,pubmed:39673992,How accurate are machine learning models in predicting anti-seizure medication responses: A systematic review.,Ahmed Abdaltawab;Lin-Ching Chang;Mohammed Mansour;Mohamad Koubeissi,2025,10.1016/j.yebeh.2024.110212,"Current epilepsy management protocols often depend on anti-seizure medication (ASM) trials and assessment of clinical response. This may delay the initiation of the ASM regimen that might optimally balance efficacy and tolerability for individual patients. Machine learning (ML) can offer a promising tool for efficiently predicting ASM response. The objective of this review is to synthesize the available information about the effectiveness and limitations of ML models in predicting and classifying the response of patients with epilepsy to ASMs, and to assess the impact of various data inputs on prediction performance. We conducted a comprehensive search of studies utilizing ML models for ASM response prediction using PubMed and Scopus up until November 2024. The review included 37 studies. Various data types, including clinical information, brain MRI, EEG, and genetic data, are useful in predicting responses to ASMs. Tree-based ML algorithms and Support Vector Machines are the most used models. Reported results vary widely, with certain models achieving near-perfect accuracy and others performing similar to random classifiers. The review also highlights the limitations of this research field, especially concerning the quality and quantity of data. The findings indicate that while ML models show great promise in predicting ASM responses in epilepsy, further research is required to refine these models for practical clinical application. The review underscores both the potential of ML in advancing precision medicine in epilepsy management and the need for continued research to improve prediction accuracy.",,https://pubmed.ncbi.nlm.nih.gov/39673992/,English,Exclude,Outside date range,How accurate are machine learning models in predicting anti-seizure medication responses: A systematic review.,,,,,0.95,0.6,
pubmed:39671281,pubmed:39671281,PubMed,pubmed:39671281,Protocol for state-based decoding of hand movement parameters using neural signals.,Mohammad Taghi Ghodrati;Sajedeh Aghababaei;Alavie Mirfathollahi;Vahid Shalchyan;Mohammad Reza Zarrindast;Mohammad Reza Daliri,2024,10.1016/j.xpro.2024.103503,"We present a protocol for decoding kinematic and kinetic parameters from the primary somatosensory cortex during active and passive hand movements in a center-out reaching task using state-based and conventional decoders. We describe steps for preparing data and using the state-based model to classify movement directions into states via feature extraction and predict parameters with regression models (partial least squares and multilinear regression) trained per state. This state-based approach outperforms conventional methods, enhancing accuracy for brain-computer interface applications. For complete details on the use and execution of this protocol, please refer to Mirfathollahi et al.",https://pubmed.ncbi.nlm.nih.gov/39671281/,https://pubmed.ncbi.nlm.nih.gov/39671281/,English,Include,,Protocol for state-based decoding of hand movement parameters using neural signals.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39668166,pubmed:39668166,PubMed,pubmed:39668166,Neural dynamics of personality trait perception and interaction preferences.,Martin Weiß;Marko Paelecke;Patrick Mussel;Grit Hein,2024,10.1038/s41598-024-76423-9,"According to recent research, self-reported Big Five personality traits are associated with preferences for faces that are representative of certain Big Five traits. Previous research has primarily focused on either preference for distinct prototypical personality faces or the accuracy of trait ratings for these faces. However, the underlying neural correlates involved in the processing of prototypical personality faces are unknown. In the present study, we aim to bridge this gap by investigating whether participants' Big Five personality traits predict preferences to interact with individuals represented by prototypical personality faces, as well as the neural processing of these facial features. Based on theoretical considerations and previous research, we focus on trait extraversion, agreeableness and neuroticism, and corresponding prototypical faces. Participants were asked to classify prototypical faces as above or below average representative of a certain trait, and then provide an interaction preference rating while face-sensitive event-related potentials (N170 and late positive potential) were measured. In line with our hypotheses, the results showed an interaction preference for faces that were perceived as high (vs. low) extraverted and agreeable and low (vs. high) neurotic. In addition, the preference for agreeable faces interacted with personality characteristics of the perceiver: The higher a persons' score on trait agreeableness, the higher the face preference ratings for both prototypical and perceived high agreeable faces. Analyses of ERP data showed that an increase in preference ratings for prototypical agreeable faces was paralleled by an increase of the late positive potential. Notably, the N170 did not show any neural signature of the hypothesized effects of personality faces. Together, these results highlight the importance of considering both perceiver characteristics as well as perceived features of an interaction partner when it comes to preference for social interaction.Protocol registration The stage 1 protocol for this Registered Report was accepted in principle on the 8th of May 2023. The protocol, as accepted by the journal, can be found at: https://doi.org/10.17605/OSF.IO/G8SCY .",,https://pubmed.ncbi.nlm.nih.gov/39668166/,English,Exclude,Not EEG-BCI focused,Neural dynamics of personality trait perception and interaction preferences.,,,,,0.9,0.8,small_sample_mentioned
pubmed:39667216,pubmed:39667216,PubMed,pubmed:39667216,Delayed knowledge transfer: Cross-modal knowledge transfer from delayed stimulus to EEG for continuous attention detection based on spike-represented EEG signals.,Pengfei Sun;Jorg De Winne;Malu Zhang;Paul Devos;Dick Botteldooren,2025,10.1016/j.neunet.2024.107003,"Decoding visual and auditory stimuli from brain activities, such as electroencephalography (EEG), offers promising advancements for enhancing machine-to-human interaction. However, effectively representing EEG signals remains a significant challenge. In this paper, we introduce a novel Delayed Knowledge Transfer (DKT) framework that employs spiking neurons for attention detection, using our experimental EEG dataset. This framework extracts patterns from audiovisual stimuli to model brain responses in EEG signals, while accounting for inherent response delays. By aligning audiovisual features with EEG signals through a shared embedding space, our approach improves the performance of brain-computer interface (BCI) systems. We also present WithMeAttention, a multimodal dataset designed to facilitate research in continuously distinguishing between target and distractor responses. Our methodology demonstrates a 3% improvement in accuracy on the WithMeAttention dataset compared to a baseline model that decodes EEG signals from scratch. This significant performance increase highlights the effectiveness of our approach Comprehensive analysis across four distinct conditions shows that rhythmic enhancement of visual information can optimize multi-sensory information processing. Notably, the two conditions featuring rhythmic target presentation - with and without accompanying beeps - achieved significantly superior performance compared to other scenarios. Furthermore, the delay distribution observed under different conditions indicates that our delay layer effectively emulates the neural processing delays in response to stimuli.",,https://pubmed.ncbi.nlm.nih.gov/39667216/,English,Exclude,Outside date range,Delayed knowledge transfer: Cross-modal knowledge transfer from delayed stimulus to EEG for continuous attention detection based on spike-represented EEG signals.,,,,,0.95,0.6,
pubmed:39667215,pubmed:39667215,PubMed,pubmed:39667215,Low-power and lightweight spiking transformer for EEG-based auditory attention detection.,Yawen Lan;Yuchen Wang;Yuping Zhang;Hong Zhu,2025,10.1016/j.neunet.2024.106977,"EEG signal analysis can be used to study brain activity and the function and structure of neural networks, helping to understand neural mechanisms such as cognition, emotion, and behavior. EEG-based auditory attention detection is using EEG signals to determine an individual's level of attention to specific auditory stimuli. In this technique, researchers record and analyze a subject's electrical activity to infer whether an individual is paying attention to a specific auditory stimulus. The model deployed in edge devices will be greatly convenient for subjects to use. However, most of the existing EEG-based auditory attention detection models use traditional neural network models, and their high computing load makes deployment on edge devices challenging. We present a pioneering approach in the form of a binarized spiking Transformer for EEG-based auditory attention detection, which is characterized by high accuracy, low power consumption, and lightweight design, making it highly suitable for deployment on edge devices. In terms of low power consumption, the network is constructed using spiking neurons, which emit sparse and binary spike sequences, which can effectively reduce computing power consumption. In terms of lightweight, we use a post-training quantization strategy to quantize the full-precision network weights into binary weights, which greatly reduces the model size. In addition, the structure of the Transformer ensures that the model can learn effective information and ensure its high performance. We verify the model through mainstream datasets, and experimental results show that our model performance can exceed the existing state-of-the-art models, and the model size can be reduced by more than 21 times compared with the original full-precision network counterpart.",,https://pubmed.ncbi.nlm.nih.gov/39667215/,English,Exclude,Outside date range,Low-power and lightweight spiking transformer for EEG-based auditory attention detection.,,,,,0.95,0.6,
pubmed:39666689,pubmed:39666689,PubMed,pubmed:39666689,Resting-state EEG microstate features for Alzheimer's disease classification.,Xiaoli Yang;Zhipeng Fan;Zhenwei Li;Jiayi Zhou,2024,10.1016/j.brs.2022.08.005,"Resting-state electroencephalogram (EEG) microstate analysis resolves EEG signals into topographical maps representing discrete, sequential network activations. These maps can be used to identify patterns in EEGs that may be indicative of underlying neurological conditions. One such pattern is observed in EEGs of patients with Alzheimer's disease (AD), where a global microstate disorganization is evident. We initially investigated the classification efficacy of microstate parameters as markers for AD classification. Subsequently, we compared the classification efficacy of EEG conventional features to ascertain the superiority of microstate features. We extracted raw EEG data from a public, independent database, OpenNeuro EEG. The raw EEG was subjected to preprocessing and band-pass filtering to obtain five distinct frequency bands. The SVM classifier was used to input the microstate feature set to determine the one with the best classification effect as the main band. In order to verify the advantage of the microstate features, the AD group and the healthy control group were filtered for the main frequency bands respectively. Then the microstate feature set and the regular feature set were extracted. The two feature sets were input into four different conventional machine learning classifiers, namely SVM, KNN, RF, and LR, in order to avoid the classifiers as the dependent variable. And the comparison of the classification results of simply two feature sets as the dependent variable can be obtained. The results show that in the Alpha (8-13 Hz) sub-band, the microstate feature set as model input to SVM is optimal for the recognition of AD, with a classification accuracy of 99.22%. The Alpha band, as the main frequency band, the microstate feature set as model input to the four classifiers obtains an average classification accuracy of 98.61%, and the average classification accuracy obtained by the conventional EEG feature set as model is 91.19%. Based on four different classifiers, microstate parameters can be served as markers to effectively classify the EEG of AD patients. The microstate feature set outperforms the conventional EEG feature set after excluding the effect of classifiers.",https://pubmed.ncbi.nlm.nih.gov/39666689/,https://pubmed.ncbi.nlm.nih.gov/39666689/,English,Include,,Resting-state EEG microstate features for Alzheimer's disease classification.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39666141,pubmed:39666141,PubMed,pubmed:39666141,Effects of a scoring aid on glasgow coma score assessment and physicians' comprehension: a simulator-based randomized clinical trial.,Paulina S C Kliem;Kai Tisljar;Pascale Grzonka;Sebastian Berger;Simon A Amacher;Gian Marco De Marchis;Tolga D Dittrich;Sabina Hunziker;Stephan Rüegg;Stefano Bassetti;Roland Bingisser;Stephan Marsch;Raoul Sutter,2024,10.1007/s00415-024-12825-z,"Examining the impact of scoring aids on the accuracy of assessing the Glasgow Coma Score (GCS) in a standardized trauma scenario (primary outcome). Evaluating physicians' understanding of the GCS assessment and clinical application (secondary outcome). This randomized trial was performed at the simulator center of a Swiss tertiary academic medical hospital. Participants included intensivists, emergency physicians, internists, and neurologists. The setting involved a trauma patient portraying a GCS of 8 (eyes 1, verbal 2, motor 5). Participants were randomized to receiving or not receiving a scoring aid. Video/audio recordings of the assessments and questionnaires were analyzed by two investigators. Among 109 participants, 55 received a scoring aid. Overall, 52% scored correctly (score interquartile range 7-8); 43% scored too low and 90% scored within a range of ± 1. A scoring aid increased accuracy (62% vs. 43%, p = 0.045) and participants' confidence, whilst decreasing assessment duration. Clinical experience further improved reliability. 89% found assessing a GCS of 8 most challenging, particularly with motor response evaluation (64%). 26% indicated tracheal intubation to be mandatory with a score of GCS ≤ 8. GCS assessment is improved by professional experience and a scoring aid, the use of which needs to be promoted in daily clinical practice. Frequent inaccuracy and misunderstanding regarding clinical applications may alter patient management and misguide treatment and prognosis. ISRCTN registry (IDISRCTN12257237) https://www.isrctn.com/ISRCTN12257237 Retrospectively registered (last amendment 08/22/2023).",,https://pubmed.ncbi.nlm.nih.gov/39666141/,English,Exclude,Not EEG-BCI focused,Effects of a scoring aid on glasgow coma score assessment and physicians' comprehension: a simulator-based randomized clinical trial.,,,,,0.9,0.8,small_sample_mentioned
pubmed:39665912,pubmed:39665912,PubMed,pubmed:39665912,The relationship of bispectral index values to conscious state: an analysis of two volunteer cohort studies.,Jordan J Wehrman;Peter J Schuller;Cameron P Casey;Annalotta Scheinin;Roosa E Kallionpää;Katja Valli;Antti Revonsuo;Oskari Kantonen;Sean Tanabe;William Filbey;Robert A Pearce;Jamie W Sleigh;Harry Scheinin;Robert D Sanders,2025,10.1016/j.bja.2024.09.032,"The ability of current depth-of-anaesthesia monitors to differentiate subtle changes in the conscious state has not been well characterised. We examine the variability in bispectral index (BIS) scores associated with disconnected conscious and unconscious states as confirmed by a novel serial awakening paradigm. Seventy adult participants, given propofol or dexmedetomidine, had a cumulative 1381 electroencephalographic (EEG) recordings across two centres. Participants were awakened periodically, and their recent conscious experience interrogated by structured questioning. BIS were reconstructed from EEG using openibis, and the distribution of BIS scores were compared using linear mixed effects modelling. The predictive capacity of BIS across states of consciousness was also examined. Reconstructed BIS scores correlated significantly with blood concentrations of propofol and dexmedetomidine (all P<0.001). However, while the average BIS was different between baseline wakefulness (mean BIS=95.1 [standard deviation=3.5]); connected consciousness with drug present (84.0 [10.9]); disconnected consciousness (70.0 [16.9]); and unconsciousness (68.1 [16.1]), the interquartile range of these states (3.6, 15.1, 23.3 and 26.8, respectively) indicated high degrees of overlap and individual variability. Connected consciousness could be differentiated from either disconnected consciousness or unconsciousness with 86% accuracy (i.e. 14% error rate), and disconnected consciousness differentiated from unconsciousness with 74% accuracy. These results agree with previous studies that BIS scores fail to reliably differentiate between states of consciousness, exacerbated by segregating connected, disconnected, and unconscious states. To develop a method that reliably identifies the conscious state of an individual (not an average), work is needed to establish the causal mechanisms of disconnection and unconsciousness.",,https://pubmed.ncbi.nlm.nih.gov/39665912/,English,Exclude,Outside date range,The relationship of bispectral index values to conscious state: an analysis of two volunteer cohort studies.,,,,,0.95,0.8,small_sample_mentioned
pubmed:39665785,pubmed:39665785,PubMed,pubmed:39665785,Ultrathin Bioelectrode Array with Improved Electrochemical Performance for Electrophysiological Sensing and Modulation.,Xiaojia Du;Leyi Yang;Xiaohu Shi;Chujie Ye;Yunfei Wang;Dekui Song;Wei Xiong;Xiaodan Gu;Chunming Lu;Nan Liu,2024,10.1021/acsnano.4c13325,"To achieve high accuracy and effectiveness in sensing and modulating neural activity, efficient charge-transfer biointerfaces and a high spatiotemporal resolution are required. Ultrathin bioelectrode arrays exhibiting mechanical compliance with biological tissues offer such biointerfaces. However, their thinness often leads to a lack of mechano-electrical stability or sufficiently high electrochemical capacitance, thus deteriorating their overall performance. Here, we report ultrathin (∼115 nm) bioelectrode arrays that simultaneously enable ultraconformability, mechano-electrical stability and high electrochemical performance. These arrays show high opto-electrical conductivity (2060 S cm",,https://pubmed.ncbi.nlm.nih.gov/39665785/,English,Exclude,Not EEG-BCI focused,Ultrathin Bioelectrode Array with Improved Electrochemical Performance for Electrophysiological Sensing and Modulation.,,,,,0.9,0.6,
pubmed:39665676,pubmed:39665676,PubMed,pubmed:39665676,"MRI findings in patients with psychogenic non-epileptic seizures: Prevalence, distribution, and classification of the findings. A single tertiary epilepsy center experience.",Aleix Jareno-Badenas;Mario Matute-González;Luis Pintor;Estefanía Conde-Blanco;Mar Carreño;Xavier Setoain;Camilo Pineda;Fernando Diego Choque-Chávez;Tomás Fernández;Núria Bargalló;Sofía González-Ortiz,2025,10.1002/epi4.13114,"Psychogenic non-epileptic seizures (PNES) mimic epileptic seizures without electroencephalographic correlation. Although classified as psychiatric disorders, their neurobiological or structural basis remains unclear. This study aimed to assess the prevalence and characteristics of MRI abnormalities in patients with PNES and those with comorbid epilepsy, compared to the general population, to enhance radiological evaluation and management. We retrospectively identified patients with a definitive diagnosis of PNES, evaluated in the refractory epilepsy unit of our tertiary epilepsy center. Patients were classified into two groups according to their comorbidity with epilepsy (PNES and PNES+). The MRI findings were evaluated and classified by two radiologists, who reported the category of the findings, laterality, and location. The two groups were compared using the chi-square test, as well as the frequencies of findings in the general population extracted from the literature. Forty-six patients fulfilled the inclusion criteria. Thirty females and 16 males. MRI findings were present in 25/35 (71.4%) patients in the PNES group and 9/11 (81.8%) In the PNES + group, showing statistically significant differences in the frequency of findings with the general population (8.4-28.1%). MRI anomalies are common in PNES patients and even more prevalent in complex cases referred to epilepsy units, underscoring the necessity of correlating MRI findings with clinical-electrical patterns. In this article, we observed a higher frequency of cerebral magnetic resonance findings in patients with psychogenic non-epileptic seizures than in the general population. We also observed a higher frequency of this pathology among women, as well as right cerebral hemisphere affections. The exposed findings suggest a potential structural basis of this pathology. This hypothesis requires confirmation with larger studies.",,https://pubmed.ncbi.nlm.nih.gov/39665676/,English,Exclude,Outside date range,"MRI findings in patients with psychogenic non-epileptic seizures: Prevalence, distribution, and classification of the findings. A single tertiary epilepsy center experience.",,,,,0.95,0.6,
pubmed:39662908,pubmed:39662908,PubMed,pubmed:39662908,Prediction of Seizure Outcome Using Combinations of Four Noninvasive Presurgical Modalities in Magnetic Resonance Imaging-negative Focal Intractable Epilepsy.,Rofat Askoro;Kota Kagawa;Go Seyama;Akitake Okamura;Akira Hashizume;Tae Onari;Yutaka Hirokawa;Koji Iida;Nobutaka Horie,2025,10.1002/epi4.12795,"In focal epilepsy cases, precise identification and resection of the epileptogenic zone increase the likelihood of achieving a seizure-free outcome. Nevertheless, localizing the source of epilepsy in magnetic resonance imaging-negative epilepsy cases presents significant challenges for clinicians. In this study, we evaluated the diagnostic efficacy and impact on the seizure outcome by using 4 noninvasive modalities, including scalp video electroencephalography, magnetoencephalography, fluorodeoxyglucose-positron emission tomography, and iomazenil single-photon emission computed tomography, in a cohort of patients with magnetic resonance imaging-negative focal epilepsy who underwent resective surgery. The concordance status of each modality was assessed relative to the lobar resection area, and surgical outcome was assessed by Engel Classification at least 1 year after surgery. Comparison and diagnostic analyses were calculated for each individual and all possible combinations of scalp video electroencephalography, magnetoencephalography, fluorodeoxyglucose-positron emission tomography, and single-photon emission computed tomography with respect to Engel class I outcome. Eighteen patients (66.6%, 18/27) had Engel class I outcomes. Patients with at least 2 concordant modalities were associated with Engel class I outcome (p = 0.0262). For individual modality, fluorodeoxyglucose-positron emission tomography achieved the highest yield of sensitivity (72.2%) compared to scalp video electroencephalography, magnetoencephalography, and single-photon emission computed tomography (50.0%, 61.1%, and 61.6%, respectively). Scalp video electroencephalography, magnetoencephalography, and single-photon emission computed tomography showed similar specificities of 77.7%, while fluorodeoxyglucose-positron emission tomography showed a specificity of 55.5%. Combined modalities were able to achieve the highest sensitivity of 83.3% when there were at least 2 concordant modalities and a specificity of 100% with various multiple combinations. Our study showed that lobar concordance from multiple modalities increases the sensitivity and specificity for a seizure-free outcome in magnetic resonance imaging-negative focal epilepsy patients who underwent resective surgery.",,https://pubmed.ncbi.nlm.nih.gov/39662908/,English,Exclude,Outside date range,Prediction of Seizure Outcome Using Combinations of Four Noninvasive Presurgical Modalities in Magnetic Resonance Imaging-negative Focal Intractable Epilepsy.,,,,,0.95,0.6,
pubmed:39662316,pubmed:39662316,PubMed,pubmed:39662316,Enhancing automatic sleep stage classification with cerebellar EEG and machine learning techniques.,Wang Manli;Guan Junwen;Sun Tong;Wang Junjie;Yuan Yikai;Zhou Yicheng;Zhang Yi;Yang Xiaoyu;Li Xuepei;Yang Jingguo;Zhou Xuebin;Yu Hang,2025,10.1016/j.compbiomed.2024.109515,"Sleep disorders have become a significant health concern in modern society. To investigate and diagnose sleep disorders, sleep analysis has emerged as the primary research method. Conventional polysomnography primarily relies on cerebral electroencephalography (EEG) and electromyography (EMG) for sleep stage scoring, but manual scoring is time-consuming and subjective. This study investigated the potential application of cerebellar EEG combined with machine learning in automatic sleep stage classification. Twenty-five male mice underwent 24-h cerebral EEG/cerebellar EEG/EMG recording, and manual sleep staging was performed. Various machine learning models, including Light Gradient Boosting (LGBoost), Extreme Gradient Boosting, Categorical Boosting, Support Vector Machine, Logistic Regression, Random Forest, Long Short-Term Memory and Convolutional Neural Network, were applied for automatic sleep stage classification. The performance of different models and the efficacy of cerebellar EEG, cerebral EEG, and EMG were compared under different training:test set ratios. Cerebellar EEG exhibited significant differences in power spectral density across wakefulness, non-rapid eye movement sleep stages, and rapid eye movement sleep stages, particularly at frequencies >7 Hz. LGBoost, Extreme Gradient Boosting, and Categorical Boosting models showed comparable performance, with LGBoost being selected for further analyses due to its shorter computation time. Cerebral EEG consistently demonstrated the highest precision, recall/sensitivity, and specificity in classifying sleep stages across all training:test set ratios, followed by cerebellar EEG, which outperformed EMG. Combining the top 5 cerebellar EEG features with cerebral EEG features yielded better classification performance than combining EMG features with cerebral EEG features. Using the top 20 features, the model achieved mean area under the receiver operating characteristic curve values of 0.98 ± 0.08, 0.98 ± 0.10, and 0.99 ± 0.07 for wakefulness, non-rapid eye movement sleep stages, and rapid eye movement sleep stages, respectively. The cerebellum may play a unique and important role in sleep-wake regulation. Incorporating cerebellar EEG into polysomnography has the potential to enhance the accuracy and efficiency of sleep stage classification.",,https://pubmed.ncbi.nlm.nih.gov/39662316/,English,Exclude,Outside date range,Enhancing automatic sleep stage classification with cerebellar EEG and machine learning techniques.,,,,,0.95,0.6,
pubmed:39661965,pubmed:39661965,PubMed,pubmed:39661965,Accuracy of Machine Learning in Detecting Pediatric Epileptic Seizures: Systematic Review and Meta-Analysis.,Zhuan Zou;Bin Chen;Dongqiong Xiao;Fajuan Tang;Xihong Li,2024,10.1378/chest.92.1.63,"Real-time monitoring of pediatric epileptic seizures poses a significant challenge in clinical practice. In recent years, machine learning (ML) has attracted substantial attention from researchers for diagnosing and treating neurological diseases, leading to its application for detecting pediatric epileptic seizures. However, systematic evidence substantiating its feasibility remains limited. This systematic review aimed to consolidate the existing evidence regarding the effectiveness of ML in monitoring pediatric epileptic seizures with an effort to provide an evidence-based foundation for the development and enhancement of intelligent tools in the future. We conducted a systematic search of the PubMed, Cochrane, Embase, and Web of Science databases for original studies focused on the detection of pediatric epileptic seizures using ML, with a cutoff date of August 27, 2023. The risk of bias in eligible studies was assessed using the QUADAS-2 (Quality Assessment of Diagnostic Accuracy Studies-2). Meta-analyses were performed to evaluate the C-index and the diagnostic 4-grid table, using a bivariate mixed-effects model for the latter. We also examined publication bias for the C-index by using funnel plots and the Egger test. This systematic review included 28 original studies, with 15 studies on ML and 13 on deep learning (DL). All these models were based on electroencephalography data of children. The pooled C-index, sensitivity, specificity, and accuracy of ML in the training set were 0.76 (95% CI 0.69-0.82), 0.77 (95% CI 0.73-0.80), 0.74 (95% CI 0.70-0.77), and 0.75 (95% CI 0.72-0.77), respectively. In the validation set, the pooled C-index, sensitivity, specificity, and accuracy of ML were 0.73 (95% CI 0.67-0.79), 0.88 (95% CI 0.83-0.91), 0.83 (95% CI 0.71-0.90), and 0.78 (95% CI 0.73-0.82), respectively. Meanwhile, the pooled C-index of DL in the validation set was 0.91 (95% CI 0.88-0.94), with sensitivity, specificity, and accuracy being 0.89 (95% CI 0.85-0.91), 0.91 (95% CI 0.88-0.93), and 0.89 (95% CI 0.86-0.92), respectively. Our systematic review demonstrates promising accuracy of artificial intelligence methods in epilepsy detection. DL appears to offer higher detection accuracy than ML. These findings support the development of DL-based early-warning tools in future research. PROSPERO CRD42023467260; https://www.crd.york.ac.uk/prospero/display_record.php?ID=CRD42023467260.",,https://pubmed.ncbi.nlm.nih.gov/39661965/,English,Exclude,Review/survey papers,Accuracy of Machine Learning in Detecting Pediatric Epileptic Seizures: Systematic Review and Meta-Analysis.,,,,,0.95,0.6,
pubmed:39660274,pubmed:39660274,PubMed,pubmed:39660274,Decoding Depth of Meditation: Electroencephalography Insights From Expert Vipassana Practitioners.,Nicco Reggente;Christian Kothe;Tracy Brandmeyer;Grant Hanada;Ninette Simonian;Sean Mullen;Tim Mullen,2025,10.31234/osf.io/x23me,"Meditation practices have demonstrated numerous psychological and physiological benefits, but capturing the neural correlates of varying meditative depths remains challenging. In this study, we aimed to decode self-reported time-varying meditative depth in expert practitioners using electroencephalography (EEG). Expert Vipassana meditators ( We achieved significant accuracy in decoding self-reported meditative depth across unseen sessions. The spontaneous emergence method yielded improved decoding performance compared with traditional probing and correlated more strongly with postsession outcome measures. Best performance was achieved by a novel machine learning method that fused spatial, spectral, and connectivity information. Conventional EEG channel-level methods and preselected default mode network regions fell short in capturing the complex neural dynamics associated with varying meditation depths. This study demonstrates the feasibility of decoding personally defined meditative depth using EEG. The findings highlight the complex, multivariate nature of neural activity during meditation and introduce spontaneous emergence as an ecologically valid and less obtrusive experiential sampling method. These results have implications for advancing neurofeedback techniques and enhancing our understanding of meditative practices. We investigated meditative depth in expert Vipassana practitioners (",,https://pubmed.ncbi.nlm.nih.gov/39660274/,English,Exclude,Outside date range,Decoding Depth of Meditation: Electroencephalography Insights From Expert Vipassana Practitioners.,,,,,0.95,0.6,
pubmed:39660042,pubmed:39660042,PubMed,pubmed:39660042,Four-class ASME BCI: investigation of the feasibility and comparison of two strategies for multiclassing.,Simon Kojima;Shin'ichiro Kanoh,2024,10.1109/tbme.2016.2628861,"The ASME (stands for Auditory Stream segregation Multiclass ERP) paradigm is proposed and used for an auditory brain-computer interface (BCI). In this paradigm, a sequence of sounds that are perceived as multiple auditory streams are presented simultaneously, and each stream is an oddball sequence. The users are requested to focus selectively on deviant stimuli in one of the streams, and the target of the user attention is detected by decoding event-related potentials (ERPs). To achieve multiclass ASME BCI, the number of streams must be increased. However, increasing the number of streams is not easy because of a person's limited audible frequency range. One method to achieve multiclass ASME with a limited number of streams is to increase the target stimuli in a single stream. Two approaches for the ASME paradigm, ASME-4stream (four streams with a single target stimulus in each stream) and ASME-2stream (two streams with two target stimuli in each stream) were investigated. Fifteen healthy subjects with no neurological disorders participated in this study. An electroencephalogram was acquired, and ERPs were analyzed. The binary classification and BCI simulation (detecting the target class of the trial out of four) were conducted with the help of linear discriminant analysis, and its performance was evaluated offline. Its usability and workload were also evaluated using a questionnaire. Discriminative ERPs were elicited in both paradigms. The average accuracies of the BCI simulations were 0.83 (ASME-4stream) and 0.86 (ASME-2stream). In the ASME-2stream paradigm, the latency and the amplitude of P300 were shorter and larger, the average binary classification accuracy was higher, and the average weighted workload was smaller. Both four-class ASME paradigms achieved a sufficiently high accuracy (over 80%). The shorter latency and larger amplitude of P300 and the smaller workload indicated that subjects could perform the task confidently and had high usability in ASME-2stream compared to ASME-4stream paradigm. A paradigm with multiple target stimuli in a single stream could create a multiclass ASME BCI with limited streams while maintaining task difficulty. These findings expand the potential for an ASME BCI multiclass extension, offering practical auditory BCI choices for users.",https://pubmed.ncbi.nlm.nih.gov/39660042/,https://pubmed.ncbi.nlm.nih.gov/39660042/,English,Include,,Four-class ASME BCI: investigation of the feasibility and comparison of two strategies for multiclassing.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39659516,pubmed:39659516,PubMed,pubmed:39659516,Contribution of Scalp Regions to Machine Learning-Based Classification of Dementia Utilizing Resting-State qEEG Signals.,Chanda Simfukwe;Seong Soo A An;Young Chul Youn,2024,10.1016/j.neurobiolaging.2008.09.020,"This study aims to investigate using eyes-open (EO) and eyes-closed (EC) resting-state EEG data to diagnose cognitive impairment using machine learning methods, enhancing timely intervention and cost-effectiveness in dementia research. A total of 890 participants aged 40-90 were included in the study, comprising 269 healthy controls (HC), 356 individuals with mild cognitive impairment (MCI), and 265 with Alzheimer's disease (AD) from a cohort study. Resting-state EEG (rEEG) signals were recorded and transformed into relative power spectral density (PSD) data for analysis. The processed PSD data, representing 19 scalp regions, were then input into a Random Forest (RF) machine learning classifier to identify distinctive EEG patterns across the groups. Statistical comparisons between the groups were conducted using one-way ANOVA, applied to the relative PSD features extracted from the EEG data, to assess significant differences in EEG activity across the diagnostic categories. The study found that rEEG-based categorization effectively differentiates between cognitively impaired individuals and healthy individuals. The EO rEEG achieved the highest performance metrics across various models. For HC vs MCI (combined hemisphere), the accuracy, sensitivity, specificity, and AUC were 92%, 99%, 83%, and 96%, respectively. For HC vs AD (parietal, temporal, occipital), these metrics were 95%, 96%, 94%, and 99%. The HC vs CASE (MCI + AD) (combined hemisphere) results were 90%, 99%, 73%, and 92%. The metrics for HC vs MCI vs AD (frontal, parietal, temporal) were 89%, 88%, 94%, and 96%. The study demonstrates that EO rEEG can effectively distinguish between cognitive impairment and healthy states, leading to early diagnosis, cost-effective treatment, and better clinical outcomes for dementia patients. EO and EC rEEG models trained with relative PSD, particularly from parietal, temporal, occipital, and central scalp regions, can significantly assist clinicians in practice.",https://pubmed.ncbi.nlm.nih.gov/39659516/,https://pubmed.ncbi.nlm.nih.gov/39659516/,English,Include,,Contribution of Scalp Regions to Machine Learning-Based Classification of Dementia Utilizing Resting-State qEEG Signals.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39657530,pubmed:39657530,PubMed,pubmed:39657530,Tensor dictionary-based heterogeneous transfer learning to study emotion-related gender differences in brain.,Lan Yang;Chen Qiao;Takafumi Kanamori;Vince D Calhoun;Julia M Stephen;Tony W Wilson;Yu-Ping Wang,2025,10.1561/2200000067,"In practice, collecting auxiliary labeled data with same feature space from multiple domains is difficult. Thus, we focus on the heterogeneous transfer learning to address the problem of insufficient sample sizes in neuroimaging. Viewing subjects, time, and features as dimensions, brain activation and dynamic functional connectivity data can be treated as high-order heterogeneous data with heterogeneity arising from distinct feature space. To use the heterogeneous priori knowledge from the low-dimensional brain activation data to improve the classification performance of high-dimensional dynamic functional connectivity data, we propose a tensor dictionary-based heterogeneous transfer learning framework. It combines supervised tensor dictionary learning with heterogeneous transfer learning for enhance high-order heterogeneous knowledge sharing. The former can encode the underlying discriminative features in high-order data into dictionaries, while the latter can transfer heterogeneous knowledge encoded in dictionaries through feature transformation derived from mathematical relationship between domains. The primary focus of this paper is gender classification using fMRI data to identify emotion-related brain gender differences during adolescence. Additionally, experiments on simulated data and EEG data are included to demonstrate the generalizability of the proposed method. Experimental results indicate that incorporating prior knowledge significantly enhances classification performance. Further analysis of brain gender differences suggests that temporal variability in brain activity explains differences in emotion regulation strategies between genders. By adopting the heterogeneous knowledge sharing strategy, the proposed framework can capture the multifaceted characteristics of the brain, improve the generalization of the model, and reduce training costs. Understanding the gender specific neural mechanisms of emotional cognition helps to develop the gender-specific treatments for neurological diseases.",,https://pubmed.ncbi.nlm.nih.gov/39657530/,English,Exclude,Outside date range,Tensor dictionary-based heterogeneous transfer learning to study emotion-related gender differences in brain.,,,,,0.95,0.6,
pubmed:39657325,pubmed:39657325,PubMed,pubmed:39657325,A novel method of cognitive overload assessment based on a fusion feature selection using EEG signals.,Zhongrui Li;Li Tong;Ying Zeng;Yuanlong Gao;Diankun Gong;Kai Yang;Yidong Hu;Bin Yan,2024,10.1088/1741-2552/ad9cc0,"Cognitive overload, as an overload state of cognitive workload, negatively impacts individuals' task performance and mental health. Cognitive overload assessment models based on Electroencephalography (EEG) can effectively prevent the occurrence of overload through early warning, thereby enhancing task execution efficiency and safeguarding individuals' mental health. Although existing EEG-based cognitive load assessment methods have achieved significant research outcomes, evaluating cognitive overload remains an ongoing challenge. Current research aims to develop an effective cognitive overload assessment model and enhance its efficacy through feature selection methods.&#xD;Approach. In the cognitive overload assessment model, we firstly employ Variational Mode Decomposition (VMD) to adaptively decompose the signal from each channel into four sub-band signals to capture valuable time-frequency information. Subsequently, frequency domain features are extracted from each sub-band, and an effective feature selection method based on Mutual Information (MI) and Neighborhood Component Analysis (NCA) was applied for feature selection, which optimizes the distribution of the feature space while considering feature correlations, making the selected features more representative. Finally, traditional machine learning methods are utilized for classification, and the effectiveness of the proposed method is tested using both offline and online classification results.&#xD;Main results. The average accuracy of offline cognitive overload assessment using the proposed method on local and open datasets is 82.44 ± 1.59% and 78.24 ± 1.43%, respectively. The average classification accuracy of its online cognitive overload assessment is about 79.90 ± 2.53%. This indicates that the proposed method can effectively assess cognitive overload under both offline and online conditions. Furthermore, we found that higher-frequency sub-bands are more advantageous for cognitive overload assessment.&#xD;Significance. EEG signals can be used for effectively cognitive overload assessment, and the integration of feature selection methods enhances the accuracy of the evaluation, providing reliable methodological support for future cognitive overload monitoring in human-computer interaction systems.&#xD.",https://pubmed.ncbi.nlm.nih.gov/39657325/,https://pubmed.ncbi.nlm.nih.gov/39657325/,English,Include,,A novel method of cognitive overload assessment based on a fusion feature selection using EEG signals.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39655862,pubmed:39655862,PubMed,pubmed:39655862,Systematic review of experimental paradigms and deep neural networks for electroencephalography-based cognitive workload detection.,Vishnu K N;Cota Navin Gupta,2024,10.1088/2516-1091/ad8530,"This article summarizes a systematic literature review of deep neural network-based cognitive workload (CWL) estimation from electroencephalographic (EEG) signals. The focus of this article can be delineated into two main elements: first is the identification of experimental paradigms prevalently employed for CWL induction, and second, is an inquiry about the data structure and input formulations commonly utilized in deep neural networks (DNN)-based CWL detection. The survey revealed several experimental paradigms that can reliably induce either graded levels of CWL or a desired cognitive state due to sustained induction of CWL. This article has characterized them with respect to the number of distinct CWL levels, cognitive states, experimental environment, and agents in focus. Further, this literature analysis found that DNNs can successfully detect distinct levels of CWL despite the inter-subject and inter-session variability typically observed in EEG signals. Several methodologies were found using EEG signals in its native representation of a two-dimensional matrix as input to the classification algorithm, bypassing traditional feature selection steps. More often than not, researchers used DNNs as black-box type models, and only a few studies employed interpretable or explainable DNNs for CWL detection. However, these algorithms were mostly post hoc data analysis and classification schemes, and only a few studies adopted real-time CWL estimation methodologies. Further, it has been suggested that using interpretable deep learning methodologies may shed light on EEG correlates of CWL, but this remains mostly an unexplored area. This systematic review suggests using networks sensitive to temporal dependencies and appropriate input formulations for each type of DNN architecture to achieve robust classification performance. An additional suggestion is to utilize transfer learning methods to achieve high generalizability across tasks (task-independent classifiers), while simple cross-subject data pooling may achieve the same for subject-independent classifiers.",,https://pubmed.ncbi.nlm.nih.gov/39655862/,English,Exclude,Review/survey papers,Systematic review of experimental paradigms and deep neural networks for electroencephalography-based cognitive workload detection.,,,,,0.95,0.6,
pubmed:39655525,pubmed:39655525,PubMed,pubmed:39655525,Distinct Neural Connectivity Patterns During Music Listening and Imagination: An Electroencephalography Study.,Kiarash Fouladi;Hessam Ahmadi;Ali Motie-Nasrabadi,2025,10.1089/brain.2024.0042,,,https://pubmed.ncbi.nlm.nih.gov/39655525/,English,Exclude,Outside date range,Distinct Neural Connectivity Patterns During Music Listening and Imagination: An Electroencephalography Study.,,,,,0.95,0.6,
pubmed:39652971,pubmed:39652971,PubMed,pubmed:39652971,A passive brain-computer interface for operator mental fatigue estimation in monotonous surveillance operations: time-on-task and performance labeling issues.,Marcel F Hinss;Emilie S Jahanpour;Anke M Brock;Raphaëlle N Roy,2024,10.1088/1741-2552/ad9bed,,,https://pubmed.ncbi.nlm.nih.gov/39652971/,English,Exclude,Not classification-focused,A passive brain-computer interface for operator mental fatigue estimation in monotonous surveillance operations: time-on-task and performance labeling issues.,,,,,0.85,0.6,
pubmed:39652893,pubmed:39652893,PubMed,pubmed:39652893,VME-EFD : A novel framework to eliminate the Electrooculogram artifact from single-channel EEGs.,Sayedu Khasim Noorbasha;Arun Kumar,2024,10.1088/2057-1976/ad9bb6,"The diagnosis of neurological disorders often involves analyzing EEG data, which can be contaminated by artifacts from eye movements or blinking (EOG). To improve the accuracy of EEG-based analysis, we propose a novel framework, VME-EFD, which combines Variational Mode Extraction (VME) and Empirical Fourier Decomposition (EFD) for effective EOG artifact removal. In this approach, the EEG signal is first decomposed by VME into two segments: the desired EEG signal and the EOG artifact. The EOG component is further processed by EFD, where decomposition levels are analyzed based on energy and skewness. The level with the highest energy and skewness, corresponding to the artifact, is discarded, while the remaining levels are reintegrated with the desired EEG. Simulations on both synthetic and real EEG datasets demonstrate that VME-EFD outperforms existing methods, with lower RRMSE (0.1358 versus 0.1557, 0.1823, 0.2079, 0.2748), lower ΔPSD in the",https://pubmed.ncbi.nlm.nih.gov/39652893/,https://pubmed.ncbi.nlm.nih.gov/39652893/,English,Include,,VME-EFD : A novel framework to eliminate the Electrooculogram artifact from single-channel EEGs.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39652012,pubmed:39652012,PubMed,pubmed:39652012,The Effect of Cranial Sutures Should Be Considered in Transcranial Electrical Stimulation.,Alistair Carroll;Caroline D Rae;Donel Martin;Socrates Dokos;Colleen Loo,2025,10.1088/1741-2552/ac43f7,"Computational modeling is used to optimize transcranial electrical stimulation (tES) approaches, and the precision of these models is dependent on their anatomical accuracy. We are unaware of any computational modeling of tES that has included cranial sutures. The aims of the study were to review the literature on the timing of closure of the coronal and squamous sutures, which are situated under electrode placements used in tES; to review the literature regarding differences in skull and suture conductivity and to determine a more accurate conductivity for sutures; and to identify magnetic resonance image (MRI) techniques that could be used to detect cranial sutures. A scoping review of medical literature was conducted. We conducted computational modeling of a cranial bone plug using COMSOL Multiphysics finite element software, utilizing methodology and results from a previous study. We assessed use of the ""3D Slicer"" software to identify sutures in routine T1-weighted MRI scans. Reports from forensic examinations and computed tomography (CT) scans showed suture closure does not correlate with age. Our computational modeling determined a cranial suture conductivity of 0.32 S/m, which is much higher than for skull (compact skull 0.004 S/m, standard trilayer 0.013 S/m). 3D slicer enabled rapid and precise identification of the anatomy and location of cranial sutures. Cranial sutures persist throughout the lifespan and have a far higher conductivity than skull bone. Cranial sutures can be localized quickly and precisely using a combination of MRI and readily available modeling software. Sutures should be included in tES computational modeling and electroencephalography source imaging to improve the accuracy of results.",,https://pubmed.ncbi.nlm.nih.gov/39652012/,English,Exclude,Outside date range,The Effect of Cranial Sutures Should Be Considered in Transcranial Electrical Stimulation.,,,,,0.95,0.6,
pubmed:39651732,pubmed:39651732,PubMed,pubmed:39651732,Negative Emotion Differentiation Promotes Cognitive Reappraisal: Evidence From Electroencephalogram Oscillations and Phase-Amplitude Coupling.,Yali Wang;Chenyu Shangguan;Sijin Li;Wenhai Zhang,2024,10.1016/j.ijpsycho.2023.07.001,"Cognitive reappraisal, an effective emotion regulation strategy, is influenced by various individual factors. Although previous studies have established a link between negative emotion differentiation (NED) and cognitive reappraisal, the underlying neural mechanisms remain largely unknown. Using electroencephalography, this study investigates the influence and neural basis of NED in cognitive reappraisal by integrating aspects of event-related potentials, neural oscillation rhythms, and cross-frequency coupling. The findings revealed that individuals with high NED demonstrated a significant decrease in parietal late positive potential amplitudes during cognitive reappraisal, suggesting enhanced cognitive reappraisal abilities. Moreover, high NED individuals displayed increased γ synchronization, parietal α-γ coupling, and frontal θ-γ coupling when reappraising negative emotions than those with low emotion differentiation ability. Machine learning analysis of these neural indicators highlighted the superior classification and predictive accuracy of multimodal indicators for NED as opposed to unimodal indicators. Overall, this multimodal evidence provides a comprehensive interpretation of the neurophysiological mechanisms through which NED influences cognitive reappraisal and provides preliminary empirical support for personalized cognitive reappraisal interventions to alleviate emotional problems.",https://pubmed.ncbi.nlm.nih.gov/39651732/,https://pubmed.ncbi.nlm.nih.gov/39651732/,English,Include,,Negative Emotion Differentiation Promotes Cognitive Reappraisal: Evidence From Electroencephalogram Oscillations and Phase-Amplitude Coupling.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39651716,pubmed:39651716,PubMed,pubmed:39651716,The influence of music elements on the understanding of emotional musical meaning: based on the perspective of interval structure.,Tiantian Liu;Shuyi Liu;Zirui Ling;Songhan Liu;Lele Fang,2025,10.1097/wnr.0000000000002119,"Music has become an indispensable part of people's lives, frequently encountered in various contexts of daily living. Understanding the emotional significance of music is a crucial foundation for its use. This study employed the cross-modal affective priming paradigm, combined with event-related potential technology to investigate the influence of music elements on the emotional musical meaning from the perspective of interval structure. Two different forms of musical intervals (melodic interval and harmonic interval) and intervals with different varying degrees of consonance were used as priming stimuli and emotional words as target stimuli. The research results found that, compared to melodic intervals, participants responded faster and with higher accuracy under the harmonic interval condition, which also elicited a larger N400 component. Furthermore, the N400 amplitudes were smaller in four conditions compared to the dissonant-positive and consonant-positive conditions, and the consonant-negative condition elicited a significantly larger N400 amplitude than the dissonant-negative and partially consonant-negative conditions. This finding suggest that both interval type and consonance level influence emotional musical meaning, and interval structure plays a critical role in the understanding of emotional musical meaning.",,https://pubmed.ncbi.nlm.nih.gov/39651716/,English,Exclude,Outside date range,The influence of music elements on the understanding of emotional musical meaning: based on the perspective of interval structure.,,,,,0.95,0.8,small_sample_mentioned
pubmed:39650521,pubmed:39650521,PubMed,pubmed:39650521,Auditory-GAN: deep learning framework for improved auditory spatial attention detection.,Tasleem Kausar;Yun Lu;Muhammad Awais Asghar;Adeeba Kausar;Siqi Cai;Saeed Ahmed;Ahmad Almogren,2024,10.1007/s12021-018-9358-0,"Recent advances in auditory attention detection from multichannel electroencephalography (EEG) signals encounter the challenges of the scarcity of available online EEG data and the detection of auditory attention with low latency. To this end, we propose a complete deep auditory generative adversarial network auxiliary, named auditory-GAN, designed to handle these challenges while generating EEG data and executing auditory spatial detection. The proposed auditory-GAN system consists of a spectro-spatial feature extraction (SSF) module and an auditory generative adversarial network auxiliary (AD-GAN) classifier. The SSF module extracts the spatial feature maps by learning the topographic specificity of alpha power from EEG signals. The designed AD-GAN network addresses the need for extensive training data by synthesizing augmented versions of original EEG data. We validated the proposed method on the widely used KUL dataset. The model assesses the quality of generated EEG images and the accuracy of auditory spatial attention detection. Results show that the proposed auditory-GAN can produce convincing EEG data and achieves a significant ",https://pubmed.ncbi.nlm.nih.gov/39650521/,https://pubmed.ncbi.nlm.nih.gov/39650521/,English,Include,,Auditory-GAN: deep learning framework for improved auditory spatial attention detection.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39644930,pubmed:39644930,PubMed,pubmed:39644930,Frontal localisation of a theory-based anxiety disorder biomarker - Goal conflict specific rhythmicity.,Shabah M Shadli;Bruce R Russell;Veema Lodhia;Ian J Kirk;Paul Glue;Neil McNaughton,2025,10.1016/j.jad.2024.12.007,"Anxiety disorders are a major global issue. Diagnosis via symptoms, not biological causes, delivers poor treatment outcomes. Our frontal EEG biomarker, Goal Conflict Specific Rhythmicity (GCSR; 4-12 Hz), developed from our long-standing detailed neuropsychological theory of anxiety processes, is reduced by all chemical types of selective anxiolytic and is high in cases across a range of currently diagnosed anxiety disorders. We assessed frontal sources of GCSR, recording scalp EEG at either low resolution (Experiment 1, 32 channels, University of Otago, ♀:33, ♂:16) or high resolution (Experiment 2, 128 channels, University of Auckland, ♀:10, ♂:8) in healthy participants performing a Stop Signal Task to generate GCSR as previously. sLORETA demonstrated GCSR sources consistently in the right inferior frontal gyrus and, more strongly but less consistently, medial frontal gyrus. Variation was consistent with that of stopping in the same Stop Signal Task, depending on task demands. The sources of GCSR are consistent with our theory that hippocampal output receives goal information, detects conflict, and returns a negative biasing signal to the areas encoding goals in the current task. They match the variation in the control of stopping when response urgency changes. GCSR appears to index a biological type of anxiety unlike any current diagnosis and should help improve accuracy of diagnosis - anchored to actions of selective anxiolytic drugs. This task-related frontal ""theta"" rhythmicity provides proof-of-concept for further development of our theory of the neuropsychology of anxiety in direct human tests.",,https://pubmed.ncbi.nlm.nih.gov/39644930/,English,Exclude,Outside date range,Frontal localisation of a theory-based anxiety disorder biomarker - Goal conflict specific rhythmicity.,,,,,0.95,0.8,small_sample_mentioned
pubmed:39644878,pubmed:39644878,PubMed,pubmed:39644878,Machine learning based on event-related oscillations of working memory differentiates between preclinical Alzheimer's disease and normal aging.,Ke Liao;Laura E Martin;Sodiq Fakorede;William M Brooks;Jeffrey M Burns;Hannes Devos,2025,10.1016/j.clinph.2024.11.013,"To apply machine learning approaches on EEG event-related oscillations (ERO) to discriminate preclinical Alzheimer's disease (AD) from age- and sex-matched controls. Twenty-two cognitively normal preclinical AD participants with elevated amyloid and 21 cognitively normal controls without elevated amyloid completed n-back working memory tasks (n = 0, 1, 2). The absolute and relative power of ERO was extracted using the discrete wavelet transform in the delta, theta, alpha, and beta bands. Four machine learning methods were employed, and classification performance was assessed using three metrics. The low-frequency bands produced higher discriminative performances compared to high-frequency bands. The 2-back task yielded the best classification capability among the three tasks. The highest area under the curve value (0.86) was achieved in the 2-back delta band nontarget condition data. The highest accuracy (80.47%) was obtained in the 2-back delta and theta bands nontarget data. The highest F1 score (0.82) was in the 2-back theta band nontarget data. The support vector machine achieved the highest performance among tested classifiers. This study demonstrates the promise of using machine learning on EEG ERO from working memory tasks to detect preclinical AD. EEG ERO may reveal pathophysiological differences in the earliest stage of AD when no cognitive impairments are apparent.",,https://pubmed.ncbi.nlm.nih.gov/39644878/,English,Exclude,Outside date range,Machine learning based on event-related oscillations of working memory differentiates between preclinical Alzheimer's disease and normal aging.,,,,,0.95,0.8,small_sample_mentioned
pubmed:39644559,pubmed:39644559,PubMed,pubmed:39644559;pubmed:39168653,Atypical oscillatory and aperiodic signatures of visual sampling in developmental dyslexia.,Alessia Santoni;Giuseppe Di Dona;David Melcher;Laura Franchin;Luca Ronconi,2025,10.1016/j.cognition.2021.105012,"Temporal processing deficits in Developmental Dyslexia (DD) have been documented extensively at the behavioral level, leading to the formulation of neural theories positing that such anomalies in parsing multisensory input rely on aberrant synchronization of neural oscillations or to an excessive level of neural noise. Despite reading being primarily supported by visual functions, experimental evidence supporting these theories remains scarce. Here, we tested 26 adults with DD (9 females) and 31 neurotypical controls (16 females) with a temporal segregation/integration task that required participants to either integrate or segregate two rapidly presented displays while their EEG activity was recorded. We confirmed a temporal sampling deficit in DD, which specifically affected the rapid segregation of visual input. While the ongoing alpha frequency and the excitation/inhibition (E/I) ratio (i.e., an index of neural noise quantified by the aperiodic exponent) were differently modulated based on task demands in typical readers, DD participants exhibited an impairment in alpha speed modulation and an altered E/I ratio that affected their rapid visual sampling. Nonetheless, an association between visual temporal sampling accuracy and both alpha frequency and the E/I ratio measured at rest were evident in the DD group, further confirming an anomalous interplay between alpha synchronization, the E/I ratio and active visual sampling. These results provide evidence that both trait- and state-like differences in alpha-band synchronization and neural noise levels coexist in the dyslexic brain and are synergistically responsible for cascade effects on visual sampling and reading.",,https://pubmed.ncbi.nlm.nih.gov/39644559/,English,Exclude,Outside date range,Atypical oscillatory and aperiodic signatures of visual sampling in developmental dyslexia.,,,,,0.95,0.8,small_sample_mentioned
pubmed:39643220,pubmed:39643220,PubMed,pubmed:39643220,Predictive utility of artificial intelligence on schizophrenia treatment outcomes: A systematic review and meta-analysis.,Reza Saboori Amleshi;Mehran Ilaghi;Masoud Rezaei;Moein Zangiabadian;Hossein Rezazadeh;Gregers Wegener;Shokouh Arjmand,2025,10.1016/j.neubiorev.2024.105968,"Identifying optimal treatment approaches for schizophrenia is challenging due to varying symptomatology and treatment responses. Artificial intelligence (AI) shows promise in predicting outcomes, prompting this systematic review and meta-analysis to evaluate various AI models' predictive utilities in schizophrenia treatment. A systematic search was conducted, and the risk of bias was evaluated. The pooled sensitivity, specificity, and diagnostic odds ratio with 95 % confidence intervals between AI models and the reference standard for response to treatment were assessed. Diagnostic accuracy measures were calculated, and subgroup analysis was performed based on the input data of AI models. Out of the 21 included studies, AI models achieved a pooled sensitivity of 70 % and specificity of 76 % in predicting schizophrenia treatment response with substantial predictive capacity and a near-to-high level of test accuracy. Subgroup analysis revealed EEG-based models to have the highest sensitivity (89 %) and specificity (94 %), followed by imaging-based models (76 % and 80 %, respectively). However, significant heterogeneity was observed across studies in treatment response definitions, participant characteristics, and therapeutic interventions. Despite methodological variations and small sample sizes in some modalities, this study underscores AI's predictive utility in schizophrenia treatment, offering insights for tailored approaches, improving adherence, and reducing relapse risk.",,https://pubmed.ncbi.nlm.nih.gov/39643220/,English,Exclude,Outside date range,Predictive utility of artificial intelligence on schizophrenia treatment outcomes: A systematic review and meta-analysis.,,,,,0.95,0.6,
pubmed:39642643,pubmed:39642643,PubMed,pubmed:39642643,Intra- and inter-channel deep convolutional neural network with dynamic label smoothing for multichannel biosignal analysis.,Peiji Chen;Wenyang Li;Yifan Tang;Shunta Togo;Hiroshi Yokoi;Yinlai Jiang,2025,10.1016/j.neunet.2024.106960,"Efficient processing of multichannel biosignals has significant application values in the fields of healthcare and human-machine interaction. Although previous research has achieved high recognition performance with deep convolutional neural networks, several key challenges still remain: (1) Effective extraction of spatial and temporal features from the multichannel biosignals. (2) Appropriate trade-off between performance and complexity for improving applicability in real-life situations given that traditional machine learning and 2D-based CNN approaches often involve excessive preprocessing steps or model parameters; and (3) Generalization ability of neural networks to compensate for domain difference and to reduce overfitting during training process. To address challenges 1 and 2, we propose a 1D-based deep intra and inter channel (I2C) convolution neural network. The I2C convolutional block is introduced to replace the standard convolutional layer, further extending it to several state-of-the-art modules, with the intent of extracting more effective features from multichannel biosignals with fewer parameters. To address challenge 3, we integrate a branch model into the main model to perform dynamic label smoothing, enabling the model to learn domain difference and improve its generalization ability. Experiments were conducted on three public multichannel biosignals databases, namely ISRUC-S3, HEF and Ninapro-DB1. The results suggest that the proposed method exhibits significant competitive advantages in accuracy, complexity, and generalization ability.",,https://pubmed.ncbi.nlm.nih.gov/39642643/,English,Exclude,Outside date range,Intra- and inter-channel deep convolutional neural network with dynamic label smoothing for multichannel biosignal analysis.,,,,,0.95,0.8,overfit_terms_found
pubmed:39642146,pubmed:39642146,PubMed,pubmed:39642146,Hearing and cognitive decline in aging differentially impact neural tracking of context-supported versus random speech across linguistic timescales.,Elena Bolt;Katarina Kliestenec;Nathalie Giroud,2024,10.18637/jss.v082.i13,"Cognitive decline and hearing loss are common in older adults and often co-occur while investigated separately, affecting the neural processing of speech. This study investigated the interaction between cognitive decline, hearing loss, and contextual cues in speech processing. Participants aged 60 years and older were assessed for cognitive decline using the Montreal Cognitive Assessment and for hearing ability using a four-frequency pure tone average. They listened to in-house-designed matrix-style sentences that either provided supportive context or were random, while we recorded their electroencephalography. Neurophysiological responses were analyzed through auditory evoked potentials and speech tracking at different linguistic timescales (i.e., phrase, word, syllable and phoneme rate) using phase-locking values. The results showed that cognitive decline was associated with decreased response accuracy in a speech recognition task. Cognitive decline significantly impacted the P2 component of auditory evoked potentials, while hearing loss influenced speech tracking at the word and phoneme rates, but not at the phrase or syllable rates. Contextual cues enhanced speech tracking at the syllable rate. These findings suggest that cognitive decline and hearing loss differentially affect the neural mechanisms underlying speech processing, with contextual cues playing a significant role in enhancing syllable rate tracking. This study emphasises the importance of considering both cognitive and auditory factors when studying speech processing in older people and highlights the need for further research to investigate the interplay between cognitive decline, hearing loss and contextual cues in speech processing.",https://pubmed.ncbi.nlm.nih.gov/39642146/,https://pubmed.ncbi.nlm.nih.gov/39642146/,English,Include,,Hearing and cognitive decline in aging differentially impact neural tracking of context-supported versus random speech across linguistic timescales.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39640940,pubmed:39640940,PubMed,pubmed:39640940,"EEG background activity, seizure burden and early childhood outcomes in neonatal encephalopathy in Uganda: a prospective feasibility cohort study.",Sean R Mathieson;Carol Nanyunja;Samantha Sadoo;Sherinah Nakalembe;Eleanor Duckworth;Stella Muryasingura;Natalia Niombi;Jacopo Proietti;Mariam Busingye;Annettee Nakimuli;Vicki Livingstone;Emily L Webb;Ivan Mambule;Geraldine B Boylan;Cally J Tann,2024,10.1016/j.eclinm.2024.102937,"Intrapartum-related neonatal encephalopathy (NE) is a leading cause of childhood mortality and morbidity. Continuous electroencephalography (EEG) is gold standard for neonatal brain monitoring; however, low-income country data is lacking. We examined EEG in a Ugandan cohort with NE to describe feasibility, background activity, seizure prevalence and burden, and associations with clinical presentation and outcome. Neonates with NE were recruited from a single hospital referral centre in Kampala, Uganda (Oct 2019-Oct 2020) and underwent EEG monitoring. Feasibility was assessed as to whether EEG monitoring of diagnostic quality could be achieved from days 1-5. Evolution of clinical presentation was assessed by Sarnat classification and daily Thompson score was performed. EEG background severity was graded at 12, 24, 48 and 72 h after birth, and at time of Thompson score. Seizures were annotated remotely by experts and assessed for frequency, duration, burden, and status epilepticus. Early childhood outcome was assessed at follow up, and adverse outcome defined as death or neurodevelopmental impairment (NDI) at 18-24 months of age. In this prospective feasibility cohort study, diagnostic quality EEGs were recorded for 50 of 51 recruited neonates (median duration 71.4 h, IQR 52.4-72.2), indicating feasibility. Of 39 participants followed to 18-24 months, 13 died and 7 had NDI. Daily Thompson score and EEG background grade were strongly correlated across all timepoints (days 1-5). Thompson score of ≥7 was most predictive of moderate-severe EEG background abnormality (AUC 0.83). Prognostic accuracy of moderate-severe EEG background grade to predict NDI was high (AUC 0.74). Electrographic seizures were seen in 52% (26); median seizure burden was high at 264 min (IQR 27.8-523.7, range 1.3-1374.1); half (13) had status epilepticus. EEG monitoring was feasible as a research tool in this sub-Saharan Africa setting. EEG background activity correlated strongly with scored neurological assessment and predicted adverse early childhood outcome. Seizure prevalence and burden, including status epilepticus, were high in this uncooled cohort with important potential longer-term implications for survivors. Bill & Melinda Gates Foundation grant number OPP1210890; Wellcome Trust Innovator award (209325/Z/17/Z).",https://pubmed.ncbi.nlm.nih.gov/39640940/,https://pubmed.ncbi.nlm.nih.gov/39640940/,English,Include,,"EEG background activity, seizure burden and early childhood outcomes in neonatal encephalopathy in Uganda: a prospective feasibility cohort study.",Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39637937,pubmed:39637937,PubMed,pubmed:39637937,Tennis experience impacts time estimation within different timing processes: An ERP study.,Hongjie Tang;Zhongqi Zhao;Liyue Lin;Shuying Chen;Huixin Han;Xinhong Jin,2025,10.1016/j.neuropsychologia.2024.109059,"Elite tennis players demonstrate an outstanding ability to predict the timing of their shots during matches, especially during prolonged rallies. Exploring the characteristics of this temporal perception advantage and its cognitive processing mechanisms may help explain the influence of sports experience on temporal perception abilities. We recruited 28 tennis athletes and 28 controls with no sports experience and measured their behavioral performance and brain neural activity characteristics using a time-to-contact paradigm under different temporal context conditions. The results indicated that in the time estimation task, tennis athletes had significantly smaller absolute bias and lower delayed response ratios than non-athlete controls. Performance of both groups in the timing task without a beat context was significantly better than that with a rhythmic context. During the timing process, the amplitude of the contingent negative variation (CNV) was most closely associated with the processing of temporal information, where tennis athletes were significantly greater than that of non-athletes. The CNV amplitude induced in the left brain area was significantly smaller than that in the midline brain area and the right brain area. Overall, we found that tennis players showed a distinct advantage in timing accuracy, characterized by earlier prediction preparation and higher utilization of temporal information.",,https://pubmed.ncbi.nlm.nih.gov/39637937/,English,Exclude,Outside date range,Tennis experience impacts time estimation within different timing processes: An ERP study.,,,,,0.95,0.6,
pubmed:39637549,pubmed:39637549,PubMed,pubmed:39637549,Preictal period optimization for deep learning-based epileptic seizure prediction.,Petros Koutsouvelis;Bartlomiej Chybowski;Alfredo Gonzalez-Sulser;Shima Abdullateef;Javier Escudero,2024,10.1088/1741-2552/ad9ad0,,,https://pubmed.ncbi.nlm.nih.gov/39637549/,English,Exclude,Not EEG-BCI focused,Preictal period optimization for deep learning-based epileptic seizure prediction.,,,,,0.9,0.6,
pubmed:39636636,pubmed:39636636,PubMed,pubmed:39636636,Predictors of Death or Severe Impairment in Neonates With Hypoxic-Ischemic Encephalopathy.,Hannah C Glass;Thomas R Wood;Bryan A Comstock;Adam L Numis;Sonia L Bonifacio;Marie-Coralie Cornet;Fernando F Gonzalez;Adriana Morell;Sarah E Kolnik;Yi Li;Amit Mathur;Ulrike Mietzsch;Tai-Wei Wu;Courtney J Wusthoff;Marianne Thoresen;Patrick J Heagerty;Sandra E Juul;Yvonne W Wu,2024,10.1159/000530745,"Outcomes after hypoxic-ischemic encephalopathy (HIE) are variable. Predicting death or severe neurodevelopmental impairment (NDI) in affected neonates is crucial for guiding management and parent communication. To predict death or severe NDI in neonates who receive hypothermia for HIE. This prognostic study included participants enrolled in a large US clinical trial conducted in US neonatal intensive care units who were born between January 2017 and October 2019 and followed up to age 2 years. Eligible participants were neonates with moderate-severe HIE born at 36 weeks or more gestation and with 2-year outcome data. Data were analyzed June 2023. External validation was performed with a UK cohort. Clinical, electroencephalography (EEG), and magnetic resonance imaging (MRI) variables were curated and examined at 24 hours and following cooling. Death or severe NDI at age 2 years. Severe NDI was defined as Bayley Scales of Infant Toddler Development cognitive score below 70, Gross Motor Function Classification System score of 3 or higher, or quadriparesis. Model performance metrics were derived from training, internal, and external validation datasets. Among 424 neonates (mean [SD] gestational age, 39.1 [1.4] weeks; 192 female [45.3%]; 28 Asian [6.6%], 50 Black [11.8%], 311 White [73.3%]), 105 (24.7%) had severe encephalopathy at enrollment. Overall, 59 (13.9%) died and 46 (10.8%) had severe NDI. In the 24-hour model, the combined presence of 3 clinical characteristics-(1) severely abnormal EEG, (2) pH level of 7.11 or below, and (3) 5-minute Apgar score of 0-had a specificity of 99.6% (95% CI, 97.5%-100%) and a positive predictive value (PPV) of 95.2% (95% CI, 73.2%-99.3%). Validation model metrics were 97.9% (95% CI, 92.7%-99.8%) for internal specificity, with a PPV of 77.8% (95% CI, 43.4%-94.1%), and 97.6% (95% CI, 95.1%-99.0%) for external specificity, with a PPV of 46.2% (95% CI, 23.3%-70.8%). In the postcooling model, specificity for T1, T2, or diffusion-weighted imaging (DWI) abnormality in at least 2 of 3 deep gray regions (ie, thalamus, caudate, putamen and/or globus pallidus) plus a severely abnormal EEG within the first 24 hours was 99.1% (95% CI, 96.8%-99.9%), with a PPV of 91.7% (95% CI, 72.8%-97.8%). Internal specificity in this model was 98.9% (95% CI, 94.1%-100%), with a PPV of 92.9% (95% CI, 64.2%-99.0%); external specificity was 98.6% (95% CI, 96.5%-99.6%), with a PPV of 83.3% (95% CI, 64.1%-93.4%). In this prognostic study of neonates with moderate or severe HIE who were treated with therapeutic hypothermia, simple models using readily available clinical, EEG, and MRI results during the hospital admission had high specificity and PPV for death or severe NDI at age 2 years.",https://pubmed.ncbi.nlm.nih.gov/39636636/,https://pubmed.ncbi.nlm.nih.gov/39636636/,English,Include,,Predictors of Death or Severe Impairment in Neonates With Hypoxic-Ischemic Encephalopathy.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.55,external_test_reported;small_sample_mentioned
pubmed:39636478,pubmed:39636478,PubMed,pubmed:39636478,TdCCA with Dual-Modal Signal Fusion: Degenerated Occipital and Frontal Connectivity of Adult Moyamoya Disease for Early Identification.,Yuchen Ran;Yingwei Fan;Shuang Wu;Chao Chen;Yangxi Li;Tianxin Gao;Houdi Zhang;Cong Han;Xiaoying Tang,2025,10.3171/2023.7.focus23327,"Cognitive impairment in patients with moyamoya disease (MMD) manifests earlier than clinical symptoms. Early identification of brain connectivity changes is essential for uncovering the pathogenesis of cognitive impairment in MMD. We proposed a temporally driven canonical correlation analysis (TdCCA) method to achieve dual-modal synchronous information fusion from electroencephalogram (EEG) and functional near-infrared spectroscopy (fNIRS) for exploring the differences in brain connectivity between MMD and normal control groups. The dual-modal fusion features were extracted based on the imaginary part of coherence of the EEG signal (EEG iCOH) and the Pearson correlation coefficients of the fNIRS signal (fNIRS COR) in the resting and working memory state. The machine learning model showed that the accuracy of TdCCA method reached 97%, far higher than single-modal features and feature-level fusion CCA method. Brain connectivity analysis revealed a significant reduction in the strength of the connections between the right occipital lobe and frontal lobes (EEG iOCH: p = 0.022, fNIRS COR p = 0.011) in MMD. These differences reflected the impaired transient memory and executive function in MMD patients. This study contributes to the understanding of the neurophysiological nature of cognitive impairment in MMD and provides a potential adjuvant early identification method for individuals with chronic cerebral ischemia.",,https://pubmed.ncbi.nlm.nih.gov/39636478/,English,Exclude,Outside date range,TdCCA with Dual-Modal Signal Fusion: Degenerated Occipital and Frontal Connectivity of Adult Moyamoya Disease for Early Identification.,,,,,0.95,0.6,
pubmed:39635332,pubmed:39635332,PubMed,pubmed:39635332,A Synchronous iEEG Data Acquisition Framework for Dual Brain Interchange Systems.,Amir Hossein Ayyoubi;Behrang Fazli Besheli;Chandra Prakash Swamy;Jhan L Okkabaz;Kai J Miller;Gregory A Worrell;Nuri F Ince,2024,10.1007/s10548-014-0379-1,"This study presents a new data acquisition Framework for synchronous dual Brain Interchange (BIC) systems recording. The setup expands the capacity for data recording by offering access to up to 64 channels. The environment utilizes our Simulink model, incorporating functionalities for synchronization using a master clock and email-based status updates. We evaluated the framework in the lab simulations, and we observed a 38 ms post-synchronization delay between the systems. We also demonstrated that this error can be minimized to as low as 5 ms through adjustments in the master clock resolution and data buffer size. We estimated units' sampling frequency with high accuracy to avoid desynchronization. We evaluated the setup on the intracranial EEG (iEEG) recording simultaneously with the clinical system and performed spike detection on the post-synchronized iEEG. We observed over 95% similarity rate between the dual BIC and clinical system. Additionally, we explored the optimal configuration for ground and reference connections between systems to achieve the highest signal quality, along with investigating the implications of frequency interference in dual-system operations.",https://pubmed.ncbi.nlm.nih.gov/39635332/,https://pubmed.ncbi.nlm.nih.gov/39635332/,English,Include,,A Synchronous iEEG Data Acquisition Framework for Dual Brain Interchange Systems.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39632923,pubmed:39632923,PubMed,pubmed:39632923,Eeg based smart emotion recognition using meta heuristic optimization and hybrid deep learning techniques.,M Karthiga;E Suganya;S Sountharrajan;Balamurugan Balusamy;Shitharth Selvarajan,2024,10.1038/s41598-024-80448-5,"In the domain of passive brain-computer interface applications, the identification of emotions is both essential and formidable. Significant research has recently been undertaken on emotion identification with electroencephalogram (EEG) data. The aim of this project is to develop a system that can analyse an individual's EEG and differentiate among positive, neutral, and negative emotional states. The suggested methodology use Independent Component Analysis (ICA) to remove artefacts from Electromyogram (EMG) and Electrooculogram (EOG) in EEG channel recordings. Filtering techniques are employed to improve the quality of EEG data by segmenting it into alpha, beta, gamma, and theta frequency bands. Feature extraction is performed with a hybrid meta-heuristic optimisation technique, such as ABC-GWO. The Hybrid Artificial Bee Colony and Grey Wolf Optimiser are employed to extract optimised features from the selected dataset. Finally, comprehensive evaluations are conducted utilising DEAP and SEED, two publically accessible datasets. The CNN model attains an accuracy of approximately 97% on the SEED dataset and 98% on the DEAP dataset. The hybrid CNN-ABC-GWO model achieves an accuracy of approximately 99% on both datasets, with ABC-GWO employed for hyperparameter tuning and classification. The proposed model demonstrates an accuracy of around 99% on the SEED dataset and 100% on the DEAP dataset. The experimental findings are contrasted utilising a singular technique, a widely employed hybrid learning method, or the cutting-edge method; the proposed method enhances recognition performance.",https://pubmed.ncbi.nlm.nih.gov/39632923/,https://pubmed.ncbi.nlm.nih.gov/39632923/,English,Include,,Eeg based smart emotion recognition using meta heuristic optimization and hybrid deep learning techniques.,Include,,"mployed to extract optimised features from the selected dataset. Finally, comprehensive evaluations are conducted utilising DEAP and SEED, two publically accessible datasets. The CNN model attains an accuracy of approximately 97% on the SEED dataset and 98% on the DEAP dataset. The hybrid CNN-ABC-GWO model achieves an accuracy of approximately 99% on both datasets, with ABC-GWO employed for hyperp",,0.95,0.6,
pubmed:39629225,pubmed:39629225,PubMed,pubmed:39629225,Research on Sleep Staging Based on Support Vector Machine and Extreme Gradient Boosting Algorithm.,Yiwen Wang;Shuming Ye;Zhi Xu;Yonghua Chu;Jiarong Zhang;Wenke Yu,2024,10.1016/j.compbiomed.2023.107477,"To develop a sleep-staging algorithm based on support vector machine (SVM) and extreme gradient boosting model (XB Boost) and evaluate its performance. In this study, data features were extracted based on physiological significance, feature dimension reduction was performed through appropriate methods, and XG Boost classifier and SVM were used for classification. One hundred and twenty training sets and 80 test sets were randomly composed of the first 200 groups of data from the SHH1 database. The polysomnography (PSG) data of 20 real individuals in the clinic were selected as the experimental data. The C3 electroencephalogram (EEG), left and right electrooculogram (EOG), electromyogram (EMG), and other signals were analyzed. Finally, the stages were adjusted based on human sleep laws. The standard staging of the database and the doctor's diagnosis staging was used as the standard. The SHHS1 database test results were as follows: the average accuracy was 83.24%, the precision and recall of Stage Wake and Stage 2 NREM sleep (N2) were over 80%, and the precision, F1-Score and recall of Stage 3 NREM sleep (N3) and Rapid Eye Movement (REM) were more than 70%. The clinical data test results were as follows: the average accuracy rate was 76.37%; for Wake and N3, the precision reached 85%; for Wake, N2, and REM, the recall rate reached over 70%; for Wake, the F-1 Score reached over 90%. This study shows that the sleep staging results of the algorithm for the database and clinical data were similar. The staging results meet the requirements at the medical level.",https://pubmed.ncbi.nlm.nih.gov/39629225/,https://pubmed.ncbi.nlm.nih.gov/39629225/,English,Include,,Research on Sleep Staging Based on Support Vector Machine and Extreme Gradient Boosting Algorithm.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39629143,pubmed:39629143,PubMed,pubmed:39629143,A novel method for optimizing epilepsy detection features through multi-domain feature fusion and selection.,Guanqing Kong;Shuang Ma;Wei Zhao;Haifeng Wang;Qingxi Fu;Jiuru Wang,2024,10.3389/fnins.2023.1174005,"The methods used to detect epileptic seizures using electroencephalogram (EEG) signals suffer from poor accuracy in feature selection and high redundancy. This problem is addressed through the use of a novel multi-domain feature fusion and selection method (PMPSO). Discrete Wavelet Transforms (DWT) and Welch are used initially to extract features from different domains, including frequency domain, time-frequency domain, and non-linear domain. The first step in the detection process is to extract important features from different domains, such as frequency domain, time-frequency domain, and non-linear domain, using methods such as Discrete Wavelet Transform (DWT) and Welch. To extract features strongly correlated with epileptic classification detection, an improved particle swarm optimization (PSO) algorithm and Pearson correlation analysis are combined. Finally, Support Vector Machines (SVM), Artificial Neural Networks (ANN), Random Forest (RF) and XGBoost classifiers are used to construct epileptic seizure detection models based on the optimized detection features. According to experimental results, the proposed method achieves 99.32% accuracy, 99.64% specificity, 99.29% sensitivity, and 99.32% score, respectively. The detection performance of the three classifiers is compared using 10-fold cross-validation. Surpassing other methods in detection accuracy. Consequently, this optimized method for epilepsy seizure detection enhances the diagnostic accuracy of epilepsy seizures.",https://pubmed.ncbi.nlm.nih.gov/39629143/,https://pubmed.ncbi.nlm.nih.gov/39629143/,English,Include,,A novel method for optimizing epilepsy detection features through multi-domain feature fusion and selection.,Include,,The methods used to detect epileptic seizures using electroencephalogram (EEG) signals suffer from poor accuracy in feature selection and high redundancy. This problem is addressed through the use of a novel multi-domain feature fusion and selection method (PMPSO). Discrete Wavelet Transforms (DWT) and ,,0.95,0.25,cv_reported
pubmed:39627734,pubmed:39627734,PubMed,pubmed:39627734,Abnormal nonlinear features of EEG microstate sequence in obsessive-compulsive disorder.,Huicong Ren;Xiangying Ran;Mengyue Qiu;Shiyang Lv;Junming Wang;Chang Wang;Yongtao Xu;Zhixian Gao;Wu Ren;Xuezhi Zhou;Junlin Mu;Yi Yu;Zongya Zhao,2024,10.1186/s12888-024-06334-6,"At present, only a few studies have explored electroencephalography (EEG) microstates of patients with obsessive-compulsive disorder (OCD) and the results are inconsistent. Additionally, the nonlinear features of EEG microstate sequences contain rich information about the brain, yet how the nonlinear features of EEG microstate sequences abnormally change in patients with OCD is still unknown. Resting-state EEG data were collected from 48 OCD patients and macheted 48 healthy controls (HC). Subsequently, EEG microstate analysis was used to extract the microstate temporal parameters (duration, occurrence, coverage) and nonlinear features of EEG microstate sequences (sample entropy, Lempel-Ziv complexity, Hurst index). Finally, the temporal parameters and nonlinear features of EEG microstate sequences were sent to three kinds of machine learning models to classify OCD patients. Both groups obtained four typical EEG microstate topographies. The duration of microstates A, B, and C in OCD patients decreased significantly, while the occurrence of microstate D increased significantly compared to HC. Sample entropy and Lempel-Ziv complexity of microstate sequences in OCD patients increased significantly, while Hurst index decreased significantly compared to HC. The classification accuracy using the nonlinear features of microstate sequences reached up to 85%, significantly higher than that based on microstate temporal parameter models. This study provides supplementary findings on EEG microstates in OCD patients with a larger sample size. We found that the nonlinear features of EEG microstate sequences in OCD patients can serve as potential electrophysiological biomarkers for distinguishing OCD patients.",https://pubmed.ncbi.nlm.nih.gov/39627734/,https://pubmed.ncbi.nlm.nih.gov/39627734/,English,Include,,Abnormal nonlinear features of EEG microstate sequence in obsessive-compulsive disorder.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39626467,pubmed:39626467,PubMed,pubmed:39626467,A neuronal marker of eye contact spontaneously activated in neurotypical subjects but not in autistic spectrum disorders.,Guillaume Lio;Martina Corazzol;Roberta Fadda;Giuseppe Doneddu;Angela Sirigu,2025,10.1016/j.cortex.2024.10.022,"Attention to faces and eye contact are key behaviors for establishing social bonds in humans. In Autism Spectrum Disorders (ASD), a disturbance in neurodevelopment, impaired face processing and gaze avoidance are key clinical features for ASD diagnosis. The biological alterations underlying these impairments are not yet clearly established. Using high-density electroencephalography coupled with multi-variate pattern classification and group blind source separation methods we searched for face- and-face components-related neural signals that could best discriminate visual processing of neurotypical subjects (N = 38) from ASD participants (N = 27). We isolated a face-specific neural signal in the superior temporal sulcus peaking at 240 msec after face-stimulus onset. A machine learning algorithm applied on the extracted neural component reached 74% decoding accuracy at the same latencies, discriminating the neurotypical population from ASD subjects in whom this signal was weak. By manipulating attention on different parts of the face, we also found that the power of the evoked signal in neurotypical subjects varied depending on the region observed: it was strong when the eye region fell on the fovea to decrease on regions further away and outside the stimulus face. Such face and face-components selective neural modulations were not found in ASD, although they did show typical early face-related P100 and N170 signals. These results show that specialized cortical mechanisms for face perception show higher responses for eyes when attention is focused on gaze and that these mechanisms may be particularly affected in autism spectrum disorders.",,https://pubmed.ncbi.nlm.nih.gov/39626467/,English,Exclude,Outside date range,A neuronal marker of eye contact spontaneously activated in neurotypical subjects but not in autistic spectrum disorders.,,,,,0.95,0.8,small_sample_mentioned
pubmed:39626343,pubmed:39626343,PubMed,pubmed:39626343,Unveiling the hidden electroencephalographical rhythms during development: Aperiodic and Periodic activity in healthy subjects.,Brenda Y Angulo-Ruiz;Elena I Rodríguez-Martínez;Vanesa Muñoz;Carlos M Gómez,2025,10.1016/j.clinph.2024.11.014,"The study analyzes power spectral density (PSD) components, aperiodic (AP) and periodic (P) activity, in resting-state EEG of 240 healthy subjects from 6 to 29 years old, divided into 4 groups. We calculate AP and P components using the (Fitting Oscillations and One-Over-f (FOOOF)) plugging in EEGLAB. All PSD components were calculated from 1-45 Hz. Topography analysis, Spearman correlations, and regression analysis with age were computed for all components. AP and P activity show different topography across frequencies and age groups. Age-related decreases in AP exponent and offset parameters lead to reduced power, while P power decreases (1-6 Hz) and increases (10-15 Hz) with age. We support the distinction between the AP and P components of the PSD and its possible functional changes with age. AP power is dominant in the configuration of the canonical EEG rhythms topography, although P contribution to topography is embedded in the canonical EEG topography. Some EEG canonical characteristics are similar to those of the P component, as topographies of EEG rhythms (embedded) and increases in oscillatory frequency with age. We support that spectral power parameterization improves the interpretation and neurophysiological and functional accuracy of brain processes.",,https://pubmed.ncbi.nlm.nih.gov/39626343/,English,Exclude,Outside date range,Unveiling the hidden electroencephalographical rhythms during development: Aperiodic and Periodic activity in healthy subjects.,,,,,0.95,0.6,
pubmed:39625888,pubmed:39625888,PubMed,pubmed:39625888,Investigating the Triple Code Model in numerical cognition using stereotactic electroencephalography.,Alexander P Rockhill;Hao Tan;Christian G Lopez Ramos;Caleb Nerison;Beck Shafie;Maryam N Shahin;Adeline Fecker;Mostafa Ismail;Daniel R Cleary;Kelly L Collins;Ahmed M Raslan,2024,10.1212/wnl.57.11.2045,"The ability to conceptualize numerical quantities is an essential human trait. According to the ""Triple Code Model"" in numerical cognition, distinct neural substrates encode the processing of visual, auditory, and non-symbolic numerical representations. While our contemporary understanding of human number cognition has benefited greatly from advances in clinical imaging, limited studies have investigated the intracranial electrophysiological correlates of number processing. In this study, 13 subjects undergoing stereotactic electroencephalography for epilepsy participated in a number recognition task. Drawing upon postulates of the Triple Code Model, we presented subjects with numerical stimuli varying in representation type (symbolic vs. non-symbolic) and mode of stimuli delivery (visual vs. auditory). Time-frequency spectrograms were dimensionally reduced with principal component analysis and passed into a linear support vector machine classification algorithm to identify regions associated with number perception compared to inter-trial periods. Across representation formats, the highest classification accuracy was observed in the bilateral parietal lobes. Auditory (spoken and beeps) and visual (Arabic) number formats preferentially engaged the superior temporal cortices and the frontoparietal regions, respectively. The left parietal cortex was found to have the highest classification for number dots. Notably, the putamen exhibited robust classification accuracies in response to numerical stimuli. Analyses of spectral feature maps revealed that non-gamma frequency, below 30 Hz, had greater-than-chance classification value and could be potentially used to characterize format specific number representations. Taken together, our findings obtained from intracranial recordings provide further support and expand on the Triple Code Model for numerical cognition.",https://pubmed.ncbi.nlm.nih.gov/39625888/,https://pubmed.ncbi.nlm.nih.gov/39625888/,English,Include,,Investigating the Triple Code Model in numerical cognition using stereotactic electroencephalography.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39622463,pubmed:39622463,PubMed,pubmed:39622463,A fast dynamic causal modeling regression method for fMRI.,Haifeng Wu;Xinhang Hu;Yu Zeng,2024,10.1016/j.neuroimage.2024.120954,"Dynamic Causal Modeling (DCM) is a crucial tool for studying brain effective connectivity, offering valuable insights into brain network dynamics through functional magnetic resonance imaging (fMRI) and electrophysiology (EEG and MEG). However, its high computational complexity limits its applicability in large-scale network analysis. To address this issue, we propose a regression algorithm that integrates the Generalized Linear Model (GLM) with Sparse DCM, termed GSD. This algorithm enhances computational performance through three key optimizations: (1) utilizing the symmetry of the Fourier transform to convert complex frequency domain calculations into real number operations, thereby reducing computational complexity; (2) applying GLM and filtering techniques to minimize the effects of noise and confounds, enhancing parameter estimation accuracy; and (3) defining a new cost function to optimize variational inference and filter parameters, further improving parameter estimation accuracy. We validated the GSD algorithm using three public fMRI datasets: simulated Smith small-world network data, attention and motion measured data, and face recognition repetition effect measured data. The experimental results demonstrate that the GSD algorithm reduces computation time by over 50 % while maintaining parameter estimation performance comparable to traditional methods. These findings offer a new perspective on balancing model interpretability and computational efficiency, potentially broadening the application of DCM across various fields.",https://pubmed.ncbi.nlm.nih.gov/39622463/,https://pubmed.ncbi.nlm.nih.gov/39622463/,English,Include,,A fast dynamic causal modeling regression method for fMRI.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39622415,pubmed:39622415,PubMed,pubmed:39622415,Different responses of MVL neurons when pigeons attend to local versus global information during object classification.,Minjie Zhu;Yedong Yang;Xiaoke Niu;Yanyan Peng;Ruibin Liu;Mengbo Zhang;Yonghao Han;Zhizhong Wang,2025,10.1016/j.bbr.2024.115363,"Most prior studies have indicated that pigeons have a tendency to rely on local information for target categorization, yet there is a lack of electrophysiological evidence to support this claim. The mesopallium ventrolaterale (MVL) is believed to play a role in processing both local and global information during visual cognition. The difference between responses of MVL neurons when pigeons are focusing on local versus global information during visual object categorization remain unknown. In this study, pigeons were trained to categorize hierarchical stimuli that maintained consistency in local and global information. Subsequently, stimuli with different local and global components were presented to examine the pigeons' behavioral preferences. Not surprisingly, the behavioral findings revealed that pigeons predominantly attended to the local elements when performing categorization tasks. Moreover, MVL neurons exhibited significantly distinct responses when pigeons prioritized local versus global information. Specifically, most recording sites showed heightened gamma band power and increased nonlinear entropy values, indicating strong neural responses and rich information when pigeons concentrated on the local components of an object. Furthermore, neural population functional connectivity was weaker when the pigeons focused on local elements, suggesting that individual neurons operated more independently and effectively when focusing on local features. These findings offer electrophysiological evidence supporting the notion of pigeons displaying a behavioral preference for local information. The study provides valuable insight into the understanding of cognitive processes of pigeons when presented with complex objects, and further sheds light on the neural mechanisms underlying pigeons' behavioral preference for attending to local information.",,https://pubmed.ncbi.nlm.nih.gov/39622415/,English,Exclude,Outside date range,Different responses of MVL neurons when pigeons attend to local versus global information during object classification.,,,,,0.95,0.6,
pubmed:39622083,pubmed:39622083,PubMed,pubmed:39622083,Digital Twin for EEG seizure prediction using time reassigned Multisynchrosqueezing transform-based CNN-BiLSTM-Attention mechanism model.,Antara Ghosh;Debangshu Dey,2024,10.1088/2057-1976/ad992c,"The prediction of epileptic seizures is a classical research problem, representing one of the most challenging tasks in the analysis of brain disorders. There is active research into digital twins (DT) for various healthcare applications, as they can transform research into customized and personalized healthcare. The widespread adoption of DT technology relies on ample patient data to ensure precise monitoring and decision-making, leveraging Machine Learning (ML) and Deep Learning (DL) algorithms. Given the non-stationarity of EEG recordings, characterized by substantial frequency variations over time, there is a notable preference for advanced time-frequency methods in seizure prediction. This research proposes a DT-based seizure prediction system by applying an advanced time-frequency analysis approach known as Time-Reassigned MultiSynchroSqueezing Transform (TMSST) to EEG data to extract patient-specific impulse features and subsequently, a Deep Learning strategy, CNN-BiLSTM-Attention mechanism model is utilized in learning and classifying features for seizure prediction. The proposed architecture is named as 'Digital Twin-Net'. By estimating the group delay in the time direction, TMSST produces the frequency components that are responsible for the EEG signal's temporal behavior and those time-frequency signatures are learned by the developed CNN-BiLSTM-Attention mechanism model. Thus the combination acts as a digital twin of a patient for the prediction of epileptic seizures. The experimental results showed that the suggested approach achieved an accuracy of 99.70% when tested on 22 patients from the publicly accessible CHB-MIT dataset. The proposed method surpasses previous solutions in terms of overall performance. Consequently, the suggested method can be regarded as an efficient approach to EEG seizure prediction.",https://pubmed.ncbi.nlm.nih.gov/39622083/,https://pubmed.ncbi.nlm.nih.gov/39622083/,English,Include,,Digital Twin for EEG seizure prediction using time reassigned Multisynchrosqueezing transform-based CNN-BiLSTM-Attention mechanism model.,Include,,"M-Attention mechanism model. Thus the combination acts as a digital twin of a patient for the prediction of epileptic seizures. The experimental results showed that the suggested approach achieved an accuracy of 99.70% when tested on 22 patients from the publicly accessible CHB-MIT dataset. The proposed method surpasses previous solutions in terms of overall performance. Consequently, the suggeste",,0.95,0.6,
pubmed:39620625,pubmed:39620625,PubMed,pubmed:39620625,Neuronavigated Focalized Transcranial Direct Current Stimulation Administered During Functional Magnetic Resonance Imaging.,Filip Niemann;Alireza Shahbabaie;Sven Paßmann;Steffen Riemann;Robert Malinowski;Harun Kocataş;Leonardo M Caisachana Guevara;Mohamed Abdelmotaleb;Daria Antonenko;Felix Blankenburg;Rico Fischer;Gesa Hartwigsen;Shu-Chen Li;Michael A Nitsche;Axel Thielscher;Dagmar Timmann;Anna Fromm;Dayana Hayek;Ann-Kathrin Hubert;Andrew K Martin;Alexander Hunold;Agnes Flöel;Marcus Meinzer,2024,10.3791/67155,"Transcranial direct current stimulation (tDCS) is a noninvasive brain stimulation technique that allows the modulation of the excitability and plasticity of the human brain. Focalized tDCS setups use specific electrode arrangements to constrain the current flow to circumscribed brain regions. However, the effectiveness of focalized tDCS can be compromised by electrode positioning errors on the scalp, resulting in significant reductions of the current dose reaching the target brain regions for tDCS. Electrode placement guided by neuronavigation based on the individual's head and brain anatomy derived from structural magnetic resonance imaging (MRI) data may be suited to improve positioning accuracy. This protocol describes the method of neuronavigated electrode placement for a focalized tDCS setup, which is suitable for concurrent administration during functional MRI (fMRI). We also quantify the accuracy of electrode placement and investigate electrode drift in a concurrent tDCS-fMRI experiment. Critical steps involve the optimization of electrode positions based on current modeling that considers the individual's head and brain anatomy, the implementation of neuronavigated electrode placement on the scalp, and the administration of optimized and focal tDCS during fMRI. The regional precision of electrode placement is quantified using the Euclidean norm (L",,https://pubmed.ncbi.nlm.nih.gov/39620625/,English,Exclude,Not EEG-BCI focused,Neuronavigated Focalized Transcranial Direct Current Stimulation Administered During Functional Magnetic Resonance Imaging.,,,,,0.9,0.6,
pubmed:39619679,pubmed:39619679,PubMed,pubmed:39619679,Attention model of EEG signals based on reinforcement learning.,Wei Zhang;Xianlun Tang;Mengzhou Wang,2024,10.1109/jsen.2019.2956998,"Applying convolutional neural networks to a large number of EEG signal samples is computationally expensive because the computational complexity is linearly proportional to the number of dimensions of the EEG signal. We propose a new Gated Recurrent Unit (GRU) network model based on reinforcement learning, which considers the implementation of attention mechanisms in Electroencephalogram (EEG) signal processing scenarios as a reinforcement learning problem. The model can adaptively select target regions or position sequences from inputs and effectively extract information from EEG signals of different resolutions at multiple scales. Just as convolutional neural networks benefit from translation invariance, our proposed network also has a certain degree of translation invariance, making its computational complexity independent of the EEG signal dimension, thus maintaining a lower learning cost. Although the introduction of reinforcement learning makes the model non differentiable, we use policy gradient methods to achieve end-to-end learning of the model. We evaluated our proposed model on publicly available EEG dataset (BCI Competition IV-2a). The proposed model outperforms the current state-of-the-art techniques in the BCI Competition IV- 2a dataset with an accuracy of 86.78 and 71.54% for the subject-dependent and subject-independent modes, respectively. In the field of EEG signal processing, attention models that combine reinforcement learning principles can focus on key features, automatically filter out noise and redundant data, and improve the accuracy of signal decoding.",https://pubmed.ncbi.nlm.nih.gov/39619679/,https://pubmed.ncbi.nlm.nih.gov/39619679/,English,Include,,Attention model of EEG signals based on reinforcement learning.,Include,,"ated our proposed model on publicly available EEG dataset (BCI Competition IV-2a). The proposed model outperforms the current state-of-the-art techniques in the BCI Competition IV- 2a dataset with an accuracy of 86.78 and 71.54% for the subject-dependent and subject-independent modes, respectively. In the field of EEG signal processing, attention models that combine reinforcement learning principl",,0.95,0.6,
pubmed:39618710,pubmed:39618710,PubMed,pubmed:39618710,A review of epilepsy detection and prediction methods based on EEG signal processing and deep learning.,Xizhen Zhang;Xiaoli Zhang;Qiong Huang;Fuming Chen,2024,10.1109/access.2024.3406909,"Epilepsy is a chronic neurological disorder that poses significant challenges to patients and their families. Effective detection and prediction of epilepsy can facilitate patient recovery, reduce family burden, and streamline healthcare processes. Therefore, it is essential to propose a deep learning method for efficient detection and prediction of epileptic electroencephalography (EEG) signals. This paper reviews several key aspects of epileptic EEG signal processing, focusing on epilepsy detection and prediction. It covers publicly available epileptic EEG datasets, preprocessing techniques, feature extraction methods, and deep learning-based networks used in these tasks. The literature is categorized based on patient independence, distinguishing between patient-independent and non-patient-independent studies. Additionally, the evaluation methods are classified into general classification indicators and specific epilepsy prediction criteria, with findings organized according to the prediction cycles reported in various studies. The review reveals several important insights. Despite the availability of public datasets, they often lack diversity in epilepsy types and are collected under controlled conditions that may not reflect real-world scenarios. As a result, signal preprocessing methods tend to be limited and may not fully represent practical conditions. Feature extraction and network designs frequently emphasize fusion mechanisms, with recent advances in Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) showing promising results, suggesting that new network models warrant further exploration. Studies using patient-independent data generally produce better results than those relying on non-patient-independent data. Metrics based on general classification methods typically perform better than those using specific epilepsy prediction criteria, though future research should focus on the latter for more accurate evaluation. Epilepsy prediction cycles are typically kept under 1 h, with most studies concentrating on intervals of 30 min or less.",,https://pubmed.ncbi.nlm.nih.gov/39618710/,English,Exclude,Review/survey papers,A review of epilepsy detection and prediction methods based on EEG signal processing and deep learning.,,,,,0.95,0.6,
pubmed:39616883,pubmed:39616883,PubMed,pubmed:39616883,Brain-scale theta band functional connectome as signature of slow breathing and breath-hold phases.,Anusha A S;Pradeep Kumar G;A G Ramakrishnan,2025,10.1016/j.compbiomed.2024.109435,"The study reported herein attempts to understand the neural mechanisms engaged in the conscious control of breathing and breath-hold. The variations in the electroencephalogram (EEG) based functional connectivity (FC) of the human brain have been investigated during attentive breathing at 2 cycles per minute (cpm). The study presents its novelty through three main aspects. First, it explores the complex breathing circuitry beyond the brain stem, specifically examining how higher brain regions interact with respiratory cycles. Second, unlike previous studies that treated respiratory phases as a singular phenomenon, this research analyses inhalation, exhalation, and breath-holds separately, providing a deeper understanding of their individual dynamics and FC in the brain. Finally, the breathing protocol is designed to include inhale-hold and exhale-hold sessions alongside symmetric breathing, allowing for testing on healthy subjects rather than specialized cohorts, which were used in earlier studies. An experimental protocol involving equal durations of inhale, inhale-hold, exhale, and exhale-hold conditions, synchronized to a visual metronome, was designed and administered to 20 healthy subjects (9 females and 11 males, age: 32.0 ± 9.5 years (mean ± SD)). EEG data were collected during these sessions using the 64-channel eego™ mylab system from ANT Neuro. Further, FC was estimated for all possible pairs of EEG time series data, for 7 EEG bands. Feature selection using a genetic algorithm (GA) was performed to identify a subset of functional connections that would best distinguish the inhale, inhale-hold, exhale, and exhale-hold phases using a random committee classifier. The best accuracy of 95.056% was obtained when 403 theta-band functional connections were fed as input to the classifier, highlighting the efficacy of the theta-band functional connectome in distinguishing these phases of the respiratory cycle. This functional network was further characterized using graph measures, and observations illustrated a statistically significant difference in the efficiency of information exchange through the network during different respiratory phases.",,https://pubmed.ncbi.nlm.nih.gov/39616883/,English,Exclude,Outside date range,Brain-scale theta band functional connectome as signature of slow breathing and breath-hold phases.,,,,,0.95,0.6,
pubmed:39616638,pubmed:39616638,PubMed,pubmed:39616638,Integration of a lightweight and table-mounted robotic alignment tool with automated patient-to-image registration using robotic cone-beam CT for intracranial biopsies and stereotactic electroencephalography.,Peter Truckenmueller;Anton Früh;Johannes Felix Kissner;Nadja Katharina Moser;Martin Misch;Katharina Faust;Julia Onken;Peter Vajkoczy;Ran Xu,2024,10.3171/2024.9.focus24525,"Robotics in neurosurgery is becoming increasingly prevalent. The integration of intraoperative imaging for patient registration into workflows of newer robotic systems enhances precision and has further driven their widespread adoption. In this study, the authors report on a lightweight, table-mounted robotic system integrating robotic cone-beam CT (CB-CT) for automated patient registration in cranial biopsies and stereotactic electroencephalography (sEEG). This prospective cohort study included patients who underwent stereotactic biopsy or sEEG with the Cirq system from January 2023 to August 2024. For patient-to-image registration, an external registration matrix was secured near the patient's head before conducting CB-CT with robotic Artis Pheno. CT was then fused with preoperative planning MRI and used as the navigation dataset. Demographic and clinical data were evaluated, and entry and target errors, as well as vector deviation of sEEG electrodes, were assessed and compared with those of patients who underwent biopsies and sEEG with the frameless VarioGuide system. In 26 Cirq-assisted surgical procedures, robotic CB-CT was used for image registration in 20 cases. Of these, 15 were biopsies (mean ± SD 7 ± 1 specimens) and 5 were sEEG with 31 depth electrodes, compared to 29 VarioGuide biopsies and 3 VarioGuide sEEG cases with 25 electrodes. The mean age was 56 ± 19 years, with a male/female ratio of 1.9:1. Lesion size averaged 19 ± 17 cm3 on T1-weighted imaging and 61 ± 53 cm3 on T2-weighted imaging for Cirq and 14 ± 14 cm3 and 68 ± 47 cm3 for VarioGuide. The mean surgical times were 117 ± 34 minutes for biopsy and 269 ± 54 minutes for sEEG in the Cirq group, with skin-to-skin times of 40 ± 23 minutes for biopsy and 208 ± 74 minutes for sEEG; in comparison, surgical times of 78 ± 21 minutes for biopsy and 218 ± 33 minutes for sEEG were reported with VarioGuide, with skin-to-skin times of 34 ± 13 and 158 ± 27 minutes. No complications occurred. The mean dosage area product was 983 ± 351 µGym2 for biopsies and 1772 ± 968 µGym2 for sEEG. Cirq-assisted sEEG electrodes had mean entry and target errors of 1.4 ± 1.2 mm and 2.6 ± 1.6 mm, compared to 5.3 ± 3.3 mm and 6.5 ± 2.8 mm with VarioGuide. Mean vector deviation was 1.6 ± 0.9 mm with Cirq versus 4.9 ± 2.9 mm with VarioGuide. The integration of a lightweight, table-mounted robotic alignment tool with intraoperative CB-CT for automated patient-to-image registration enables high precision and a seamless workflow. This combination is safe, has a manageable learning curve, and holds potential to replace traditional frame-based and frameless procedures. Its efficiency and accuracy are likely to contribute to the increasing adoption of robotics in neurosurgery.",https://pubmed.ncbi.nlm.nih.gov/39616638/,https://pubmed.ncbi.nlm.nih.gov/39616638/,English,Include,,Integration of a lightweight and table-mounted robotic alignment tool with automated patient-to-image registration using robotic cone-beam CT for intracranial biopsies and stereotactic electroencephalography.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39615554,pubmed:39615554,PubMed,pubmed:39615554,Multi-layer transfer learning algorithm based on improved common spatial pattern for brain-computer interfaces.,Zhuo Cai;Yunyuan Gao;Feng Fang;Yingchun Zhang;Shunlan Du,2025,10.1016/j.jneumeth.2024.110332,"In the application of brain-computer interface, the differences in imaging methods and brain structure between subjects hinder the effectiveness of decoding algorithms when applied on different subjects. Transfer learning has been designed to solve this problem. There have been many applications of transfer learning in motor imagery (MI), however the effectiveness is still limited due to the inconsistent domain alignment, lack of prominent data features and allocation of weights in trails. In this paper, a Multi-layer transfer learning algorithm based on improved Common Spatial Patterns (MTICSP) was proposed to solve these problems. Firstly, the source domain data and target domain data were aligned by Target Alignment (TA)method to reduce distribution differences between subjects. Secondly, the mean covariance matrix of the two classes was re-weighted by calculating the distance between the covariance matrix of each trial in the source domain and the target domain. Thirdly, the improved Common Spatial Patterns (CSP) by introducing regularization coefficient was proposed to further reduce the difference between source domain and target domain to extract features. Finally, the feature blocks of the source domain and target domain were aligned again by Joint Distribution Adaptation (JDA) method. Experiments on two public datasets in two transfer paradigms multi-source to single-target (MTS) and single-source to single-target (STS) verified the effectiveness of our proposed method. The MTS and STS in the 5-person dataset were 80.21% and 77.58%, respectively, and 80.10% and 73.91%, respectively, in the 9-person dataset. Experimental results also showed that the proposed algorithm was superior to other state-of-the-art algorithms. In addition, the generalization ability of our algorithm MTICSP was validated on the fatigue EEG dataset collected by ourselves, and obtained 94.83% and 87.41% accuracy in MTS and STS experiments respectively. The proposed method combines improved CSP with transfer learning to extract the features of source and target domains effectively, providing a new method for combining transfer learning with motor imagination.",,https://pubmed.ncbi.nlm.nih.gov/39615554/,English,Exclude,Outside date range,Multi-layer transfer learning algorithm based on improved common spatial pattern for brain-computer interfaces.,,,,,0.95,0.6,
pubmed:39615261,pubmed:39615261,PubMed,pubmed:39615261,Combining three-phase EEG pattern and ipsilateral isolated eye deviation to predict seizure focus in the frontal interhemispheric fissure.,Mitsuyo Nishimura;Ayataka Fujimoto;Tohru Okanishi;Yosuke Masuda;Kota Araki;Hideo Enoki;Eiichi Ishikawa,2025,10.1016/j.yebeh.2024.110175,"Identification of seizure focus on the interhemispheric fissure (IHF) is often challenging at the step of scalp video-EEG monitoring on preoperative evaluations. We previously reported ictal three-phase EEG patterns (3Ph-EEG) and isolated eye deviation (isolated ED) to side of the seizure focus during seizures, each of which is available for identifying the seizure focus for frontal IHF (F-IHF). This study aimed to evaluate the accuracy of predicting the F-IHF focus using a combination of 3Ph-EEG and isolated ED in patients with frontal lobe epilepsy and the accuracy of predicting lateralization of the F-IHF focus using the predominance of findings. We collected 15 patients diagnosed with frontal lobe epilepsy showing clinical seizures arising only from the frontal lobe, from 131 patients with intracranial video-EEG performed between January 2012 and December 2019. All 15 patients were classified into the IHF group (n = 7) and the extra-IHF group (n = 8) based on intracranial video-EEG. We statistically evaluated the accuracies of predicting F-IHF onset using combinations of 3Ph-EEG and isolated ED on scalp-EEG: 1) 3Ph-EEG (+); 2) isolated ED (+); 3) 3Ph-EEG (+) and/or isolated ED (+); and 4) 3Ph-EEG (+) and isolated ED (+). We also evaluated the accuracy of predicting focus lateralization using 3Ph-EEG and isolated ED. Both 3Ph-EEG (+) and isolated ED (+) demonstrated good accuracy for identifying F-IHF foci. They showed identical sensitivities of 71.4 %, with odds ratios of 7.5 for 3Ph-EEG (+) and 17.5 for isolated ED (+), respectively. Only the combination of 3Ph-EEG (+) and/or isolated ED (+) showed significant associations (p = 0.007). This combination demonstrated the highest sensitivity (100 %) and modified odds ratio (39.0), indicating that all patients in the IHF group exhibited at least one of the following: 3Ph-EEG or isolated ED. The combination of 3Ph-EEG (+) and isolated ED (+) offered one of the highest specificities, at 87.5 %. To predict lateralization with the F-IHF focus, both the predominant side for the third phase of 3Ph-EEG (n = 5) and the direction of isolated ED (n = 5) were perfectly concordant with the F-IHF focus side (100 % for both). The combination of 3Ph-EEG and isolated ED can detect the IHF seizure focus with higher sensitivity in patients with frontal lobe epilepsy compared with using each method individually. Moreover, the absence of these two features eliminated the possibility of an F-IHF focus. Based on 3Ph-EEG and the direction of isolated ED, the focus side could presume lateralization of the F-IHF focus. Combining 3Ph-EEG and ipsilateral isolated ED at presurgical evaluation may help in designating locations for intracranial EEG electrodes.",,https://pubmed.ncbi.nlm.nih.gov/39615261/,English,Exclude,Outside date range,Combining three-phase EEG pattern and ipsilateral isolated eye deviation to predict seizure focus in the frontal interhemispheric fissure.,,,,,0.95,0.6,
pubmed:39614100,pubmed:39614100,PubMed,pubmed:39614100,Disrupted working memory event-related network dynamics in multiple sclerosis.,Chiara Rossi;Diego Vidaurre;Lars Costers;Marie B D'hooghe;Fahimeh Akbarian;Miguel D'haeseleer;Mark Woolrich;Guy Nagels;Jeroen Van Schependom,2024,10.1038/s42003-024-07283-2,"In multiple sclerosis (MS), working memory (WM) impairment can occur soon after disease onset and significantly affects the patient's quality of life. Functional imaging research in MS aims to investigate the neurophysiological underpinnings of WM impairment. In this context, we utilize a data-driven technique, the time delay embedded-hidden Markov model, to extract spectrally defined functional networks in magnetoencephalographic (MEG) data acquired during a WM visual-verbal n-back task. Here, we show that the activation of two networks is altered in relapsing remitting-MS patients. First, the activation of an early theta prefrontal network linked to stimulus encoding and attentional control significantly decreases in MS compared to HC. This diminished activation correlates with reduced accuracy and higher reaction time, suggesting that impaired attention control impacts task performance in MS patients. Secondly, a frontoparietal network characterized by beta coupling is activated between 300 and 600 ms post-stimulus, resembling the event-related P300, a cognitive marker extensively explored in EEG studies. The activation of this network is amplified in patients treated with benzodiazepine, in line with the well-known benzodiazepine-induced beta enhancement. Altogether, the TDE-HMM technique extracts task-relevant functional networks showing disease-specific and treatment-related alterations, revealing potential new markers to assess and track WM impairment in MS.",https://pubmed.ncbi.nlm.nih.gov/39614100/,https://pubmed.ncbi.nlm.nih.gov/39614100/,English,Include,,Disrupted working memory event-related network dynamics in multiple sclerosis.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39612132,pubmed:39612132,PubMed,pubmed:39612132,An adaptive session-incremental broad learning system for continuous motor imagery EEG classification.,Yufei Yang;Mingai Li;Linlin Wang,2025,10.1109/tetci.2023.3301385,"Motor imagery electroencephalography (MI-EEG) is usually used as a driving signal in neuro-rehabilitation systems, and its feature space varies with the recovery progress. It is required to endow the recognition model with continuous learning and self-updating capability. Broad learning system (BLS) can be remodeled in an efficient incremental learning way. However, its architecture is intractable to change automatically to adapt to new incoming MI-EEG with time-varying and complex temporal-spatial characteristics. In this paper, an adaptive session-incremental BLS (ASiBLS) is proposed based on mutual information theory and BLS. For the initial session data, a compact temporal-spatial feature extractor (CTS) is designed to acquire the temporal-spatial features, which are input to a baseline BLS (bBLS). Furthermore, for new session data, a mutual information maximization constraint (MIMC) is introduced into the loss function of CTS to make the features' probability distribution sufficiently similar to that of the previous session, a new incremental BLS sequence (iBLS) is obtained by adding a small number of nodes to the previous model, and so on. Experiments are conducted based on the BCI Competition IV-2a dataset with two sessions and IV-2b dataset with five sessions, ASiBLS achieves average decoding accuracies of 79.89% and 87.04%, respectively. The kappa coefficient and forgetting rate are also used to evaluate the model performance. The results show that ASiBLS can adaptively generate an optimized and reduced model for each session successively, which has better plasticity in learning new knowledge and stability in retaining old knowledge as well.",,https://pubmed.ncbi.nlm.nih.gov/39612132/,English,Exclude,Outside date range,An adaptive session-incremental broad learning system for continuous motor imagery EEG classification.,,,,,0.95,0.6,
pubmed:39612043,pubmed:39612043,PubMed,pubmed:39612043,A Novel Real-time Phase Prediction Network in EEG Rhythm.,Hao Liu;Zihui Qi;Yihang Wang;Zhengyi Yang;Lingzhong Fan;Nianming Zuo;Tianzi Jiang,2025,10.1007/s12264-024-01321-z,"Closed-loop neuromodulation, especially using the phase of the electroencephalography (EEG) rhythm to assess the real-time brain state and optimize the brain stimulation process, is becoming a hot research topic. Because the EEG signal is non-stationary, the commonly used EEG phase-based prediction methods have large variances, which may reduce the accuracy of the phase prediction. In this study, we proposed a machine learning-based EEG phase prediction network, which we call EEG phase prediction network (EPN), to capture the overall rhythm distribution pattern of subjects and map the instantaneous phase directly from the narrow-band EEG data. We verified the performance of EPN on pre-recorded data, simulated EEG data, and a real-time experiment. Compared with widely used state-of-the-art models (optimized multi-layer filter architecture, auto-regress, and educated temporal prediction), EPN achieved the lowest variance and the greatest accuracy. Thus, the EPN model will provide broader applications for EEG phase-based closed-loop neuromodulation.",,https://pubmed.ncbi.nlm.nih.gov/39612043/,English,Exclude,Outside date range,A Novel Real-time Phase Prediction Network in EEG Rhythm.,,,,,0.95,0.6,
pubmed:39610866,pubmed:39610866,PubMed,pubmed:39610866,Dynamic multilayer networks reveal mind wandering.,Zhongming Xu;Shaohua Tang;Zengru Di;Zheng Li,2024,10.3389/fpsyg.2019.00216,"Mind-wandering is a highly dynamic phenomenon involving frequent fluctuations in cognition. However, the dynamics of functional connectivity between brain regions during mind-wandering have not been extensively studied. We employed an analytical approach aimed at extracting recurring network states of multilayer networks built using amplitude envelope correlation and imaginary phase-locking value of delta, theta, alpha, beta, or gamma frequency band. These networks were constructed based on electroencephalograph (EEG) data collected while participants engaged in a video-learning task with mind-wandering and focused learning conditions. Recurring multilayer network states were defined via clustering based on overlapping node closeness centrality. We observed similar multilayer network states across the five frequency bands. Furthermore, the transition patterns of network states were not entirely random. We also found significant differences in metrics that characterize the dynamics of multilayer network states between mind-wandering and focused learning. Finally, we designed a classification algorithm, based on a hidden Markov model using state sequences as input, that achieved a 0.888 mean area under the receiver operating characteristic curve for within-participant detection of mind-wandering. Our approach offers a novel perspective on analyzing the dynamics of EEG data and shows potential application to mind-wandering detection.",https://pubmed.ncbi.nlm.nih.gov/39610866/,https://pubmed.ncbi.nlm.nih.gov/39610866/,English,Include,,Dynamic multilayer networks reveal mind wandering.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39608032,pubmed:39608032,PubMed,pubmed:39608032,EEG headbands vs caps: How many electrodes do I need to detect emotions? The case of the MUSE headband.,Francisco M Garcia-Moreno;Marta Badenes-Sastre;Francisca Expósito;Maria Jose Rodriguez-Fortiz;Maria Bermudez-Edo,2025,10.1016/j.compbiomed.2024.109463,"In the realm of emotion detection, comfort and portability play crucial roles in enhancing user experiences. However, few works study the reduction in the number of electrodes used to detect emotions, and none of them compare the location of these electrodes with a commercial low-cost headband. This work explores the potential of wearable EEG devices, specifically the Muse S headband, for emotion classification in terms of valence and arousal. We conducted a direct comparison between the Muse S, with its only four electrodes, and the DEAP dataset, which employs 32-electrode in a more intrusive headset. DEAP is a benchmark dataset constructed by emotions elicited by music. Our methodology focused on utilizing raw data and extracting four common frequency ranges. In particular, we select from DEAP the 4 electrodes that are similar to those in the Muse S. Additionally, we created a dataset using the Muse S, where we segmented the complete video into fixed-size temporal windows. Our 4-electrodes dataset uses film clips to elicit emotions, classified according to the Self-Assessment Manikin. Our findings indicate that the Muse S, despite its limited electrode count, can effectively discriminate between high and low valence/arousal emotions with accuracy comparable to the accuracy obtained with all the DEAP electrodes. The Gamma band emerged as particularly effective for valence detection. Using a Muse device and raw data, the best performance achieved a G-Mean only 1-2% lower than that of the DEAP dataset, demonstrating that comparable results can be obtained with a simplified setup. While the Muse-S did not reach DEAP in terms of outcomes, it proved to be a viable, lower-cost, less intrusive alternative, and adaptable for everyday use. The dataset created for this study is publicly available at https://doi.org/10.5281/zenodo.8431451.",,https://pubmed.ncbi.nlm.nih.gov/39608032/,English,Exclude,Outside date range,EEG headbands vs caps: How many electrodes do I need to detect emotions? The case of the MUSE headband.,,,,,0.95,0.6,
pubmed:39606789,pubmed:39606789,PubMed,pubmed:39606789,Beta-gamma phase-amplitude coupling of scalp electroencephalography during walking preparation in Parkinson's disease differs depending on the freezing of gait.,Yuki Kimoto;Naoki Tani;Takuto Emura;Takahiro Matsuhashi;Takuto Yamamoto;Yuya Fujita;Satoru Oshino;Koichi Hosomi;Hui Ming Khoo;Shimpei Miura;Takahiro Fujinaga;Takufumi Yanagisawa;Haruhiko Kishima,2024,10.1093/brain/awac121,"Despite using beta oscillations within the subthalamic nucleus as a biomarker of akinesia or rigidity in Parkinson's disease, a specific biomarker for freezing of gait (FOG) remains unclear. Recently, scalp phase-amplitude coupling (PAC) measured through scalp electroencephalography (EEG) has emerged as a promising tool for analyzing brain function. In this study, we examined whether PAC could be a biomarker for FOG. We enrolled 11 patients with Parkinson's disease and recorded scalp EEG in preparation for and during gait while simultaneously assessing motor function, including FOG. We investigated changes in cortical PAC during walking with and without FOG and examined its correlation with the postural instability and gait difficulty (PIGD) score. Patient characteristics were as follows: mean age 59.1 ± 6.9 years, disease duration 13.9 ± 4.1 years, and seven men. Four trials were excluded from the analysis owing to artifacts. In the trials without FOG ( Beta-gamma PAC in the sensorimotor area during preparation for walking differs depending on the emergence of FOG. As gait symptoms worsened, beta-gamma PAC in the sensorimotor area during walking gradually increased. Cortical PAC may be a biomarker for FOG in Parkinson's disease and may lead to the development of strategies to prevent falls in the future.",,https://pubmed.ncbi.nlm.nih.gov/39606789/,English,Exclude,Not classification-focused,Beta-gamma phase-amplitude coupling of scalp electroencephalography during walking preparation in Parkinson's disease differs depending on the freezing of gait.,,,,,0.85,0.6,
pubmed:39601188,pubmed:39601188,PubMed,pubmed:39601188,ILAE neonatal seizure framework to aide in determining etiology.,Elissa G Yozawitz;Maria Roberta Cilio;Eli M Mizrahi;Jee-Young Moon;Solomon L Moshé;Magda L Nunes;Perrine Plouin;Sameer Zuberi;Ronit M Pressler,2025,10.1002/epd2.20312,"To employ the neonatal seizure framework developed by the International League Against Epilepsy (ILAE) Neonatal Task force to assess its usefulness in determining the etiology of neonatal seizures. The members of the ILAE Neonatal Task Force evaluated 157 seizures from 146 neonates to determine internal validity and associations between semiology and a specific etiology. Provoked neonatal electrographic and electroclinical seizures were due to multiple etiologies. For electroclinical seizures, unilateral clonic seizures were typically seen with vascular etiologies, focal tonic seizures and sequential seizures with genetic etiologies, and myoclonic seizures with inborn errors of metabolism. Electrographic seizures were often seen in hypoxic-ischemic encephalopathy or vascular etiologies. These data suggest that the ILAE neonatal seizure classification may be used as a bedside tool to aid and guide workup to determine the etiology of seizures.",,https://pubmed.ncbi.nlm.nih.gov/39601188/,English,Exclude,Outside date range,ILAE neonatal seizure framework to aide in determining etiology.,,,,,0.95,0.6,
pubmed:39601012,pubmed:39601012,PubMed,pubmed:39601012,Quantitative assessment of neurodevelopmental maturation: a comprehensive systematic literature review of artificial intelligence-based brain age prediction in pediatric populations.,Eric Dragendorf;Eva Bültmann;Dominik Wolff,2024,10.1016/j.neuroimage.2019.01.006,"Over the past few decades, numerous researchers have explored the application of machine learning for assessing children's neurological development. Developmental changes in the brain could be utilized to gauge the alignment of its maturation status with the child's chronological age. AI is trained to analyze changes in different modalities and estimate the brain age of subjects. Disparities between the predicted and chronological age can be viewed as a biomarker for a pathological condition. This literature review aims to illuminate research studies that have employed AI to predict children's brain age. The inclusion criteria for this study were predicting brain age via AI in healthy children up to 12 years. The search term was centered around the keywords ""pediatric,"" ""artificial intelligence,"" and ""brain age"" and was utilized in PubMed and IEEEXplore. The selected literature was then examined for information on data acquisition methods, the age range of the study population, pre-processing, methods and AI techniques utilized, the quality of the respective techniques, model explanation, and clinical applications. Fifty one publications from 2012 to 2024 were included in the analysis. The primary modality of data acquisition was MRI, followed by EEG. Structural and functional MRI-based studies commonly used publicly available datasets, while EEG-based studies typically relied on self-recruitment. Many studies utilized pre-processing pipelines provided by toolkit suites, particularly in MRI-based research. The most frequently used model type was kernel-based learning algorithms, followed by convolutional neural networks. Overall, prediction accuracy may improve when multiple acquisition modalities are used, but comparing studies is challenging. In EEG, the prediction error decreases as the number of electrodes increases. Approximately one-third of the studies used explainable artificial intelligence methods to explain the model and chosen parameters. However, there is a significant clinical translation gap as no study has tested their model in a clinical routine setting. Further research should test on external datasets and include low-quality routine images for MRI. T2-weighted MRI was underrepresented. Furthermore, different kernel types should be compared on the same dataset. Implementing modern model architectures, such as convolutional neural networks, should be the next step in EEG-based research studies.",,https://pubmed.ncbi.nlm.nih.gov/39601012/,English,Exclude,Review/survey papers,Quantitative assessment of neurodevelopmental maturation: a comprehensive systematic literature review of artificial intelligence-based brain age prediction in pediatric populations.,,,,,0.95,0.6,
pubmed:39599153,pubmed:39599153,PubMed,pubmed:39599153,A Novel and Powerful Dual-Stream Multi-Level Graph Convolution Network for Emotion Recognition.,Guoqiang Hou;Qiwen Yu;Guang Chen;Fan Chen,2024,10.1016/j.eswa.2024.123550,"Emotion recognition enables machines to more acutely perceive and understand users' emotional states, thereby offering more personalized and natural interactive experiences. Given the regularity of the responses of brain activity to human cognitive processes, we propose a powerful and novel dual-stream multi-level graph convolution network (DMGCN) with the ability to capture the hierarchies of connectivity between cerebral cortex neurons and improve computational efficiency. This consists of a hierarchical dynamic geometric interaction neural network (HDGIL) and multi-level feature fusion classifier (M2FC). First, the HDGIL diversifies representations by learning emotion-related representations in multi-level graphs. Subsequently, M2FC integrates advantages from methods for early and late feature fusion and enables the addition of more details to final representations from EEG samples. We conducted extensive experiments to validate the superiority of our model over numerous state-of-the-art (SOTA) baselines in terms of classification accuracy, the efficiency of graph embedding and information propagation, achieving accuracies of 98.73%, 95.97%, 72.74% and 94.89% for our model as well as increases of up to 0.59%, 0.32%, 2.24% and 3.17% over baselines on the DEAP-Arousal, DEAP-Valence, DEAP and SEED datasets, respectively. Additionally, these experiments demonstrated the effectiveness of each module for emotion recognition tasks.",https://pubmed.ncbi.nlm.nih.gov/39599153/,https://pubmed.ncbi.nlm.nih.gov/39599153/,English,Include,,A Novel and Powerful Dual-Stream Multi-Level Graph Convolution Network for Emotion Recognition.,Include,,"tails to final representations from EEG samples. We conducted extensive experiments to validate the superiority of our model over numerous state-of-the-art (SOTA) baselines in terms of classification accuracy, the efficiency of graph embedding and information propagation, achieving accuracies of 98.73%, 95.97%, 72.74% and 94.89% for our model as well as increases of up to 0.59%, 0.32%, 2.24% and 3",,0.95,0.6,
pubmed:39598903,pubmed:39598903,PubMed,pubmed:39598903,Electroencephalography-Based Brain-Computer Interfaces in Rehabilitation: A Bibliometric Analysis (2013-2023).,Ana Sophia Angulo Medina;Maria Isabel Aguilar Bonilla;Ingrid Daniela Rodríguez Giraldo;John Fernando Montenegro Palacios;Danilo Andrés Cáceres Gutiérrez;Yamil Liscano,2024,10.1007/s12152-021-09468-6,"EEG-based Brain-Computer Interfaces (BCIs) have gained significant attention in rehabilitation due to their non-invasive, accessible ability to capture brain activity and restore neurological functions in patients with conditions such as stroke and spinal cord injuries. This study offers a comprehensive bibliometric analysis of global EEG-based BCI research in rehabilitation from 2013 to 2023. It focuses on primary research and review articles addressing technological innovations, effectiveness, and system advancements in clinical rehabilitation. Data were sourced from databases like Web of Science, and bibliometric tools (bibliometrix R) were used to analyze publication trends, geographic distribution, keyword co-occurrences, and collaboration networks. The results reveal a rapid increase in EEG-BCI research, peaking in 2022, with a primary focus on motor and sensory rehabilitation. EEG remains the most commonly used method, with significant contributions from Asia, Europe, and North America. Additionally, there is growing interest in applying BCIs to mental health, as well as integrating artificial intelligence (AI), particularly machine learning, to enhance system accuracy and adaptability. However, challenges remain, such as system inefficiencies and slow learning curves. These could be addressed by incorporating multi-modal approaches and advanced neuroimaging technologies. Further research is needed to validate the applicability of EEG-BCI advancements in both cognitive and motor rehabilitation, especially considering the high global prevalence of cerebrovascular diseases. To advance the field, expanding global participation, particularly in underrepresented regions like Latin America, is essential. Improving system efficiency through multi-modal approaches and AI integration is also critical. Ethical considerations, including data privacy, transparency, and equitable access to BCI technologies, must be prioritized to ensure the inclusive development and use of these technologies across diverse socioeconomic groups.",,https://pubmed.ncbi.nlm.nih.gov/39598903/,English,Exclude,Review/survey papers,Electroencephalography-Based Brain-Computer Interfaces in Rehabilitation: A Bibliometric Analysis (2013-2023).,,,,,0.95,0.6,
pubmed:39598300,pubmed:39598300,PubMed,pubmed:39598300,Decoding Imagined Speech from EEG Data: A Hybrid Deep Learning Approach to Capturing Spatial and Temporal Features.,Yasser F Alharbi;Yousef A Alotaibi,2024,10.1109/bci53720.2022.9734827,"Neuroimaging is revolutionizing our ability to investigate the brain's structural and functional properties, enabling us to visualize brain activity during diverse mental processes and actions. One of the most widely used neuroimaging techniques is electroencephalography (EEG), which records electrical activity from the brain using electrodes positioned on the scalp. EEG signals capture both spatial (brain region) and temporal (time-based) data. While a high temporal resolution is achievable with EEG, spatial resolution is comparatively limited. Consequently, capturing both spatial and temporal information from EEG data to recognize mental activities remains challenging. In this paper, we represent spatial and temporal information obtained from EEG signals by transforming EEG data into sequential topographic brain maps. We then apply hybrid deep learning models to capture the spatiotemporal features of the EEG topographic images and classify imagined English words. The hybrid framework utilizes a sequential combination of three-dimensional convolutional neural networks (3DCNNs) and recurrent neural networks (RNNs). The experimental results reveal the effectiveness of the proposed approach, achieving an average accuracy of 77.8% in identifying imagined English speech.",https://pubmed.ncbi.nlm.nih.gov/39598300/,https://pubmed.ncbi.nlm.nih.gov/39598300/,English,Include,,Decoding Imagined Speech from EEG Data: A Hybrid Deep Learning Approach to Capturing Spatial and Temporal Features.,Include,,"tion of three-dimensional convolutional neural networks (3DCNNs) and recurrent neural networks (RNNs). The experimental results reveal the effectiveness of the proposed approach, achieving an average accuracy of 77.8% in identifying imagined English speech.",,0.95,0.6,
pubmed:39595919,pubmed:39595919,PubMed,pubmed:39595919,Impact of Situation Awareness Variations on Multimodal Physiological Responses in High-Speed Train Driving.,Wenli Dong;Weining Fang;Hanzhao Qiu;Haifeng Bao,2024,10.1038/s41598-019-50280-3,"In safety-critical environments, human error is a leading cause of accidents, with the loss of situation awareness (SA) being a key contributing factor. Accurate SA assessment is essential for minimizing such risks and ensuring operational safety. Traditional SA measurement methods have limitations in dynamic real-world settings, while physiological signals, particularly EEG, offer a non-invasive, real-time alternative for continuous SA monitoring. However, the reliability of SA measurement based on physiological signals depends on the accuracy of SA labeling. This study aims to design an effective SA measurement paradigm specific to high-speed train driving, investigate more accurate physiological signal-based SA labeling methods, and explore the relationships between SA levels and key physiological metrics based on the developed framework. This study recruited 19 male high-speed train driver trainees and developed an SA measurement paradigm specific to high-speed train driving. A method combining subjective SA ratings and task performance was introduced to generate accurate SA labels. The results of statistical analysis confirmed the effectiveness of this paradigm in inducing SA level changes, revealing significant relationships between SA levels and key physiological metrics, including eye movement patterns, ECG features (e.g., heart rate variability), and EEG power spectral density across theta, alpha, and beta bands. This study supports the use of multimodal physiological signals for SA assessment and provides a theoretical foundation for future applications of SA monitoring in railway operations, contributing to enhanced operational safety.",https://pubmed.ncbi.nlm.nih.gov/39595919/,https://pubmed.ncbi.nlm.nih.gov/39595919/,English,Include,,Impact of Situation Awareness Variations on Multimodal Physiological Responses in High-Speed Train Driving.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39595852,pubmed:39595852,PubMed,pubmed:39595852,Seizure Onset Zone Detection Based on Convolutional Neural Networks and EEG Signals.,Zhejun Kuang;Liming Guo;Jingrui Wang;Jian Zhao;Liu Wang;Kangwei Geng,2024,10.1016/j.yebeh.2009.02.035,"The localization of seizure onset zones (SOZs) is a critical step before the surgical treatment of epilepsy. In this paper, we propose an SOZ detection method based on convolutional neural networks and EEG signals. This method aims to locate SOZs through the seizure status of each channel in multi-channel EEG signals. First, we preprocess the data with filtering, segmentation, resampling, and standardization to ensure their quality and consistency. Then, the single-channel UCI epilepsy seizure recognition dataset is used to train and test the convolutional neural network (CNN) model, achieving an accuracy of 98.70%, a sensitivity of 97.53%, and a specificity of 98.98%. Next, the multi-channel clinical EEG dataset collected by a hospital is divided into 21 single-channel site datasets and input into the model for detection, and then the seizure results of 21 sites per second are obtained. Finally, the seizure sites are visualized through the international 10-20 system electrode distribution map, diagrams of the change process of the seizure sites during seizures are drawn, and patients' SOZs are located. Our proposed method well classifies seizure and non-seizure data and successfully locates SOZs by detecting the seizure results of 21 sites through a single-channel model. This study can effectively assist doctors in locating the SOZs of patients and provide help for the diagnosis and treatment of epilepsy.",https://pubmed.ncbi.nlm.nih.gov/39595852/,https://pubmed.ncbi.nlm.nih.gov/39595852/,English,Include,,Seizure Onset Zone Detection Based on Convolutional Neural Networks and EEG Signals.,Include,,"ization to ensure their quality and consistency. Then, the single-channel UCI epilepsy seizure recognition dataset is used to train and test the convolutional neural network (CNN) model, achieving an accuracy of 98.70%, a sensitivity of 97.53%, and a specificity of 98.98%. Next, the multi-channel clinical EEG dataset collected by a hospital is divided into 21 single-channel site datasets and input",,0.95,0.6,
pubmed:39595850,pubmed:39595850,PubMed,pubmed:39595850,Single-Channel Sleep EEG Classification Method Based on LSTM and Hidden Markov Model.,Wan Chen;Yanping Cai;Aihua Li;Yanzhao Su;Ke Jiang,2024,10.1007/s10439-015-1444-y,"The single-channel sleep EEG has the advantages of convenient collection, high-cost performance, and easy daily use, and it has been widely used in the classification of sleep stages. This paper proposes a single-channel sleep EEG classification method based on long short-term memory and a hidden Markov model (LSTM-HMM). First, the single-channel EEG is decomposed using wavelet transform (WT), and multi-domain features are extracted from the component signals to characterize the EEG characteristics fully. Considering the temporal nature of sleep stage changes, this paper uses a multi-step time series as the input for the model. After that, the multi-step time series features are input into the LSTM. Finally, the HMM improves the classification results, and the final prediction results are obtained. A complete experiment was conducted on the Sleep-EDFx dataset. The results show that the proposed method can extract deep information from EEG and make full use of the sleep stage transition rule. The proposed method shows the best performance in single-channel sleep EEG classification; the accuracy, macro average F1 score, and kappa are 82.71%, 0.75, and 0.76, respectively. The proposed method can realize single-channel sleep EEG classification and provide a reference for other EEG classifications.",https://pubmed.ncbi.nlm.nih.gov/39595850/,https://pubmed.ncbi.nlm.nih.gov/39595850/,English,Include,,Single-Channel Sleep EEG Classification Method Based on LSTM and Hidden Markov Model.,Include,,"posed method can extract deep information from EEG and make full use of the sleep stage transition rule. The proposed method shows the best performance in single-channel sleep EEG classification; the accuracy, macro average F1 score, and kappa are 82.71%, 0.75, and 0.76, respectively. The proposed method can realize single-channel sleep EEG classification and provide a reference for other EEG clas",,0.95,0.6,
pubmed:39595842,pubmed:39595842,PubMed,pubmed:39595842,Musicianship Modulates Cortical Effects of Attention on Processing Musical Triads.,Jessica MacLean;Elizabeth Drobny;Rose Rizzi;Gavin M Bidelman,2024,10.1007/s10162-017-0641-9,,,https://pubmed.ncbi.nlm.nih.gov/39595842/,English,Exclude,Not EEG-BCI focused,Musicianship Modulates Cortical Effects of Attention on Processing Musical Triads.,,,,,0.9,0.6,
pubmed:39595163,pubmed:39595163,PubMed,pubmed:39595163,Methods for Identifying Epilepsy Surgery Targets Using Invasive EEG: A Systematic Review.,Karla Ivankovic;Alessandro Principe;Riccardo Zucca;Mara Dierssen;Rodrigo Rocamora,2024,10.1093/brain/awad118,"The pre-surgical evaluation for drug-resistant epilepsy achieves seizure freedom in only 50-60% of patients. Efforts to identify quantitative intracranial EEG (qEEG) biomarkers of epileptogenicity are needed. This review summarizes and evaluates the design of qEEG studies, discusses barriers to biomarker adoption, and proposes refinements of qEEG study protocols. We included exploratory and prediction prognostic studies from MEDLINE and Scopus published between 2017 and 2023 that investigated qEEG markers for identifying the epileptogenic network as the surgical target. Cohort parameters, ground truth references, and analytical approaches were extracted. Out of 1789 search results, 128 studies were included. The study designs were highly heterogeneous. Half of the studies included a non-consecutive cohort, with sample sizes ranging from 2 to 166 patients (median of 16). The most common minimum follow-up was one year, and the seizure onset zone was the most common ground truth. Prediction studies were heterogeneous in their analytical approaches, and only 25 studies validated the marker through post-surgical outcome prediction. Outcome prediction performance decreased in larger cohorts. Conversely, longer follow-up periods correlated with higher prediction accuracy, and connectivity-based approaches yielded better predictions. The data and code were available in only 9% of studies. To enhance the validation qEEG markers, we propose standardizing study designs to resemble clinical trials. This includes using a consecutive cohort with long-term follow-up, validating against surgical resection as ground truth, and evaluating markers through post-surgical outcome prediction. These considerations would improve the reliability and clinical adoption of qEEG markers.",,https://pubmed.ncbi.nlm.nih.gov/39595163/,English,Exclude,Review/survey papers,Methods for Identifying Epilepsy Surgery Targets Using Invasive EEG: A Systematic Review.,,,,,0.95,0.6,
pubmed:39594191,pubmed:39594191,PubMed,pubmed:39594191,Enhancing Epilepsy Seizure Detection Through Advanced EEG Preprocessing Techniques and Peak-to-Peak Amplitude Fluctuation Analysis.,Muawiyah A Bahhah;Eyad Talal Attar,2024,10.1109/icccis60361.2023.10425510,,https://pubmed.ncbi.nlm.nih.gov/39594191/,https://pubmed.ncbi.nlm.nih.gov/39594191/,English,Include,,Enhancing Epilepsy Seizure Detection Through Advanced EEG Preprocessing Techniques and Peak-to-Peak Amplitude Fluctuation Analysis.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39593905,pubmed:39593905,PubMed,pubmed:39593905,Generalized Gaussian Distribution Improved Permutation Entropy: A New Measure for Complex Time Series Analysis.,Kun Zheng;Hong-Seng Gan;Jun Kit Chaw;Sze-Hong Teh;Zhe Chen,2024,10.1016/j.apacoust.2016.06.008,"To enhance the performance of entropy algorithms in analyzing complex time series, generalized Gaussian distribution improved permutation entropy (GGDIPE) and its multiscale variant (MGGDIPE) are proposed in this paper. First, the generalized Gaussian distribution cumulative distribution function is employed for data normalization to enhance the algorithm's applicability across time series with diverse distributions. The algorithm further processes the normalized data using improved permutation entropy, which maintains both the absolute magnitude and temporal correlations of the signals, overcoming the equal value issue found in traditional permutation entropy (PE). Simulation results indicate that GGDIPE is less sensitive to parameter variations, exhibits strong noise resistance, accurately reveals the dynamic behavior of chaotic systems, and operates significantly faster than PE. Real-world data analysis shows that MGGDIPE provides markedly better separability for RR interval signals, EEG signals, bearing fault signals, and underwater acoustic signals compared to multiscale PE (MPE) and multiscale dispersion entropy (MDE). Notably, in underwater target recognition tasks, MGGDIPE achieves a classification accuracy of 97.5% across four types of acoustic signals, substantially surpassing the performance of MDE (70.5%) and MPE (62.5%). Thus, the proposed method demonstrates exceptional capability in processing complex time series.",https://pubmed.ncbi.nlm.nih.gov/39593905/,https://pubmed.ncbi.nlm.nih.gov/39593905/,English,Include,,Generalized Gaussian Distribution Improved Permutation Entropy: A New Measure for Complex Time Series Analysis.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39593731,pubmed:39593731,PubMed,pubmed:39593731,Improving EEG Forward Modeling Using High-Resolution Five-Layer BEM-FMM Head Models: Effect on Source Reconstruction Accuracy.,Guillermo Nuñez Ponasso;William A Wartman;Ryan C McSweeney;Peiyao Lai;Jens Haueisen;Burkhard Maess;Thomas R Knösche;Konstantin Weise;Gregory M Noetscher;Tommi Raij;Sergey N Makaroff,2024,10.3389/fnhum.2024.1279183,"Electroencephalographic (EEG) source localization is a fundamental tool for clinical diagnoses and brain-computer interfaces. We investigate the impact of model complexity on reconstruction accuracy by comparing the widely used three-layer boundary element method (BEM) as an inverse method against a five-layer BEM accelerated by the fast multipole method (BEM-FMM) and coupled with adaptive mesh refinement (AMR) as forward solver. Modern BEM-FMM with AMR can solve high-resolution multi-tissue models efficiently and accurately. We generated noiseless 256-channel EEG data from 15 subjects in the Connectome Young Adult dataset, using four anatomically relevant dipole positions, three conductivity sets, and two head segmentations; we mapped localization errors across the entire grey matter from 4000 dipole positions. The average location error among our four selected dipoles is ∼5mm (±2mm) with an orientation error of ∼12∘ (±7∘). The average source localization error across the entire grey matter is ∼9mm (±4mm), with a tendency for smaller errors on the occipital lobe. Our findings indicate that while three-layer models are robust under noiseless conditions, substantial localization errors (10-20mm) are common. Therefore, models of five or more layers may be needed for accurate source reconstruction in critical applications involving noisy EEG data.",https://pubmed.ncbi.nlm.nih.gov/39593731/,https://pubmed.ncbi.nlm.nih.gov/39593731/,English,Include,,Improving EEG Forward Modeling Using High-Resolution Five-Layer BEM-FMM Head Models: Effect on Source Reconstruction Accuracy.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39591752,pubmed:39591752,PubMed,pubmed:39591752,Multi-layer ear-scalp distillation framework for ear-EEG classification enhancement.,Ying Sun;Feiyang Zhang;Ziyu Li;Xiaolin Liu;Dezhi Zheng;Shuailei Zhang;Shangchun Fan;Xia Wu,2024,10.1088/1741-2552/ad9778,"Ear-electroencephalography (ear-EEG) holds significant promise as a practical tool in brain-computer interfaces (BCIs) due to its enhanced unobtrusiveness, comfort, and mobility compared to traditional steady-state visual evoked potential (SSVEP)-based BCI systems. However, achieving accurate SSVEP classification with ear-EEG remains a major challenge due to the significant attenuation and distortion of the signal amplitude. Our aim is to enhance the classification performance of SSVEP using ear-EEG and to increase its practical application value. To address this challenge, we focus on enhancing ear-EEG feature representations by training the model to learn features similar to those of scalp-EEG. We introduce a novel framework, termed multi-layer ear-scalp distillation (MESD), designed to optimize SSVEP target classification in ear-EEG data. This framework combines signals from the scalp to obtain multi-layer distilled knowledge through the cooperation of mid-layer feature distillation and output layer response distillation.Mainresults.We improve the classification of the initial 1 s data and achieved a maximum classification accuracy of 81.1%. We evaluate the proposed MESD framework through single-session, cross-session, and cross-subject transfer decoding, comparing it with baseline methods. The results demonstrate that the proposed framework achieves the best classification results in all experiments. Our study enhances the classification accuracy of SSVEP based on ear-EEG within a short time window. These results offer insights for the application of ear-EEG brain-computer interfaces in tasks such as auxiliary control and rehabilitation training in future endeavors.",https://pubmed.ncbi.nlm.nih.gov/39591752/,https://pubmed.ncbi.nlm.nih.gov/39591752/,English,Include,,Multi-layer ear-scalp distillation framework for ear-EEG classification enhancement.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39591745,pubmed:39591745,PubMed,pubmed:39591745,Improving subject transfer in EEG classification with divergence estimation.,Niklas Smedemark-Margulies;Ye Wang;Toshiaki Koike-Akino;Jing Liu;Kieran Parsons;Yunus Bicer;Deniz Erdoğmuş,2024,10.1088/1741-2552/ad9777,,https://pubmed.ncbi.nlm.nih.gov/39591745/,https://pubmed.ncbi.nlm.nih.gov/39591745/,English,Include,,Improving subject transfer in EEG classification with divergence estimation.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39588176,pubmed:39588176,PubMed,pubmed:39588176,"A Review of Datasets, Optimization Strategies, and Learning Algorithms for Analyzing Alzheimer's Dementia Detection.",Vanaja Thulasimani;Kogilavani Shanmugavadivel;Jaehyuk Cho;Sathishkumar Veerappampalayam Easwaramoorthy,2024,10.1016/j.knosys.2024.111615,"Alzheimer's Dementia (AD) is a progressive neurological disorder that affects memory and cognitive function, necessitating early detection for its effective management. This poses a significant challenge to global public health. The early and accurate detection of dementia is crucial for several reasons. First, timely detection facilitates early intervention and planning of treatment. Second, precise diagnostic methods are essential for distinguishing dementia from other cognitive disorders and medical conditions that may present with similar symptoms. Continuous analysis and improvements in detection methods have contributed to advancements in medical research. It helps to identify new biomarkers, refine existing diagnostic tools, and foster the development of innovative technologies, ultimately leading to more accurate and efficient diagnostic approaches for dementia. This paper presents a critical analysis of multimodal imaging datasets, learning algorithms, and optimisation techniques utilised in the context of Alzheimer's dementia detection. The focus is on understanding the advancements and challenges in employing diverse imaging modalities, such as MRI (Magnetic Resonance Imaging), PET (Positron Emission Tomography), and EEG (ElectroEncephaloGram). This study evaluated various machine learning algorithms, deep learning models, transfer learning techniques, and generative adversarial networks for the effective analysis of multi-modality imaging data for dementia detection. In addition, a critical examination of optimisation techniques encompassing optimisation algorithms and hyperparameter tuning strategies for processing and analysing images is presented in this study to discern their influence on model performance and generalisation. Thorough examination and enhancement of methods for dementia detection are fundamental for addressing the healthcare challenges posed by dementia, facilitating timely interventions, improving diagnostic accuracy, and advancing research in neurodegenerative diseases.",,https://pubmed.ncbi.nlm.nih.gov/39588176/,English,Exclude,Review/survey papers,"A Review of Datasets, Optimization Strategies, and Learning Algorithms for Analyzing Alzheimer's Dementia Detection.",,,,,0.95,0.6,
pubmed:39587325,pubmed:39587325,PubMed,pubmed:39587325,Using high-frequency oscillations from brief intraoperative neural recordings to predict the seizure onset zone.,Behrang Fazli Besheli;Zhiyi Sha;Jay R Gavvala;Sacit Karamursel;Michael Quach;Chandra Prakash Swamy;Amir Hossein Ayyoubi;Alica M Goldman;Daniel J Curry;Sameer A Sheth;David Darrow;Kai J Miller;David J Francis;Gregory A Worrell;Thomas R Henry;Nuri F Ince,2024,10.1038/s43856-024-00654-0,"While high-frequency oscillations (HFOs) and their stereotyped clusters (sHFOs) have emerged as potential neuro-biomarkers for the rapid localization of the seizure onset zone (SOZ) in epilepsy, their clinical application is hindered by the challenge of automated elimination of pseudo-HFOs originating from artifacts in heavily corrupted intraoperative neural recordings. This limitation has led to a reliance on semi-automated detectors, coupled with manual visual artifact rejection, impeding the translation of findings into clinical practice. In response, we have developed a computational framework that integrates sparse signal processing and ensemble learning to automatically detect genuine HFOs of intracranial EEG data. This framework is utilized during intraoperative monitoring (IOM) while implanting electrodes and postoperatively in the epilepsy monitoring unit (EMU) before the respective surgery. Our framework demonstrates a remarkable ability to eliminate pseudo-HFOs in heavily corrupted neural data, achieving accuracy levels comparable to those obtained through expert visual inspection. It not only enhances SOZ localization accuracy of IOM to a level comparable to EMU but also successfully captures sHFO clusters within IOM recordings, exhibiting high specificity to the primary SOZ. These findings suggest that intraoperative HFOs, when processed with computational intelligence, can be used as early feedback for SOZ tailoring surgery to guide electrode repositioning, enhancing the efficacy of the overall invasive therapy. Medication-resistant epilepsy is a form of epilepsy that cannot be controlled with drugs. In such cases, surgery is often required to remove the brain regions where seizures start. To identify these areas, electrodes are typically implanted in the brain, and the patient’s brain activity is monitored for several days or weeks in the hospital, a process that can be lengthy and risky. We investigated whether seizure-causing brain regions could be identified earlier by applying a computational intelligence method to brain signals recorded during electrode implantation surgery. Our algorithm automatically detected abnormal high-frequency oscillations (HFOs) associated with epileptic brain tissue, improving the accuracy of identifying the areas that need to be removed. This approach could help clinicians make quicker, more precise decisions, reducing the need for prolonged monitoring and minimizing risks.",https://pubmed.ncbi.nlm.nih.gov/39587325/,https://pubmed.ncbi.nlm.nih.gov/39587325/,English,Include,,Using high-frequency oscillations from brief intraoperative neural recordings to predict the seizure onset zone.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39586499,pubmed:39586499,PubMed,pubmed:39586499,Classification of motor imagery EEG with ensemble RNCA model.,T Thenmozhi;R Helen;S Mythili,2025,10.1016/j.bbr.2024.115345,"Motor Imagery (MI) based brain-computer interface (BCI) systems are used for regaining the motor functions of neurophysiologically affected persons. But the performance of MI tasks is degraded due to the presence of redundant EEG channels. Hence, a novel ensemble regulated neighborhood component analysis (ERNCA) method provides a perfect identification of neural region that stimulate motor movements. Domains of statistical, frequency, spatial and transform-based features narrowed down the misclassification rate. The gradient boosting method selects the relevant features thereby reduces the computational complexity. Finally, Bayesian optimized ensemble classifier finetuned the classification accuracies of 97.22 % and 91.62 % for Datasets IIIa and IVa respectively. This approach is further strengthened by analyzing real-time data with the accuracy of 93.75 %. This method qualifies out of four benchmark methods with significant percent of improvement in accuracy for these three datasets. As per the spatial distribution of refined EEG channels, majority of the brain's motor functions concentrates on frontal and central cortex regions of brain.",,https://pubmed.ncbi.nlm.nih.gov/39586499/,English,Exclude,Outside date range,Classification of motor imagery EEG with ensemble RNCA model.,,,,,0.95,0.6,
pubmed:39586346,pubmed:39586346,PubMed,pubmed:39586346,Different oscillatory mechanisms of dementia-related diseases with cognitive impairment in closed-eye state.,Talifu Zikereya;Yuchen Lin;Zhizhen Zhang;Ignacio Taguas;Kaixuan Shi;Chuanliang Han,2024,10.1016/j.neuroimage.2024.120945,"The escalating global trend of aging has intensified the focus on health concerns prevalent among the elderly. Notably, Dementia related diseases, including Alzheimer's disease (AD) and frontotemporal dementia (FTD), significantly impair the quality of life for both affected seniors and their caregivers. However, the underlying neural mechanisms of these diseases remain incompletely understood, especially in terms of neural oscillations. In this study, we leveraged an open dataset containing 36 CE, 23 FTD, and 29 healthy controls (HC) to investigate these mechanisms. We accurately and clearly identified three stable oscillation targets (theta, ∼5 Hz, alpha, ∼10 Hz, and beta, ∼18 Hz) that facilitate differentiation between AD, FTD, and HC both statistically and through classification using machine learning algorithms. Overall, the differences between AD and HC were the most pronounced, with FTD exhibiting intermediate characteristics. The differences in the theta and alpha bands showed a global pattern, whereas the differences in the beta band were localized to the central-temporal region. Moreover, our analysis revealed that the relative theta power was significantly and negatively correlated with the Mini Mental State Examination (MMSE) scores, while the relative alpha and beta power showed a significant positive correlation. This study is the first to pinpoint multiple robust and effective neural oscillation targets to distinguish AD, offering a simple and convenient method that holds promise for future applications in the early screening of large-scale dementia-related diseases.",,https://pubmed.ncbi.nlm.nih.gov/39586346/,English,Exclude,Not EEG-BCI focused,Different oscillatory mechanisms of dementia-related diseases with cognitive impairment in closed-eye state.,,,,,0.9,0.6,
pubmed:39584595,pubmed:39584595,PubMed,pubmed:39584595,Early Salience Signals Predict Interindividual Asymmetry in Decision Accuracy Across Rewarding and Punishing Contexts.,Sean Westwood;Marios G Philiastides,2024,10.1523/jneurosci.4537-03.2004,"Asymmetry in choice patterns across rewarding and punishing contexts has long been observed in behavioural economics. Within existing theories of reinforcement learning, the mechanistic account of these behavioural differences is still debated. We propose that motivational salience-the degree of bottom-up attention attracted by a stimulus with relation to motivational goals-offers a potential mechanism to modulate stimulus value updating and decision policy. In a probabilistic reversal learning task, we identified post-feedback signals from EEG and pupillometry that captured differential activity with respect to rewarding and punishing contexts. We show that the degree of between-context distinction in these signals predicts interindividual asymmetries in decision accuracy. Finally, we contextualise these effects in relation to the neural pathways that are currently centred in theories of reward and punishment learning, demonstrating how the motivational salience network could plausibly fit into a range of existing frameworks.",https://pubmed.ncbi.nlm.nih.gov/39584595/,https://pubmed.ncbi.nlm.nih.gov/39584595/,English,Include,,Early Salience Signals Predict Interindividual Asymmetry in Decision Accuracy Across Rewarding and Punishing Contexts.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39584052,pubmed:39584052,PubMed,pubmed:39584052,Comparative analysis of dimensionality reduction techniques for EEG-based emotional state classification.,Seyed-Ali Sadegh-Zadeh;Nasrin Sadeghzadeh;Ommolbanin Soleimani;Saeed Shiry Ghidary;Sobhan Movahedi;Seyed-Yaser Mousavi,2024,10.62347/zwry8401,"The aim of this study is to evaluate the impact of various dimensionality reduction methods, including principal component analysis (PCA), Laplacian score, and Chi-square feature selection, on the classification performance of an electroencephalogram (EEG) dataset. We applied dimensionality reduction techniques, including PCA, Laplacian score, and Chi-square feature selection, and assessed their impact on the classification performance of EEG data using linear regression, K-nearest neighbour (KNN), and Naive Bayes classifiers. The models were evaluated in terms of their classification accuracy and computational efficiency. Our findings suggest that all dimensionality reduction strategies generally improved or maintained classification accuracy while reducing the computational load. Notably, PCA and Autofeat techniques led to increased accuracy for the models. The use of dimensionality reduction techniques can enhance EEG data classification by reducing computational demands without compromising accuracy. These results demonstrate the potential for these techniques to be applied in scenarios where both computational efficiency and high accuracy are desired. The code used in this study is available at https://github.com/movahedso/Emotion-analysis.",https://pubmed.ncbi.nlm.nih.gov/39584052/,https://pubmed.ncbi.nlm.nih.gov/39584052/,English,Include,,Comparative analysis of dimensionality reduction techniques for EEG-based emotional state classification.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39581300,pubmed:39581300,PubMed,pubmed:39581300,Can personality traits be predicted from resting-state EEG oscillations? A replication study.,Christoph Fruehlinger;Katharina Paul;Jan Wacker,2024,10.1016/j.biopsycho.2024.108955,"Personality neuroscience seeks to uncover the neurobiological underpinnings of personality. Identifying links between measures of brain activity and personality traits is important in this respect. Using an entirely inductive approach, Jach et al. (2020) attempted to predict personality trait scores from resting-state spectral electroencephalography (EEG) using multivariate pattern analysis (MVPA) and found meaningful results for Agreeableness. The exploratory nature of this work and concerns about replicability in general require a rigorous replication, which was the aim of the current study. We applied the same analytic approach to a large data set (N = 772) to evaluate the robustness of the previous results. Similar to Jach et al. (2020), 8 min of resting-state EEG before and after unrelated tasks with both eyes open and closed were analyzed using support vector regressions (SVR). A 10-fold cross-validation was used to evaluate the prediction accuracy between the spectral power of 59 EEG electrodes within 30 frequency bins ranging from 1 to 30 Hz and Big Five personality trait scores. We were not able to replicate the findings for Agreeableness. We extended the analysis by parameterizing the total EEG signal into its periodic and aperiodic signal components. However, neither component was meaningfully associated with the Big Five personality traits. Our results do not support the initial results and indicate that personality traits may at least not be substantially predictable from resting-state spectral power. Future identification of robust and replicable brain-personality associations will likely require alternative analysis methods and rigorous preregistration of all analysis steps.",https://pubmed.ncbi.nlm.nih.gov/39581300/,https://pubmed.ncbi.nlm.nih.gov/39581300/,English,Include,,Can personality traits be predicted from resting-state EEG oscillations? A replication study.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.25,cv_reported
pubmed:39581069,pubmed:39581069,PubMed,pubmed:39581069,Deep learning techniques for automated Alzheimer's and mild cognitive impairment disease using EEG signals: A comprehensive review of the last decade (2013 - 2024).,Madhav Acharya;Ravinesh C Deo;Xiaohui Tao;Prabal Datta Barua;Aruna Devi;Anirudh Atmakuru;Ru-San Tan,2025,10.1016/j.cmpb.2024.108506,"Mild Cognitive Impairment (MCI) and Alzheimer's Disease (AD) are progressive neurological disorders that significantly impair the cognitive functions, memory, and daily activities. They affect millions of individuals worldwide, posing a significant challenge for its diagnosis and management, leading to detrimental impacts on patients' quality of lives and increased burden on caregivers. Hence, early detection of MCI and AD is crucial for timely intervention and effective disease management. This study presents a comprehensive systematic review focusing on the applications of deep learning in detecting MCI and AD using electroencephalogram (EEG) signals. Through a rigorous literature screening process based on the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines, the research has investigated 74 different papers in detail to analyze the different approaches used to detect MCI and AD neurological disorders. The findings of this study stand out as the first to deal with the classification of dual MCI and AD (MCI+AD) using EEG signals. This unique approach has enabled us to highlight the state-of-the-art high-performing models, specifically focusing on deep learning while examining their strengths and limitations in detecting the MCI, AD, and the MCI+AD comorbidity situations. The present study has not only identified the current limitations in deep learning area for MCI and AD detection but also proposes specific future directions to address these neurological disorders by implement best practice deep learning approaches. Our main goal is to offer insights as references for future research encouraging the development of deep learning techniques in early detection and diagnosis of MCI and AD neurological disorders. By recommending the most effective deep learning tools, we have also provided a benchmark for future research, with clear implications for the practical use of these techniques in healthcare.",,https://pubmed.ncbi.nlm.nih.gov/39581069/,English,Exclude,Outside date range,Deep learning techniques for automated Alzheimer's and mild cognitive impairment disease using EEG signals: A comprehensive review of the last decade (2013 - 2024).,,,,,0.95,0.6,
pubmed:39580816,pubmed:39580816,PubMed,pubmed:39580816,Identification of autism spectrum disorder using electroencephalography and machine learning: a review.,Anamika Ranaut;Padmavati Khandnor;Trilok Chand,2024,10.1088/1741-2552/ad9681,"Autism Spectrum Disorder (ASD) is a neurodevelopmental condition characterized by communication barriers, societal disengagement, and monotonous actions. Traditional diagnostic methods for ASD rely on clinical observations and behavioural assessments, which are time-consuming. In recent years, researchers have focused mainly on the early diagnosis of ASD due to the unavailability of recognised causes and the lack of permanent curative solutions. Electroencephalography (EEG) research in ASD offers insight into the neural dynamics of affected individuals. This comprehensive review examines the unique integration of EEG, machine learning, and statistical analysis for ASD identification, highlighting the promise of an interdisciplinary approach for enhancing diagnostic precision. The comparative analysis of publicly available EEG datasets for ASD, along with local data acquisition methods and their technicalities, is presented in this paper. This study also compares preprocessing techniques, and feature extraction methods, followed by classification models and statistical analysis which are discussed in detail. In addition, it briefly touches upon comparisons with other modalities to contextualize the extensiveness of ASD research. Moreover, by outlining research gaps and future directions, this work aims to catalyse further exploration in the field, with the main goal of facilitating more efficient and effective early identification methods that may be helpful to the lives of ASD individuals.",,https://pubmed.ncbi.nlm.nih.gov/39580816/,English,Exclude,Review/survey papers,Identification of autism spectrum disorder using electroencephalography and machine learning: a review.,,,,,0.95,0.6,
pubmed:39577701,pubmed:39577701,PubMed,pubmed:39577701,Enhancing detection of SSVEP-based BCIs via a novel temporally local canonical correlation analysis.,Guoxian Xia;Li Wang;Shiming Xiong;Jiaxian Deng,2025,10.1016/j.jneumeth.2024.110325,"In recent years, spatial filter-based frequency recognition methods have become popular in steady-state visual evoked potential (SSVEP)-based brain-computer interface (BCI) systems. However, these methods are ineffective in suppressing local noise, and they rely on the length of the data. In practical applications, enhancing recognition performance with short data windows is a significant challenge for the BCI systems. With extracting temporal information and eliminating local noise, a temporally local canonical correlation analysis based on training data-driven (TI-tdCCA) method is proposed to enhance the recognition performance of SSVEPs. Based on a novel framework, the filters are derived by incorporating the Laplacian matrix through the use of TI-CCA between the concatenated training data and individual templates. The target frequency is subsequently determined by applying the appropriate spatial filters and Laplacian matrix. The experimental results on two datasets, consisting of 40 classes and recording from 35 and 70 subjects respectively, demonstrate that the proposed method consistently outperforms the eight competing methods in the majority of cases. The proposed method is simultaneously evaluated by an extended version that incorporates artificial reference signals. The extended method demonstrates a significant improvement over the proposed method. Specifically, with a time window of 0.7 s, the average recognition accuracy of the subjects increases by 10.71 % on the Benchmark dataset and by 6.98 % on the BETA dataset, respectively. Our extended method outperforms the state-of-the-art methods by at least 3 %, and it effectively suppresses local noise and maintains excellent scalability. The proposed method can effectively combine spatial and temporal filters to improve the recognition performance of SSVEPs.",,https://pubmed.ncbi.nlm.nih.gov/39577701/,English,Exclude,Outside date range,Enhancing detection of SSVEP-based BCIs via a novel temporally local canonical correlation analysis.,,,,,0.95,0.6,
pubmed:39577097,pubmed:39577097,PubMed,pubmed:39577097,Convolution spatial-temporal attention network for EEG emotion recognition.,Lei Cao;Binlong Yu;Yilin Dong;Tianyu Liu;Jie Li,2024,10.1088/1361-6579/ad9661,"In recent years, emotion recognition using electroencephalogram (EEG) signals has garnered significant interest due to its non-invasive nature and high temporal resolution. We introduced a groundbreaking method that bypasses traditional manual feature engineering, emphasizing data preprocessing and leveraging the topological relationships between channels to transform EEG signals from two-dimensional time sequences into three-dimensional spatio-temporal representations. Maximizing the potential of deep learning, our approach provides a data-driven and robust method for identifying emotional states. Leveraging the synergy between convolutional neural network and attention mechanisms facilitated automatic feature extraction and dynamic learning of inter-channel dependencies. Our method showcased remarkable performance in emotion recognition tasks, confirming the effectiveness of our approach, achieving average accuracy of 98.62% for arousal and 98.47% for valence, surpassing previous state-of-the-art results of 95.76% and 95.15%. Furthermore, we conducted a series of pivotal experiments that broadened the scope of emotion recognition research, exploring further possibilities in the field of emotion recognition.",https://pubmed.ncbi.nlm.nih.gov/39577097/,https://pubmed.ncbi.nlm.nih.gov/39577097/,English,Include,,Convolution spatial-temporal attention network for EEG emotion recognition.,Include,,"xtraction and dynamic learning of inter-channel dependencies. Our method showcased remarkable performance in emotion recognition tasks, confirming the effectiveness of our approach, achieving average accuracy of 98.62% for arousal and 98.47% for valence, surpassing previous state-of-the-art results of 95.76% and 95.15%. Furthermore, we conducted a series of pivotal experiments that broadened the s",,0.95,0.6,
pubmed:39575804,pubmed:39575804,PubMed,pubmed:39575804,Identification of Salient Brain Regions for Anxiety Disorders Using Nonlinear EEG Feature Analysis.,Tetiana Biloborodova;Inna Skarga-Bandurova;Maryna Derkach;Danylo Matiuk;Nataliya Zagorodna,2024,10.3233/shti241088,"In this paper, we present a novel approach for identifying salient brain regions and interpreting the ability of nonlinear EEG features to discriminate between anxiety disorders and healthy controls. The proposed method involves the integration of advanced EEG preprocessing and artefact correction, nonlinear feature extraction using conditional permutation entropy, and interpretable machine learning to identify relevant electrodes. The extracted nonlinear features show statistically significant differences between classes, demonstrating high discriminative ability. The discriminative ability was confirmed with T-tests (p = 1.05e-10) and Mann-Whitney U tests (p = 2.65e-11), demonstrating robust statistical significance. Classification results support these findings and guide the identification of relevant electrodes, enhancing the interpretability of the discriminative features. This approach highlights potential brain regions critical for anxiety disorder diagnosis, paving the way for more targeted interventions and improved clinical outcomes.",https://pubmed.ncbi.nlm.nih.gov/39575804/,https://pubmed.ncbi.nlm.nih.gov/39575804/,English,Include,,Identification of Salient Brain Regions for Anxiety Disorders Using Nonlinear EEG Feature Analysis.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39574662,pubmed:39574662,PubMed,pubmed:39574662,Deep Multimodal Representations and Classification of First-Episode Psychosis via Live Face Processing.,Rahul Singh;Yanlei Zhang;Dhananjay Bhaskar;Vinod Srihari;Cenk Tek;Xian Zhang;J Adam Noah;Smita Krishnaswamy;Joy Hirsch,2024,10.1007/3-540-45129-3_27,"Schizophrenia is a severe psychiatric disorder associated with a wide range of cognitive and neurophysiological dysfunctions and long-term social difficulties. In this paper, we test the hypothesis that integration of multiple simultaneous acquisitions of neuroimaging, behavioral, and clinical information will be better for prediction of early psychosis than unimodal recordings. We propose a novel framework to investigate the neural underpinnings of the early psychosis symptoms (that can develop into Schizophrenia with age) using multimodal acquisitions of neural and behavioral recordings including functional near-infrared spectroscopy (fNIRS) and electroencephalography (EEG), and facial features. Our data acquisition paradigm is based on live face-to-face interaction in order to study the neural correlates of social cognition in first-episode psychosis (FEP). We propose a novel deep representation learning framework, Neural-PRISM, for learning joint multimodal compressed representations combining neural as well as behavioral recordings. These learned representations are subsequently used to describe, classify, and predict the severity of early psychosis in patients, as measured by the Positive and Negative Syndrome Scale (PANSS) and Global Assessment of Functioning (GAF) scores. We found that incorporating joint multimodal representations from fNIRS and EEG along with behavioral recordings enhances classification between typical controls and FEP individuals. Additionally, our results suggest that geometric and topological features such as curvatures and path signatures of the embedded trajectories of brain activity enable detection of discriminatory neural characteristics in early psychosis.",https://pubmed.ncbi.nlm.nih.gov/39574662/,https://pubmed.ncbi.nlm.nih.gov/39574662/,English,Include,,Deep Multimodal Representations and Classification of First-Episode Psychosis via Live Face Processing.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39572577,pubmed:39572577,PubMed,pubmed:39572577,Chisco: An EEG-based BCI dataset for decoding of imagined speech.,Zihan Zhang;Xiao Ding;Yu Bao;Yi Zhao;Xia Liang;Bing Qin;Ting Liu,2024,10.1038/s41597-024-04114-1,"The rapid advancement of deep learning has enabled Brain-Computer Interfaces (BCIs) technology, particularly neural decoding techniques, to achieve higher accuracy and deeper levels of interpretation. Interest in decoding imagined speech has significantly increased because its concept akin to ""mind reading"". However, previous studies on decoding neural language have predominantly focused on brain activity patterns during human reading. The absence of imagined speech electroencephalography (EEG) datasets has constrained further research in this field. We present the Chinese Imagined Speech Corpus (Chisco), including over 20,000 sentences of high-density EEG recordings of imagined speech from healthy adults. Each subject's EEG data exceeds 900 minutes, representing the largest dataset per individual currently available for decoding neural language to date. Furthermore, the experimental stimuli include over 6,000 everyday phrases across 39 semantic categories, covering nearly all aspects of daily language. We believe that Chisco represents a valuable resource for the fields of BCIs, facilitating the development of more user-friendly BCIs.",https://pubmed.ncbi.nlm.nih.gov/39572577/,https://pubmed.ncbi.nlm.nih.gov/39572577/,English,Include,,Chisco: An EEG-based BCI dataset for decoding of imagined speech.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39571936,pubmed:39571936,PubMed,pubmed:39571936,Biomarker and neuropsychological correlates of the N400 event-related potential in Alzheimer's disease.,Allie R Geiger;Matthew J Euler;Jasmin E Guevara;Julia Vehar;Jace B King;Kevin Duff;John M Hoffman,2025,10.1038/s41380-020-0721-9,"The current study sought to characterize the relationship of the N400 (N4) effect event-related potential to Alzheimer's disease (AD) biomarkers and broader cognition in older adults on the late-life cognitive continuum. Participants who were cognitively intact (n = 43), or had amnestic mild cognitive impairment (MCI; n = 19), or mild AD (n = 12), completed a word-pair judgement task during concurrent EEG recording to elicit the N400. The Repeatable Battery for the Assessment of Neuropsychological Status (RBANS) and biomarker data (PET-imaged beta-amyloid (aβ) deposition, apolipoprotein-E ε4 (APOE4) allele status, hippocampal volumes) were collected as part of a larger study. The AD group had slower response times and poorer accuracy on the word-pair judgement task than the intact group. The N4 effect was smaller and occurred later in AD relative to intact participants. MCI participants' values were intermediate. N4 effect amplitudes were not associated with RBANS scores but were positively associated with aβ deposition. Conversely, poorer performance across most RBANS Indexes and the Total score was associated with longer N4 latencies. There was also a negative association between hippocampal volumes and the N4 latency and a positive association between aβ deposition and latency. Finally, the latency of the N4 independently predicted variance in RBANS Total scores, above and beyond aβ deposition, hippocampal volumes, and APOE4 allele status. These findings support the relevance of the N4 effect in individuals along the late-life cognitive continuum, and motivate future studies into its potential as a longitudinal predictor in AD.",,https://pubmed.ncbi.nlm.nih.gov/39571936/,English,Exclude,Outside date range,Biomarker and neuropsychological correlates of the N400 event-related potential in Alzheimer's disease.,,,,,0.95,0.8,small_sample_mentioned
pubmed:39571641,pubmed:39571641,PubMed,pubmed:39571641,VAEEG: Variational auto-encoder for extracting EEG representation.,Tong Zhao;Yi Cui;Taoyun Ji;Jiejian Luo;Wenling Li;Jun Jiang;Zaifen Gao;Wenguang Hu;Yuxiang Yan;Yuwu Jiang;Bo Hong,2024,10.1016/j.neuroimage.2024.120946,"The electroencephalogram (EEG) exhibits characteristics of complexity and strong randomness. Existing deep learning models for EEG typically target specific objectives and datasets, with their scalability constrained by the size of the dataset, resulting in limited perceptual and generalization abilities. In order to obtain more intuitive, concise, and useful representations of brain activity, we constructed a reconstruction-based self-supervised learning model for EEG based on Variational Autoencoder (VAE) with separate frequency bands, termed variational auto-encoder for EEG (VAEEG). VAEEG achieved outstanding reconstruction performance. Furthermore, we validated the efficacy of the latent representations in three clinical tasks concerning pediatric brain development, epileptic seizure, and sleep stage classification. We discovered that certain latent features: 1) correlate with adolescent brain developmental changes; 2) exhibit significant distinctions in the distribution between epileptic seizures and background activity; 3) show significant variations across different sleep cycles. In corresponding downstream fitting or classification tasks, models constructed based on the representations extracted by VAEEG demonstrated superior performance. Our model can extract effective features from complex EEG signals, serving as an early feature extractor for downstream classification tasks. This reduces the amount of data required for downstream tasks, simplifies the complexity of downstream models, and streamlines the training process.",https://pubmed.ncbi.nlm.nih.gov/39571641/,https://pubmed.ncbi.nlm.nih.gov/39571641/,English,Include,,VAEEG: Variational auto-encoder for extracting EEG representation.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39570849,pubmed:39570849,PubMed,pubmed:39570849,"FDCN-C: A deep learning model based on frequency enhancement, deformable convolution network, and crop module for electroencephalography motor imagery classification.",Hong-Jie Liang;Ling-Long Li;Guang-Zhong Cao,2024,10.1016/j.engappai.2022.105347,"Motor imagery (MI)-electroencephalography (EEG) decoding plays an important role in brain-computer interface (BCI), which enables motor-disabled patients to communicate with external world via manipulating smart equipment. Currently, deep learning (DL)-based methods are popular for EEG decoding. Whereas the utilization efficiency of EEG features in frequency and temporal domain is not sufficient, which results in poor MI classification performance. To address this issue, an EEG-based MI classification model based on a frequency enhancement module, a deformable convolutional network, and a crop module (FDCN-C) is proposed. Firstly, the frequency enhancement module is innovatively designed to address the issue of extracting frequency information. It utilizes convolution kernels at continuous time scales to extract features across different frequency bands. These features are screened by calculating attention and integrated into the original EEG data. Secondly, for temporal feature extraction, a deformable convolution network is employed to enhance feature extraction capabilities, utilizing offset parameters to modulate the convolution kernel size. In spatial domain, a one-dimensional convolution layer is designed to integrate all channel information. Finally, a dilated convolution is used to form a crop classification module, wherein the diverse receptive fields of the EEG data are computed multiple times. Two public datasets are employed to verify the proposed FDCN-C model, the classification accuracy obtained from the proposed model is greater than that of state-of-the-art methods. The model's accuracy has improved by 14.01% compared to the baseline model, and the ablation study has confirmed the effectiveness of each module in the model.",https://pubmed.ncbi.nlm.nih.gov/39570849/,https://pubmed.ncbi.nlm.nih.gov/39570849/,English,Include,,"FDCN-C: A deep learning model based on frequency enhancement, deformable convolution network, and crop module for electroencephalography motor imagery classification.",Include,," crop classification module, wherein the diverse receptive fields of the EEG data are computed multiple times. Two public datasets are employed to verify the proposed FDCN-C model, the classification accuracy obtained from the proposed model is greater than that of state-of-the-art methods. The model's accuracy has improved by 14.01% compared to the baseline model, and the ablation study has confi",,0.95,0.6,
pubmed:39570847,pubmed:39570847,PubMed,pubmed:39570847,Boosted Harris Hawks Shuffled Shepherd Optimization Augmented Deep Learning based motor imagery classification for brain computer interface.,Fatmah Yousef Assiri;Mahmoud Ragab,2024,10.3389/fnins.2021.774857,"Motor imagery (MI) classification has been commonly employed in making brain-computer interfaces (BCI) to manage the outside tools as a substitute neural muscular path. Effectual MI classification in BCI improves communication and mobility for people with a breakdown or motor damage, delivering a bridge between the brain's intentions and exterior actions. Employing electroencephalography (EEG) or aggressive neural recordings, machine learning (ML) methods are used to interpret patterns of brain action linked with motor image tasks. These models frequently depend upon models like support vector machine (SVM) or deep learning (DL) to distinguish among dissimilar MI classes, such as visualizing left or right limb actions. This procedure allows individuals, particularly those with motor disabilities, to utilize their opinions to command exterior devices like robotic limbs or computer borders. This article presents a Boosted Harris Hawks Shuffled Shepherd Optimization Augmented Deep Learning (BHHSHO-DL) technique based on Motor Imagery Classification for BCI. The BHHSHO-DL technique mainly exploits the hyperparameter-tuned DL approach for MI identification for BCI. Initially, the BHHSHO-DL technique performs data preprocessing utilizing the wavelet packet decomposition (WPD) model. Besides, the enhanced densely connected networks (DenseNet) model extracts the preprocessed data's complex and hierarchical feature patterns. Meanwhile, the BHHSHO technique-based hyperparameter tuning process is accomplished to elect optimal parameter values of the enhanced DenseNet model. Finally, the classification procedure is implemented by utilizing the convolutional autoencoder (CAE) model. The simulation value of the BHHSHO-DL methodology is performed on a benchmark dataset. The performance validation of the BHHSHO-DL methodology portrayed a superior accuracy value of 98.15% and 92.23% over other techniques under BCIC-III and BCIC-IV datasets.",https://pubmed.ncbi.nlm.nih.gov/39570847/,https://pubmed.ncbi.nlm.nih.gov/39570847/,English,Include,,Boosted Harris Hawks Shuffled Shepherd Optimization Augmented Deep Learning based motor imagery classification for brain computer interface.,Include,,volutional autoencoder (CAE) model. The simulation value of the BHHSHO-DL methodology is performed on a benchmark dataset. The performance validation of the BHHSHO-DL methodology portrayed a superior accuracy value of 98.15% and 92.23% over other techniques under BCIC-III and BCIC-IV datasets.,,0.95,0.6,
pubmed:39570515,pubmed:39570515,PubMed,pubmed:39570515,Accurate depth of anesthesia monitoring based on EEG signal complexity and frequency features.,Tianning Li;Yi Huang;Peng Wen;Yan Li,2024,10.1186/s40708-024-00241-y,"Accurate monitoring of the depth of anesthesia (DoA) is essential for ensuring patient safety and effective anesthesia management. Existing methods, such as the Bispectral Index (BIS), are limited in real-time accuracy and robustness. Current methods have problems in generalizability across diverse patient datasets and are sensitive to artifacts, making it difficult to provide reliable DoA assessments in real time. This study proposes a novel method for DoA monitoring using EEG signals, focusing on accuracy, robustness, and real-time application. EEG signals were pre-processed using wavelet denoising and discrete wavelet transform (DWT). Features such as Permutation Lempel-Ziv Complexity (PLZC) and Power Spectral Density (PSD) were extracted. A random forest regression model was employed to estimate anesthetic states, and an unsupervised learning method using the Hurst exponent algorithm and hierarchical clustering was introduced to detect transitions between anesthesia states. The method was tested on two independent datasets (UniSQ and VitalDB), achieving an average Pearson correlation coefficient of 0.86 and 0.82, respectively. For the combined dataset, the model demonstrated an R-squared value of 0.70, a RMSE of 6.31, a MAE of 8.38, and a Pearson correlation of 0.84, showcasing its robustness and generalizability. This approach offers a more accurate and reliable real-time DoA monitoring tool that could significantly improve patient safety and anesthesia management, especially in diverse clinical environments.",https://pubmed.ncbi.nlm.nih.gov/39570515/,https://pubmed.ncbi.nlm.nih.gov/39570515/,English,Include,,Accurate depth of anesthesia monitoring based on EEG signal complexity and frequency features.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39569894,pubmed:39569894,PubMed,pubmed:39569894,Brain-computer interfaces patient preferences: a systematic review.,Jamie F M Brannigan;Kishan Liyanage;Hugo Layard Horsfall;Luke Bashford;William Muirhead;Adam Fry,2024,10.1088/1741-2552/ad94a6,,,https://pubmed.ncbi.nlm.nih.gov/39569894/,English,Exclude,Review/survey papers,Brain-computer interfaces patient preferences: a systematic review.,,,,,0.95,0.6,
pubmed:39569866,pubmed:39569866,PubMed,pubmed:39569866,Enhancing neuroprosthesis calibration: the advantage of integrating prior training over exclusive use of new data.,Caleb J Thomson;Troy N Tully;Eric S Stone;Christian B Morrell;Erik J Scheme;David J Warren;Douglas T Hutchinson;Gregory A Clark;Jacob A George,2024,10.1016/j.ifacol.2023.01.109,,,https://pubmed.ncbi.nlm.nih.gov/39569866/,English,Exclude,Not EEG-BCI focused,Enhancing neuroprosthesis calibration: the advantage of integrating prior training over exclusive use of new data.,,,,,0.9,0.6,
pubmed:39566651,pubmed:39566651,PubMed,pubmed:39566651,Causal brain network analysis of driving fatigue based on generalized orthogonalized partially directed coherence.,Daping Chen;Xin Zhou;Wanchao Yao;Fuwang Wang,2025,10.1016/j.neulet.2024.138057,"Driving fatigue is a serious threat to driving safety. Therefore, it is of great significance to accurately detect driving fatigue. In this study, the generalized orthogonal partial directed coherence (gOPDC) algorithm, which measures the time-frequency domain interaction of electroencephalogram (EEG) signals, was used to accurately estimate the connectivity between cortical channels. The causal brain network of driver continuous driving is constructed. The results show that the clustering coefficient and global efficiency tend to decrease with the increase in driving time. Causal information flow in the left prefrontal, parietal, occipital regions and the right posterior frontal region increased significantly when subjects transitioned from awake to fatigued, while causal information flow in the right prefrontal, parietal, occipital regions and the left posterior frontal region decreased mutually significantly. Compared with the traditional driving fatigue algorithm, the accuracy of the method used in this paper is higher than the traditional methods.",,https://pubmed.ncbi.nlm.nih.gov/39566651/,English,Exclude,Outside date range,Causal brain network analysis of driving fatigue based on generalized orthogonalized partially directed coherence.,,,,,0.95,0.6,
pubmed:39566011,pubmed:39566011,PubMed,pubmed:39566011,Prediction of Survival After Pediatric Cardiac Arrest Using Quantitative EEG and Machine Learning Techniques.,Maayke Hunfeld;Marit Verboom;Sabine Josemans;Annemiek van Ravensberg;Dirk Straver;Femke Lückerath;Geurt Jongbloed;Corinne Buysse;Robert van den Berg,2024,10.1212/wnl.0000000000210043,"Early neuroprognostication in children with reduced consciousness after cardiac arrest (CA) is a major clinical challenge. EEG is frequently used for neuroprognostication in adults, but has not been sufficiently validated for this indication in children. Using machine learning techniques, we studied the predictive value of quantitative EEG (qEEG) features for survival 12 months after CA, based on EEG recordings obtained 24 hours after CA in children. The results were confirmed through visual analysis of EEG background patterns. This is a retrospective single-center study including children (0-17 years) with CA, who were subsequently admitted to the pediatric intensive care unit (PICU) of a tertiary care hospital between 2012 and 2021 after return of circulation (ROC) and were monitored using EEG at 24 hours after ROC. Signal features were extracted from a 30-minute EEG segment 24 hours after CA and used to train a random forest model. The background pattern from the same EEG fragment was visually classified. The primary outcome was survival or death 12 months after CA. Analysis of the prognostic accuracy of the model included calculation of receiver-operating characteristic and predictive values. Feature contribution to the model was analyzed using Shapley values. Eighty-six children were included (in-hospital CA 27%, out-of-hospital CA 73%). The median age at CA was 2.6 years; 53 (62%) were male. Mortality at 12 months was 56%; main causes of death on the PICU were withdrawal of life-sustaining therapies because of poor neurologic prognosis (52%) and brain death (31%). The random forest model was able to predict death at 12 months with an accuracy of 0.77 and positive predictive value of 1.0. Continuity and amplitude of the EEG signal were the signal parameters most contributing to the model classification. Visual analysis showed that no patients with a background pattern other than continuous with amplitudes exceeding 20 μV were alive after 12 months. Both qEEG and visual EEG background classification for registrations obtained 24 hours after ROC form a strong predictor of nonsurvival 12 months after CA in children.",https://pubmed.ncbi.nlm.nih.gov/39566011/,https://pubmed.ncbi.nlm.nih.gov/39566011/,English,Include,,Prediction of Survival After Pediatric Cardiac Arrest Using Quantitative EEG and Machine Learning Techniques.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39565521,pubmed:39565521,PubMed,pubmed:39565521,A Method for Detecting Depression in Adolescence Based on an Affective Brain-Computer Interface and Resting-State Electroencephalogram Signals.,Zijing Guan;Xiaofei Zhang;Weichen Huang;Kendi Li;Di Chen;Weiming Li;Jiaqi Sun;Lei Chen;Yimiao Mao;Huijun Sun;Xiongzi Tang;Liping Cao;Yuanqing Li,2025,10.1007/s12264-024-01319-7,"Depression is increasingly prevalent among adolescents and can profoundly impact their lives. However, the early detection of depression is often hindered by the time-consuming diagnostic process and the absence of objective biomarkers. In this study, we propose a novel approach for depression detection based on an affective brain-computer interface (aBCI) and the resting-state electroencephalogram (EEG). By fusing EEG features associated with both emotional and resting states, our method captures comprehensive depression-related information. The final depression detection model, derived through decision fusion with multiple independent models, further enhances detection efficacy. Our experiments involved 40 adolescents with depression and 40 matched controls. The proposed model achieved an accuracy of 86.54% on cross-validation and 88.20% on the independent test set, demonstrating the efficiency of multimodal fusion. In addition, further analysis revealed distinct brain activity patterns between the two groups across different modalities. These findings hold promise for new directions in depression detection and intervention.",,https://pubmed.ncbi.nlm.nih.gov/39565521/,English,Exclude,Outside date range,A Method for Detecting Depression in Adolescence Based on an Affective Brain-Computer Interface and Resting-State Electroencephalogram Signals.,,,,,0.95,0.0,cv_reported;external_test_reported
pubmed:39564323,pubmed:39564323,PubMed,pubmed:39564323,Meta-analysis on QEEG Changes to Antidepressant Treatment Among Patients with Depression.,Anamika Srivastava;Soumyajit Sanyal;Seema Jaiswal;Shrikant Srivastava,2024,10.1016/s0165-1781(99)00010-4,"Diagnostic and treatment accuracy of depression can lead to a better and possibly earlier response and remission in patients. The literature, though scanty, seems to suggest that quantitative electroencephalography (QEEG) can predict the outcome of antidepressant effects. Articles published between January 1990 and July 2019, including those dealing with QEEG recordings before and after the initiation of antidepressant medication, were included. The pooled effect size and subgroup analysis of waveforms were calculated to predict response to antidepressants. In all, 572 results were retrieved from the searches, of which 20 studies were included. Pooled data using a random-effects model (REM) calculated an effect size of 0.80 (95% CI [0.64-0.97]). Heterogeneity of the sample was low with Tau² = 0.02; df = 18 ( QEEG is a valuable predictor of the antidepressant response. Among the EEG frequencies, the theta band showed the most significant change with treatment.",,https://pubmed.ncbi.nlm.nih.gov/39564323/,English,Exclude,Review/survey papers,Meta-analysis on QEEG Changes to Antidepressant Treatment Among Patients with Depression.,,,,,0.95,0.6,
pubmed:39564260,pubmed:39564260,PubMed,pubmed:39564260,"Development and Validation of a Culturally Adapted, Event-related Potential Paradigm for Assessing Alcohol Cue Reactivity and Error Processing in Alcohol Dependence.",Anupa Arunkumar Shenoy;Samir Kumar Praharaj;Shweta Rai;Kirtana R Nayak;Arun Sasidharan;Hari Prakash Palaniswamy;Chinmay Ajit Suryavanshi;Sumit Sharma;Umesh Shreekantiah;Vrinda Marigowda,2024,10.1371/journal.pone.0037466,"Research on event-related potentials (ERP) in addiction highlights the importance of cognitive ERP markers, such as P300 and error-related negativity (ERN), in distinguishing between alcohol-dependent patients and healthy controls. We aimed to develop and validate ERP paradigms utilizing culturally validated stimuli to evoke P300 and ERN for the Indian population. In a cross-sectional study, 16 alcohol-dependent patients and age-matched healthy controls were recruited. For P300, we designed a visual oddball (Go/No-Go) task using culturally appropriate alcohol and non-alcohol-related images. To study ERN, we used the Assessing Neurocognition via Gamified Experimental Logic (ANGEL) task, developed in India, integrating its ""game"" levels to capture error monitoring with fewer trials. A 32-channel EEG-ERP system was used for data acquisition. Participants showed high engagement in the visual Go/No-Go task, with 94.4% accuracy. The P300 difference wave showed significantly higher amplitudes ( The visual Go/No-Go task and the ANGEL task are promising tools for understanding the neurocognitive mechanisms underlying alcohol dependence in the Indian context.",https://pubmed.ncbi.nlm.nih.gov/39564260/,https://pubmed.ncbi.nlm.nih.gov/39564260/,English,Include,,"Development and Validation of a Culturally Adapted, Event-related Potential Paradigm for Assessing Alcohol Cue Reactivity and Error Processing in Alcohol Dependence.",Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39562659,pubmed:39562659,PubMed,pubmed:39562659,Electroencephalographic signatures of migraine in small prospective and large retrospective cohorts.,Bihua Bie;Samer Ghosn;Shehryar R Sheikh;Matheus Lima Diniz Araujo;Reena Mehra;MaryAnn Mays;Carl Y Saab,2024,10.1038/s41598-024-80249-w,"Migraine is one of the most common neurological disorders in the US. Currently, the diagnosis and management of migraine are based primarily on subjective self-reported measures, which compromises the reliability of clinical diagnosis and the ability to robustly discern candidacy for available therapies and track treatment response. In this study, we used a computational pipeline for the automated, rapid, high-throughput, and objective analysis of encephalography (EEG) data at Cleveland Clinic to identify signatures that correlate with migraine. We performed two independent analyses, a prospective analysis (n = 62 subjects) and a retrospective age-matched analysis on a larger cohort (n = 734) obtained from the sleep registry at Cleveland Clinic. In the prospective analysis, no significant difference between migraine and control groups was detected in the mean power spectral density (PSD) of an all-electrodes montage in the frequency range of 1-32 Hz, whereas a significant PSD increase in single occipital electrodes was found at 12 Hz in migraine patients. We then trained machine learning models on the binary classification of migraine versus control using EEG power features, resulting in high accuracies (82-83%) with occipital electrodes' power at 12 Hz ranking highest in the contribution to the model's performance. Further retrospective analysis also showed a consistent increase in power from occipital electrodes at 12 and 13 Hz in migraine patients. These results demonstrate distinct and localized changes in brain activity measured by EEG that can potentially serve as biomarkers in the diagnosis and personalized therapy for individuals with migraine.",https://pubmed.ncbi.nlm.nih.gov/39562659/,https://pubmed.ncbi.nlm.nih.gov/39562659/,English,Include,,Electroencephalographic signatures of migraine in small prospective and large retrospective cohorts.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39561591,pubmed:39561591,PubMed,pubmed:39561591,The influence of different flavor peptides on brain perception via scalp electroencephalogram and development of a taste model.,Hongbo Li;Xuchao Feng;Zhenbin Liu;Wenting Wang;Lufei Tian;Dan Xu;Bimal Chitrakar;Zhenkun Cui;Liangbin Hu;Haizhen Mo,2025,10.1016/j.foodchem.2024.141953,"Traditional taste evaluation methods often rely on subjective assessments, introducing biases. To address this, we propose using electroencephalography (EEG) to explore the link between brain activity and taste perception. Our EEG analysis showed significant activity differences in specific brain regions, particularly at electrodes Pz, FT7, F7, and TP7, highlighting their role in taste signal processing. Consistent activity at Pz across various tastes supports the development of a mathematical model and sensory evaluation system. We used wavelet packet transform for EEG signal preprocessing, followed by feature extraction and classification with the Common Spatial Pattern (CSP) and Support Vector Machine (SVM) algorithms. Testing five taste categories-sour, sweet, bitter, salty, and umami-resulted in an overall prediction accuracy of 0.7613, with the highest accuracy of 0.8235 for ""sweet"" taste. Despite challenges in predicting ""sour"" and ""salty"" tastes, our study demonstrates the potential of combining wavelet packet transform, CSP, and SVM for EEG-based taste classification.",,https://pubmed.ncbi.nlm.nih.gov/39561591/,English,Exclude,Outside date range,The influence of different flavor peptides on brain perception via scalp electroencephalogram and development of a taste model.,,,,,0.95,0.6,
pubmed:39560448,pubmed:39560448,PubMed,pubmed:39560448,A Modified Transformer Network for Seizure Detection Using EEG Signals.,Wenrong Hu;Juan Wang;Feng Li;Daohui Ge;Yuxia Wang;Qingwei Jia;Shasha Yuan,2024,10.1142/s0129065725500030,"Seizures have a serious impact on the physical function and daily life of epileptic patients. The automated detection of seizures can assist clinicians in taking preventive measures for patients during the diagnosis process. The combination of deep learning (DL) model with convolutional neural network (CNN) and transformer network can effectively extract both local and global features, resulting in improved seizure detection performance. In this study, an enhanced transformer network named Inresformer is proposed for seizure detection, which is combined with Inception and Residual network extracting different scale features of electroencephalography (EEG) signals to enrich the feature representation. In addition, the improved transformer network replaces the existing Feedforward layers with two half-step Feedforward layers to enhance the nonlinear representation of the model. The proposed architecture utilizes discrete wavelet transform (DWT) to decompose the original EEG signals, and the three sub-bands are selected for signal reconstruction. Then, the Co-MixUp method is adopted to solve the problem of data imbalance, and the processed signals are sent to the Inresformer network for seizure information capture and recognition. Finally, discriminant fusion is performed on the results of three-scale EEG sub-signals to achieve final seizure recognition. The proposed network achieves the best accuracy of 100% on Bonn dataset and the average accuracy of 98.03%, sensitivity of 95.65%, and specificity of 98.57% on the long-term CHB-MIT dataset. Compared to the existing DL networks, the proposed method holds significant potential for clinical research and diagnosis applications with competitive performance.",https://pubmed.ncbi.nlm.nih.gov/39560448/,https://pubmed.ncbi.nlm.nih.gov/39560448/,English,Include,,A Modified Transformer Network for Seizure Detection Using EEG Signals.,Include,,"formation capture and recognition. Finally, discriminant fusion is performed on the results of three-scale EEG sub-signals to achieve final seizure recognition. The proposed network achieves the best accuracy of 100% on Bonn dataset and the average accuracy of 98.03%, sensitivity of 95.65%, and specificity of 98.57% on the long-term CHB-MIT dataset. Compared to the existing DL networks, the propos",,0.95,0.6,
pubmed:39560447,pubmed:39560447,PubMed,pubmed:39560447,SATEER: Subject-Aware Transformer for EEG-Based Emotion Recognition.,Romeo Lanzino;Danilo Avola;Federico Fontana;Luigi Cinque;Francesco Scarcello;Gian Luca Foresti,2024,10.1142/s0129065725500029,"This study presents a Subject-Aware Transformer-based neural network designed for the Electroencephalogram (EEG) Emotion Recognition task (SATEER), which entails the analysis of EEG signals to classify and interpret human emotional states. SATEER processes the EEG waveforms by transforming them into Mel spectrograms, which can be seen as particular cases of images with the number of channels equal to the number of electrodes used during the recording process; this type of data can thus be processed using a Computer Vision pipeline. Distinct from preceding approaches, this model addresses the variability in individual responses to identical stimuli by incorporating a User Embedder module. This module enables the association of individual profiles with their EEGs, thereby enhancing classification accuracy. The efficacy of the model was rigorously evaluated using four publicly available datasets, demonstrating superior performance over existing methods in all conducted benchmarks. For instance, on the AMIGOS dataset (A dataset for Multimodal research of affect, personality traits, and mood on Individuals and GrOupS), SATEER's accuracy exceeds 99.8% accuracy across all labels and showcases an improvement of 0.47% over the state of the art. Furthermore, an exhaustive ablation study underscores the pivotal role of the User Embedder module and each other component of the presented model in achieving these advancements.",https://pubmed.ncbi.nlm.nih.gov/39560447/,https://pubmed.ncbi.nlm.nih.gov/39560447/,English,Include,,SATEER: Subject-Aware Transformer for EEG-Based Emotion Recognition.,Include,,"lity in individual responses to identical stimuli by incorporating a User Embedder module. This module enables the association of individual profiles with their EEGs, thereby enhancing classification accuracy. The efficacy of the model was rigorously evaluated using four publicly available datasets, demonstrating superior performance over existing methods in all conducted benchmarks. For instance,",,0.95,0.6,
pubmed:39560446,pubmed:39560446,PubMed,pubmed:39560446,Enhancing Motor Imagery Classification with Residual Graph Convolutional Networks and Multi-Feature Fusion.,Fangzhou Xu;Weiyou Shi;Chengyan Lv;Yuan Sun;Shuai Guo;Chao Feng;Yang Zhang;Tzyy-Ping Jung;Jiancai Leng,2025,10.1142/s0129065724500692,"Stroke, an abrupt cerebrovascular ailment resulting in brain tissue damage, has prompted the adoption of motor imagery (MI)-based brain-computer interface (BCI) systems in stroke rehabilitation. However, analyzing electroencephalogram (EEG) signals from stroke patients poses challenges. To address the issues of low accuracy and efficiency in EEG classification, particularly involving MI, the study proposes a residual graph convolutional network (M-ResGCN) framework based on the modified ",,https://pubmed.ncbi.nlm.nih.gov/39560446/,English,Exclude,Outside date range,Enhancing Motor Imagery Classification with Residual Graph Convolutional Networks and Multi-Feature Fusion.,,,,,0.95,0.6,
pubmed:39560445,pubmed:39560445,PubMed,pubmed:39560445,Deep Learning Recognition of Paroxysmal Kinesigenic Dyskinesia Based on EEG Functional Connectivity.,Liang Zhao;Renling Zou;Linpeng Jin,2025,10.1142/s0129065725500017,"Paroxysmal kinesigenic dyskinesia (PKD) is a rare neurological disorder marked by transient involuntary movements triggered by sudden actions. Current diagnostic approaches, including genetic screening, face challenges in identifying secondary cases due to symptom overlap with other disorders. This study introduces a novel PKD recognition method utilizing a resting-state electroencephalogram (EEG) functional connectivity matrix and a deep learning architecture (AT-1CBL). Resting-state EEG data from 44 PKD patients and 44 healthy controls (HCs) were collected using a 128-channel EEG system. Functional connectivity matrices were computed and transformed into graph data to examine brain network property differences between PKD patients and controls through graph theory. Source localization was conducted to explore neural circuit differences in patients. The AT-1CBL model, integrating 1D-CNN and Bi-LSTM with attentional mechanisms, achieved a classification accuracy of 93.77% on phase lag index (PLI) features in the Theta band. Graph theoretic analysis revealed significant phase synchronization impairments in the Theta band of the functional brain network in PKD patients, particularly in the distribution of weak connections compared to HCs. Source localization analyses indicated greater differences in functional connectivity in sensorimotor regions and the frontal-limbic system in PKD patients, suggesting abnormalities in motor integration related to clinical symptoms. This study highlights the potential of deep learning models based on EEG functional connectivity for accurate and cost-effective PKD diagnosis, supporting the development of portable EEG devices for clinical monitoring and diagnosis. However, the limited dataset size may affect generalizability, and further exploration of multimodal data integration and advanced deep learning architectures is necessary to enhance the robustness of PKD diagnostic models.",,https://pubmed.ncbi.nlm.nih.gov/39560445/,English,Exclude,Outside date range,Deep Learning Recognition of Paroxysmal Kinesigenic Dyskinesia Based on EEG Functional Connectivity.,,,,,0.95,0.6,
pubmed:39559393,pubmed:39559393,PubMed,pubmed:39559393,The brain-heart connection: Value of concurrent ECG and EEG recordings in epilepsy management.,Jeremy D Slater;Selim Benbadis;Richard L Verrier,2024,10.1046/j.1540-8167.2001.00841.x,"Concurrent electrocardiogram (ECG) and electroencephalogram (EEG) recording both ictally and interictally has significant value in the comprehensive management of epilepsy. This review highlights the diagnostic utility of simultaneous ECG and EEG monitoring in differentiating between epileptic and cardiac events, detecting cardiac abnormalities, and identifying autonomic dysfunction. The critical role of this combined approach to defining the mechanisms underlying cardiac morbidity and sudden cardiac death in patients with epilepsy and in guiding therapeutic interventions is underscored. The ""Epileptic Heart Syndrome"" is examined, illustrating how chronic epilepsy can adversely affect cardiac structure and function, leading to increased risk for interictal cardiac arrhythmias, morbidities, and mortality. The findings emphasize the need for standardized protocols for routine concurrent ECG and EEG recording in epilepsy monitoring units both ictally and interictally to ensure comprehensive patient care, improve diagnostic accuracy, and potentially reduce epilepsy-related morbidity and mortality. Future research directions are proposed to address existing gaps and to advance the technology and methodology for concurrent monitoring including wearable and computer-based monitoring systems.",,https://pubmed.ncbi.nlm.nih.gov/39559393/,English,Exclude,Review/survey papers,The brain-heart connection: Value of concurrent ECG and EEG recordings in epilepsy management.,,,,,0.95,0.6,
pubmed:39558681,pubmed:39558681,PubMed,pubmed:39558681,Electroencephalographic (EEG) Stages in Patients With Cerebral Edema Following Cardiac Arrest.,David E Horvat;Julia S Keenan;Caroline Conley;Katelyn Staso;Dana B Harrar;Arnold J Sansevere,2025,10.1177/08830738241289161,"ObjectiveTo describe electroencephalographic (EEG) changes in pediatric patients with cerebral edema after cardiac arrest.MethodsA retrospective study of patients admitted to the pediatric intensive care unit from July 2021 to January 2023. We included patients with cardiac arrest and changes in EEG background with clinical changes and/or neuroimaging consistent with cerebral edema. We excluded patients with electrographic seizures. We applied American Clinical Neurophysiology Society standardized critical care EEG terminology to classify EEG background, noting timing of the change in background classification. Clinical variables included age, sex, and neuroimaging findings and were described with descriptive statistics.ResultsNine patients met inclusion criteria, with median age 24 months (interquartile range 21-49), and 89% were male. There were 5 common EEG stages: stage 1, burst suppression/burst attenuation; stage 2, continuous/discontinuous ± multifocal sporadic epileptiform discharges ± rhythmic or periodic patterns; stage 3, discontinuous/burst suppression/burst attenuation ± rhythmic or periodic patterns; stage 4, gradual voltage suppression; and stage 5, diffuse suppression. The ranges for each stage were as follows: stage 1, 2-10 hours; stage 2, 2.5-15.5 hours; stage 3, 0.5-6.24 hours; and stage 4, 0.5-11 hours. We could not calculate the duration of stage 5 given no uniform time to EEG discontinuation. One patient had a clinical change in stage 3. Remaining patients presented with fixed and dilated pupils with global anoxic injury.ConclusionsEEG stages of cerebral edema have not been described after pediatric cardiac arrest. These stages may be relevant to other patient populations. Early stages may be a therapeutic target for intracranial pressure-lowering medications and/or neuroprotective strategies to minimize sequalae of cerebral edema.",,https://pubmed.ncbi.nlm.nih.gov/39558681/,English,Exclude,Outside date range,Electroencephalographic (EEG) Stages in Patients With Cerebral Edema Following Cardiac Arrest.,,,,,0.95,0.6,
pubmed:39558668,pubmed:39558668,PubMed,pubmed:39558668,Enhanced neural sensitivity to brief changes of happy over angry facial expressions in preschoolers: A fast periodic visual stimulation study.,Sandra Naumann;Mareike Bayer;Isabel Dziobek,2025,10.1080/00221325.2012.732125,"Across childhood, emotion perception from facial expressions has traditionally been studied with event-related potentials (ERP). Here, we explored the novel fast periodic visual stimulation (FPVS) electroencephalography (EEG) approach to provide information about how brief changes in facial expressions are processed implicitly in young children's brains. Utilizing two FPVS tasks for the first time in preschoolers, we examined brain responses to (1) the discrimination of brief changes in facial expressions at maximum intensity and (2) thresholds for discrimination of gradual increasing facial expression intensities. Within a stream of neutral faces at 6 Hz, happy and angry faces were embedded with a frequency of 1.2 Hz. Additionally, children performed an emotion recognition task (ERT). Data were collected in the context of a training study for socio-emotional competencies with typically developing children (N = 74; 5.1[0.9] years; 34 females). FPVS data were collected post-training, where training was included as a controlling factor. Across FPVS tasks, we detected robust expression change responses, particularly with larger responses for happy versus angry faces in the maximum intensity task. ERT results paralleled neural findings with faster reaction times and higher accuracy rates for happy versus angry faces. For gradual increases in emotional intensity, we found linear increases in responses across emotions. The majority of the sample showed a significant expression change at 60% intensity. With its implicit nature, short duration, and robustness of individual responses, our results highlight the potential of FPVS in comparison to classical ERP methods to study neural mechanisms of emotion perception in preschool samples.",,https://pubmed.ncbi.nlm.nih.gov/39558668/,English,Exclude,Outside date range,Enhanced neural sensitivity to brief changes of happy over angry facial expressions in preschoolers: A fast periodic visual stimulation study.,,,,,0.95,0.6,
pubmed:39558602,pubmed:39558602,PubMed,pubmed:39558602,Meditation expertise influences response bias and prestimulus alpha activity in the somatosensory signal detection task.,Maik Mylius;Simon Guendelman;Fivos Iliopoulos;Vittorio Gallese;Laura Kaltwasser,2025,10.1162/jocn.2009.21247,"This study investigates the proposed mechanism of mindfulness, its impact on body awareness and interoception, and its potential benefits for mental and physical health. Using psychophysical assessments, we compared 31 expert meditators with 33 matched controls (non-meditators who engage in regular reading, more than 5 h per week) in terms of somatosensory accuracy with a somatosensory signal detection task (SSDT) and interoceptive sensibility via self-report measures. We hypothesized that meditators would demonstrate superior somatosensory accuracy, indicative of heightened body awareness, potentially linked to increased alpha modulation in the somatosensory cortex, as observed via electroencephalography (EEG). In the SSDT, participants attempted to detect near-threshold tactile stimuli presented with a non-informative light in half of the trials. Contrary to our expectations, the findings showed that meditators had a lower decision threshold rather than higher accuracy. EEG results corroborated earlier research, indicating reduced prestimulus alpha power in meditators, suggesting enhanced alpha modulation. Furthermore, a trial-by-trial analysis revealed a negative correlation between prestimulus alpha activity and tactile perception. Compared to controls, meditators also reported greater interoceptive sensibility, less emotional suppression, and fewer difficulties in describing feelings. These findings may imply that enhanced tactile perception is associated with lower prestimulus alpha activity by reducing sensory filtering in the somatosensory cortex, thus increasing response rates without necessarily improving accuracy among meditators.",,https://pubmed.ncbi.nlm.nih.gov/39558602/,English,Exclude,Outside date range,Meditation expertise influences response bias and prestimulus alpha activity in the somatosensory signal detection task.,,,,,0.95,0.8,small_sample_mentioned
pubmed:39556943,pubmed:39556943,PubMed,pubmed:39556943,A multi-feature fusion graph attention network for decoding motor imagery intention in spinal cord injury patients.,Jiancai Leng;Licai Gao;Xiuquan Jiang;Yitai Lou;Yuan Sun;Chen Wang;Jun Li;Heng Zhao;Chao Feng;Fangzhou Xu;Yang Zhang;Tzyy-Ping Jung,2024,10.1088/1741-2552/ad9403,,,https://pubmed.ncbi.nlm.nih.gov/39556943/,English,Exclude,Not EEG-BCI focused,A multi-feature fusion graph attention network for decoding motor imagery intention in spinal cord injury patients.,,,,,0.9,0.6,
pubmed:39556089,pubmed:39556089,PubMed,pubmed:39556089,Retrospective characterization of seizure semiology and treatment using continuous video-EEG monitoring in neonatal encephalopathy in Uganda.,J Proietti;C Nanyunja;S R Mathieson;E Duckworth;S Sadoo;I Mambule;A Nakimuli;C J Tann;G B Boylan,2025,10.1001/jamanetworkopen.2023.43429,"Neonatal encephalopathy (NE) is a leading cause of childhood death and disability, particularly in sub-Saharan Africa. Detection of NE-related seizures is challenging. We explored NE seizure semiology and management in Uganda. Video-EEG was recorded (days 1-5), seizure semiology reviewed according to ILAE classification and administration of antiseizure medication (ASM) evaluated. Clinicians treated seizures based on the clinical presentation alone. Among 50 participants, 52% (26) had EEG-confirmed seizures; 70% (18) combined electroclinical/electrographic; 4% (1) exclusively electroclinical; 22% (6) electrographic. Of those with electroclinical seizures (19), 42% displayed >1 semiology. Distribution of seizure semiology was; clonic 34% (11); autonomic 24% (8, of which 6 had prolonged ictal apnea); automatisms 18% (6); behavioral arrest 12% (4); and sequential 12% (4). ASM was administered to 64% (32/50). Of those with EEG-confirmed seizures, only 62% (16/26) received ASM. In the non-seizure group, 38% (9/24) received ASM during monitoring. ASM was administered 42 times, of which 45% (19) were considered appropriate. In this Ugandan NE population, incidence of seizures was high and clinical manifestations frequent. Clonic, autonomic and automatisms were most common. Clinical management was challenging, with both under and overtreatment evident. Respiratory impairment due to autonomic seizures frequently went unrecognized and is a prominent concern, particularly in settings without neonatal intensive care.",,https://pubmed.ncbi.nlm.nih.gov/39556089/,English,Exclude,Outside date range,Retrospective characterization of seizure semiology and treatment using continuous video-EEG monitoring in neonatal encephalopathy in Uganda.,,,,,0.95,0.8,small_sample_mentioned
pubmed:39555305,pubmed:39555305,PubMed,pubmed:39555305,Lattice 123 pattern for automated Alzheimer's detection using EEG signal.,Sengul Dogan;Prabal Datta Barua;Mehmet Baygin;Turker Tuncer;Ru-San Tan;Edward J Ciaccio;Hamido Fujita;Aruna Devi;U Rajendra Acharya,2024,10.1007/s11571-024-10104-1,"This paper presents an innovative feature engineering framework based on lattice structures for the automated identification of Alzheimer's disease (AD) using electroencephalogram (EEG) signals. Inspired by the Shannon information entropy theorem, we apply a probabilistic function to create the novel Lattice123 pattern, generating two directed graphs with minimum and maximum distance-based kernels. Using these graphs and three kernel functions (signum, upper ternary, and lower ternary), we generate six feature vectors for each input signal block to extract textural features. Multilevel discrete wavelet transform (MDWT) was used to generate low-level wavelet subbands. Our proposed model mirrors deep learning approaches, facilitating feature extraction in frequency and spatial domains at various levels. We used iterative neighborhood component analysis to select the most discriminative features from the extracted vectors. An iterative hard majority voting and a greedy algorithm were used to generate voted vectors to select the optimal channel-wise and overall results. Our proposed model yielded a classification accuracy of more than 98% and a geometric mean of more than 96%. Our proposed Lattice123 pattern, dynamic graph generation, and MDWT-based multilevel feature extraction can detect AD accurately as the proposed pattern can extract subtle changes from the EEG signal accurately. Our prototype is ready to be validated using a large and diverse database.",https://pubmed.ncbi.nlm.nih.gov/39555305/,https://pubmed.ncbi.nlm.nih.gov/39555305/,English,Include,,Lattice 123 pattern for automated Alzheimer's detection using EEG signal.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39555303,pubmed:39555303,PubMed,pubmed:39555303,Assessment of rTMS treatment effects for methamphetamine addiction based on EEG functional connectivity.,Yongcong Li;Banghua Yang;Jun Ma;Yunzhe Li;Hui Zeng;Jie Zhang,2024,10.1007/s11571-024-10097-x,"Methamphetamine (MA) addiction leads to impairment of neural communication functions in the brain, and functional connectivity (FC) may be a valid indicator. However, it is unclear how FC in the brain changes in methamphetamine use disorder (MUD) after treatment with repetitive transcranial magnetic stimulation (rTMS). Thirty-four patients with MUD participated in this study. The subjects were randomized to receive the active or sham rTMS for four weeks. Subjects performed electroencephalography (EEG) examinations and visual analogue scale (VAS) assessments before and after the treatment. The FC networks were constructed and visualized, and then the graph theory analysis was carried out. Finally, machine learning was used to classify FC networks before and after rTMS. The results showed that (1) the active group showed a significant enhancement in connectivity in the beta band; (2) the global efficiency, local efficiency, and aggregation coefficient of the active group in the beta band decreased significantly; (3) the LDA algorithm combined with the beta band FC matrix achieved an average accuracy of 82.5% in distinguishing before and after treatment. This study demonstrated that brain FC could effectively assess the therapeutic effect of rTMS, among which the beta band was the most sensitive and effective frequency band. The online version contains supplementary material available at 10.1007/s11571-024-10097-x.",https://pubmed.ncbi.nlm.nih.gov/39555303/,https://pubmed.ncbi.nlm.nih.gov/39555303/,English,Include,,Assessment of rTMS treatment effects for methamphetamine addiction based on EEG functional connectivity.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39555298,pubmed:39555298,PubMed,pubmed:39555298,An effective classification approach for EEG-based motor imagery tasks combined with attention mechanisms.,Jixiang Li;Wuxiang Shi;Yurong Li,2024,10.1007/s11571-024-10115-y,"Currently, electroencephalogram (EEG)-based motor imagery (MI) signals have been received extensive attention, which can assist disabled subjects to control wheelchair, automatic driving and other activities. However, EEG signals are easily affected by some factors, such as muscle movements, wireless devices, power line, etc., resulting in the low signal-to-noise ratios and the worse recognition results on EEG decoding. Therefore, it is crucial to develop a stable model for decoding MI-EEG signals. To address this issue and further improve the decoding performance for MI tasks, a hybrid structure combining convolutional neural networks and bidirectional long short-term memory (BLSTM) model, namely CBLSTM, is developed in this study to handle the various EEG-based MI tasks. Besides, the attention mechanism (AM) model is further adopted to adaptively assign the weight of EEG vital features and enhance the expression which beneficial to classification for MI tasks. First of all, the spatial features and the time series features are extracted by CBLSTM from preprocessed MI-EEG data, respectively. Meanwhile, more effective features information can be mined by the AM model, and the softmax function is utilized to recognize intention categories. Ultimately, the numerical results illustrate that the model presented achieves an average accuracy of 98.40% on the public physioNet dataset and faster training process for decoding MI tasks, which is superior to some other advanced models. Ablation experiment performed also verifies the effectiveness and feasibility of the developed model. Moreover, the established network model provides a good basis for the application of brain-computer interface in rehabilitation medicine.",https://pubmed.ncbi.nlm.nih.gov/39555298/,https://pubmed.ncbi.nlm.nih.gov/39555298/,English,Include,,An effective classification approach for EEG-based motor imagery tasks combined with attention mechanisms.,Include,,"rmation can be mined by the AM model, and the softmax function is utilized to recognize intention categories. Ultimately, the numerical results illustrate that the model presented achieves an average accuracy of 98.40% on the public physioNet dataset and faster training process for decoding MI tasks, which is superior to some other advanced models. Ablation experiment performed also verifies the e",,0.95,0.6,
pubmed:39555297,pubmed:39555297,PubMed,pubmed:39555297,PSPN: Pseudo-Siamese Pyramid Network for multimodal emotion analysis.,Yanyan Yin;Wanzeng Kong;Jiajia Tang;Jinghao Li;Fabio Babiloni,2024,10.1007/s11571-024-10123-y,"Emotion recognition plays an important role in human life and healthcare. The EEG has been extensively researched as an objective indicator of intense emotions. However, current existing methods lack sufficient analysis of shallow and deep EEG features. In addition, human emotions are complex and variable, making it difficult to comprehensively represent emotions using a single-modal signal. As a signal associated with gaze tracking and eye movement detection, Eye-related signals provide various forms of supplementary information for multimodal emotion analysis. Therefore, we propose a Pseudo-Siamese Pyramid Network (PSPN) for multimodal emotion analysis. The PSPN model employs a Depthwise Separable Convolutional Pyramid (DSCP) to extract and integrate intrinsic emotional features at various levels and scales from EEG signals. Simultaneously, we utilize a fully connected subnetwork to extract the external emotional features from eye-related signals. Finally, we introduce a Pseudo-Siamese network that integrates a flexible cross-modal dual-branch subnetwork to collaboratively utilize EEG emotional features and eye-related behavioral features, achieving consistency and complementarity in multimodal emotion recognition. For evaluation, we conducted experiments on the DEAP and SEED-IV public datasets. The experimental results demonstrate that multimodal fusion significantly improves the accuracy of emotion recognition compared to single-modal approaches. Our PSPN model achieved the best accuracy of 96.02% and 96.45% on the valence and arousal dimensions of the DEAP dataset, and 77.81% on the SEED-IV dataset, respectively. Our code link is: https://github.com/Yinyanyan003/PSPN.git.",https://pubmed.ncbi.nlm.nih.gov/39555297/,https://pubmed.ncbi.nlm.nih.gov/39555297/,English,Include,,PSPN: Pseudo-Siamese Pyramid Network for multimodal emotion analysis.,Include,,"ultimodal emotion recognition. For evaluation, we conducted experiments on the DEAP and SEED-IV public datasets. The experimental results demonstrate that multimodal fusion significantly improves the accuracy of emotion recognition compared to single-modal approaches. Our PSPN model achieved the best accuracy of 96.02% and 96.45% on the valence and arousal dimensions of the DEAP dataset, and 77.81",,0.95,0.6,
pubmed:39555294,pubmed:39555294,PubMed,pubmed:39555294,Functional connectivity of EEG motor rhythms after spinal cord injury.,Jiancai Leng;Xin Yu;Chongfeng Wang;Jinzhao Zhao;Jianqun Zhu;Xinyi Chen;Zhaoxin Zhu;Xiuquan Jiang;Jiaqi Zhao;Chao Feng;Qingbo Yang;Jianfei Li;Lin Jiang;Fangzhou Xu;Yang Zhang,2024,10.1007/s11571-024-10136-7,"Spinal cord injury (SCI), which is the injury of the spinal cord site resulting in motor dysfunction, has prompted the use of motor imagery (MI)-based brain computer interface (BCI) systems for motor function reconstruction. However, analyzing electroencephalogram signals and brain function mechanisms for SCI patients is challenging. This is due to their low signal-to-noise ratio and high variability. We propose using the phase locking value (PLV) to construct the brain network in α and β rhythms for both SCI patients and healthy individuals. This approach aims to analyze the changes in brain network connectivity and brain function mechanisms following SCI. The results show that the connection strength of the α rhythm in the healthy control (HC) group is stronger than that in the SCI group, and the connection strength in the β rhythm of the SCI group is stronger than that in the HC group. Moreover, we extract the PLV with common spatial pattern (PLV-CSP) feature from the MI data of the SCI group. The experimental results for 12 SCI patients include that the peak classification accuracy is 100%, and the average accuracy of the ten-fold cross-verification is 95.6%. Our proposed approach can be used as a potential valuable method for SCI pathological studies and MI-based BCI rehabilitation systems.",https://pubmed.ncbi.nlm.nih.gov/39555294/,https://pubmed.ncbi.nlm.nih.gov/39555294/,English,Include,,Functional connectivity of EEG motor rhythms after spinal cord injury.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39555292,pubmed:39555292,PubMed,pubmed:39555292,Affective EEG-based cross-session person identification using hierarchical graph embedding.,Honggang Liu;Xuanyu Jin;Dongjun Liu;Wanzeng Kong;Jiajia Tang;Yong Peng,2024,10.1007/s11571-024-10132-x,"The electroencephalogram (EEG) signal is being investigated as a more confidential biometric for person identification. Despite recent advancements, a persistent challenge lies in the influence of variations in affective states. Affective states consistently exist during data collection, regardless of the protocol used. Additionally, the inherently non-stationary nature of EEG makes it susceptible to fluctuations in affective states over time. Therefore, it would be highly crucial to perform precise EEG-based person identification under varying affective states. This paper employed an integrated Multi-scale Convolution and Graph Pooling network (MCGP) to mitigate the impact of affective state variations. MCGP utilized multiple 1D convolutions at different scales to dynamically extract and fuse features. Additionally, a graph pooling layer with an attention mechanism was incorporated to generate hierarchical graph embeddings. These embeddings were concatenated as inputs for a fully connected classification layer. Experiments were conducted on the SEED and SEED-V dataset, revealing that MCGP achieved an average accuracy of 85.51% for SEED and 88.69% for SEED-V in cross-session conditions involving mixed affective states. Under single affective state cross-session scenario, MCGP achieved an average accuracy of 85.75% for SEED and 88.06% for SEED-V for the same affective states, while obtaining 79.57% for SEED and 84.52% for SEED-V for different affective states. Results indicated that, compared to the baseline methods, MCGP effectively mitigated the impact of variations in affective states across different sessions. In single affective state cross-session scenario, identification performance for the same affective states was slightly higher than that for different affective states.",https://pubmed.ncbi.nlm.nih.gov/39555292/,https://pubmed.ncbi.nlm.nih.gov/39555292/,English,Include,,Affective EEG-based cross-session person identification using hierarchical graph embedding.,Include,,"embeddings. These embeddings were concatenated as inputs for a fully connected classification layer. Experiments were conducted on the SEED and SEED-V dataset, revealing that MCGP achieved an average accuracy of 85.51% for SEED and 88.69% for SEED-V in cross-session conditions involving mixed affective states. Under single affective state cross-session scenario, MCGP achieved an average accuracy o",,0.95,0.6,
pubmed:39555291,pubmed:39555291,PubMed,pubmed:39555291,EEG emotion recognition based on an innovative information potential index.,Atefeh Goshvarpour;Ateke Goshvarpour,2024,10.1007/s11571-024-10077-1,"The recent exceptional demand for emotion recognition systems in clinical and non-medical applications has attracted the attention of many researchers. Since the brain is the primary object of understanding emotions and responding to them, electroencephalogram (EEG) signal analysis is one of the most popular approaches in affect classification. Previously, different approaches have been presented to benefit from brain connectivity information. We envisioned analyzing the interactions between brain electrodes with the information potential and providing a new index to quantify the connectivity matrix. The current study proposed a simple measure based on the cross-information potential between pairs of EEG electrodes to characterize emotions. This measure was tested for different EEG frequency bands to realize which EEG waves could be fruitful in recognizing emotions. Support vector machine and k-nearest neighbor (kNN) were implemented to classify four emotion categories based on two-dimensional valence and arousal space. Experimental results on the Database for Emotion Analysis using Physiological signals revealed a maximum accuracy of 90.14%, a sensitivity of 89.71%, and an F-score of 94.57% using kNN. The gamma frequency band obtained the highest recognition rates. Furthermore, low valence-low arousal was classified more effectively than other classes.",https://pubmed.ncbi.nlm.nih.gov/39555291/,https://pubmed.ncbi.nlm.nih.gov/39555291/,English,Include,,EEG emotion recognition based on an innovative information potential index.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39555290,pubmed:39555290,PubMed,pubmed:39555290,Vocal tasks-based EEG and speech signal analysis in children with neurodevelopmental disorders: a multimodal investigation.,Yogesh Sharma;Bikesh Kumar Singh;Sangeeta Dhurandhar,2024,10.1007/s11571-024-10096-y,"Neurodevelopmental disorders (NDs) often hamper multiple functional prints of a child brain. Despite several studies on their neural and speech responses, multimodal researches on NDs are extremely rare. The present work examined the electroencephalography (EEG) and speech signals of the ND and control children, who performed ""Hindi language"" vocal tasks (V) of seven different categories, viz. 'vowel', 'consonant', 'one syllable', 'multi-syllable', 'compound', 'complex', and 'sentence' (V1-V7). Statistical testing of EEG parameters showed substantially high beta and gamma band energies in frontal, central, and temporal head sites of NDs for tasks V1-V5 and in parietal too for V6. For the 'sentence' task (V7), the NDs yielded significantly high theta and low alpha energies in the parietal area. These findings imply that even performing a general context-based task exerts a heavy cognitive loading in neurodevelopmental subjects. They also exhibited poor auditory comprehension while executing a long phrasing. Further, the speech signal analysis manifested significantly high amplitude (for V1-V7) and frequency (for V3-V7) perturbations in the voices of ND children. Moreover, the classification of subjects as ND or control was done via EEG and speech features. We attained 100% accuracy, precision, and F-measure using EEG features of all tasks, and using speech features of the 'complex' task. Jointly, the 'complex' task transpired as the best vocal stimuli among V1-V7 for characterizing ND brains. Meanwhile, we also inspected inter-relations between EEG energies and speech attributes of the ND group. Our work, thus, represents a unique multimodal layout to explore the distinctiveness of neuro-impaired children.",https://pubmed.ncbi.nlm.nih.gov/39555290/,https://pubmed.ncbi.nlm.nih.gov/39555290/,English,Include,,Vocal tasks-based EEG and speech signal analysis in children with neurodevelopmental disorders: a multimodal investigation.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39555288,pubmed:39555288,PubMed,pubmed:39555288,Black-white hole pattern: an investigation on the automated chronic neuropathic pain detection using EEG signals.,Irem Tasci;Mehmet Baygin;Prabal Datta Barua;Abdul Hafeez-Baig;Sengul Dogan;Turker Tuncer;Ru-San Tan;U Rajendra Acharya,2024,10.1007/s11571-024-10078-0,"Electroencephalography (EEG) signals provide information about the brain activities, this study bridges neuroscience and machine learning by introducing an astronomy-inspired feature extraction model. In this work, we developed a novel feature extraction function, black-white hole pattern (BWHPat) which dynamically selects the most suitable pattern from 14 options. We developed BWHPat in a four-phase feature engineering model, involving multileveled feature extraction, feature selection, classification, and cortex map generation. Textural and statistical features are extracted in the first phase, while tunable q-factor wavelet transform (TQWT) aids in multileveled feature extraction. The second phase employs iterative neighborhood component analysis (INCA) for feature selection, and the k-nearest neighbors (kNN) classifier is applied for classification, yielding channel-specific results. A new cortex map generation model highlights the most active channels using median and intersection functions. Our BWHPat-driven model consistently achieved over 99% classification accuracy across three scenarios using the publicly available EEG pain dataset. Furthermore, a semantic cortex map precisely identifies pain-affected brain regions. This study signifies the contribution to EEG signal classification and neuroscience. The BWHPat pattern establishes a unique link between astronomy and feature extraction, enhancing the understanding of brain activities.",https://pubmed.ncbi.nlm.nih.gov/39555288/,https://pubmed.ncbi.nlm.nih.gov/39555288/,English,Include,,Black-white hole pattern: an investigation on the automated chronic neuropathic pain detection using EEG signals.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39555286,pubmed:39555286,PubMed,pubmed:39555286,EEG-based schizophrenia detection using fusion of effective connectivity maps and convolutional neural networks with transfer learning.,Sara Bagherzadeh;Ahmad Shalbaf,2024,10.1007/s11571-024-10121-0,"Schizophrenia (SZ) is a serious mental disorder that can mainly be distinguished by symptoms including delusions and hallucinations. This mental disorder makes difficult conditions for the person and her/his relatives. Electroencephalogram (EEG) signal is a sophisticated neuroimaging technique that helps neurologists to diagnose this mental disorder. Estimating and evaluating brain effective connectivity between electrode pairs is an appropriate way of diagnosing brain states in neuroscience studies. In this study, we construct a novel image from multi-channels of EEG based on the fusion of three effective connectivity, partial directed coherence (PDC), and direct directed transfer function (dDTF) and transfer entropy (TE) at three consecutive time windows. Then, this image was used as input of five well-known convolutional neural networks (CNNs) through transfer learning (TL) to learn patterns related to SZ patients to diagnose this disorder from normal participants from two public databases. Also, the majority voting method was used to improve these results based on ensemble results of the five CNNs, i.e., ResNet-50, Inception-v3, DenseNet-201, EfficientNetB0, and NasNet-Mobile. The highest average accuracy, specificity and sensitivity to diagnose SZ patients from healthy participants were obtained using EfficientNetB0 through the Leave-One-Subject-out (LOSO) Cross-Validation criterion equal to 96.67%, 96.23%, 96.82%, 95.15%, 94.42% and 96.28% for the first and second databases, respectively. Also, as we suggested, the ensemble approach of EfficientNetB0, ResNet-50 and NasNet-Mobile increased the accuracy by approximately 3%. Our results show the effectiveness of providing fused images from multichannel EEG signals to the ensemble of CNNs through TL to diagnose SZ than state-of-the-art studies.",https://pubmed.ncbi.nlm.nih.gov/39555286/,https://pubmed.ncbi.nlm.nih.gov/39555286/,English,Include,,EEG-based schizophrenia detection using fusion of effective connectivity maps and convolutional neural networks with transfer learning.,Include,,"ajority voting method was used to improve these results based on ensemble results of the five CNNs, i.e., ResNet-50, Inception-v3, DenseNet-201, EfficientNetB0, and NasNet-Mobile. The highest average accuracy, specificity and sensitivity to diagnose SZ patients from healthy participants were obtained using EfficientNetB0 through the Leave-One-Subject-out (LOSO) Cross-Validation criterion equal to ",,0.95,0.45,cv_reported;small_sample_mentioned
pubmed:39555281,pubmed:39555281,PubMed,pubmed:39555281,Automatic detection of Alzheimer's disease from EEG signals using an improved AFS-GA hybrid algorithm.,Ruofan Wang;Qiguang He;Lianshuan Shi;Yanqiu Che;Haojie Xu;Changzhi Song,2024,10.1007/s11571-024-10130-z,"Alzheimer's Disease (AD) is a neurodegenerative disorder characterized by energy diffusion and partial disconnection in the brain, with its main feature being an insidious onset and subtle clinical symptoms. Electroencephalogram (EEG) as a primary tool for assessing and aiding in the diagnosis of brain diseases has been widely used in AD detection. Accurate diagnosis is crucial for preventing the transition from early cognitive impairment to AD and providing early treatment for AD patients. This study aims to establish a hybrid model based on the Improved Artificial Fish Swarm Algorithm (IAFS) and Genetic Algorithm (GA)-IAFS-GA, to determine the optimal channel combination for AD detection under multiple EEG signals. Geometric features and complexity features of AD EEG signals were extracted using Second Order Difference Plot (SODP) and entropy analysis across the full frequency band. Subsequently, Pearson correlation was used for feature ranking, selecting the six least correlated features for each channel. The Relief algorithm was then used to fuse these selected features, with one fused feature representing one channel. Based on this, a feature selection optimization algorithm, IAFS-GA, combining the improved artificial fish swarm algorithm and genetic algorithm, was proposed. Finally, the feature combination was input into a Naive Bayes classifier for the identification of AD patients and normal controls. The feature combination was input into a Naive Bayes classifier for the identification of AD patients and normal controls. Using a five-fold cross-validation strategy across the entire frequency band, the classification accuracy reached 93.53%, with a sensitivity of 98.74%, specificity of 98.25%, and an AUC area of 97.82%. This framework can quickly select appropriate brain channels to enhance the efficiency of detecting AD and other neurological diseases. Moreover, it is the first time that an improved artificial fish swarm genetic combination algorithm and SODP features has been used for channel selection in EEG, proving to be an effective method for AD detection. It is based on SODP analysis, entropy analysis, and intelligent algorithms, which can assist clinicians in rapidly diagnosing AD, reducing the misdiagnosis rate of false positives, and expanding our understanding of brain function in patients with neurological diseases.",https://pubmed.ncbi.nlm.nih.gov/39555281/,https://pubmed.ncbi.nlm.nih.gov/39555281/,English,Include,,Automatic detection of Alzheimer's disease from EEG signals using an improved AFS-GA hybrid algorithm.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.25,cv_reported
pubmed:39555277,pubmed:39555277,PubMed,pubmed:39555277,Resting state EEG microstate profiling and a machine-learning based classifier model in epilepsy.,Asha Sa;Sudalaimani C;Devanand P;Subodh Ps;Arya Ml;Devika Kumar;Sanjeev V Thomas;Ramshekhar N Menon,2024,10.1007/s11571-024-10095-z,"Electroencephalography-based (EEG) microstate analysis is a promising and widely studied method in which spontaneous cerebral activity is segmented into sub second level quasi-stable states and analyzed. Currently it is being widely explored due to increasing evidence of the association of microstates with cognitive functioning and large-scale brain networks identified by functional magnetic resonance imaging (fMRI). In our study using the four archetypal microstates (A, B, C and D), we investigated the changes in resting state EEG microstate dynamics in persons with temporal lobe epilepsy (TLE) and idiopathic generalized epilepsy (IGE) compared to healthy controls (HC). Machine learning was applied to study its feasibility in differentiating between different groups using microstate statistics. We found significant differences in all parameters related to Microstate D (fronto-parietal network) in TLE patients and Microstate B (visual processing) in IGE patients compared to HCs. Occurrence, duration and time coverage of Microstate B was highest in IGE when compared to the other groups. We also found significant deviations in transition probabilities for both epilepsy groups, particularly into Microstate C (salience network) in IGE. Classification accuracy into clinical groups was found to exceed 70% using microstate parameters which improved on incorporating neuropsychological test differences. To the best of our knowledge, the current study is the first to compare and validate the use of microstate features to discriminate between two disparate epilepsy syndromes (TLE, IGE) and HCs using machine learning suggesting that resting state EEG microstates can be used for endophenotyping and to study resting state dysfunction in epilepsy. The online version contains supplementary material available at 10.1007/s11571-024-10095-z.",https://pubmed.ncbi.nlm.nih.gov/39555277/,https://pubmed.ncbi.nlm.nih.gov/39555277/,English,Include,,Resting state EEG microstate profiling and a machine-learning based classifier model in epilepsy.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39555272,pubmed:39555272,PubMed,pubmed:39555272,Quantitative analysis and machine learning-based interpretation of EEG signals in coma and brain-death diagnosis.,Boning Li;Jinsha Liu;Tao Zhang;Yang Cao;Jianting Cao,2024,10.1007/s11571-024-10131-y,"Electroencephalography (EEG) reflects brain activity and is crucial for diagnosing states such as coma and brain-death. However, the clinical interpretation of EEG signals faces challenges due to the patients' faint brain activity and the complexities of the intensive care unit environment, further compounded by the absence of quantified standards for signal analysis. This study developed an improved denoise method tailored to the characteristics of Coma/Brain-Death EEG signals. The spectral feature map derived from the EEG signal via Variational Mode Decomposition (VMD) with a mode number (K) of 5, represents the frequency-based energy distribution. Subsequently, by integrating the Recursive Feature Elimination (RFE) algorithm with Support Vector Machine (SVM) algorithm employing cross-validation method, distinctive energy features in the 4-9Hz frequency band of coma patients compared to brain-death patients are identified. An accuracy of 99.59% and an F1-score of 99.61% for the SVM classifier demonstrate the high precision and reliability of the method. The application of specific machine learning algorithms provides robust theoretical support for the nuanced clinical interpretation of EEG signals across different levels of consciousness. This approach not only deepens scientific understanding of EEG signal variations associated with distinct consciousness levels but also establishes a solid foundation for future research aimed at quantifying EEG signal characteristics for the diagnosis and monitoring of brain diseases like epilepsy, Alzheimer's, and sleep disorders.",https://pubmed.ncbi.nlm.nih.gov/39555272/,https://pubmed.ncbi.nlm.nih.gov/39555272/,English,Include,,Quantitative analysis and machine learning-based interpretation of EEG signals in coma and brain-death diagnosis.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.25,cv_reported
pubmed:39555270,pubmed:39555270,PubMed,pubmed:39555270,Development of a humanoid robot control system based on AR-BCI and SLAM navigation.,Yao Wang;Mingxing Zhang;Meng Li;Hongyan Cui;Xiaogang Chen,2024,10.1007/s11571-024-10122-z,"Brain-computer interface (BCI)-based robot combines BCI and robotics technology to realize the brain's intention to control the robot, which not only opens up a new way for the daily care of the disabled individuals, but also provides a new way of communication for normal people. However, the existing systems still have shortcomings in many aspects such as friendliness of human-computer interaction, and interaction efficient. This study developed a humanoid robot control system by integrating an augmented reality (AR)-based BCI with a simultaneous localization and mapping (SLAM)-based scheme for autonomous indoor navigation. An 8-target steady-state visual evoked potential (SSVEP)-based BCI was implemented to enable direct control of the humanoid robot by the user. A Microsoft HoloLens was utilized to display visual stimuli for eliciting SSVEPs. Filter bank canonical correlation analysis (FBCCA), a training-free method, was used to detect SSVEPs in this study. By leveraging SLAM technology, the proposed system alleviates the need for frequent control commands transmission from the user, thereby effectively reducing their workload. Online results from 12 healthy subjects showed this developed BCI system was able to select a command out of eight potential targets with an average accuracy of 94.79%. The autonomous navigation subsystem enabled the humanoid robot to autonomously navigate to a destination chosen utilizing the proposed BCI. Furthermore, all participants successfully completed the experimental task using the developed system without any prior training. These findings illustrate the feasibility of the developed system and its potential to contribute novel insights into humanoid robots control strategies.",https://pubmed.ncbi.nlm.nih.gov/39555270/,https://pubmed.ncbi.nlm.nih.gov/39555270/,English,Include,,Development of a humanoid robot control system based on AR-BCI and SLAM navigation.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39555269,pubmed:39555269,PubMed,pubmed:39555269,Classification algorithm for motor imagery fusing CNN and attentional mechanisms based on functional near-infrared spectroscopy brain image.,Xingbin Shi;Baojiang Li;Wenlong Wang;Yuxin Qin;Haiyan Wang;Xichao Wang,2024,10.1007/s11571-024-10116-x,"With the continuing development of brain-computer interface technology, the analysis and interpretation of brain signals are becoming increasingly important. In the field of brain-computer interfaces, motor imagery (MI) is an important paradigm for generating specific brain signals through thought alone, rather than actual movement, for computer decoding. Functional near-infrared spectroscopy (fNIRS) imaging technology has been increasingly used in brain-computer interfaces due to its advantages of non-invasiveness, low resource requirements, low cost, and high spatial resolution. Scientists have done a lot of work in channel selection, feature selection, and then applying traditional machine learning methods for classification, but the results achieved so far are still insufficient to meet the conditions for realizing fNIRS brain-computer interfaces. To achieve a higher level of classification of fNIRS signals, we propose a method that fuses CNN and attention mechanisms to analyze the near-infrared signals of motor imagery and mental arithmetic data, which is fed into a neural network by deriving signals of changes in oxygenated hemoglobin (HbO) and deoxygenated hemoglobin (HbR) concentrations through the modified Beer-Lambert law, and then applied to the fNIRS dataset of 29 healthy subjects to validate the proposed method. In the fNIRS-based BCI, the average classification accuracy of the MI signal from HbR and HbO reaches 85.92% and 86.21%, respectively, and the average classification accuracy of the MA signal reaches 89.66% and 88.79%, respectively. The advantage of our approach is that it is lightweight and improves the classification accuracy of current BCI fNIRS signals.",https://pubmed.ncbi.nlm.nih.gov/39555269/,https://pubmed.ncbi.nlm.nih.gov/39555269/,English,Include,,Classification algorithm for motor imagery fusing CNN and attentional mechanisms based on functional near-infrared spectroscopy brain image.,Include,," concentrations through the modified Beer-Lambert law, and then applied to the fNIRS dataset of 29 healthy subjects to validate the proposed method. In the fNIRS-based BCI, the average classification accuracy of the MI signal from HbR and HbO reaches 85.92% and 86.21%, respectively, and the average classification accuracy of the MA signal reaches 89.66% and 88.79%, respectively. The advantage of o",,0.95,0.6,
pubmed:39555268,pubmed:39555268,PubMed,pubmed:39555268,Reliable electrocortical dynamics of target-directed pass-kicks.,Daghan Piskin;Daniel Büchel;Tim Lehmann;Jochen Baumeister,2024,10.1007/s11571-024-10094-0,"Football is one of the most played sports in the world and kicking with adequate accuracy increases the likelihood of winning a competition. Although studies with different target-directed movements underline the role of distinctive cortical activity on superior accuracy, little is known about cortical dynamics associated with kicking. Mobile electroencephalography is a popular tool to investigate cortical modulations during movement, however, inherent and artefact-related pitfalls may obscure the reliability of functional sources and their activity. The purpose of this study was therefore to describe consistent cortical dynamics underlying target-directed pass-kicks based on test-retest reliability estimates. Eleven participants performed a target-directed kicking task at two different sessions within one week. Electroencephalography was recorded using a 65-channel mobile system and behavioural data were collected including motion range, acceleration and accuracy performance. Functional sources were identified using independent component analysis and clustered in two steps with the components of first and subsequently both sessions. Reliability estimates of event-related spectral perturbations were computed pixel-wise for participants contributing with components of both sessions. The parieto-occipital and frontal clusters were reproducible for the same majority of the sample at both sessions. Their activity showed consistent alpha desyhronization and theta sychnronisation patterns with substantial reliability estimates revealing visual and attentional demands in different phases of kicking. The findings of our study reveal prominent cortical demands during the execution of a target-directed kick which may be considered in practical implementations and provide promising academic prospects in the comprehension and investigation of cortical activity associated with target-directed movements. The online version contains supplementary material available at 10.1007/s11571-024-10094-0.",https://pubmed.ncbi.nlm.nih.gov/39555268/,https://pubmed.ncbi.nlm.nih.gov/39555268/,English,Include,,Reliable electrocortical dynamics of target-directed pass-kicks.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39555266,pubmed:39555266,PubMed,pubmed:39555266,Research progress of epileptic seizure prediction methods based on EEG.,Zhongpeng Wang;Xiaoxin Song;Long Chen;Jinxiang Nan;Yulin Sun;Meijun Pang;Kuo Zhang;Xiuyun Liu;Dong Ming,2024,10.1007/s11571-024-10109-w,"At present, at least 30% of refractory epilepsy patients in the world cannot be effectively controlled and treated. The suddenness and unpredictability of seizures greatly affect the physical and mental health and even the life safety of patients, and the realization of early prediction of seizures and the adoption of interventions are of great significance to the improvement of patients' quality of life. In this paper, we firstly introduce the design process of EEG-based seizure prediction methods, introduce several databases commonly used in the research, and summarize the commonly used methods in pre-processing, feature extraction, classification and identification, and post-processing. Then, based on scalp EEG and intracranial EEG respectively, we reviewed the current status of epileptic seizure prediction research from five commonly used feature analysis methods, and make a comprehensive evaluation of both. Finally, this paper describes the reasons why the current algorithms cannot be applied to the clinic, summarizes their limitations, and gives corresponding suggestions, aiming to provide improvement directions for subsequent research. In addition, deep learning algorithms have emerged in recent years, and this paper also compares the advantages and disadvantages of deep learning algorithms with traditional machine learning methods, in the hope of providing researchers with new technologies and new ideas and making significant breakthroughs in the field of epileptic seizure prediction.",,https://pubmed.ncbi.nlm.nih.gov/39555266/,English,Exclude,Review/survey papers,Research progress of epileptic seizure prediction methods based on EEG.,,,,,0.95,0.6,
pubmed:39555265,pubmed:39555265,PubMed,pubmed:39555265,Multiple-source distribution deep adaptive feature norm network for EEG emotion recognition.,Lei Zhu;Fei Yu;Wangpan Ding;Aiai Huang;Nanjiao Ying;Jianhai Zhang,2024,10.1007/s11571-024-10092-2,"Electroencephalogram (EEG) emotion recognition plays an important role in human-computer interaction, and a higher recognition accuracy can improve the user experience. In recent years, domain adaptive methods in transfer learning have been used to construct a general emotion recognition model to deal with domain difference among different subjects and sessions. However, it is still challenging to effectively reduce domain difference in domain adaptation. In this paper, we propose a Multiple-Source Distribution Deep Adaptive Feature Norm Network for EEG emotion recognition, which reduce domain difference by improving the transferability of task-specific features. In detail, the domain adaptive method of our model employs a three-layer network topology, inserts Adaptive Feature Norm to self-supervised adjustment between different layers, and combines a multiple-kernel selection approach to mean embedding matching. The method proposed in this paper achieves the best classification performance in the SEED and SEED-IV datasets. In SEED dataset, the average accuracy of cross-subject and cross-session experiments is 85.01 and 91.93%, respectively. In SEED-IV dataset, the average accuracy is 58.81% in cross-subject experiments and 59.51% in cross-session experiments. The experimental results demonstrate that our method can effectively reduce the domain difference and improve the emotion recognition accuracy.",https://pubmed.ncbi.nlm.nih.gov/39555265/,https://pubmed.ncbi.nlm.nih.gov/39555265/,English,Include,,Multiple-source distribution deep adaptive feature norm network for EEG emotion recognition.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39555263,pubmed:39555263,PubMed,pubmed:39555263,STEADYNet: Spatiotemporal EEG analysis for dementia detection using convolutional neural network.,Pramod H Kachare;Sandeep B Sangle;Digambar V Puri;Mousa Mohammed Khubrani;Ibrahim Al-Shourbaji,2024,10.1007/s11571-024-10153-6,"Dementia is a neuro-degenerative disorder with a high death rate, mainly due to high human error, time, and cost of the current clinical diagnostic techniques. The existing dementia detection methods using hand-crafted electroencephalogram (EEG) signal features are unreliable. A convolution neural network using spatiotemporal EEG signals (STEADYNet) is presented to improve the dementia detection. The STEADYNet uses a multichannel temporal EEG signal as input. The network is grouped into feature extraction and classification components. The feature extraction comprises two convolution layers to generate complex features, a max-pooling layer to reduce the EEG signal's spatiotemporal redundancy, and a dropout layer to improve the network's generalization. The classification processes the feature extraction output nonlinearly using two fully-connected layers to generate salient features and a softmax layer to generate disease probabilities. Two publicly available multiclass datasets of dementia are used for evaluation. The STEADYNet outperforms existing automatic dementia detection methods with accuracies of ",https://pubmed.ncbi.nlm.nih.gov/39555263/,https://pubmed.ncbi.nlm.nih.gov/39555263/,English,Include,,STEADYNet: Spatiotemporal EEG analysis for dementia detection using convolutional neural network.,Include,,"olution layers to generate complex features, a max-pooling layer to reduce the EEG signal's spatiotemporal redundancy, and a dropout layer to improve the network's generalization. The classification processes the feature extraction output nonlinearly using two fully-connected layers to generate salient features and a softmax layer to generate disease probabilities. Two publicly available multiclas",,0.95,0.6,
pubmed:39555262,pubmed:39555262,PubMed,pubmed:39555262,Multiresolution feature fusion for smart diagnosis of schizophrenia in adolescents using EEG signals.,Rakesh Ranjan;Bikash Chandra Sahana,2024,10.1007/s11571-024-10120-1,"Numerous studies on early detection of schizophrenia (SZ) have utilized all available channels or employed set of a few time domain or frequency domain features, while a limited number of features may not be sufficient enough to perform diagnosis efficiently. To encounter these problems, an automated diagnosis model is proposed for the efficient diagnosis of schizophrenia symptomatic adolescent subjects from electroencephalogram (EEG) signals via machine intelligence. A publicly accessible EEG dataset featuring 16-channels EEG obtained from 84 adolescents (45 SZ symptomatic and 39 healthy control) is used to demonstrate the work. Initially, the signals are decomposed into sub-bands using two multi-resolution signal analysis methods: Empirical Wavelet Transform and Empirical mode decomposition. 75 unique features from each sub-bands are extracted and the few selective prominent features are applied to machine learning classifiers for optimal sub-band selection. Subsequently, a hybrid model is proposed, combining convolutional neural network (CNN) and ensemble bagged tree, incorporating both deep learning and handcrafted features to perform SZ diagnosis. This innovative model achieved superior classification performance compared to existing methods, offering a promising approach for SZ diagnosis. Furthermore, the study explores the impact of different brain regions and combined regional data in SZ diagnosis comprehensively. Hence, this computer-assisted decision-making model minimizes the limitations of prior studies by providing a more robust and efficient diagnostic system for schizophrenia.",https://pubmed.ncbi.nlm.nih.gov/39555262/,https://pubmed.ncbi.nlm.nih.gov/39555262/,English,Include,,Multiresolution feature fusion for smart diagnosis of schizophrenia in adolescents using EEG signals.,Exclude,No performance metrics reported,No metrics found in full text,,0.9,0.6,
pubmed:39555256,pubmed:39555256,PubMed,pubmed:39555256,Sustained attention detection in humans using a prefrontal theta-EEG rhythm.,Pankaj Kumar Sahu;Karan Jain,2024,10.1007/s11571-024-10113-0,"This research highlights the importance of the prefrontal theta-EEG rhythm in sustained attention monitoring over the Fp1 electrode. In an experiment conducted with 20 participants, four successive mental tasks are sent briefly by an automated computer program connected to a speakerphone: wait, relax, get ready, and concentrate. Furthermore, each individual participated in this experiment 20 times. The result is determined by how well the individual performed on the task and by examining the collected data. Subjects who start to focus on a target in fewer than 100 s are considered high-focused, and those who take more than 100 s are referred to as low-focused. The gamma, beta, alpha, and theta EEG rhythms are classified using multi-stage discrete wavelet transform for the high-focused and low-focused subjects. Then, eight statistical features are computed for the theta, alpha, beta, and gamma rhythms for the high-focused and low-focused subjects. Finally, these features train the proposed model with a 55% training and 45% testing ratio. The K-Nearest Neighbour (KNN), a machine learning classifier, is applied to classify these features. The research findings are (a) that the KNN classifier attained the best f1-score of 88.88% for theta-EEG rhythm, (b) additionally, the KNN classifier got 85.71% f1-score with alpha-EEG rhythm, 66.66% f1-score with beta, and gamma EEG rhythms, and 53.33% f1-score with the combination of all the EEG rhythms (theta, alpha, beta, and gamma). This research concludes that the theta-EEG rhythm is highly relevant in identifying the human ""attentive state"" compared to other EEG rhythms.",https://pubmed.ncbi.nlm.nih.gov/39555256/,https://pubmed.ncbi.nlm.nih.gov/39555256/,English,Include,,Sustained attention detection in humans using a prefrontal theta-EEG rhythm.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39555252,pubmed:39555252,PubMed,pubmed:39555252,Short-length SSVEP data extension by a novel generative adversarial networks based framework.,Yudong Pan;Ning Li;Yangsong Zhang;Peng Xu;Dezhong Yao,2024,10.1007/s11571-024-10134-9,"Steady-state visual evoked potentials (SSVEPs) based brain-computer interface (BCI) has received considerable attention due to its high information transfer rate (ITR) and available quantity of targets. However, the performance of frequency identification methods heavily hinges on the amount of user calibration data and data length, which hinders the deployment in real-world applications. Recently, generative adversarial networks (GANs)-based data generation methods have been widely adopted to create synthetic electroencephalography data, holds promise to address these issues. In this paper, we proposed a GAN-based end-to-end signal transformation network for Time-window length Extension, termed as TEGAN. TEGAN transforms short-length SSVEP signals into long-length artificial SSVEP signals. Additionally, we introduced a two-stage training strategy and the LeCam-divergence regularization term to regularize the training process of GAN during the network implementation. The proposed TEGAN was evaluated on two public SSVEP datasets (a 4-class and 12-class dataset). With the assistance of TEGAN, the performance of traditional frequency recognition methods and deep learning-based methods have been significantly improved under limited calibration data. And the classification performance gap of various frequency recognition methods has been narrowed. This study substantiates the feasibility of the proposed method to extend the data length for short-time SSVEP signals for developing a high-performance BCI system. The proposed GAN-based methods have the great potential of shortening the calibration time and cutting down the budget for various real-world BCI-based applications.",https://pubmed.ncbi.nlm.nih.gov/39555252/,https://pubmed.ncbi.nlm.nih.gov/39555252/,English,Include,,Short-length SSVEP data extension by a novel generative adversarial networks based framework.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39555250,pubmed:39555250,PubMed,pubmed:39555250,Decoded EEG neurofeedback-guided cognitive reappraisal training for emotion regulation.,Linling Li;Xueying Gui;Gan Huang;Li Zhang;Feng Wan;Xue Han;Jianhong Wang;Dong Ni;Zhen Liang;Zhiguo Zhang,2024,10.1007/s11571-024-10108-x,"Neurofeedback, when combined with cognitive reappraisal, offers promising potential for emotion regulation training. However, prior studies have predominantly relied on functional magnetic resonance imaging, which could impede its clinical feasibility. Furthermore, these studies have primarily focused on reducing negative emotions while overlooking the importance of enhancing positive emotions. In our current study, we developed a novel electroencephalogram (EEG) neurofeedback-guided cognitive reappraisal training protocol for emotion regulation. We recruited forty-two healthy subjects (20 females; 22.4 ± 2.2 years old) who were randomly assigned to either the neurofeedback group or the control group. We evaluated the efficacy of this newly proposed neurofeedback training approach in regulating emotions evoked by pictures with different valence levels (low positive and high negative). Initially, we trained an EEG-based emotion decoding model for each individual using offline data. During the training process, we calculated the subjects' real-time self-regulation performance based on the decoded emotional states and fed it back to the subjects as feedback signals. Our results indicate that the proposed decoded EEG neurofeedback-guided cognitive reappraisal training protocol significantly enhanced emotion regulation performance for stimuli with low positive valence. Additionally, wavelet energy and differential entropy features in the high-frequency band played a crucial role in emotion classification and were associated with neural plasticity changes induced by emotion regulation. These findings validate the beneficial effects of the proposed EEG neurofeedback protocol and offer insights into the neural mechanisms underlying its training effects. This novel decoded neurofeedback training protocol presents a promising cost-effective and non-invasive treatment technique for emotion-related mental disorders.",https://pubmed.ncbi.nlm.nih.gov/39555250/,https://pubmed.ncbi.nlm.nih.gov/39555250/,English,Include,,Decoded EEG neurofeedback-guided cognitive reappraisal training for emotion regulation.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39554850,pubmed:39554850,PubMed,pubmed:39554850,Discriminative possibilistic clustering promoting cross-domain emotion recognition.,Yufang Dan;Di Zhou;Zhongheng Wang,2024,10.4310/sii.2009.v2.n3.a8,"The affective Brain-Computer Interface (aBCI) systems strive to enhance prediction accuracy for individual subjects by leveraging data from multiple subjects. However, significant differences in EEG (Electroencephalogram) feature patterns among subjects often hinder these systems from achieving the desired outcomes. Although studies have attempted to address this challenge using subject-specific classifier strategies, the scarcity of labeled data remains a major hurdle. In light of this, Domain Adaptation (DA) technology has gradually emerged as a prominent approach in the field of EEG-based emotion recognition, attracting widespread research interest. The crux of DA learning lies in resolving the issue of distribution mismatch between training and testing datasets, which has become a focal point of academic attention. Currently, mainstream DA methods primarily focus on mitigating domain distribution discrepancies by minimizing the Maximum Mean Discrepancy (MMD) or its variants. Nevertheless, the presence of noisy samples in datasets can lead to pronounced shifts in domain means, thereby impairing the adaptive performance of DA methods based on MMD and its variants in practical applications to some extent. Research has revealed that the traditional MMD metric can be transformed into a 1-center clustering problem, and the possibility clustering model is adept at mitigating noise interference during the data clustering process. Consequently, the conventional MMD metric can be further relaxed into a possibilistic clustering model. Therefore, we construct a distributed distance measure with Discriminative Possibilistic Clustering criterion (DPC), which aims to achieve two objectives: (1) ensuring the discriminative effectiveness of domain distribution alignment by finding a shared subspace that minimizes the overall distribution distance between domains while maximizing the semantic distribution distance according to the principle of ""sames attract and opposites repel""; and (2) enhancing the robustness of distribution distance measure by introducing a fuzzy entropy regularization term. Theoretical analysis confirms that the proposed DPC is an upper bound of the existing MMD metric under certain conditions. Therefore, the MMD objective can be effectively optimized by minimizing the DPC. Finally, we propose a domain adaptation in Emotion recognition based on DPC (EDPC) that introduces a graph Laplacian matrix to preserve the geometric structural consistency between data within the source and target domains, thereby enhancing label propagation performance. Simultaneously, by maximizing the use of source domain discriminative information to minimize domain discrimination errors, the generalization performance of the DA model is further improved. Comparative experiments on several representative domain adaptation learning methods using multiple EEG datasets (i.e., SEED and SEED-IV) show that, in most cases, the proposed method exhibits better or comparable consistent generalization performance.",https://pubmed.ncbi.nlm.nih.gov/39554850/,https://pubmed.ncbi.nlm.nih.gov/39554850/,English,Include,,Discriminative possibilistic clustering promoting cross-domain emotion recognition.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39554267,pubmed:39554267,PubMed,pubmed:39554267,"Neonatal Seizures: New Evidence, Classification, and Guidelines.",Julie Ziobro;Betsy Pilon;Courtney J Wusthoff;Giulia M Benedetti;Shavonne L Massey;Elissa Yozawitz;Adam L Numis;Ronit Pressler;Renée A Shellhaas,2024,10.1177/15357597241253382,"Neonates are susceptible to seizures due to their unique physiology and combination of risks associated with gestation, delivery, and the immediate postnatal period. Advances in neonatal care have improved outcomes for some of our most fragile patients, but there are persistent challenges for epileptologists in identifying neonatal seizures, diagnosing etiologies, and providing the most appropriate care, with an ultimate goal to maximize patient outcomes. In just the last few years, there have been critical advances in the state of the science, as well as new evidence-based guidelines for diagnosis, classification, and treatment of neonatal seizures. This review will provide updated knowledge about the pathophysiology of neonatal seizures, classification of the provoked seizures and neonatal epilepsies, state of the art guidance on EEG monitoring in the neonatal ICU, current treatment guidelines for neonatal seizures, and potential for future advancement in treatment.",,https://pubmed.ncbi.nlm.nih.gov/39554267/,English,Exclude,Review/survey papers,"Neonatal Seizures: New Evidence, Classification, and Guidelines.",,,,,0.95,0.6,
pubmed:39551893,pubmed:39551893,PubMed,pubmed:39551893,Validation of direct recording of electrically evoked cortical auditory evoked potentials through a cochlear implant system.,Don Bell-Souder;Chen Chen;Anthony Spahr;Anu Sharma,2024,10.1038/s41598-024-79528-3,"Cochlear implants (CI) are one of the most successful treatments available to enable individuals with severe to profound hearing loss to regain access to the world of sound. This is accomplished through the electrical stimulation of the auditory nerve using electrodes implanted inside the cochlea. The use of subjective user feedback makes the process of fitting these devices much more challenging in cases where users are not able to actively or accurately report their experience (e.g. pediatrics), making an objective measurement that reflects the accuracy or effectiveness of a program quite attractive. We recorded one objective measure, the electrically-stimulated cortical auditory evoked potential (eCAEP), non-invasively using the CI in response to a simulated speech sound in seven adult participants and compared it to their eCAEP recorded using a scalp EEG set-up. The eCAEPs recorded with CI electrodes were comparable to scalp recorded eCAEPs (grand mean cross-correlation of r = 0.83, individual mean cross-correlations ranged from 0.13 to 0.70). Evoked potential peaks P1, N1 and P2 showed no significant latency difference based on if the eCAEP was recorded on the scalp or using the CI. The eCAEP waveforms recorded via the CI appear to converge in a distinct P1-N1-P2 waveform by as early as 130 sweeps. In conclusion, in this study we show the feasibility of recording the eCAEP directly through the CI system, which could potentially be used to guide CI fitting and track auditory cortex development in response to CI use.",https://pubmed.ncbi.nlm.nih.gov/39551893/,https://pubmed.ncbi.nlm.nih.gov/39551893/,English,Include,,Validation of direct recording of electrically evoked cortical auditory evoked potentials through a cochlear implant system.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39551877,pubmed:39551877,PubMed,pubmed:39551877,An adaptive multi-graph neural network with multimodal feature fusion learning for MDD detection.,Tao Xing;Yutao Dou;Xianliang Chen;Jiansong Zhou;Xiaolan Xie;Shaoliang Peng,2024,10.1038/s41598-024-79981-0,"Major Depressive Disorder (MDD) is an affective disorder that can lead to persistent sadness and a decline in the quality of life, increasing the risk of suicide. Utilizing multimodal data such as electroencephalograms and patient interview audios can facilitate the timely detection of MDD. However, existing depression detection methods either consider only a single modality or do not fully account for the differences and similarities between modalities in multimodal approaches, potentially overlooking the latent information inherent in various modal data. To address these challenges, we propose EMO-GCN, a multimodal depression detection method based on an adaptive multi-graph neural network. By employing graph-based methods to model data from various modalities and extracting features from them, the potential correlations between modalities are uncovered. The model's performance on the MODMA dataset is outstanding, achieving an accuracy (ACC) of 96.30%. Ablation studies further confirm the effectiveness of the model's individual components.The experimental results of EMO-GCN demonstrate the application prospects of graph-based multimodal analysis in the field of mental health, offering new perspectives for future research.",,https://pubmed.ncbi.nlm.nih.gov/39551877/,English,Exclude,Not EEG-BCI focused,An adaptive multi-graph neural network with multimodal feature fusion learning for MDD detection.,,,,,0.9,0.6,
pubmed:39551094,pubmed:39551094,PubMed,pubmed:39551094,Longitudinal Analysis of Amplitude-Integrated Electroencephalography for Outcome Prediction in Infants with Hypoxic-Ischemic Encephalopathy: A Validation Study.,Mathies Rondagh;Linda S de Vries;Andrea van Steenis;Unoke Meder;Laszlo Szakacs;Agnes Jermendy;Sylke J Steggerda,2025,10.1016/j.jpeds.2024.114407,"To validate the prognostic accuracy of a previously published tool (HOPE calculator) using longitudinal analysis of amplitude-integrated electroencephalography (aEEG) background activity and sleep-wake cycling to predict favorable or adverse 2-year neurodevelopmental outcome in infants with hypoxic-ischemic encephalopathy (HIE) undergoing therapeutic hypothermia (TH), and to evaluate the predictive value for outcome at 5-8 years of age. Single-center retrospective cohort study in 117 infants who underwent TH for HIE between 2008 and 2022. We scored 2-channel aEEG BGPs, sleep-wake cycling, and seizure activity at 6-hour intervals for 84 hours. Neurodevelopmental outcome at 2 years was evaluated using the Bayley Scales of Infant Development-III, defining adverse outcome as death, cerebral palsy, and/or cognitive/motor scores of <85. Adverse outcome at 5-8 years was defined as a total IQ score of <85, a Movement-ABC-2 score of less than p15, cerebral palsy, severe sensory impairment, or death. The prediction model showed an area under the curve of 0.90 (95% CI, 0.83-0.95) at 2 years and 0.83 (95% CI, 0.73-0.92) at 5-8 years. Mean predicted probability of favorable outcome was 74.5% (95% CI, 69.4-79.6) in the favorable outcome group compared with 32.8% (95% CI, 23.5-42.2) in the adverse outcome group (P < .001) at 2 years (n = 115) and 76.85% (95% CI, 70.0-83.4) compared with 40.7% (95% CI, 30.0-51.4) at 5-8 years (n = 68). Our study provided external validation of the HOPE calculator, assessing longitudinal aEEG background activity during TH in infants with HIE. The results suggest that this method can predict favorable or adverse outcomes accurately not only at 2 but also at 5-8 years of age.",,https://pubmed.ncbi.nlm.nih.gov/39551094/,English,Exclude,Outside date range,Longitudinal Analysis of Amplitude-Integrated Electroencephalography for Outcome Prediction in Infants with Hypoxic-Ischemic Encephalopathy: A Validation Study.,,,,,0.95,0.35,external_test_reported
pubmed:39548230,pubmed:39548230,PubMed,pubmed:39548230,Research on cognitive neural mechanism of consumers convinced by intelligent recommendation platform eavesdropping.,Qiuhua Zhu;Rui Sun;Dong Lv;Ru Xia Cheng;Jiajia Zuo;Shukun Qin,2024,10.1038/s41598-024-79281-7,"The negative inference that consumers hold 'eavesdropping' views concerning the intelligent recommendation services of digital platforms is fostering their selective exposure to information that aligns with their preferred viewpoints. This, in turn, exacerbates their psychological defense against digital platforms, causing consumers to become more prone to verifying existing beliefs and fostering the polarization of information choices. This phenomenon directly impacts the effectiveness of smart recommendations and the accuracy of digital platforms' predictions of consumer behavior, potentially even adversely affecting brand trust and the long-term stability of platform usage. From the perspectives of self-verification and cognitive closure, this study delves into the influence of 'eavesdropping' inference cues within intelligent recommendation systems on consumers' selective exposure to information and the underlying psychological mechanisms. Experimental findings indicated: (1) Behavioral results showed that consumers who believed in eavesdropping by digital platforms, under conditions of high comprehensibility, were more inclined to selectively engage with consistent information as opposed to inconsistent information. Under conditions of low comprehensibility, however, information consistency had no significant effect on consumers' selective exposure. (2) EEG results revealed that, based on the need for cognitive closure, individuals in the high comprehensibility group, during the self-verification process, exhibited more cognitive conflict and required greater cognitive effort when presented with inconsistent information compared to those in the consistent information group. This, in turn, elicited higher N2 and N450 amplitudes. This study uncovered the psychological mechanism underlying this phenomenon. When consumers developed a skeptical perspective on perceived eavesdropping by digital platforms within intelligent recommendation systems, they promptly engaged in self-verification, driven by the need for cognitive closure. The study's findings offered practical guidance to digital platforms on how to alleviate consumer suspicions when designing intelligent recommendation services, thereby mitigating negative consumer reactions to the perception of 'eavesdropping'. This insight held significant theoretical and practical value at the intersection of digital marketing and psychology.",https://pubmed.ncbi.nlm.nih.gov/39548230/,https://pubmed.ncbi.nlm.nih.gov/39548230/,English,Include,,Research on cognitive neural mechanism of consumers convinced by intelligent recommendation platform eavesdropping.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39548177,pubmed:39548177,PubMed,pubmed:39548177,Partial prior transfer learning based on self-attention CNN for EEG decoding in stroke patients.,Jun Ma;Wanlu Ma;Jingjing Zhang;Yongcong Li;Banghua Yang;Chunlei Shan,2024,10.1038/s41598-024-79202-8,"The utilization of motor imagery-based brain-computer interfaces (MI-BCI) has been shown to assist stroke patients activate motor regions in the brain. In particular, the brain regions activated by unilateral upper limb multi-task are more extensive, which is more beneficial for rehabilitation, but it also increases the difficulty of decoding. In this paper, self-attention convolutional neural network based partial prior transfer learning (SACNN-PPTL) is proposed to improve the classification performance of patients' MI multi-task. The backbone network of the algorithm is SACNN, which accords with the inherent features of electroencephalogram (EEG) and contains the temporal feature module, the spatial feature module and the feature generalization module. In addition, PPTL is introduced to transfer part of the target domain while preserving the generalization of the base model while improving the specificity of the target domain. In the experiment, five backbone networks and three training modes are selected as comparison algorithms. The experimental results show that SACNN-PPTL had a classification accuracy of 55.4%±0.17 in four types of MI tasks for 22 patients, which is significantly higher than comparison algorithms (P < 0.05). SACNN-PPTL effectively improves the decoding performance of MI tasks and promotes the development of BCI-based rehabilitation for unilateral upper limb.",https://pubmed.ncbi.nlm.nih.gov/39548177/,https://pubmed.ncbi.nlm.nih.gov/39548177/,English,Include,,Partial prior transfer learning based on self-attention CNN for EEG decoding in stroke patients.,Include,,"city of the target domain. In the experiment, five backbone networks and three training modes are selected as comparison algorithms. The experimental results show that SACNN-PPTL had a classification accuracy of 55.4%±0.17 in four types of MI tasks for 22 patients, which is significantly higher than comparison algorithms (P < 0.05). SACNN-PPTL effectively improves the decoding performance of MI ta",,0.95,0.6,
pubmed:39547497,pubmed:39547497,PubMed,pubmed:39547497,Gamma oscillation optimally predicts finger movements.,Qi Chen;Elizabeth Flad;Rachel N Gatewood;Maya S Samih;Talon Krieger;Yan Gai,2025,10.1016/j.brainres.2024.149335,"Our fingers are the most dexterous and complicated parts of our body and play a significant role in our daily activities. Non-invasive techniques, such as Electroencephalography (EEG) and Electromyography (EMG) can be used to collect neural and muscular signals related to finger movements. In this study, we combined an 8-channel EMG and a 31-channel EEG while the human subject moved one of the five fingers on the right hand. To identify the best EEG frequency features that encode distinct finger movements, we systematically examined the decoding accuracies of the slow-cortical potentials and three types of sensorimotor rhythms, namely the Mu, beta, and gamma oscillations. For both EMG and EEG, we came up with a simple and unified root mean square or power approach that avoided the complex signal features used by previous studies. The signal features were then fed into a feedforward artificial-neural-network (ANN) classifier. We found that the low-gamma oscillation provided the best decoding performance over the other frequency bands, ranging from 65.0 % to 89.0 %, which was comparable to the EMG performance. Combining EMG and low gamma into a single ANN can further improve the outcome for subjects who had showed suboptimal performances with EMG or EEG alone. This study provided a simple and efficient algorithm for prosthetics that assist patients with sensorimotor impairments.",,https://pubmed.ncbi.nlm.nih.gov/39547497/,English,Exclude,Outside date range,Gamma oscillation optimally predicts finger movements.,,,,,0.95,0.6,
pubmed:39546881,pubmed:39546881,PubMed,pubmed:39546881,Fast processing and classification of epileptic seizures based on compressed EEG signals.,Achraf Djemal;Ahmed Yahia Kallel;Cherif Ouni;Rihem El Baccouch;Dhouha Bouchaala;Fatma Kammoun Feki;Chahnez Charfi Triki;Ahmed Fakhfakh;Olfa Kanoun,2025,10.1016/j.compbiomed.2024.109346,"The diagnosis of epilepsy based on visual inspection of electroencephalogram (EEG) signals is inherently complex and prone to error, even for physicians, mainly due to the large number of signals involved and the variability between individuals. These same challenges make the development of portable epilepsy diagnostic systems for everyday use difficult. Key obstacles include the immense complexity of signal processing and the inherent ambiguity in accurately classifying disease. For these reasons, we propose in this paper the deployment of compressive sensing to condense EEG signals while preserving relevant information, allowing seizure classification based on systematically selected features of the reconstructed signals. Based on a dataset comprising EEG recordings from 13 epileptic patients with various seizure types, we explore the deployment of the discrete cosine transform (DCT) and random matrix multiplication for compression ratios ranging from 5% to 70%, balancing data reduction with signal fidelity. Following the extraction of relevant features, selection was performed based on mutual information and a correlation matrix to preserve only the most relevant features for analysis. For classification, following a comparison of adequate machine learning models, XGBoost is chosen as it realizes a classification accuracy of 98.78%. The CS method was implemented on an STM32 microcontroller and a Raspberry Pi for reconstruction and classification, to demonstrate feasibility as an embedded system. At 70% compression, significant improvements have been observed: 70% file size reduction, 84% decrease in transmission time (from 2518.532s to 400.392s), and substantial energy savings (e.g., from 11.5±0.707 mWh to 4.5±0.707 mWh for Patient 12). Thereby, the signal quality was maintained with PSNR of 16.15±3.98 and Pearson correlation coefficient of 0.68±0.15. The proposed system highlights the potential for efficient, portable, real-time epilepsy diagnosis systems that achieve precise and fully automated seizure classification.",,https://pubmed.ncbi.nlm.nih.gov/39546881/,English,Exclude,Outside date range,Fast processing and classification of epileptic seizures based on compressed EEG signals.,,,,,0.95,0.6,
pubmed:39545725,pubmed:39545725,PubMed,pubmed:39545725,Decoding Continuous Tracking Eye Movements from Cortical Spiking Activity.,Kendra K Noneman;J Patrick Mayo,2025,10.1142/s0129065724500709,"Eye movements are the primary way primates interact with the world. Understanding how the brain controls the eyes is therefore crucial for improving human health and designing visual rehabilitation devices. However, brain activity is challenging to decipher. Here, we leveraged machine learning algorithms to reconstruct tracking eye movements from high-resolution neuronal recordings. We found that continuous eye position could be decoded with high accuracy using spiking data from only a few dozen cortical neurons. We tested eight decoders and found that neural network models yielded the highest decoding accuracy. Simpler models performed well above chance with a substantial reduction in training time. We measured the impact of data quantity (e.g. number of neurons) and data format (e.g. bin width) on training time, inference time, and generalizability. Training models with more input data improved performance, as expected, but the format of the behavioral output was critical for emphasizing or omitting specific oculomotor events. Our results provide the first demonstration, to our knowledge, of continuously decoded eye movements across a large field of view. Our comprehensive investigation of predictive power and computational efficiency for common decoder architectures provides a much-needed foundation for future work on real-time gaze-tracking devices.",,https://pubmed.ncbi.nlm.nih.gov/39545725/,English,Exclude,Outside date range,Decoding Continuous Tracking Eye Movements from Cortical Spiking Activity.,,,,,0.95,0.6,
pubmed:39545146,pubmed:39545146,PubMed,pubmed:39545146,Multi-source domain adaptation for EEG emotion recognition based on inter-domain sample hybridization.,Xu Wu;Xiangyu Ju;Sheng Dai;Xinyu Li;Ming Li,2024,10.1016/j.bspc.2022.103687,"Electroencephalogram (EEG) is widely used in emotion recognition due to its precision and reliability. However, the nonstationarity of EEG signals causes significant differences between individuals or sessions, making it challenging to construct a robust model. Recently, domain adaptation (DA) methods have shown excellent results in cross-subject EEG emotion recognition by aligning marginal distributions. Nevertheless, these methods do not consider emotion category labels, which can lead to label confusion during alignment. Our study aims to alleviate this problem by promoting conditional distribution alignment during domain adaptation to improve cross-subject and cross-session emotion recognition performance. This study introduces a multi-source domain adaptation common-branch network for EEG emotion recognition and proposes a novel sample hybridization method. This method enables the introduction of target domain data information by directionally hybridizing source and target domain samples without increasing the overall sample size, thereby enhancing the effectiveness of conditional distribution alignment in domain adaptation. Cross-subject and cross-session experiments were conducted on two publicly available datasets, SEED and SEED-IV, to validate the proposed model. In cross-subject emotion recognition, our method achieved an average accuracy of 90.27% on the SEED dataset, with eight out of 15 subjects attaining a recognition accuracy higher than 90%. For the SEED-IV dataset, the recognition accuracy also reached 73.21%. Additionally, in the cross-session experiment, we sequentially used two out of the three session data as source domains and the remaining session as the target domain for emotion recognition. The proposed model yielded average accuracies of 94.16 and 75.05% on the two datasets, respectively. Our proposed method aims to alleviate the difficulties of emotion recognition from the limited generalization ability of EEG features across subjects and sessions. Though adapting the multi-source domain adaptation and the sample hybridization method, the proposed method can effectively transfer the emotion-related knowledge of known subjects and achieve accurate emotion recognition on unlabeled subjects.",https://pubmed.ncbi.nlm.nih.gov/39545146/,https://pubmed.ncbi.nlm.nih.gov/39545146/,English,Include,,Multi-source domain adaptation for EEG emotion recognition based on inter-domain sample hybridization.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39543314,pubmed:39543314,PubMed,pubmed:39543314,Using data from cue presentations results in grossly overestimating semantic BCI performance.,Milan Rybář;Riccardo Poli;Ian Daly,2024,10.1038/s41598-024-79309-y,"Neuroimaging studies have reported the possibility of semantic neural decoding to identify specific semantic concepts from neural activity. This offers promise for brain-computer interfaces (BCIs) for communication. However, translating these findings into a BCI paradigm has proven challenging. Existing EEG-based semantic decoding studies often rely on neural activity recorded when a cue is present, raising concerns about decoding reliability. To address this, we investigate the effects of cue presentation on EEG-based semantic decoding. In an experiment with a clear separation between cue presentation and mental task periods, we attempt to differentiate between semantic categories of animals and tools in four mental tasks. By using state-of-the-art decoding analyses, we demonstrate significant mean classification accuracies up to 71.3% during cue presentation but not during mental tasks, even with adapted analyses from previous studies. These findings highlight a potential issue when using neural activity recorded during cue presentation periods for semantic decoding. Additionally, our results show that semantic decoding without external cues may be more challenging than current state-of-the-art research suggests. By bringing attention to these issues, we aim to stimulate discussion and drive advancements in the field toward more effective semantic BCI applications.",https://pubmed.ncbi.nlm.nih.gov/39543314/,https://pubmed.ncbi.nlm.nih.gov/39543314/,English,Include,,Using data from cue presentations results in grossly overestimating semantic BCI performance.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39543049,pubmed:39543049,PubMed,pubmed:39543049,Frontal EEG correlation based human emotion identification and classification.,S V Thiruselvam;M Ramasubba Reddy,2025,10.4236/jbise.2014.78061,"Humans express their feelings and intentions of their actions or communication through emotions. Recent advancements in technology involve machines in human communication in day-to-day life. Thus, understanding of human emotions by machines will be very helpful in assisting the user in a far better way. Various physiological and non-physiological signals can be used to make the machines to recognize the emotion of a person. The identification of emotional content in the signals is crucial to understand emotion and the machines act with emotional intelligence at appropriate times, thus providing a better human machine interaction with emotion identification system and mental health monitoring for psychiatric patients. This work includes the creation of an emotion EEG dataset, the development of an algorithm for identifying the emotion elicitation segments in the EEG signal, and the classification of emotions from EEG signals. The EEG signals are divided into 3s segments, and the segments with emotional content are selected based on the decrease in correlation between the frontal electrodes. The selected segments are validated with the facial expressions of the subjects in the appropriate time segments of the face video. EEGNet is used to classify the emotion from the EEG signal. The classification accuracy with the selected emotional EEG segments is higher compared to the accuracy using all the EEG segments. In subject-specific classification, an average accuracy of 80.87% is obtained from the network trained with selected EEG segments, and 70.5% is obtained from training with all EEG segments. In subject-independent classification, the accuracy of classification is 67% and 63.8% with and without segment selection, respectively. The proposed method of selection of EEG segments is validated using the DEAP dataset, and classification accuracies and F1-scores of subject dependent and subject-independent methods are presented.",,https://pubmed.ncbi.nlm.nih.gov/39543049/,English,Exclude,Outside date range,Frontal EEG correlation based human emotion identification and classification.,,,,,0.95,0.6,
pubmed:39542109,pubmed:39542109,PubMed,pubmed:39542109,ST-SHAP: A hierarchical and explainable attention network for emotional EEG representation learning and decoding.,Minmin Miao;Jin Liang;Zhenzhen Sheng;Wenzhe Liu;Baoguo Xu;Wenjun Hu,2025,10.1016/j.jneumeth.2024.110317,"Emotion recognition using electroencephalogram (EEG) has become a research hotspot in the field of human-computer interaction, how to sufficiently learn complex spatial-temporal representations of emotional EEG data and obtain explainable model prediction results are still great challenges. In this study, a novel hierarchical and explainable attention network ST-SHAP which combines the Swin Transformer (ST) and SHapley Additive exPlanations (SHAP) technique is proposed for automatic emotional EEG classification. Firstly, a 3D spatial-temporal feature of emotional EEG data is generated via frequency band filtering, temporal segmentation, spatial mapping, and interpolation to fully preserve important spatial-temporal-frequency characteristics. Secondly, a hierarchical attention network is devised to sufficiently learn an abstract spatial-temporal representation of emotional EEG and perform classification. Concretely, in this decoding model, the W-MSA module is used for modeling correlations within local windows, the SW-MSA module allows for information interactions between different local windows, and the patch merging module further facilitates local-to-global multiscale modeling. Finally, the SHAP method is utilized to discover important brain regions for emotion processing and improve the explainability of the Swin Transformer model. Two benchmark datasets, namely SEED and DREAMER, are used for classification performance evaluation. In the subject-dependent experiments, for SEED dataset, ST-SHAP achieves an average accuracy of 97.18%, while for DREAMER dataset, the average accuracy is 96.06% and 95.98% on arousal and valence dimension respectively. In addition, important brain regions that conform to prior knowledge of neurophysiology are discovered via a data-driven approach for both datasets. In terms of subject-dependent and subject-independent emotional EEG decoding accuracies, our method outperforms several closely related existing methods. These experimental results fully prove the effectiveness and superiority of our proposed algorithm.",,https://pubmed.ncbi.nlm.nih.gov/39542109/,English,Exclude,Outside date range,ST-SHAP: A hierarchical and explainable attention network for emotional EEG representation learning and decoding.,,,,,0.95,0.6,
pubmed:39542068,pubmed:39542068,PubMed,pubmed:39542068,Electrophysiological indexes of the cognitive-motor trade-off associated with motor response complexity in a cognitive task.,Bianca Maria di Bello;Andrea Casella;Merve Aydin;Stefania Lucia;Francesco Di Russo;Sabrina Pitzalis,2024,10.1016/j.neuroimage.2024.120931,"Complex actions require more cognitive and motor control than simple ones. Literature shows that to face complexity, the brain must make a compromise between available resources usually giving priority to motor control. However, literature has minimally explored the effect of the motor response complexity on brain processing associated with cognitive tasks. Consequently, it is unknown whether carrying out a cognitive task requiring motor responses of increasing complexity could reduce cognitive processing keeping stable motor control. Therefore, this study aims to investigate possible modulations exerted by increasing motor response complexity in a cognitive task on brain processing. To this aim, we analyzed the event-related potentials and behavioral responses during a cognitive task with increasing complexity of the required motor response (keypress, reaching and stepping). Results showed the increasing motor complexity enhances early visual and attentional processing (P1 and N1 components) but reduces the late post-perceptual cognitive control (P3 component). Additionally, we found a component following the P3 which was specific for stimuli requiring a response. This component, labeled N750, increased amplitude along with the response motor complexity. Behaviorally, response accuracy was not affected by complexity. Results indicated that in cognitive tasks stimulus processing is affected by the complexity of the motor response. Complex responses require a greater investment of early perceptual and attentional resources, but at late phases of processing, cognitive resources are less available in favor of motor resources. This confirms the idea of the motor-priority cognitive-motor trade-off of the brain.",,https://pubmed.ncbi.nlm.nih.gov/39542068/,English,Exclude,Not EEG-BCI focused,Electrophysiological indexes of the cognitive-motor trade-off associated with motor response complexity in a cognitive task.,,,,,0.9,0.6,
pubmed:39541652,pubmed:39541652,PubMed,pubmed:39541652,Customized GPT model largely increases surgery decision accuracy for pharmaco-resistant epilepsy.,Kuo-Liang Chiang;Yu-Cheng Chou;Hsin Tung;Chin-Yin Huang;Liang-Po Hsieh;Kai-Ping Chang;Shang-Yeong Kwan;Wan-Yu Huang,2024,10.1016/j.jocn.2024.110918,"To develop an enhanced epilepsy diagnosis system by integrating an expert-informed ontology with a custom generative pre-trained transformer (GPT), validated by inferring possible seizure lateralization and localization using retrospective textual data from the pre-surgical assessments of patients with pharmaco-resistant epilepsy (PRE). We developed an AI system for epilepsy diagnosis using Protégé with OWL/SWRL, integrating a knowledge base with seizure semiology, seizure types EEG descriptors, expert insights, and literature to pinpoint seizure locations. A customized GPT model was then tailored for specific diagnostic needs. Validated through 16 surgical cases, the system's accuracy in seizure localization and the JSON (JavaScript Object Notation) Epilepsy Matcher's term matching capabilities were confirmed against a Protégé-based knowledge base. A total of 117 patients with PRE underwent video-EEG monitoring at a single institution. However, only 16 of these patients received epilepsy surgery. The Protégé system achieved 75 % accuracy in diagnosing epilepsy from 16 cases using semiology, which increased to 87.5 % with EEG data. The Json Epilepsy Matcher further improved accuracy to 87.5 % with symptoms alone and 93.8 % when including EEG data, highlighting the benefits of applying GPT techniques. This study highlights the efficacy of the JSON Epilepsy Matcher in improving seizure diagnosis accuracy. When combined with EEG data, it achieves a 93.8 % accuracy rate, suggesting a potential improvement in the practicality and generalizability of the original ontology expert system, boosting physicians' confidence in confirming surgery and potentially sparing many children from prolonged suffering. This innovative approach not only improves diagnostic accuracy but also sets a precedent for future applications of AI in neurology.",https://pubmed.ncbi.nlm.nih.gov/39541652/,https://pubmed.ncbi.nlm.nih.gov/39541652/,English,Include,,Customized GPT model largely increases surgery decision accuracy for pharmaco-resistant epilepsy.,Include,,"G descriptors, expert insights, and literature to pinpoint seizure locations. A customized GPT model was then tailored for specific diagnostic needs. Validated through 16 surgical cases, the system's accuracy in seizure localization and the JSON (JavaScript Object Notation) Epilepsy Matcher's term matching capabilities were confirmed against a Protégé-based knowledge base. A total of 117 patients ",,0.95,0.6,
pubmed:39540265,pubmed:39540265,PubMed,pubmed:39540265,Defining neonatal status epilepticus: A scoping review from the ILAE neonatal task force.,Magda L Nunes;Elissa G Yozawitz;Courtney J Wusthoff;Renée A Shellhaas;Efraín Olivas-Peña;Jo M Wilmshurst;Ronit M Pressler;Chahnez C Triki;Hans Hartmann;Terrie Inder;Geraldine B Boylan;Kette Valente;Solomon L Moshe;Eli M Mizrahi;Nicholas S Abend,2025,10.1007/s10072-009-0115-x,"To review the available literature concerning the definition of neonatal status epilepticus (SE) and/or seizure burden. The International League Against Epilepsy Neonatal Task Force performed a scoping review of the definitions of neonatal SE. Following a systematic literature review, articles were screened and data were abstracted regarding: (1) article characteristics (author identification, publication year, journal name, digital object identifier, title, objective, and study design); (2) cohort characteristics (sample size, gestational age, seizure etiology); (3) definition of SE and/or seizure burden; and (4) the method used to identify and classify SE, including routine EEG (EEG), continuous EEG monitoring (cEEG), amplitude-integrated EEG (aEEG), or clinical features. The scoping review yielded 44 articles containing a definition of neonatal SE. Studies mainly included infants with hypoxic-ischemic encephalopathy or neonates considered at risk for seizures. SE identification and classification most often relied on cEEG. The majority of studies based the definition of SE on seizure duration, including summed duration of seizures comprising ≥50% of any 1-h epoch, recurrent seizures for >50% of the total recording time, or either electrographic seizures lasting >30 min and/or repeated electrographic seizures totaling >50% in any 1-h period. Seizure burden was reported in 20 studies, and the most commonly used approach assessed total seizure burden, defined as total duration of EEG seizures in minutes. Sixteen studies assessed the relationship between seizure burden and outcomes, and most identified a significant association between higher seizure burden and unfavorable outcomes. This scoping review demonstrates a substantial variation in neonatal SE definitions across the literature. The most common definitions were based around a 30-min seizure duration criterion, but evidence was insufficient to support that 30 min was a cutoff defining prolonged seizures or that seizures exceeding this burden were more likely to be pharmacoresistant or associated with worse outcomes. As a next step, the Neonatal Task Force intends to develop a standardized approach to assessing and describing neonatal seizure burden and defining neonatal SE. Prolonged seizures are a neurologic emergency, if untreated, can lead to permanent injury or death. In adults and children, seizures lasting longer than 30 min are believed to cause brain damage. However, it is not clear if this definition can be applied to neonates. The International League Against Epilepsy Neonatal Taskforce performed a scoping literature review which identified 44 articles containing a definition of neonatal status epilepticus. In this article, the authors reviewed the current used definitions for prolonged seizures in neonates to establish a relationship between seizure duration and neurological outcome. As a next step, the Neonatal Task Force intends to develop a standardized approach to assessing and describing neonatal seizure burden and defining neonatal SE.",,https://pubmed.ncbi.nlm.nih.gov/39540265/,English,Exclude,Outside date range,Defining neonatal status epilepticus: A scoping review from the ILAE neonatal task force.,,,,,0.95,0.6,
pubmed:39539941,pubmed:39539941,PubMed,pubmed:39539941,Reinforcement learning in motor skill acquisition: using the reward positivity to understand the mechanisms underlying short- and long-term behavior adaptation.,Mariane F B Bacelar;Keith R Lohse;Juliana O Parma;Matthew W Miller,2024,10.3758/s13423-015-0999-9,"According to reinforcement learning, humans adjust their behavior based on the difference between actual and anticipated outcomes (i.e., prediction error) with the main goal of maximizing rewards through their actions. Despite offering a strong theoretical framework to understand how we acquire motor skills, very few studies have investigated reinforcement learning predictions and its underlying mechanisms in motor skill acquisition. In the present study, we explored a 134-person dataset consisting of learners' feedback-evoked brain activity (reward positivity; RewP) and motor accuracy during the practice phase and delayed retention test to investigate whether these variables interacted according to reinforcement learning predictions. Results showed a non-linear relationship between RewP and trial accuracy, which was moderated by the learners' performance level. Specifically, high-performing learners were more sensitive to violations in reward expectations compared to low-performing learners, likely because they developed a stronger representation of the skill and were able to rely on more stable outcome predictions. Furthermore, contrary to our prediction, the average RewP during acquisition did not predict performance on the delayed retention test. Together, these findings support the use of reinforcement learning models to understand short-term behavior adaptation and highlight the complexity of the motor skill consolidation process, which would benefit from a multi-mechanistic approach to further our understanding of this phenomenon.",,https://pubmed.ncbi.nlm.nih.gov/39539941/,English,Exclude,Not EEG-BCI focused,Reinforcement learning in motor skill acquisition: using the reward positivity to understand the mechanisms underlying short- and long-term behavior adaptation.,,,,,0.9,0.6,
pubmed:39539721,pubmed:39539721,PubMed,pubmed:39539721,Parkinson's disease detection from EEG signal employing autoencoder and RBFNN-based hybrid deep learning framework utilizing power spectral density.,Ferdaus Anam Jibon;Alif Tasbir;Md Alamin Talukder;Md Ashraf Uddin;Fazla Rabbi;Md Salam Uddin;Fars K Alanazi;Mohsin Kazi,2024,10.3389/fnhum.2019.00118,"Early detection of Parkinson's disease (PD) is essential for halting its progression, yet challenges remain in leveraging deep learning for accurate identification. This study aims to overcome these obstacles by introducing a hybrid deep learning approach that enhances PD detection through a combination of autoencoder (AE) and radial basis function neural network (RBFNN). The proposed method analyzes the power spectral density (PSD) of preprocessed electroencephalography (EEG) signals, with artifacts removed, to assess energy distribution across EEG sub-bands. AEs are employed to extract features from reconstructed signals, which are subsequently classified by an RBFNN. The approach is validated on UC SanDiego's EEG dataset, consisting of 31 subjects and 93 minutes of recordings. The hybrid model demonstrates promising performance, achieving a classification accuracy of 99%. The improved accuracy is attributed to advanced feature selection techniques, robust data preprocessing, and the integration of AEs with RBFNN, setting a new benchmark in PD detection frameworks. This study highlights the efficacy of the hybrid deep learning framework in detecting PD, particularly emphasizing the importance of using multiple EEG channels and advanced preprocessing techniques. The results underscore the potential of this approach for practical clinical applications, offering a reliable solution for early and accurate PD detection.",https://pubmed.ncbi.nlm.nih.gov/39539721/,https://pubmed.ncbi.nlm.nih.gov/39539721/,English,Include,,Parkinson's disease detection from EEG signal employing autoencoder and RBFNN-based hybrid deep learning framework utilizing power spectral density.,Include,," RBFNN. The approach is validated on UC SanDiego's EEG dataset, consisting of 31 subjects and 93 minutes of recordings. The hybrid model demonstrates promising performance, achieving a classification accuracy of 99%. The improved accuracy is attributed to advanced feature selection techniques, robust data preprocessing, and the integration of AEs with RBFNN, setting a new benchmark in PD detection",,0.95,0.6,
pubmed:39538281,pubmed:39538281,PubMed,pubmed:39538281,The two-stage processing of judgment of confidence: evidence from ERP.,Zhaolan Li;Wenwu Dai;Ning Jia,2024,10.1186/s40359-024-02147-0,"The judgment of confidence (JOC) refers to the confidence in the accuracy of the target item individuals have just retrieved and is a typical retrospective metacognitive monitoring process. In the classical paradigm of JOC, JOC occurs after the recognition or recall task. While initially viewed as a single-stage monitoring process, recent research on JOC suggests its internal mechanisms may be more complex, potentially encompassing both retrieval and monitoring processes. This study aims to delve into these mechanisms concerning neural temporal processes. In this study, event-related potential (ERP) was used to compare N400 and slow-wave ERPs of high and low JOCs at different time windows using a classic JOC paradigm. Behavioral results showed an inverted-U shaped relationship between response time (RT) and JOCs, peaking at magnitude 3 before declining. There were significantly longer RT for low JOCs compared with high JOCs, along with lower recognition scores. The ERP results showed that low JOCs induced larger N400 in the right frontal lobe and right central area, while high JOCs induced larger slow-wave components (500 ~ 700ms) in the right frontal lobe. Based on these findings, the present study suggests that JOC involves two processing stages. N400 reflects the process of cue acquisition, while the slow-wave component reflects the process of cue application. Furthermore, a two-stage model was proposed and validated, enriching the study of metacognition monitoring mechanisms, offering insights into the processing mechanisms of retrospective metacognitive monitoring.",,https://pubmed.ncbi.nlm.nih.gov/39538281/,English,Exclude,Not EEG-BCI focused,The two-stage processing of judgment of confidence: evidence from ERP.,,,,,0.9,0.6,
pubmed:39538198,pubmed:39538198,PubMed,pubmed:39538198,Electroencephalography based delirium screening in acute supratentorial stroke.,Gesine Hermann;Friederike Baumgarte;Julius Welzel;Peter Nydahl;Gregor Kuhlenbäumer;Nils Gerd Margraf,2024,10.1007/s12028-020-00938-y,"Up to 25% of patients suffering from an acute stroke are diagnosed with delirium during the hospital stay, with older age increasing the risk. Generalized slowing in the electroencephalogram (EEG) supports the diagnosis of delirium. We examined the potential of single-channel EEG (DeltaScan Within the first five days after stroke onset, patients received single-channel EEG DeltaScan In 9 of 53 patients (52-90 years) delirium was diagnosed according to DSM-V criteria. Sensitivity of DeltaScan When EEG is used in clinical practice to support a delirium diagnosis in stroke patients, bihemispheric recordings are likely preferable over unilateral recordings. Slowing in the delta- or theta-frequency spectrum over the site of stroke may lead to false-positive results in single channel EEG based delirium scoring.",https://pubmed.ncbi.nlm.nih.gov/39538198/,https://pubmed.ncbi.nlm.nih.gov/39538198/,English,Include,,Electroencephalography based delirium screening in acute supratentorial stroke.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39537110,pubmed:39537110,PubMed,pubmed:39537110,The impact of task difficulty on neural modulation throughout a visuomotor multi-day practice training.,Shuai Feng;Siyu Hong;Xin Zhang;Xing Wang;Lin Chen,2024,10.1016/j.brainresbull.2024.111124,"The effectiveness of rehabilitation is contingent upon the motor recovery process which typically involves long-term motor skill re-acquisition. Given that the learning process can be modulated by task difficulty, elucidating the underlying neural mechanism is essential for optimizing rehabilitation prescription to suit different patient conditions. This study aimed to investigate the impact of task difficulty on cortical response during force-control training via electroencephalography (EEG). An 8-day visuomotor force-tracking training experiment was conducted. Healthy right-handed participants (N=33) were recruited and randomly assigned to 3 groups, and each group was tasked with a different level of difficulty. The task difficulty was manipulated by variation in force-production complexity and execution sequence assignments, with real-time visual feedback provided to participants for self-output adjustment. Behavioral performance was quantitatively assessed using a pre-defined score metric related to performance accuracy. The EEG signals were collected, and corresponding event-related desynchronization (ERD) and relative functional connectivity (FC) during the task execution were analyzed within the alpha- (8-13 Hz) and beta- (15-30 Hz) bands. A post-training experiment was also performed to evaluate the near-transfer capability of learning. Results showed all the behavioral performances improved during practice, while higher task difficulty level was affiliated with better post-training near-transfer ability. The dynamic neural response to training could be mediated by changes in difficulty level, where increased task complexity corresponded with the heightened activities in the beta-band priorly within the right dorsolateral prefrontal area. Additionally, stronger alpha-band functional connectivity was observed to be predominantly associated with the left motor area (LMA) during challenging tasks, and the intensification in connectivity persisted selectively post-training which appeared to be acritical factor for skill transfer performance improvement. These findings illustrated the dynamic neural mechanism through which task difficulty affects behavioral performance during long-term motor training with accurate force-control purpose. The selectively strengthened functional connectivity may contribute to facilitating new task execution after training interventions. Therefore, beneficial neural modulation can be expected to be feasible by well-designed task difficulty strategies for effective motor rehabilitation.",https://pubmed.ncbi.nlm.nih.gov/39537110/,https://pubmed.ncbi.nlm.nih.gov/39537110/,English,Include,,The impact of task difficulty on neural modulation throughout a visuomotor multi-day practice training.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39536528,pubmed:39536528,PubMed,pubmed:39536528,Insomnia disorder is associated with 24-hour cortical hyperarousal.,Yanyuan Dai;Jingwen Ma;Alexandros N Vgontzas;Baixin Chen;Le Chen;Jun Wu;Dandan Zheng;Jiansheng Zhang;Maria Karataraki;Yun Li,2024,10.1016/j.sleep.2024.11.002,"Cortical hyperarousal has been proposed as a primary underlying mechanism for insomnia disorder. However, most evidence comes from nighttime sleep and whether patients with insomnia disorder have cortical hyperarousal through the 24-h sleep/wake cycle is not resolved. We included 49 patients with insomnia disorder and 49 age-and sex-matched normal sleepers. All participants underwent an over-night polysomnography followed by a Multiple Sleep Latency Test during daytime. Nighttime and daytime delta, theta, alpha, sigma and beta relative power at central electroencephalogram derivations during wakefulness and non-rapid eye movement (NREM) sleep were calculated. Insomnia disorder was defined based on the International Classification of Sleep Disorders Third Edition criteria. Insomnia with objective short sleep duration was defined as patients with insomnia who slept <7 h based on nighttime polysomnography recording. Compared to normal sleepers, patients with insomnia disorder had significantly higher nighttime (P = 0.040) and daytime (P = 0.021) relative electroencephalogram power in beta during NREM sleep and marginally significantly lower relative electroencephalogram power in theta (P = 0.060) during nighttime wakefulness. Furthermore, linear trend association was observed across normal sleepers, and patients with insomnia who slept ≥7 h and insomnia who slept <7 h in relative electroencephalogram power in beta during nighttime and daytime NREM sleep, and relative electroencephalogram power in theta during nighttime wakefulness (all P for trend <0.05). Increased high-frequency electroencephalogram power during nighttime and daytime sleep suggests that insomnia is a disorder of 24-h cortical hyperarousal. Decreasing both nighttime and daytime cortical arousal levels should be our therapeutic target for insomnia.",,https://pubmed.ncbi.nlm.nih.gov/39536528/,English,Exclude,Not EEG-BCI focused,Insomnia disorder is associated with 24-hour cortical hyperarousal.,,,,,0.9,0.8,small_sample_mentioned
pubmed:39536406,pubmed:39536406,PubMed,pubmed:39536406,Localizing the seizure onset zone and predicting the surgery outcomes in patients with drug-resistant epilepsy: A new approach based on the causal network.,Mingming Chen;Kunlin Guo;Kai Lu;Kunying Meng;Junfeng Lu;Yajing Pang;Lipeng Zhang;Yuxia Hu;Renping Yu;Rui Zhang,2025,10.1016/j.cmpb.2024.108483,"Accurate localization of the seizure onset zone (SOZ) is crucial for surgical treatment in patients with drug-resistant epilepsy (DRE). However, clinical identification of SOZ often relies on physician experience and has a certain subjectivity. Therefore, it is emergent to develop quantitative computational tools to assist clinicians in identifying SOZ. We conduct a retrospective study on intracranial electroencephalography (iEEG) data from 46 patients with DRE. The interactions between different brain regions are quantified by using the phase transfer entropy (PTE), based on which the causal influence index (CII) is proposed to quantify the degree of influence of nodes on the network. Subsequently, the features extracted by the CII are used to construct a random forest classification model, which the performance in identifying SOZ and the generalizability are validated in patients with successful surgeries. Then, based on the CII features of the clinically labeled SOZ, a logistic regression prediction model is constructed to predict the probability of surgical success. The statistical analysis between patients with successful and failed surgery is conducted with the Mann-Whitney U test. Finally, the consistency between the predicted SOZ and the clinically labeled SOZ is verified across different Engel classes. The classification model combining the low-frequency and high-frequency features can achieve an accuracy of 82.18% (sensitivity: 85.01%, specificity: 79.69%) and an area under curve (AUC) of 0.90 in identifying SOZ. Furthermore, the model exhibits strong generalizability in identifying SOZ in patients with MRI lesional and non-lesional, as well as those implanted with electrocorticography (ECOG) and stereotactic EEG (SEEG) electrodes. Moreover, the prediction model could achieve an average accuracy of 79.8% and an AUC of 0.84. Of note, the prediction of surgical success probability is significant between patients with successful and failed surgeries (P<0.001). Correspondingly, the highest consistency between model-predicted SOZ and clinically labeled SOZ can be observed in patients with successful surgeries, but this consistency gradually decreases with increasing Engel classes. These results demonstrate that the CII may be a potential biomarker for identifying the SOZ in patients with DRE, which may provide a new perspective for the treatment of epilepsy.",,https://pubmed.ncbi.nlm.nih.gov/39536406/,English,Exclude,Outside date range,Localizing the seizure onset zone and predicting the surgery outcomes in patients with drug-resistant epilepsy: A new approach based on the causal network.,,,,,0.95,0.6,
pubmed:39536364,pubmed:39536364,PubMed,pubmed:39536364,Video-based automatic seizure detection in pharmacoresistant epilepsy: A prospective exploratory study.,Fredrik K Andersson;Helena Gauffin;Hans Lindehammar;Patrick Vigren,2024,10.1016/j.yebeh.2024.110118,"The objective of this study was to evaluate the diagnostic yield and clinical utility of an automated AI video-based seizure detection device, Nelli®, (SDD) in pharmacoresistant epilepsy patients. The SDD captures and automatically classifies nocturnal motor behavior suggestive of epileptic seizures or non-epileptic motor behavior of potential clinical value. Patients with focal epilepsy and pharmacoresistance referred for inpatient long-term video-EEG monitoring were prospectively recruited. Participants were monitored in their home at night with the SDD for a median of 15.5 nights. Captured video recordings were analyzed by clinical experts and each SDD-registration session was classified as diagnostic or not. Clinical utility for each participant was assessed from pre-specified utility measures. The outcome measures were compared between major focal motor and subtle focal motor seizures. One SDD-registration session in each of the 20 participants was performed and analyzed. Video recordings were captured in 18 sessions. Diagnostic yield was found in 11 registration sessions (55.0 %) and clinical utility in 8 registration sessions (40.0 %). No significant difference was found between the AI-algorithm classification and clinical experts' consensus assessment of captured video recordings as epileptic or not. Positive predictive value was 81.8 % for registration sessions containing video recordings classified as epileptic seizures. The diagnostic yield and clinical utility were significantly higher among major focal motor seizures (81.8 % and 63.6 %) compared to subtle focal motor seizures. The SDD is useful to evaluate patients with pharmacoresistant epilepsy and major focal motor seizures (hyperkinetic, tonic, clonic, focal to bilateral tonic-clonic seizures); it may facilitate the diagnostic process in patients referred for long-term inpatient video-EEG evaluation and beneficially change anti-seizure treatments. The SDD provided accurate classification of major focal motor seizures as epileptic, or non-epileptic, and may serve as a useful diagnostic tool to distinguish epileptic and non-epileptic episodic events with a prominent motor component.",https://pubmed.ncbi.nlm.nih.gov/39536364/,https://pubmed.ncbi.nlm.nih.gov/39536364/,English,Include,,Video-based automatic seizure detection in pharmacoresistant epilepsy: A prospective exploratory study.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39534363,pubmed:39534363,PubMed,pubmed:39534363,EEG classification based on visual stimuli via adversarial learning.,Rahul Mishra;Arnav Bhavsar,2024,10.1007/s11571-023-09967-7,"In this work, we propose a dual path deep learning architecture for the application of visual brain decoding. The inputs to the proposed network are the electroencephalogram (EEG) signals which are evoked due to the external stimuli, specifically, images in this case. The objective is to classify the EEG signals based on the image categories under which they were evoked. Our approach involves the combinations of convolution neural networks (CNN) on the time axis and the channel axis. Importantly, for the purpose of learning subject-invariant features, we also make use of the gradient reversal layer (GRL). This addition to our network boosts the performance of our system. In addition, we also propose to use guided back-propagation for the selection of more informative EEG channels, and finally, with the reduced number of channels, we estimate the performance of the proposed network which is almost similar to the version when considering all EEG channels.",https://pubmed.ncbi.nlm.nih.gov/39534363/,https://pubmed.ncbi.nlm.nih.gov/39534363/,English,Include,,EEG classification based on visual stimuli via adversarial learning.,Exclude,No performance metrics reported,No metrics found in full text,,0.9,0.6,
pubmed:39528969,pubmed:39528969,PubMed,pubmed:39528969,Attentional network deficits in patients with migraine: behavioral and electrophysiological evidence.,Yuxin Chen;Siyuan Xie;Libo Zhang;Desheng Li;Hui Su;Rongfei Wang;Ran Ao;Xiaoxue Lin;Yingyuan Liu;Shuhua Zhang;Deqi Zhai;Yin Sun;Shuqing Wang;Li Hu;Zhao Dong;Xuejing Lu,2024,10.1186/s10194-024-01905-0,"Patients with migraine often experience not only headache pain but also cognitive dysfunction, particularly in attention, which is frequently overlooked in both diagnosis and treatment. The influence of these attentional deficits on the pain-related clinical characteristics of migraine remains poorly understood, and clarifying this relationship could improve care strategies. This study included 52 patients with migraine and 34 healthy controls. We employed the Attentional Network Test for Interactions and Vigilance-Executive and Arousal Components paradigm, combined with electroencephalography, to assess attentional deficits in patients with migraine, with an emphasis on phasic alerting, orienting, executive control, executive vigilance, and arousal vigilance. An extreme gradient boosting binary classifier was trained on features showing group differences to distinguish patients with migraine from healthy controls. Moreover, an extreme gradient boosting regression model was developed to predict clinical characteristics of patients with migraine using their attentional deficit features. For general performance, patients with migraine presented a larger inverse efficiency score, a higher prestimulus beta-band power spectral density and a lower gamma-band event-related synchronization at Cz electrode, and stronger high alpha-band activity at the primary visual cortex, compared to healthy controls. Although no behavior differences in three basic attentional networks were found, patients showed magnified N1 amplitude and prolonged latency of P2 for phasic alerting-trials as well as an increased orienting evoked-P1 amplitude. For vigilance function, improvements in the hit rate of executive vigilance-trials were exhibited in controls but not in patients. Besides, patients with migraine exhibited longer reaction time as well as larger variability in arousal vigilance-trials than controls. The binary classifier developed by such attentional deficit features achieved an F1 score of 0.762 and an accuracy of 0.779 in distinguishing patients with migraine from healthy controls. Crucially, the predicted value available from the regression model involving attentional deficit features significantly correlated with the real value for the frequency of headache. Patients with migraine demonstrated significant attentional deficits, which can be used to differentiate migraine patients from healthy populations and to predict clinical characteristics. These findings highlight the need to address cognitive dysfunction, particularly attentional deficits, in the clinical management of migraine.",https://pubmed.ncbi.nlm.nih.gov/39528969/,https://pubmed.ncbi.nlm.nih.gov/39528969/,English,Include,,Attentional network deficits in patients with migraine: behavioral and electrophysiological evidence.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39528958,pubmed:39528958,PubMed,pubmed:39528958,The utility of wearable electroencephalography combined with behavioral measures to establish a practical multi-domain model for facilitating the diagnosis of young children with attention-deficit/hyperactivity disorder.,I-Chun Chen;Che-Lun Chang;Meng-Han Chang;Li-Wei Ko,2024,10.1186/s11689-024-09578-1,"A multi-method, multi-informant approach is crucial for evaluating attention-deficit/hyperactivity disorders (ADHD) in preschool children due to the diagnostic complexities and challenges at this developmental stage. However, most artificial intelligence (AI) studies on the automated detection of ADHD have relied on using a single datatype. This study aims to develop a reliable multimodal AI-detection system to facilitate the diagnosis of ADHD in young children. 78 young children were recruited, including 43 diagnosed with ADHD (mean age: 68.07 ± 6.19 months) and 35 with typical development (mean age: 67.40 ± 5.44 months). Machine learning and deep learning methods were adopted to develop three individual predictive models using electroencephalography (EEG) data recorded with a wearable wireless device, scores from the computerized attention assessment via Conners' Kiddie Continuous Performance Test Second Edition (K-CPT-2), and ratings from ADHD-related symptom scales. Finally, these models were combined to form a single ensemble model. The ensemble model achieved an accuracy of 0.974. While individual modality provided the optimal classification with an accuracy rate of 0.909, 0.922, and 0.950 using the ADHD-related symptom rating scale, the K-CPT-2 score, and the EEG measure, respectively. Moreover, the findings suggest that teacher ratings, K-CPT-2 reaction time, and occipital high-frequency EEG band power values are significant features in identifying young children with ADHD. This study addresses three common issues in ADHD-related AI research: the utility of wearable technologies, integrating databases from diverse ADHD diagnostic instruments, and appropriately interpreting the models. This established multimodal system is potentially reliable and practical for distinguishing ADHD from TD, thus further facilitating the clinical diagnosis of ADHD in preschool young children.",https://pubmed.ncbi.nlm.nih.gov/39528958/,https://pubmed.ncbi.nlm.nih.gov/39528958/,English,Include,,The utility of wearable electroencephalography combined with behavioral measures to establish a practical multi-domain model for facilitating the diagnosis of young children with attention-deficit/hyperactivity disorder.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39534365,pubmed:39534365,PubMed,pubmed:39534365,Tensor decomposition-based channel selection for motor imagery-based brain-computer interfaces.,Ziwei Huang;Qingguo Wei,2024,10.1007/s11571-023-09940-4,"The number of electrode channels in a brain-computer interface (BCI) affects not only its classification performance, but also its convenience in practical applications. Despite many studies on channel selection in motor imagery (MI)-based BCI systems, they consist in matrix analysis of EEG signals, which inevitably loses the interactive information among multiple domains such as space, time and frequency. In this paper, a tensor decomposition-based channel selection (TCS) method is employed for MI BCIs. A three-way tensor is yielded by wavelet transform of a single-trial EEG signal and decomposed into three factor matrices by a regularized canonical polyadic decomposition (CPD). The channel factor matrix is used for channel selection and the important channels are selected by calculating the correlation between channels. Regularized common spatial pattern (RCSP) is employed for feature extraction and support vector machine (SVM) for classification. The proposed TCS-RCSP algorithm was evaluated on three BCI data sets and compared with the RCSP with all channels (AC-RCSP) and the RCSP with selected channels by correlation-based channel selection method (CCS-RCSP). The results indicate that TCS-RCSP achieved significantly better overall accuracy than AC-RCSP (94.4% vs. 86.3%) with ",https://pubmed.ncbi.nlm.nih.gov/39534365/,https://pubmed.ncbi.nlm.nih.gov/39534365/,English,Include,,Tensor decomposition-based channel selection for motor imagery-based brain-computer interfaces.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39532054,pubmed:39532054,PubMed,pubmed:39532054,Phoneme-related potentials recorded from normal hearing listeners and cochlear implant users in a selective attention paradigm to continuous speech.,Nina Aldag;Waldo Nogueira,2024,10.1016/j.heares.2024.109136,"Cochlear implants can restore the ability to understand speech in patients with profound sensorineural hearing loss. At present, it is not fully understood how cochlear implant users perceive speech and how electric hearing provided by a cochlear implant differs from acoustic hearing. Phoneme-related potentials characterize neural responses to individual instances of phonemes extracted from continuous speech. This retrospective study investigated phoneme-related potentials in cochlear implant users in a selective attention paradigm. Responses were compared between normal hearing listeners and cochlear implant users, and between attended and unattended conditions. Differences between phoneme categories were compared and a classifier was trained to predict the phoneme category from the neural representation. The phoneme-related potentials of cochlear implant users showed similar responses to the ones obtained in normal hearing listeners for early responses (< 100 ms) but not for later responses (> 100 ms) where peaks were smaller or absent. Attention led to an enhancement of the response, whereas latency was mostly not affected by attention. The temporal morphology of the response was influenced by the phonetic features of the stimulus, allowing a classification of the phoneme category based on the phoneme-related potentials. There is a clinical need for methods that can rapidly and objectively assess the speech understanding performance of cochlear implant users. Phoneme-related potentials may provide such a link between the acoustic and the neural representations of phonemes. They may also reveal the challenges of individual subjects and thus provide indications for patient-specific auditory training, rehabilitation programs or the fitting of cochlear implant parameters.",,https://pubmed.ncbi.nlm.nih.gov/39532054/,English,Exclude,Not EEG-BCI focused,Phoneme-related potentials recorded from normal hearing listeners and cochlear implant users in a selective attention paradigm to continuous speech.,,,,,0.9,0.6,
pubmed:39531928,pubmed:39531928,PubMed,pubmed:39531928,Recognizing and explaining driving stress using a Shapley additive explanation model by fusing EEG and behavior signals.,Liu Yang;Ruoling Zhou;Guofa Li;Ying Yang;Qianxi Zhao,2025,10.1016/j.aap.2024.107835,"Driving stress is a critical factor leading to road traffic accidents. Despite numerous studies that have been conducted on driving stress recognition, most of them only focus on accuracy improvement without taking model interpretability into account. In this study, an explainable driving stress recognition framework was presented to quantify stress based on electroencephalography (EEG) and behavior data. Based on the extraction of key EEG and behavior features and feature selection, low, medium, and high levels of driving stress were identified using seven machine learning algorithms. The recognition results when only using EEG or behavior features were compared with the result when fusing EEG together with behavior features. Then, the dependency effects between brain activity, driving behavior, and stress were analyzed using the SHapley Additive exPlanation (SHAP) method, and fuzzy rules were obtained by decision tree method. Results indicated that after feature selection, the accuracy of the combined EEG and behavior feature set improved by 8.56% and 26.51% compared to the single EEG and behavior feature sets respectively, and the accuracy rate of 84.93% was achieved. Furthermore, the variations in driver behavior and physiology under stress were identified by the visualization results of SHAP and the quantitative analysis method of decision tree. The changes of different brain regions in the same frequency band showed higher synchronicity under driving stress stimulation. The changes caused by increased stress can be explained by lower speed, smaller maximum lateral lane deviation, smaller accelerator pedal depth and larger brake depth, along with the power changes of the θ and β-band of the brain.",,https://pubmed.ncbi.nlm.nih.gov/39531928/,English,Exclude,Outside date range,Recognizing and explaining driving stress using a Shapley additive explanation model by fusing EEG and behavior signals.,,,,,0.95,0.6,
pubmed:39531921,pubmed:39531921,PubMed,pubmed:39531921,Predicting the Risk of Driving Under the Influence of Alcohol Using EEG-Based Machine Learning.,Pin-Yang Yeh;Cheuk-Kwan Sun;Yu-Ru Sue,2025,10.1016/j.compbiomed.2024.109405,"Driving under the influence of alcohol (DUIA) is closely associated with alcohol use disorder (AUD). Our previous study on machine learning (ML) algorithms revealed a very high accuracy of decision trees with neuropsychological features in predicting the risk of DUIA despite limited data availability. Thus, this study aimed at comparing six well-known ML algorithms based on electroencephalographic (EEG) signals to differentiate adults with AUD and DUIA (AUD-DD) from those with AUD without DUIA (AUD-NDD) and controls. Fifteen AUD-DD and 10 AUD-NDD participants were recruited from a single tertiary referral center. Fourteen social drinkers without DUIA served as controls. Their EEG signals related to driving conditions were gathered using a VR headset with eight electrodes (F3, F4, Fz, C3, C4, Cz, P3, and P4). Based on the labeled features of EEG asymmetry and theta/beta ratio (TBR), comparisons between different algorithms were conducted. Fz and Cz electrodes exhibited differences in TBR across the three groups (all p < 0.02), while there were no significant differences between AUD-DD individuals and social drinkers. In contrast, asymmetries of between-group differences were not observed (all p > 0.09). K-nearest neighbors (KNN) with TBR showed the highest accuracy (83 %) in distinguishing AUD-DD individuals from controls, while logistic regression (LR), support vector machines (SVM), and naive Bayes (NB) with EEG asymmetric features demonstrated high accuracy in identifying DUIA (all 80 %) in AUD adults. LR, SVM, and NB with asymmetry may be employed in predicting DUIA among AUD adults, while KNN with TBR may be used for identifying DUIA in the general population.",,https://pubmed.ncbi.nlm.nih.gov/39531921/,English,Exclude,Outside date range,Predicting the Risk of Driving Under the Influence of Alcohol Using EEG-Based Machine Learning.,,,,,0.95,0.8,small_sample_mentioned
pubmed:39531690,pubmed:39531690,PubMed,pubmed:39531690,Confidence regulates feedback processing during human probabilistic learning.,Michael Ben Yehuda;Robin A Murphy;Mike E Le Pelley;Danielle J Navarro;Nick Yeung,2025,10.1037/xge0001669,"Uncertainty presents a key challenge when learning how best to act to attain a desired outcome. People can report uncertainty in the form of confidence judgments, but how such judgments contribute to learning and subsequent decisions remains unclear. In a series of three experiments employing an operant learning task, we tested the hypothesis that confidence plays a central role in learning by regulating resource allocation to the seeking and processing of feedback. We predicted that, as participants' confidence in their task knowledge grew, they would discount feedback when it was provided and be correspondingly less willing to pay for it when it was costly. Consistent with these predictions, we found that higher confidence was associated with reduced electrophysiological markers of feedback processing and decreased updating of beliefs following feedback receipt. Bayesian modeling suggests that this decrease in processing was due to a drop in the expected informative value of novel information when participants were highly confident. Thus, when choosing whether to pay a fee to receive further feedback, participants' subjective confidence, rather than the objective accuracy of their decisions, guided their choices. Overall, our results suggest that confidence regulates learning and subsequent decision making. (PsycInfo Database Record (c) 2025 APA, all rights reserved).",,https://pubmed.ncbi.nlm.nih.gov/39531690/,English,Exclude,Outside date range,Confidence regulates feedback processing during human probabilistic learning.,,,,,0.95,0.8,small_sample_mentioned
pubmed:39531567,pubmed:39531567,PubMed,pubmed:39531567,An Asynchronous Training-Free SSVEP-BCI Detection Algorithm for Non-Equal Prior Probability Scenarios.,Junsong Wang;Yuntian Cui;Hongxin Zhang;Haolin Wu;Chen Yang,2024,10.1109/tnsre.2024.3496727,"SSVEP-based brain-computer interface (BCI) systems have received a lot of attention due to their relatively high Signal to Noise Ratio (SNR) and less training requirements. Most of the existing steady-state visual evoked potential (SSVEP) detection algorithms treat the prior probability of each alternative target being selected as equal. In this study, the prior probability distribution of alternative targets was introduced into the SSVEP recognition algorithm, and an asynchronous training-free SSVEP-BCI detection algorithm for non-equal prior probability scenarios was proposed. This algorithm is based on the Spatio-temporal equalization multi-window technique (STE-MW) and introduces the Maximum A Posteriori criterion (MAP), which makes full use of prior information to improve the performance of the asynchronous training-free BCI system. In addition, we proposed a mutual information-based performance evaluation metric called Mutual information rate (MIR) specifically for non-equal prior probability scenarios. This evaluation framework is designed to provide a more accurate estimation of the information transmission performance of BCI systems in such scenarios. A 10-target simulated vehicle control offline experiment involving 17 subjects showed that the proposed method improved the average MIR by 6.48%. Online free control experiments involving 12 subjects showed that the proposed method improved the average MIR by 14.93%, and significantly reduced the average instruction time. The proposed algorithm is more suitable for practical engineering application scenarios that are asynchronous and training-free; the extremely high accuracy is guaranteed while maintaining a low false alarm rate, which can be applied to asynchronous BCI systems that require high stability.",https://pubmed.ncbi.nlm.nih.gov/39531567/,https://pubmed.ncbi.nlm.nih.gov/39531567/,English,Include,,An Asynchronous Training-Free SSVEP-BCI Detection Algorithm for Non-Equal Prior Probability Scenarios.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39529572,pubmed:39529572,PubMed,pubmed:39529572,ECG-based epileptic seizure prediction: Challenges of current data-driven models.,Sotirios Kalousios;Jens Müller;Hongliu Yang;Matthias Eberlein;Ortrud Uckermann;Gabriele Schackert;Witold H Polanski;Georg Leonhardt,2025,10.1002/epi4.13073,"Up to a third of patients with epilepsy fail to achieve satisfactory seizure control. A reliable method of predicting seizures would alleviate psychological and physical impact. Dysregulation in heart rate variability (HRV) has been found to precede epileptic seizures and may serve as an extracerebral predictive biomarker. This study aims to identify the preictal HRV dynamics and unveil the factors impeding the clinical application of ECG-based seizure prediction. Thirty-nine adult patients (eight women; median age: 38, [IQR = 31, 56.5]) with 252 seizures were included. Each patient had more than three recorded epileptic seizures, each at least 2 hours apart. For each seizure, one hour of ECG prior to seizure onset was analyzed and 97 HRV features were extracted from overlapping three-minute windows with 10s stride. Two separate patient-specific experiments were performed using a support vector machine (SVM). Firstly, the separability of training data was examined in a non-causal trial. Secondly, the prediction was attempted in pseudo-prospective conditions. Finally, visualized HRV data, clinical metadata, and results were correlated. The mean receiver operating characteristic (ROC) area under the curve (AUC) for the non-causal experiment was 0.823 (±0.12), with 208 (82.5%) seizures achieving an improvement over chance (IoC) classification score (p < 0.05, Hanley & McNeil test). In pseudo-prospective classification, the ROC-AUC was 0.569 (±0.17), and 86 (49.4%) seizures were classified with IoC. Off-sample optimized SVMs failed to improve performance. Major limiting factors identified include non-stationarity, variable preictal duration and dynamics. The latter is expressed as both inter-seizure onset zone (SOZ) and intra-SOZ variability. The pseudo-prospective preictal classification achieving IoC in approximately half of tested seizures suggests the presence of genuine preictal HRV dynamics, but the overall performance does not warrant clinical application at present. The limiting factors identified are often overlooked in non-causal study designs. While current deterministic prediction methods prove inadequate, probabilistic approaches may offer a promising alternative. Many patients with epilepsy suffer from uncontrollable seizures and would greatly benefit from a reliable seizure prediction method. Currently, no such system is available to meet this need. Previous studies suggest that changes in the electrocardiogram (ECG) precede seizures by several minutes. In our work, we evaluated whether variations in heart rate could be used to predict epileptic seizures. Our findings indicate that we are still far from achieving results suitable for clinical application and highlight several limiting factors of present seizure prediction approaches.",,https://pubmed.ncbi.nlm.nih.gov/39529572/,English,Exclude,Outside date range,ECG-based epileptic seizure prediction: Challenges of current data-driven models.,,,,,0.95,0.6,
pubmed:39528813,pubmed:39528813,PubMed,pubmed:39528813,Exploration of an intrinsically explainable self-attention based model for prototype generation on single-channel EEG sleep stage classification.,Brenton Adey;Ahsan Habib;Chandan Karmakar,2024,10.1038/s41598-024-79139-y,"Prototype-based methods in deep learning offer interpretable explanations for decisions by comparing inputs to typical representatives in the data. This study explores the adaptation of SESM, a self-attention-based prototype method successful in electrocardiogram (ECG) tasks, for electroencephalogram (EEG) signals. The architecture is evaluated on sleep stage classification, exploring its efficacy in predicting stages with single-channel EEG. The model achieves comparable test accuracy compared to EEGNet, a state-of-the-art black-box architecture for EEG classification. The generated prototypical components are exaimed qualitatively and using the area over the perterbation curve (AOPC) indicate some alignment with expected bio-markers for different sleep stages such as alpha spindles and slow waves in non-REM sleep, but the results are severely limited by the model's ability to only extract and present information in the time-domain. Ablation studies are used to explore the impact of kernel size, number of heads, and diversity threshold on model performance and explainability. This study represents the first application of a self-attention based prototype method to EEG data and provides a step forward in explainable AI for EEG data analysis.",https://pubmed.ncbi.nlm.nih.gov/39528813/,https://pubmed.ncbi.nlm.nih.gov/39528813/,English,Include,,Exploration of an intrinsically explainable self-attention based model for prototype generation on single-channel EEG sleep stage classification.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39527944,pubmed:39527944,PubMed,pubmed:39527944,Influence of sleep on seizures and interictal epileptiform discharges in epilepsy.,Jun-Sang Sunwoo,2025,10.47936/encephalitis.2024.00087,"Sleep significantly influences seizure occurrence and interictal epileptiform discharges (IEDs) in patients with epilepsy. Sleep-related epilepsy, where seizures occur exclusively or predominantly during sleep, has been observed in various epilepsy syndromes. Understanding the influence of sleep on seizures and IEDs is crucial in the diagnosis, classification, and management of epilepsy. Although there is a bidirectional relationship between sleep and epilepsy, this review focuses on the influence of sleep on seizures and IEDs in epilepsy. Seizures are more common during non-rapid eye movement (NREM) sleep, particularly during stage N2, and are suppressed during rapid eye movement (REM) sleep. Sleep also activates IEDs, increasing the diagnostic yield of EEG recordings. The rate of IEDs increases during NREM sleep, reaches its maximum during stage N3, and decreases during REM sleep. Sleep affects the electrical field of IEDs, with an increase of spiking fields during NREM sleep and a decrease during REM sleep. In the localization of epileptogenic foci, REM sleep is less sensitive but more specific than NREM sleep. Thalamocortical EEG synchronization during NREM sleep and desynchronization during REM sleep underlie their opposing effects on seizures and IEDs. Accumulating evidence has suggested an antiseizure effect of orexinergic antagonism in animal studies. Interventions that promote REM sleep, including orexinergic antagonists, should be studied in the future as novel treatment strategies for epilepsy.",,https://pubmed.ncbi.nlm.nih.gov/39527944/,English,Exclude,Outside date range,Influence of sleep on seizures and interictal epileptiform discharges in epilepsy.,,,,,0.95,0.6,
pubmed:39527843,pubmed:39527843,PubMed,pubmed:39527843,A class alignment network based on self-attention for cross-subject EEG classification.,Sufan Ma;Dongxiao Zhang;Jiayi Wang;Jialiang Xie,2024,10.1088/2057-1976/ad90e8,"Due to the inherent variability in EEG signals across different individuals, domain adaptation and adversarial learning strategies are being progressively utilized to develop subject-specific classification models by leveraging data from other subjects. These approaches primarily focus on domain alignment and tend to overlook the critical task-specific class boundaries. This oversight can result in weak correlation between the extracted features and categories. To address these challenges, we propose a novel model that uses the known information from multiple subjects to bolster EEG classification for an individual subject through adversarial learning strategies. Our method begins by extracting both shallow and attention-driven deep features from EEG signals. Subsequently, we employ a class discriminator to encourage the same-class features from different domains to converge while ensuring that the different-class features diverge. This is achieved using our proposed discrimination loss function, which is designed to minimize the feature distance for samples of the same class across different domains while maximizing it for those from different classes. Additionally, our model incorporates two parallel classifiers that are harmonious yet distinct and jointly contribute to decision-making. Extensive testing on two publicly available EEG datasets has validated our model's efficacy and superiority.",https://pubmed.ncbi.nlm.nih.gov/39527843/,https://pubmed.ncbi.nlm.nih.gov/39527843/,English,Include,,A class alignment network based on self-attention for cross-subject EEG classification.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39524776,pubmed:39524776,PubMed,pubmed:39524776,Enhancing drug-target interaction predictions in context of neurodegenerative diseases using bidirectional long short-term memory in male Swiss albino mice pharmaco-EEG analysis.,Shahnawaz Qureshi;Syed Muhammad Zeeshan Iqbal;Asif Ameer;Seppo Karrila;Yazeed Yasin Ghadi;Syed Aziz Shah,2024,10.1145/3411408.3411461,"Emerging diseases like Parkinson or Alzheimer's, which are not curable, endanger human mental health and are challenging to research. Drug target interactions (DTI) are pivotal in the screening of candidate drugs and focus on a small pool of drug targets. Electroencephalogram shows the responses to psychotropic medicines in the brain bioelectric activity. Synaptic activity can be analyzed by using Local Field Potential recordings obtained from micro-electrodes implanted in the brain. The aim is to evaluate the effects of drug on brain bioelectric activity and increase the drug classification accuracy. The ultimate goal is to advance our understanding of how drugs affect synaptic activity and open the door to more focused treatment for neurodegenerative diseases. In this study, Pharmaco-EEG recordings are processed using Advanced neural network models, particularly Convolutional Neural Networks, to assess the effects of medications. The five different medicines used in this study are Ephedrine, Fluoxetine, Kratom, Morphine, and Saline. The signals observed are local field potential signals. To overcome some limits of DTI prediction, we propose Bidirectional Long Short-Term Memory (LSTM) for the categorization of intracranial EEG (i-EEG) data, departing from standard approaches. Similar EEG patterns are presumably caused by drugs that work by homologous pharmacological pathways, producing similar psychotropic effects. To improve accuracy and reduce training loss, our study introduces a bidirectional LSTM model for classification along with Bayesian optimization. High recall, precision, and F1-Scores, particularly a 95% F1-Score for morphine, ephedrine, fluoxetine, and saline, suggest good performance in predicting these drug classes. Kratom produces a somewhat lower recall of 94%, but a high F1-Score of 97% and perfect precision of 1.00. The weighted average F1-Score, macro average, and overall accuracy are all consistently high (around 97%), indicating that the model works well throughout the spectrum of drugs. Improved model performance was demonstrated by using a diversified dataset with five drug categories and bidirectional LSTM boosted with Bayesian optimization for hyperparameter tuning. From earlier limited-category models, it represents a substantial advancement.",https://pubmed.ncbi.nlm.nih.gov/39524776/,https://pubmed.ncbi.nlm.nih.gov/39524776/,English,Include,,Enhancing drug-target interaction predictions in context of neurodegenerative diseases using bidirectional long short-term memory in male Swiss albino mice pharmaco-EEG analysis.,Include,,"g Local Field Potential recordings obtained from micro-electrodes implanted in the brain. The aim is to evaluate the effects of drug on brain bioelectric activity and increase the drug classification accuracy. The ultimate goal is to advance our understanding of how drugs affect synaptic activity and open the door to more focused treatment for neurodegenerative diseases. In this study, Pharmaco-EE",,0.95,0.6,
pubmed:39517980,pubmed:39517980,PubMed,pubmed:39517980,Steady-State Visual Evoked Potential-Based Brain-Computer Interface System for Enhanced Human Activity Monitoring and Assessment.,Yuankun Chen;Xiyu Shi;Varuna De Silva;Safak Dogan,2024,10.1088/1741-2552/ac6ae5,"Advances in brain-computer interfaces (BCIs) have enabled direct and functional connections between human brains and computing systems. Recent developments in artificial intelligence have also significantly improved the ability to detect brain activity patterns. In particular, using steady-state visual evoked potentials (SSVEPs) in BCIs has enabled noticeable advances in human activity monitoring and identification. However, the lack of publicly available electroencephalogram (EEG) datasets has limited the development of SSVEP-based BCI systems (SSVEP-BCIs) for human activity monitoring and assisted living. This study aims to provide an open-access multicategory EEG dataset created under the SSVEP-BCI paradigm, with participants performing forward, backward, left, and right movements to simulate directional control commands in a virtual environment developed in Unity. The purpose of these actions is to explore how the brain responds to visual stimuli of control commands. An SSVEP-BCI system is proposed to enable hands-free control of a virtual target in the virtual environment allowing participants to maneuver the virtual target using only their brain activity. This work demonstrates the feasibility of using SSVEP-BCIs in human activity monitoring and assessment. The preliminary experiment results indicate the effectiveness of the developed system with high accuracy, successfully classifying 89.88% of brainwave activity.",https://pubmed.ncbi.nlm.nih.gov/39517980/,https://pubmed.ncbi.nlm.nih.gov/39517980/,English,Include,,Steady-State Visual Evoked Potential-Based Brain-Computer Interface System for Enhanced Human Activity Monitoring and Assessment.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39517978,pubmed:39517978,PubMed,pubmed:39517978,A Cross-Attention-Based Class Alignment Network for Cross-Subject EEG Classification in a Heterogeneous Space.,Sufan Ma;Dongxiao Zhang,2024,10.1016/j.neuroimage.2007.01.051,"Domain adaptation (DA) techniques have emerged as a pivotal strategy in addressing the challenges of cross-subject classification. However, traditional DA methods are inherently limited by the assumption of a homogeneous space, requiring that the source and target domains share identical feature dimensions and label sets, which is often impractical in real-world applications. Therefore, effectively addressing the challenge of EEG classification under heterogeneous spaces has emerged as a crucial research topic. We present a comprehensive framework that addresses the challenges of heterogeneous spaces by implementing a cross-domain class alignment strategy. We innovatively construct a cross-encoder to effectively capture the intricate dependencies between data across domains. We also introduce a tailored class discriminator accompanied by a corresponding loss function. By optimizing the loss function, we facilitate the aggregation of features with corresponding classes between the source and target domains, while ensuring that features from non-corresponding classes are dispersed. Extensive experiments were conducted on two publicly available EEG datasets. Compared to advanced methods that combine label alignment with transfer learning, our method demonstrated superior performance across five heterogeneous space scenarios. Notably, in four heterogeneous label space scenarios, our method outperformed the advanced methods by an average of 7.8%. Moreover, in complex scenarios involving both heterogeneous label spaces and heterogeneous feature spaces, our method outperformed the state-of-the-art methods by an average of 4.1%. This paper presents an efficient model for cross-subject EEG classification under heterogeneous spaces, which significantly addresses the challenges of EEG classification within heterogeneous spaces, thereby opening up new perspectives and avenues for research in related fields.",https://pubmed.ncbi.nlm.nih.gov/39517978/,https://pubmed.ncbi.nlm.nih.gov/39517978/,English,Include,,A Cross-Attention-Based Class Alignment Network for Cross-Subject EEG Classification in a Heterogeneous Space.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39517865,pubmed:39517865,PubMed,pubmed:39517865,Application of Electroencephalography Sensors and Artificial Intelligence in Automated Language Teaching.,Yanlin Chen;Wuxiong Wang;Shen Yan;Yiming Wang;Xinran Zheng;Chunli Lv,2024,10.1111/risa.13759,"This study developed an automated language learning teaching assessment system based on electroencephalography (EEG) and differential language large models (LLMs), aimed at enhancing language instruction effectiveness by monitoring learners' cognitive states in real time and personalizing teaching content accordingly. Through detailed experimental design, the paper validated the system's application in various teaching tasks. The results indicate that the system exhibited high precision, recall, and accuracy in teaching effectiveness tests. Specifically, the method integrating differential LLMs with the EEG fusion module achieved a precision of 0.96, recall of 0.95, accuracy of 0.96, and an F1-score of 0.95, outperforming other automated teaching models. Additionally, ablation experiments further confirmed the critical role of the EEG fusion module in enhancing teaching quality and accuracy, providing valuable data support and theoretical basis for future improvements in teaching methods and system design.",https://pubmed.ncbi.nlm.nih.gov/39517865/,https://pubmed.ncbi.nlm.nih.gov/39517865/,English,Include,,Application of Electroencephalography Sensors and Artificial Intelligence in Automated Language Teaching.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39517862,pubmed:39517862,PubMed,pubmed:39517862,Decoding Brain Signals from Rapid-Event EEG for Visual Analysis Using Deep Learning.,Madiha Rehman;Humaira Anwer;Helena Garay;Josep Alemany-Iturriaga;Isabel De la Torre Díez;Hafeez Ur Rehman Siddiqui;Saleem Ullah,2024,10.1016/j.bspc.2024.106081,"The perception and recognition of objects around us empower environmental interaction. Harnessing the brain's signals to achieve this objective has consistently posed difficulties. Researchers are exploring whether the poor accuracy in this field is a result of the design of the temporal stimulation (block versus rapid event) or the inherent complexity of electroencephalogram (EEG) signals. Decoding perceptive signal responses in subjects has become increasingly complex due to high noise levels and the complex nature of brain activities. EEG signals have high temporal resolution and are non-stationary signals, i.e., their mean and variance vary overtime. This study aims to develop a deep learning model for the decoding of subjects' responses to rapid-event visual stimuli and highlights the major factors that contribute to low accuracy in the EEG visual classification task.The proposed multi-class, multi-channel model integrates feature fusion to handle complex, non-stationary signals. This model is applied to the largest publicly available EEG dataset for visual classification consisting of 40 object classes, with 1000 images in each class. Contemporary state-of-the-art studies in this area investigating a large number of object classes have achieved a maximum accuracy of 17.6%. In contrast, our approach, which integrates Multi-Class, Multi-Channel Feature Fusion (MCCFF), achieves a classification accuracy of 33.17% for 40 classes. These results demonstrate the potential of EEG signals in advancing EEG visual classification and offering potential for future applications in visual machine models.",https://pubmed.ncbi.nlm.nih.gov/39517862/,https://pubmed.ncbi.nlm.nih.gov/39517862/,English,Include,,Decoding Brain Signals from Rapid-Event EEG for Visual Analysis Using Deep Learning.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39517712,pubmed:39517712,PubMed,pubmed:39517712,Resting-State Electroencephalogram Depression Diagnosis Based on Traditional Machine Learning and Deep Learning: A Comparative Analysis.,Haijun Lin;Jing Fang;Junpeng Zhang;Xuhui Zhang;Weiying Piao;Yukun Liu,2024,10.3390/ijerph18031327,"The global prevalence of Major Depressive Disorder (MDD) is increasing at an alarming rate, underscoring the urgent need for timely and accurate diagnoses to facilitate effective interventions and treatments. Electroencephalography remains a widely used neuroimaging technique in psychiatry, due to its non-invasive nature and cost-effectiveness. With the rise of computational psychiatry, the integration of EEG with artificial intelligence has yielded remarkable results in diagnosing depression. This review offers a comparative analysis of two predominant methodologies in research: traditional machine learning and deep learning methods. Furthermore, this review addresses key challenges in current research and suggests potential solutions. These insights aim to enhance diagnostic accuracy for depression and also foster further development in the area of computational psychiatry.",,https://pubmed.ncbi.nlm.nih.gov/39517712/,English,Exclude,Review/survey papers,Resting-State Electroencephalogram Depression Diagnosis Based on Traditional Machine Learning and Deep Learning: A Comparative Analysis.,,,,,0.95,0.6,
pubmed:39515528,pubmed:39515528,PubMed,pubmed:39515528,Depression diagnosis: EEG-based cognitive biomarkers and machine learning.,Kiran Boby;Sridevi Veerasingam,2025,10.1016/j.bbr.2024.115325,"Depression is a complex mental illness that has significant effects on people as well as society. The traditional techniques for the diagnosis of depression, along with the potential of nascent biomarkers especially EEG-based biomarkers, are studied. This review explores the significance of cognitive biomarkers, offering a comprehensive understanding of their role in the overall assessment of depression. It also investigates the effects of depression on various brain regions, outlines promising areas for future research, and emphasizes the importance of understanding the neurophysiological roots of depression. Furthermore, it elucidates how machine learning and deep learning models are integrated into EEG-based depression diagnosis, emphasizing their importance in optimizing personalized therapeutic protocols and improving diagnostic accuracy with EEG data analysis.",,https://pubmed.ncbi.nlm.nih.gov/39515528/,English,Exclude,Outside date range,Depression diagnosis: EEG-based cognitive biomarkers and machine learning.,,,,,0.95,0.6,
pubmed:39514976,pubmed:39514976,PubMed,pubmed:39514976,Classification of hand movements from EEG using a FusionNet based LSTM network.,Li Ji;Leiye Yi;Chaohang Huang;Haiwei Li;Wenjie Han;Ningning Zhang,2024,10.1088/1741-2552/ad905d,,https://pubmed.ncbi.nlm.nih.gov/39514976/,https://pubmed.ncbi.nlm.nih.gov/39514976/,English,Include,,Classification of hand movements from EEG using a FusionNet based LSTM network.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39514384,pubmed:39514384,PubMed,pubmed:39514384,Decoding aging and cognitive functioning through spatiotemporal EEG patterns: Introducing spatiotemporal information-based similarity analysis.,Wang Wan;Zhilin Gao;Zhongze Gu;Chung-Kang Peng;Xingran Cui,2024,10.1063/5.0203249,"Exploring spatiotemporal patterns of high-dimensional electroencephalography (EEG) time series generated from complex brain system is crucial for deciphering aging and cognitive functioning. Analyzing high-dimensional EEG series poses challenges, particularly when employing distance-based methods for spatiotemporal dynamics. Therefore, we proposed an innovative methodology for multi-channel EEG data, termed as Spatiotemporal Information-based Similarity (STIBS) analysis. The core of this method is to first perform state space compression of multi-channel EEG time series using global field power, which can provide insight into the dynamic integration of spatiotemporal patterns between the steady states and non-steady states of brain. Subsequently, we quantify the pairwise differences and non-randomness of spatiotemporal patterns using an information-based similarity analysis. Results demonstrated that this method holds the potential to serve as a distinguishing marker between young and elderly on both pairwise differences and non-randomness indices. Young individuals and those with higher cognitive abilities exhibit more complex macrostructure and non-random spatiotemporal patterns, whereas both aging and cognitive decline lead to more randomized spatiotemporal patterns. We further extended the proposed analytics to brain regions adversarial STIBS (bra-STIBS), highlighting differences between young and elderly, as well as high and low cognitive groups. Furthermore, utilizing the STIBS-based XGBoost model yields superior recognition accuracy in aging (93.05%) and cognitive functioning (74.29%, 64.19%, and 80.28%, respectively, for attention, memory, and compatibility performance recognition). STIBS-based methodology not only contributes to the ongoing exploration of neurobiological changes in aging but also provides a powerful tool for characterizing the spatiotemporal nonlinear dynamics of the brain and their implications for cognitive functioning.",https://pubmed.ncbi.nlm.nih.gov/39514384/,https://pubmed.ncbi.nlm.nih.gov/39514384/,English,Include,,Decoding aging and cognitive functioning through spatiotemporal EEG patterns: Introducing spatiotemporal information-based similarity analysis.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39512386,pubmed:39512386,PubMed,pubmed:39512386,BrainNet: an automated approach for brain stress prediction utilizing electrodermal activity signal with XLNet model.,Liao Xuanzhi;Abeer Hakeem;Linda Mohaisen;Muhammad Umer;Muhammad Attique Khan;Shrooq Alsenan;Shtwai Alsubai;Nisreen Innab,2024,10.1109/access.2020.2988348,"Brain stress monitoring has emerged as a critical research area for understanding and managing stress and neurological health issues. This burgeoning field aims to provide accurate information and prediction about individuals' stress levels by analyzing behavioral data and physiological signals. To address this emerging problem, this research study proposes an innovative approach that uses an attention mechanism-based XLNet model (called BrainNet) for continuous stress monitoring and stress level prediction. The proposed model analyzes streams of brain data, including behavioral and physiological signal patterns using Swell and WESAD datasets. Testing on the Swell multi-class dataset, the model achieves an impressive accuracy of 95.76%. Furthermore, when evaluated on the WESAD dataset, it demonstrates even higher accuracy, reaching 98.32%. When applied to the binary classification of stress and no stress using the Swell dataset, the model achieves an outstanding accuracy of 97.19%. Comparative analysis with other previously published research studies underscores the superior performance of the proposed approach. In addition, cross-validation confirms the significance, efficacy, and robustness of the model in brain stress level prediction and aligns with the goals of smart diagnostics for understanding neurological behaviors.",,https://pubmed.ncbi.nlm.nih.gov/39512386/,English,Exclude,Not EEG-BCI focused,BrainNet: an automated approach for brain stress prediction utilizing electrodermal activity signal with XLNet model.,,,,,0.9,0.25,cv_reported
pubmed:39511694,pubmed:39511694,PubMed,pubmed:39511694,Comparing retro-cue benefit mechanisms in visual working memory: completely valid vs. highly valid retro-cues.,Qiang Liu;Lijing Guo;Dan Nie;Kai Fu;Chaoxiong Ye,2024,10.1186/s40359-024-02145-2,"Visual working memory (VWM) plays a crucial role in temporarily maintaining and manipulating visual information. Retro-cue benefit (RCB) refers to the enhancement of memory performance when attention is directed toward a subset of items in VWM after their initial encoding. Our recent electroencephalogram (EEG) studies indicate that cue validity affects the mechanisms underlying RCB formation. However, previous research has not thoroughly examined whether these mechanisms differ between completely valid and highly valid cue conditions. This study investigates the consistency of RCB mechanisms under conditions of complete (100%) and high (80%) retro-cue validity. We manipulated retro-cue validity and examined cognitive processing mechanisms under different validity conditions using EEG. Specifically, we focused on the N2pc component, which reflects attentional resource allocation, and the contralateral delay activity (CDA) component, which reflects the quantity of information retained in VWM. The results, encompassing both behavioral and event-related potential (ERP) findings, show that participants in both the 100% and 80% cue validity conditions exhibit robust RCB. Notably, the degree of RCB remains consistent across these conditions, indicating that participants utilize retro-cues to enhance VWM performance to the same extent. In the 80% cue validity condition, a significant retro-cue cost (RCC) was observed, indicating that participants selectively discarded uncued items from VWM. In invalid trials, response accuracy drops to chance levels, supporting the removal hypothesis. ERP results reveal that attentional resource allocation (N2pc) and the quantity of retained information (CDA) remain uniform across cue validity conditions. The mechanism responsible for RCB formation appears to involve an all-or-nothing process of discarding uncued information rather than a flexible resource allocation strategy. This study provides insights into attention allocation and information-processing mechanisms in VWM, suggesting that conclusions drawn from tasks with completely valid retro-cues can be integrated with findings from highly valid cue tasks. These findings also illuminate the flexibility of internal attentional resource allocation during RCB formation and contribute to our understanding of attention processes in VWM.",https://pubmed.ncbi.nlm.nih.gov/39511694/,https://pubmed.ncbi.nlm.nih.gov/39511694/,English,Include,,Comparing retro-cue benefit mechanisms in visual working memory: completely valid vs. highly valid retro-cues.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39511257,pubmed:39511257,PubMed,pubmed:39511257,A hybrid local-global neural network for visual classification using raw EEG signals.,Shuning Xue;Bu Jin;Jie Jiang;Longteng Guo;Jing Liu,2024,10.1038/s41598-024-77923-4,"EEG-based brain-computer interfaces (BCIs) have the potential to decode visual information. Recently, artificial neural networks (ANNs) have been used to classify EEG signals evoked by visual stimuli. However, methods using ANNs to extract features from raw signals still perform lower than traditional frequency-domain features, and the methods are typically evaluated on small-scale datasets at a low sample rate, which can hinder the capabilities of deep-learning models. To overcome these limitations, we propose a hybrid local-global neural network, which can be trained end-to-end from raw signals without handcrafted features. Specifically, we first propose a reweight module to learn channel weights adaptively. Then, a local feature extraction module is designed to capture basic EEG features. Next, a spatial integration module fuses information from each electrode, and a global feature extraction module integrates overall time-domain characteristics. Additionally, a feature fusion module is proposed to extract efficient features in high sampling rate settings. The proposed model achieves state-of-the-art results on two commonly used small-scale datasets and outperforms baseline methods on three under-studied large-scale datasets. Ablation experimental results demonstrate that the proposed modules have a stable performance improvement ability on multiple datasets across different sample rates, providing a robust end-to-end learning framework.",https://pubmed.ncbi.nlm.nih.gov/39511257/,https://pubmed.ncbi.nlm.nih.gov/39511257/,English,Include,,A hybrid local-global neural network for visual classification using raw EEG signals.,Exclude,No performance metrics reported,No metrics found in full text,,0.9,0.6,
pubmed:39509990,pubmed:39509990,PubMed,pubmed:39509990,Spectral peak analysis and intrinsic neural timescales as markers for the state of consciousness.,Ezequiel Pablo Espinosa;Di Zang;Andrea Buccellato;Zengxin Qi;Xuehai Wu;Samira Abbasi;Yasir Catal;Stephan Lechner;Federico Zilio;Georg Northoff,2024,10.1038/s42003-023-05109-1,"Resting state EEG in patients with disorders of consciousness (DOC) is characterized by an increase of power in the delta frequency band and a concurrent decrease in the alpha range, equivalent to a weakening or disappearance of the alpha peak. Prolongation of Intrinsic Neural Timescales (INTs) is also associated with DOCs. Together, this raises the question whether the decreased alpha peak relates to the prolonged INTs and, importantly, how that can be used for diagnosing the state of consciousness in DOC individuals. Analyzing resting state EEG recordings from both healthy subjects and DOC patients, we measure INTs through autocorrelation window (ACW) and utilize peak analysis to quantify the weakening of the alpha peak. First, we replicate previous findings of prolonged ACW in DOC patients. We then identify significantly lower alpha peak measures in DOC compared to controls. Interestingly, spectral peaks shift from the alpha to the theta range in several DOC subjects while such change is absent in healthy controls. Next, our study reveals a close relationship between ACW and alpha peak in both healthy and DOC subjects, a correlation that holds for theta peaks in DOC. Further, the prolonged ACW correlates with the state of consciousness, as quantified by the Coma Recovery Scale-Revised (CRS-R), and mediates the relationship between theta peak and CRS-R. Finally, through split analyses and machine learning, we show that ACW and alpha peak measures conjointly distinguish healthy controls and DOC patients with high accuracy (95.5%). In conclusion, we demonstrate that the prolongation of ACW, together with spectral peak measures, holds promise to serve as additional EEG biomarkers for diagnosing the state of consciousness in DOC subjects.",https://pubmed.ncbi.nlm.nih.gov/39509990/,https://pubmed.ncbi.nlm.nih.gov/39509990/,English,Include,,Spectral peak analysis and intrinsic neural timescales as markers for the state of consciousness.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39509814,pubmed:39509814,PubMed,pubmed:39509814,A temporal-spectral fusion transformer with subject-specific adapter for enhancing RSVP-BCI decoding.,Xujin Li;Wei Wei;Shuang Qiu;Huiguang He,2025,10.1016/j.neunet.2024.106844,"The Rapid Serial Visual Presentation (RSVP)-based Brain-Computer Interface (BCI) is an efficient technology for target retrieval using electroencephalography (EEG) signals. The performance improvement of traditional decoding methods relies on a substantial amount of training data from new test subjects, which increases preparation time for BCI systems. Several studies introduce data from existing subjects to reduce the dependence of performance improvement on data from new subjects, but their optimization strategy based on adversarial learning with extensive data increases training time during the preparation procedure. Moreover, most previous methods only focus on the single-view information of EEG signals, but ignore the information from other views which may further improve performance. To enhance decoding performance while reducing preparation time, we propose a Temporal-Spectral fusion transformer with Subject-specific Adapter (TSformer-SA). Specifically, a cross-view interaction module is proposed to facilitate information transfer and extract common representations across two-view features extracted from EEG temporal signals and spectrogram images. Then, an attention-based fusion module fuses the features of two views to obtain comprehensive discriminative features for classification. Furthermore, a multi-view consistency loss is proposed to maximize the feature similarity between two views of the same EEG signal. Finally, we propose a subject-specific adapter to rapidly transfer the knowledge of the model trained on data from existing subjects to decode data from new subjects. Experimental results show that TSformer-SA significantly outperforms comparison methods and achieves outstanding performance with limited training data from new subjects. This facilitates efficient decoding and rapid deployment of BCI systems in practical use.",,https://pubmed.ncbi.nlm.nih.gov/39509814/,English,Exclude,Outside date range,A temporal-spectral fusion transformer with subject-specific adapter for enhancing RSVP-BCI decoding.,,,,,0.95,0.6,
pubmed:39509804,pubmed:39509804,PubMed,pubmed:39509804,A universal method for seizure onset zone localization in focal epilepsy using standard deviation of spike amplitude.,Xiang Ji;Yuanyuan Dang;Ming Song;Aijun Liu;Hulin Zhao;Tianzi Jiang,2024,10.1016/j.eplepsyres.2024.107475,"Precisely localizing the seizure onset zone (SOZ) is critical for focal epilepsy surgery. Existing methods mainly focus on high-frequency activities in stereo-electroencephalography, but often fail when seizures are not driven by high-frequency activities. Recognized as biomarkers of epileptic seizures, ictal spikes in SOZ induce epileptiform discharges in other brain regions. Based on this understanding, we aim to develop a universal algorithm to localize SOZ and investigate how ictal spikes within the SOZ induce seizures. We proposed a novel metric called standard deviation of spike amplitude (SDSA) and utilized channel-averaged SDSA to describe seizure processes and detect seizures. By integrating SDSA values in specific intervals, the score for each channel located within SOZ was calculated. Channels with high SOZ scores were clustered as SOZ. The localization accuracy was asserted using area under the receiver operating characteristic (ROC) curve. Further, we analyzed early ictal signals from SOZ channels and investigated factors influencing their duration to reveal the seizure inducing conditions. We analyzed data from 15 patients with focal epilepsy. The channel-averaged SDSA successfully detected all 28 seizures without false alarms. Using SDSA integration, we achieved precise SOZ localization with an average area under ROC curve (AUC) of 0.96, significantly outperforming previous methods based on high-frequency activities. Further, we discovered that energy of ictal spikes in SOZ was concentrated at a specific frequency distributed in [6, 12 Hz]. Additionally, we found that the higher the energy per second in this frequency band, the faster ictal spikes could induce seizures. The SDSA metric offered precise SOZ localization with robustness and low computational cost, making it suitable for clinical practice. By studying the propagation patterns of ictal spikes between the SOZ and non-SOZ, we suggest that ictal spikes from SOZ need to accumulate energy at a specific central frequency to induce epileptic spikes in non-SOZ, which may have significant implications for understanding the seizure onset pattern.",https://pubmed.ncbi.nlm.nih.gov/39509804/,https://pubmed.ncbi.nlm.nih.gov/39509804/,English,Include,,A universal method for seizure onset zone localization in focal epilepsy using standard deviation of spike amplitude.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39508998,pubmed:39508998,PubMed,pubmed:39508998,Mark3D - A semi-automated open-source toolbox for 3D head- surface reconstruction and electrode position registration using a smartphone camera video.,Suranjita Ganguly;Malaaika Mihir Chhaya;Ankita Jain;Aditya Koppula;Mohan Raghavan;Kousik Sarathy Sridharan,2025,10.1016/j.cmpb.2010.05.008,"Source localization in EEG necessitates co-registering the EEG sensor locations with the subject's MRI, where EEG sensor locations are typically captured using electromagnetic tracking or 3D scanning of the subject's head with EEG cap, using commercially available 3D scanners. Both methods have drawbacks, where, electromagnetic tracking is slow and immobile, while 3D scanners are expensive. Photogrammetry offers a cost-effective alternative but requires multiple photos to sample the head, with good spatial sampling to adequately reconstruct the head surface. Post-reconstruction, the existing tools for electrode position labelling on the 3D head-surface have limited visual feedback and do not easily accommodate customized montages, which are typical in multi-modal measurements. We introduce Mark3D, an open-source, integrated tool for 3D head-surface reconstruction from phone camera video. It eliminates the need for keeping track of spatial sampling during image capture for video-based photogrammetry reconstruction. It also includes blur detection algorithms, a user-friendly interface for electrode and tracking, and integrates with popular toolboxes such as FieldTrip and MNE Python. The accuracy of the proposed method was benchmarked with the head-surface derived from a commercially available handheld 3D scanner Einscan-Pro + (Shining 3D Inc.,) which we treat as the ""ground truth"". We used reconstructed head-surfaces of ground truth (G1) and phone camera video (M",,https://pubmed.ncbi.nlm.nih.gov/39508998/,English,Exclude,Outside date range,Mark3D - A semi-automated open-source toolbox for 3D head- surface reconstruction and electrode position registration using a smartphone camera video.,,,,,0.95,0.6,
pubmed:39508559,pubmed:39508559,PubMed,pubmed:39508559,Empathy enhances decoding accuracy of human neurophysiological responses to emotional facial expressions of humans and dogs.,Miiamaaria V Kujala;Lauri Parkkonen;Jan Kujala,2024,10.1007/s10548-015-0456-0,"Despite the growing interest in the nonhuman animal emotionality, we currently know little about the human brain processing of nonconspecific emotional expressions. Here, we characterized the millisecond-scale temporal dynamics of human brain responses to conspecific human and nonconspecific canine emotional facial expressions. Our results revealed generally similar cortical responses to human and dog facial expressions in the occipital cortex during the first 500 ms, temporal cortex at 100-500 ms and parietal cortex at 150-350 ms from the stimulus onset. Responses to dog faces were pronounced at the latencies in temporal cortices corresponding to the time windows of early posterior negativity and late posterior positivity, suggesting attentional engagement to emotionally salient stimuli. We also utilized support vector machine-based classifiers to discriminate between the brain responses to different images. The subject trait-level empathy correlated with the accuracy of classifying the brain responses of aggressive from happy dog faces and happy from neutral human faces. This result likely reflects the attentional enhancement provoked by the subjective ecological salience of the stimuli.",,https://pubmed.ncbi.nlm.nih.gov/39508559/,English,Exclude,Not EEG-BCI focused,Empathy enhances decoding accuracy of human neurophysiological responses to emotional facial expressions of humans and dogs.,,,,,0.9,0.6,
pubmed:39507500,pubmed:39507500,PubMed,pubmed:39507500,Dynamic GNNs for Precise Seizure Detection and Classification from EEG Data.,Arash Hajisafi;Haowen Lin;Yao-Yi Chiang;Cyrus Shahabi,2024,10.1007/978-981-97-2238-9_16,"Diagnosing epilepsy requires accurate seizure detection and classification, but traditional manual EEG signal analysis is resource-intensive. Meanwhile, automated algorithms often overlook EEG's geometric and semantic properties critical for interpreting brain activity. This paper introduces NeuroGNN, a dynamic Graph Neural Network (GNN) framework that captures the dynamic interplay between the EEG electrode locations and the semantics of their corresponding brain regions. The specific brain region where an electrode is placed critically shapes the nature of captured EEG signals. Each brain region governs distinct cognitive functions, emotions, and sensory processing, influencing both the semantic and spatial relationships within the EEG data. Understanding and modeling these intricate brain relationships are essential for accurate and meaningful insights into brain activity. This is precisely where the proposed NeuroGNN framework excels by dynamically constructing a graph that encapsulates these evolving spatial, temporal, semantic, and taxonomic correlations to improve precision in seizure detection and classification. Our extensive experiments with real-world data demonstrate that NeuroGNN significantly outperforms existing state-of-the-art models.",https://pubmed.ncbi.nlm.nih.gov/39507500/,https://pubmed.ncbi.nlm.nih.gov/39507500/,English,Include,,Dynamic GNNs for Precise Seizure Detection and Classification from EEG Data.,Include,,"in regions. The specific brain region where an electrode is placed critically shapes the nature of captured EEG signals. Each brain region governs distinct cognitive functions, emotions, and sensory processing, influencing both the semantic and spatial relationships within the EEG data. Understanding and modeling these intricate brain relationships are essential for accurate and meaningful insight",,0.95,0.6,
pubmed:39507061,pubmed:39507061,PubMed,pubmed:39507061,High-order brain network feature extraction and classification method of first-episode schizophrenia: an EEG study.,Yanxia Kang;Jianghao Zhao;Yanli Zhao;Zilong Zhao;Yuan Dong;Manjie Zhang;Guimei Yin;Shuping Tan,2024,10.1016/j.ajp.2023.103687,"A multimodal persistent topological feature extraction and classification method is proposed to enhance the recognition accuracy of first-episode schizophrenia patients. This approach addresses the limitations of traditional higher-order brain network analyses that rely on single persistent features (e.g., persistent images). The study utilized resting-state EEG data from 198 subjects recruited at Huilongguan Hospital in Beijing, comprising 102 males and 96 females, with a mean age of 30 years and mean education of 14 years. Persistent topological features were extracted using adaptive thresholding during persistent homology (PH) filtrations. The distribution of these features was visualized through heatmaps and persistence entropies, while the generation process was elucidated using Betti curves and persistence landscapes. The classification performance of the multimodal persistent topological features was assessed using various machine learning classifiers. The classifier yielding the highest performance was selected for comparison with traditional brain network features derived from graph theory and single persistent topological features. The results revealed significant topological changes in first-episode schizophrenia patients throughout the persistent homology filtering compared to healthy subjects. The univariate feature selection algorithm achieved a classification accuracy of 94.6% with a combination of attributes meeting the criterion of AC ≥ 0.6. The proposed method demonstrates clinical significance for the early identification and diagnosis of first-episode schizophrenia patients, offering a new research perspective for constructing higher-order functional connectivity networks and extracting topological structure features.",https://pubmed.ncbi.nlm.nih.gov/39507061/,https://pubmed.ncbi.nlm.nih.gov/39507061/,English,Include,,High-order brain network feature extraction and classification method of first-episode schizophrenia: an EEG study.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39506076,pubmed:39506076,PubMed,pubmed:39506076,Synchronization-based fusion of EEG and eye blink signals for enhanced decoding accuracy.,Emad Alyan;Stefan Arnau;Julian Elias Reiser;Edmund Wascher,2024,10.1038/s41598-024-78542-9,"Decoding locomotor tasks is crucial in cognitive neuroscience for understanding brain responses to physical tasks. Traditional methods like EEG offer brain activity insights but may require additional modalities for enhanced interpretative precision and depth. The integration of EEG with ocular metrics, particularly eye blinks, presents a promising avenue for understanding cognitive processes by combining neural and ocular behaviors. However, synchronizing EEG and eye blink activities poses a significant challenge due to their frequently inconsistent alignment. Our study with 35 participants performing various locomotor tasks such as standing, walking, and transversing obstacles introduced a novel methodology, pcEEG+, which fuses EEG principal components (pcEEG) with aligned eye blink data (syncBlink). The results demonstrated that pcEEG+ significantly improved decoding accuracy in locomotor tasks, reaching 78% in some conditions, and surpassed standalone pcEEG and syncBlink methods by 7.6% and 22.7%, respectively. The temporal generalization matrix confirmed the consistency of pcEEG+ across tasks and times. The results were replicated using two driving simulator datasets, thereby confirming the validity of our method. This study demonstrates the efficacy of the pcEEG+ method in decoding locomotor tasks, underscoring the importance of temporal synchronization for accuracy and offering a deeper insight into brain activity during complex movements.",https://pubmed.ncbi.nlm.nih.gov/39506076/,https://pubmed.ncbi.nlm.nih.gov/39506076/,English,Include,,Synchronization-based fusion of EEG and eye blink signals for enhanced decoding accuracy.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39504647,pubmed:39504647,PubMed,pubmed:39504647,Interhemispheric asynchrony of NREM EEG at the beginning and end of sleep describes evening vigilance performance in patients undergoing diagnostic polysomnography.,Karen McCloy;Brett Duce;Nadeeka Dissanayaka;Craig Hukins;Udantha Abeyratne,2024,10.1088/1361-6579/ad8f8f,,,https://pubmed.ncbi.nlm.nih.gov/39504647/,English,Exclude,Not classification-focused,Interhemispheric asynchrony of NREM EEG at the beginning and end of sleep describes evening vigilance performance in patients undergoing diagnostic polysomnography.,,,,,0.85,0.6,
pubmed:39504300,pubmed:39504300,PubMed,pubmed:39504300,A Feature Fusion Model Based on Temporal Convolutional Network for Automatic Sleep Staging Using Single-Channel EEG.,Jiameng Bao;Guangming Wang;Tianyu Wang;Ning Wu;Shimin Hu;Won Hee Lee;Sio-Long Lo;Xiangguo Yan;Yang Zheng;Gang Wang,2024,10.1109/jbhi.2024.3457969,"Sleep staging is a crucial task in sleep monitoring and diagnosis, but clinical sleep staging is both time-consuming and subjective. In this study, we proposed a novel deep learning algorithm named feature fusion temporal convolutional network (FFTCN) for automatic sleep staging using single-channel EEG data. This algorithm employed a one-dimensional convolutional neural network (1D-CNN) to extract temporal features from raw EEG, and a two-dimensional CNN (2D-CNN) to extract time-frequency features from spectrograms generated through continuous wavelet transform (CWT) at the epoch level. These features were subsequently fused and further fed into a temporal convolutional network (TCN) to classify sleep stages at the sequence level. Moreover, a two-step training strategy was used to enhance the model's performance on an imbalanced dataset. Our proposed method exhibits superior performance in the 5-class classification task for healthy subjects, as evaluated on the SHHS-1, Sleep-EDF-153, and ISRUC-S1 datasets. This work provided a straightforward and promising method for improving the accuracy of automatic sleep staging using only single-channel EEG, and the proposed method exhibited great potential for future applications in professional sleep monitoring, which could effectively alleviate the workload of sleep technicians.",https://pubmed.ncbi.nlm.nih.gov/39504300/,https://pubmed.ncbi.nlm.nih.gov/39504300/,English,Include,,A Feature Fusion Model Based on Temporal Convolutional Network for Automatic Sleep Staging Using Single-Channel EEG.,Include,," in the 5-class classification task for healthy subjects, as evaluated on the SHHS-1, Sleep-EDF-153, and ISRUC-S1 datasets. This work provided a straightforward and promising method for improving the accuracy of automatic sleep staging using only single-channel EEG, and the proposed method exhibited great potential for future applications in professional sleep monitoring, which could effectively a",,0.95,0.6,
pubmed:39504276,pubmed:39504276,PubMed,pubmed:39504276,Reconstructing Multi-Stroke Characters From Brain Signals Toward Generalizable Handwriting Brain-Computer Interfaces.,Xiaomeng Yang;Xinzhu Xiong;Xufei Li;Qi Lian;Junming Zhu;Jianmin Zhang;Yu Qi;Yueming Wang,2024,10.1109/tnsre.2024.3492191,"Handwriting Brain-Computer Interfaces (BCIs) provides a promising communication avenue for individuals with paralysis. While English-based handwriting BCIs have achieved rapid typewriting with 26 lowercase letters (mostly containing one stroke each), it is difficult to extend to complex characters, especially those with multiple strokes and large character sets. The Chinese characters, including over 3500 commonly used characters with 10.3 strokes per character on average, represent a highly complex writing system. This paper proposes a Chinese handwriting BCI system, which reconstructs multi-stroke handwriting trajectories from brain signals. Through the recording of cortical neural signals from the motor cortex, we reveal distinct neural representations for stroke-writing and pen-lift phases. Leveraging this finding, we propose a stroke-aware approach to decode stroke-writing trajectories and pen-lift movements individually, which can reconstruct recognizable characters (accuracy of 86% with 400 characters). Our approach demonstrates high stability over 5 months, shedding light on generalized and adaptable handwriting BCIs.",https://pubmed.ncbi.nlm.nih.gov/39504276/,https://pubmed.ncbi.nlm.nih.gov/39504276/,English,Include,,Reconstructing Multi-Stroke Characters From Brain Signals Toward Generalizable Handwriting Brain-Computer Interfaces.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39502794,pubmed:39502794,PubMed,pubmed:39502794,M/EEG source localization for both subcortical and cortical sources using a convolutional neural network with a realistic head conductivity model.,Hikaru Yokoyama;Naotsugu Kaneko;Noboru Usuda;Tatsuya Kato;Hui Ming Khoo;Ryohei Fukuma;Satoru Oshino;Naoki Tani;Haruhiko Kishima;Takufumi Yanagisawa;Kimitaka Nakazawa,2024,10.1111/j.2517-6161.1995.tb02031.x,"While electroencephalography (EEG) and magnetoencephalography (MEG) are well-established noninvasive methods in neuroscience and clinical medicine, they suffer from low spatial resolution. Electrophysiological source imaging (ESI) addresses this by noninvasively exploring the neuronal origins of M/EEG signals. Although subcortical structures are crucial to many brain functions and neuronal diseases, accurately localizing subcortical sources of M/EEG remains particularly challenging, and the feasibility is still a subject of debate. Traditional ESIs, which depend on explicitly defined regularization priors, have struggled to set optimal priors and accurately localize brain sources. To overcome this, we introduced a data-driven, deep learning-based ESI approach without the need for these priors. We proposed a four-layered convolutional neural network (4LCNN) designed to locate both subcortical and cortical sources underlying M/EEG signals. We also employed a sophisticated realistic head conductivity model using the state-of-the-art segmentation method of ten different head tissues from individual MRI data to generate realistic training data. This is the first attempt at deep learning-based ESI targeting subcortical regions. Our method showed excellent accuracy in source localization, particularly in subcortical areas compared to other methods. This was validated through M/EEG simulations, evoked responses, and invasive recordings. The potential for accurate source localization of the 4LCNNs demonstrated in this study suggests future contributions to various research endeavors such as the clinical diagnosis, understanding of the pathophysiology of various neuronal diseases, and basic brain functions.",https://pubmed.ncbi.nlm.nih.gov/39502794/,https://pubmed.ncbi.nlm.nih.gov/39502794/,English,Include,,M/EEG source localization for both subcortical and cortical sources using a convolutional neural network with a realistic head conductivity model.,Include,,"en different head tissues from individual MRI data to generate realistic training data. This is the first attempt at deep learning-based ESI targeting subcortical regions. Our method showed excellent accuracy in source localization, particularly in subcortical areas compared to other methods. This was validated through M/EEG simulations, evoked responses, and invasive recordings. The potential for",,0.95,0.6,
pubmed:39502490,pubmed:39502490,PubMed,pubmed:39502490,Diagnosing epileptic seizures using combined features from independent components and prediction probability from EEG data.,Madiha Khalid;Ali Raza;Adnan Akhtar;Furqan Rustam;Julien Brito Ballester;Carmen Lili Rodriguez;Isabel de la Torre Díez;Imran Ashraf,2024,10.1177/20552076241277185,"Epileptic seizures are neurological events that pose significant risks of physical injuries characterized by sudden, abnormal bursts of electrical activity in the brain, often leading to loss of consciousness and uncontrolled movements. Early seizure detection is essential for timely treatments and better patient outcomes. To address this critical issue, there is a need for an advanced artificial intelligence approach for the early detection of epileptic seizure disorder. This study primarily focuses on designing a novel ensemble approach to perform early detection of epileptic seizure disease with high performance. A novel ensemble approach consisting of a fast, independent component analysis random forest (FIR) and prediction probability is proposed, which uses electroencephalography (EEG) data to investigate the efficacy of the proposed approach for early detection of epileptic seizures. The FIR model extracts independent components and class prediction probability features, creating a new feature set. The proposed model combined integrated component analysis (ICA) with predicting probability to enhance seizure recognition accuracy scores. Extensive experimental evaluations demonstrate that FIR assists machine learning models to obtain superior results compared to original features. The research gap is addressed using combined features to improve the performance of epileptic seizure detection compared to a single feature set. In particular, the ensemble model FIR with support vector machine (FIR + SVM) outperforms other methods, achieving an accuracy of 98.4% for epileptic seizure detection. The proposed FIR has the potential for early diagnosis of epileptic seizures and can significantly help the medical industry with enhanced detection and timely interventions.",https://pubmed.ncbi.nlm.nih.gov/39502490/,https://pubmed.ncbi.nlm.nih.gov/39502490/,English,Include,,Diagnosing epileptic seizures using combined features from independent components and prediction probability from EEG data.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39500053,pubmed:39500053,PubMed,pubmed:39500053,Patient-specific visual neglect severity estimation for stroke patients with neglect using EEG.,Deniz Kocanaogullari;Richard Gall;Jennifer Mak;Xiaofei Huang;Katie Mullen;Sarah Ostadabbas;George F Wittenberg;Emily S Grattan;Murat Akcakaya,2024,10.1088/1741-2552/ad8efc,,,https://pubmed.ncbi.nlm.nih.gov/39500053/,English,Exclude,Not classification-focused,Patient-specific visual neglect severity estimation for stroke patients with neglect using EEG.,,,,,0.85,0.6,
pubmed:39500051,pubmed:39500051,PubMed,pubmed:39500051,"Leveraging textured flickers: a leap toward practical, visually comfortable, and high-performance dry EEG code-VEP BCI.",Frédéric Dehais;Kalou Cabrera Castillos;Simon Ladouce;Pierre Clisson,2024,10.1088/1741-2552/ad8ef7,,,https://pubmed.ncbi.nlm.nih.gov/39500051/,English,Exclude,Not classification-focused,"Leveraging textured flickers: a leap toward practical, visually comfortable, and high-performance dry EEG code-VEP BCI.",,,,,0.85,0.6,
pubmed:39500044,pubmed:39500044,PubMed,pubmed:39500044,Estimating cognitive workload using a commercial in-ear EEG headset.,Christoph Tremmel;Dean J Krusienski;Mc Schraefel,2024,10.1088/1741-2552/ad8ef8,,,https://pubmed.ncbi.nlm.nih.gov/39500044/,English,Exclude,Not classification-focused,Estimating cognitive workload using a commercial in-ear EEG headset.,,,,,0.85,0.6,
pubmed:39499403,pubmed:39499403,PubMed,pubmed:39499403,Unveiling Frequency-Specific Microstate Correlates of Anxiety and Depression Symptoms.,Siyang Xue;Xinke Shen;Dan Zhang;Zhenhua Sang;Qiting Long;Sen Song;Jian Wu,2024,10.1016/j.jpsychires.2023.07.021,"Electroencephalography (EEG) microstates are canonical voltage topographies that reflect the temporal dynamics of brain networks on a millisecond time scale. Abnormalities in broadband microstate parameters have been observed in subjects with psychiatric symptoms, indicating their potential as clinical biomarkers. Considering distinct information provided by specific frequency bands of EEG, we hypothesized that microstates in decomposed frequency bands could provide a more detailed depiction of the underlying neuropathological mechanism. In this study, with a large open access resting-state dataset (n = 203), we examined the properties of frequency-specific microstates and their relationship with anxiety and depression symptoms. We conducted clustering on EEG topographies in decomposed frequency bands (delta, theta, alpha and beta), and determined the number of clusters with a meta-criterion. Microstate parameters, including global explained variance (GEV), duration, coverage, occurrence and transition probability, were calculated for eyes-open and eyes-closed states, respectively. Their ability to predict the severity of depression and anxiety symptoms were systematically identified by correlation, regression and classification analyses. Distinct microstate patterns were observed across different frequency bands. Microstate parameters in the alpha band held the best predictive power for emotional symptoms. Microstates B (GEV, coverage) and parieto-central maximum microstate E (coverage, occurrence, transitions from B to E) in the alpha band exhibited significant correlations with depression and anxiety, respectively. Microstate parameters of the alpha band achieved predictive R-square of 0.100 for anxiety scores, which is much higher than those of broadband (R-square = -0.026, p < 0.01). Similar results were found in classification of participants with high and low anxiety symptom scores (68% accuracy in alpha vs. 52% in broadband). These results suggested the value of frequency-specific microstates in predicting emotional symptoms.",https://pubmed.ncbi.nlm.nih.gov/39499403/,https://pubmed.ncbi.nlm.nih.gov/39499403/,English,Include,,Unveiling Frequency-Specific Microstate Correlates of Anxiety and Depression Symptoms.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39497149,pubmed:39497149,PubMed,pubmed:39497149,Exploring easily accessible neurophysiological biomarkers for predicting Alzheimer's disease progression: a systematic review.,Matteo Costanzo;Carolina Cutrona;Giorgio Leodori;Leonardo Malimpensa;Fabrizia D'antonio;Antonella Conte;Daniele Belvisi,2024,10.1186/s13195-024-01607-4,"Alzheimer disease (AD) remains a significant global health concern. The progression from preclinical stages to overt dementia has become a crucial point of interest for researchers. This paper reviews the potential of neurophysiological biomarkers in predicting AD progression, based on a systematic literature search following PRISMA guidelines, including 55 studies. EEG-based techniques have been predominantly employed, whereas TMS studies are less common. Among the investigated neurophysiological measures, spectral power measurements and event-related potentials-based measures, including P300 and N200 latencies, have emerged as the most consistent and reliable biomarkers for predicting the likelihood of conversion to AD. In addition, TMS-based indices of cortical excitability and synaptic plasticity have also shown potential in assessing the risk of conversion to AD. However, concerns persist regarding the methodological discrepancies among studies, the accuracy of these neurophysiological measures in comparison to established AD biomarkers, and their immediate clinical applicability. Further research is needed to validate the predictive capabilities of EEG and TMS measures. Advancements in this area could lead to cost-effective, reliable biomarkers, enhancing diagnostic processes and deepening our understanding of AD pathophysiology.",,https://pubmed.ncbi.nlm.nih.gov/39497149/,English,Exclude,Review/survey papers,Exploring easily accessible neurophysiological biomarkers for predicting Alzheimer's disease progression: a systematic review.,,,,,0.95,0.6,
pubmed:39496779,pubmed:39496779,PubMed,pubmed:39496779,TATPat based explainable EEG model for neonatal seizure detection.,Turker Tuncer;Sengul Dogan;Irem Tasci;Burak Tasci;Rena Hajiyeva,2024,10.1038/s41598-024-77609-x,"The most cost-effective data collection method is electroencephalography (EEG) to obtain meaningful information about the brain. Therefore, EEG signal processing is very important for neuroscience and machine learning (ML). The primary objective of this research is to detect neonatal seizures and explain these seizures using the new version of Directed Lobish. This research uses a publicly available neonatal EEG signal dataset to get comparative results. In order to classify these EEG signals, an explainable feature engineering (EFE) model has been proposed. In this EFE model, there are four essential phases and these phases: (i) automaton and transformer-based feature extraction, (ii) feature selection deploying cumulative weight-based neighborhood component analysis (CWNCA), (iii) the Directed Lobish (DLob) and Causal Connectome Theory (CCT)-based explainable result generation and (iv) classification deploying t algorithm-based support vector machine (tSVM). In the first phase, we have used a channel transformer to get channel numbers and these values have been divided into three levels and these levels are named (1) high, (2) medium and (3) low. By utilizing these levels, we have created an automaton and this automaton has three nodes (each node defines each level). In the feature extraction phase, transition tables of these nodes has been extracted. Therefore, the proposed feature extraction function is termed Triple Nodes Automaton-based Transition table Pattern (TATPat). The used EEG signal dataset contains 19 channels and there are 9 (= 3",https://pubmed.ncbi.nlm.nih.gov/39496779/,https://pubmed.ncbi.nlm.nih.gov/39496779/,English,Include,,TATPat based explainable EEG model for neonatal seizure detection.,Include,,"The most cost-effective data collection method is electroencephalography (EEG) to obtain meaningful information about the brain. Therefore, EEG signal processing is very important for neuroscience and machine learning (ML). The primary objective of this research is to detect neonatal seizures and explain these seizures using the new version of Direct",,0.95,0.6,
pubmed:39496663,pubmed:39496663,PubMed,pubmed:39496663,Design of EEG based thought identification system using EMD & deep neural network.,Rahul Agrawal;Chetan Dhule;Garima Shukla;Sofia Singh;Urvashi Agrawal;Najah Alsubaie;Mohammed S Alqahtani;Mohamed Abbas;Ben Othman Soufiene,2024,10.1038/s41598-024-64961-1,"Biological communication system for neurological disorder patients is similar to the Brain Computer Interface in a way that it facilitates the connection to the outside world in real time. The interdisciplinary field of Electroencephalogram based message depiction is gaining importance as it assists the paralysed person to communicate. In the proposed method a novel approach of feature extraction is done by Empirical Mode Decomposition on non- stationary & non-linear kind of EEG signal. EMD helps in the effective time frequency analysis by disintegrating the EEG signal in the form of six Intrinsic Mode Functions with help of the frequency components. In all nine features are extracted from the decomposed IMFs so as to predict the states or messages of the patient. The above computed features are then served to the Deep Neural Network to perform the classification. The performance of suggested method is studied through applying it to the acquired database generated by the designed hardware as well as also in real time message depiction. The maximum classification accuracy 97% for the acquired database & 85% in real time are obtained respectively by comparative analysis. The command messages generated from the proposed system helps the person suffering from neurological disorder to establish the communication link with the outside world in an efficient way. Thus, the proposed novel method shows better performance in real time message depiction purpose as related to other existing methods.",https://pubmed.ncbi.nlm.nih.gov/39496663/,https://pubmed.ncbi.nlm.nih.gov/39496663/,English,Include,,Design of EEG based thought identification system using EMD & deep neural network.,Include,,e performance of suggested method is studied through applying it to the acquired database generated by the designed hardware as well as also in real time message depiction. The maximum classification accuracy 97% for the acquired database & 85% in real time are obtained respectively by comparative analysis. The command messages generated from the proposed system helps the person suffering from neu,,0.95,0.6,
pubmed:39496200,pubmed:39496200,PubMed,pubmed:39496200,Temporal attention fusion network with custom loss function for EEG-fNIRS classification.,Chayut Bunterngchit;Jiaxing Wang;Jianqiang Su;Yihan Wang;Shiqi Liu;Zeng-Guang Hou,2024,10.1088/1741-2552/ad8e86,,https://pubmed.ncbi.nlm.nih.gov/39496200/,https://pubmed.ncbi.nlm.nih.gov/39496200/,English,Include,,Temporal attention fusion network with custom loss function for EEG-fNIRS classification.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39495693,pubmed:39495693,PubMed,pubmed:39495693,AFSleepNet: Attention-Based Multi-View Feature Fusion Framework for Pediatric Sleep Staging.,Yunfeng Zhu;Yunxiao Wu;Zhiya Wang;Ligang Zhou;Chen Chen;Zhifei Xu;Wei Chen,2024,10.1109/tnsre.2024.3490757,"The widespread prevalence of sleep problems in children highlights the importance of timely and accurate sleep staging in the diagnosis and treatment of pediatric sleep disorders. However, most existing sleep staging methods rely on one-dimensional raw polysomnograms or two-dimensional spectrograms, which omit critical details due to single-view processing. This shortcoming is particularly apparent in pediatric sleep staging, where the lack of a specialized network fails to meet the needs of precision medicine. Therefore, we introduce AFSleepNet, a novel attention-based multi-view feature fusion network tailored for pediatric sleep analysis. The model utilizes multimodal data (EEG, EOG, EMG), combining one-dimensional convolutional neural networks to extract time-invariant features and bidirectional-long-short-term memory to learn the transition rules among sleep stages, as well as employing short-time Fourier transform to generate two-dimensional spectral maps. This network employs a fusion method with self-attention mechanism and innovative pre-training strategy. This strategy can maintain the feature extraction capabilities of AFSleepNet from different views, enhancing the robustness of the multi-view model while effectively preventing model overfitting, thereby achieving efficient and accurate automatic sleep stage analysis. A ""leave-one-subject-out"" cross-validation on CHAT and clinical datasets demonstrated the excellent performance of AFSleepNet, with mean accuracies of 87.5% and 88.1%, respectively. Superiority over existing methods improves the accuracy and reliability of pediatric sleep staging.",https://pubmed.ncbi.nlm.nih.gov/39495693/,https://pubmed.ncbi.nlm.nih.gov/39495693/,English,Include,,AFSleepNet: Attention-Based Multi-View Feature Fusion Framework for Pediatric Sleep Staging.,Include,,"ss-validation on CHAT and clinical datasets demonstrated the excellent performance of AFSleepNet, with mean accuracies of 87.5% and 88.1%, respectively. Superiority over existing methods improves the accuracy and reliability of pediatric sleep staging.",,0.95,0.45,cv_reported;overfit_terms_found
pubmed:39490945,pubmed:39490945,PubMed,pubmed:39490945,Motor task-to-task transfer learning for motor imagery brain-computer interfaces.,Daeun Gwon;Minkyu Ahn,2024,10.1016/j.neuroimage.2024.120906,"Motor imagery (MI) is one of the popular control paradigms in the non-invasive brain-computer interface (BCI) field. MI-BCI generally requires users to conduct the imagination of movement (e.g., left or right hand) to collect training data for generating a classification model during the calibration phase. However, this calibration phase is generally time-consuming and tedious, as users conduct the imagination of hand movement several times without being given feedback for an extended period. This obstacle makes MI-BCI non user-friendly and hinders its use. On the other hand, motor execution (ME) and motor observation (MO) are relatively easier tasks, yield lower fatigue than MI, and share similar neural mechanisms to MI. However, few studies have integrated these three tasks into BCIs. In this study, we propose a new task-to-task transfer learning approach of 3-motor tasks (ME, MO, and MI) for building a better user-friendly MI-BCI. For this study, 28 subjects participated in 3-motor tasks experiment, and electroencephalography (EEG) was acquired. User opinions regarding the 3-motor tasks were also collected through questionnaire survey. The 3-motor tasks showed a power decrease in the alpha rhythm, known as event-related desynchronization, but with slight differences in the temporal patterns. In the classification analysis, the cross-validated accuracy (within-task) was 67.05 % for ME, 65.93 % for MI, and 73.16 % for MO on average. Consistently with the results, the subjects scored MI (3.16) as the most difficult task compared with MO (1.42) and ME (1.41), with p < 0.05. In the analysis of task-to-task transfer learning, where training and testing are performed using different task datasets, the ME-trained model yielded an accuracy of 65.93 % (MI test), which is statistically similar to the within-task accuracy (p > 0.05). The MO-trained model achieved an accuracy of 60.82 % (MI test). On the other hand, combining two datasets yielded interesting results. ME and 50 % of the MI-trained model (50-shot) classified MI with a 69.21 % accuracy, which outperformed the within-task accuracy (p < 0.05), and MO and 50 % of the MI-trained model showed an accuracy of 66.75 %. Of the low performers with a within-task accuracy of 70 % or less, 90 % (n = 21) of the subjects improved in training with ME, and 76.2 % (n = 16) improved in training with MO on the MI test at 50-shot. These results demonstrate that task-to-task transfer learning is possible and could be a promising approach to building a user-friendly training protocol in MI-BCI.",,https://pubmed.ncbi.nlm.nih.gov/39490945/,English,Exclude,Review/survey papers,Motor task-to-task transfer learning for motor imagery brain-computer interfaces.,,,,,0.95,0.6,
pubmed:39484299,pubmed:39484299,PubMed,pubmed:39484299,Wearable EEG-Based Brain-Computer Interface for Stress Monitoring.,Brian Premchand;Liyuan Liang;Kok Soon Phua;Zhuo Zhang;Chuanchu Wang;Ling Guo;Jennifer Ang;Juliana Koh;Xueyi Yong;Kai Keng Ang,2024,10.3389/frai.2022.1072801,"Detecting stress is important for improving human health and potential, because moderate levels of stress may motivate people towards better performance at cognitive tasks, while chronic stress exposure causes impaired performance and health risks. We propose a Brain-Computer Interface (BCI) system to detect stress in the context of high-pressure work environments. The BCI system includes an electroencephalogram (EEG) headband with dry electrodes and an electrocardiogram (ECG) chest belt. We collected EEG and ECG data from 40 participants during two stressful cognitive tasks: the Cognitive Vigilance Task (CVT), and the Multi-Modal Integration Task (MMIT) we designed. We also recorded self-reported stress levels using the Dundee Stress State Questionnaire (DSSQ). The DSSQ results indicated that performing the MMIT led to significant increases in stress, while performing the CVT did not. Subsequently, we trained two different models to classify stress from non-stress states, one using EEG features, and the other using heart rate variability (HRV) features extracted from the ECG. Our EEG-based model achieved an overall accuracy of 81.0% for MMIT and 77.2% for CVT. However, our HRV-based model only achieved 62.1% accuracy for CVT and 56.0% for MMIT. We conclude that EEG is an effective predictor of stress in the context of stressful cognitive tasks. Our proposed BCI system shows promise in evaluating mental stress in high-pressure work environments, particularly when utilizing an EEG-based BCI.",https://pubmed.ncbi.nlm.nih.gov/39484299/,https://pubmed.ncbi.nlm.nih.gov/39484299/,English,Include,,Wearable EEG-Based Brain-Computer Interface for Stress Monitoring.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39483809,pubmed:39483809,PubMed,pubmed:39483809,Novel ML-Based Algorithm for Detecting Seizures from Single-Channel EEG.,Yazan M Dweiri;Taqwa K Al-Omary,2024,10.1016/j.spen.2008.03.007,"There is a need for seizure classification based on EEG signals that can be implemented with a portable device for in-home continuous minoring of epilepsy. In this study, we developed a novel machine learning algorithm for seizure detection suitable for wearable systems. Extreme gradient boosting (XGBoost) was implemented to classify seizures from single-channel EEG obtained from an open-source CHB-MIT database. The results of classifying 1-s EEG segments are shown to be sufficient to obtain the information needed for seizure detection and achieve a high seizure sensitivity of up to 89% with low computational cost. This algorithm can be impeded in single-channel EEG systems that use in- or around-the-ear electrodes for continuous seizure monitoring at home.",https://pubmed.ncbi.nlm.nih.gov/39483809/,https://pubmed.ncbi.nlm.nih.gov/39483809/,English,Include,,Novel ML-Based Algorithm for Detecting Seizures from Single-Channel EEG.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39483735,pubmed:39483735,PubMed,pubmed:39483735,Prediction of pharmacological treatment efficacy using electroencephalography-based salience network in patients with major depressive disorder.,Kang-Min Choi;Taegyeong Lee;Chang-Hwan Im;Seung-Hwan Lee,2024,10.1038/npp.2017.103,"Recent resting-state electroencephalogram (EEG) studies have consistently reported an association between aberrant functional brain networks (FBNs) and treatment-resistant traits in patients with major depressive disorder (MDD). However, little is known about the changes in FBNs in response to external stimuli in these patients. This study investigates whether changes in the salience network (SN) could predict responsiveness to pharmacological treatment in resting-state and external stimuli conditions. Thirty-one drug-naïve patients with MDD (aged 46.61 ± 10.05, female 28) and twenty-one healthy controls (aged 43.86 ± 14.14, female 19) participated in the study. After 8 weeks of pharmacological treatment, the patients were divided into non-remitted MDD (nrMDD, n = 14) and remitted-MDD (rMDD, n = 17) groups. EEG data under three conditions (resting-state, standard, and deviant) were analyzed. The SN was constructed with three cortical regions as nodes and weighted phase-lag index as edges, across alpha, low-beta, high-beta, and gamma bands. A repeated measures analysis of the variance model was used to examine the group-by-condition interaction. Machine learning-based classification analyses were also conducted between the nrMDD and rMDD groups. A notable group-by-condition interaction was observed in the high-beta band between nrMDD and rMDD. Specifically, patients with nrMDD exhibited hypoconnectivity between the dorsal anterior cingulate cortex and right insula (p = 0.030). The classification analysis yielded a maximum classification accuracy of 80.65%. Our study suggests that abnormal condition-dependent changes in the SN could serve as potential predictors of pharmacological treatment efficacy in patients with MDD.",https://pubmed.ncbi.nlm.nih.gov/39483735/,https://pubmed.ncbi.nlm.nih.gov/39483735/,English,Include,,Prediction of pharmacological treatment efficacy using electroencephalography-based salience network in patients with major depressive disorder.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39483710,pubmed:39483710,PubMed,pubmed:39483710,Support vector machine classification of patients with depression based on resting-state electroencephalography.,Chia-Yen Yang;Yin-Zhen Chen,2024,10.3389/fpsyt.2021.629870,"Depression is one of the most common mental disorders. Although depression is typically diagnosed by identifying specific symptoms and through history, no recognized standard for depression diagnosis exists. This assures the development of objective diagnostic tools for depression. We investigated the differences in the resting-state electroencephalograms (EEGs) of patients with depression and healthy controls (HCs) to distinguish patients from HCs by using a support vector machine (SVM) classifier with the following two feature selection approaches: t test and receiver operating characteristic analysis. We used the EEG data from the Patient Repository of EEG Data + Computational Tools; this study included 21 patients with depressive disorder (MDD) and 21 HCs. The relative frequency power, alpha interhemispheric asymmetry, left-right coherence, strength, clustering coefficient (CC), shortest path length, sample entropy (SampEn), multiscale entropy (MSE), and detrended fluctuation analysis (DFA) data were extracted to determine candidate EEG features associated with depression. With the t-test selection, the SVM classifier demonstrated the highest performance with the accuracy, sensitivity, and specificity of 96.66%, 95.93%, and 97.550% for the eye-open condition and 91.33%, 90.59%, and 91.81% for the eye-closed condition, respectively. For comparisons of features in the 2 selection approaches, the most influential features were relative frequency power and left-right coherence. Using this information to distinguish patients with MDD from HC subjects with the SVM classifier resulted in a mean accuracy over 90%. Although this result may not be robust enough for clinical applications, further exploration is necessary given the simplicity, objectivity, and efficiency of the classifier.",https://pubmed.ncbi.nlm.nih.gov/39483710/,https://pubmed.ncbi.nlm.nih.gov/39483710/,English,Include,,Support vector machine classification of patients with depression based on resting-state electroencephalography.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39483493,pubmed:39483493,PubMed,pubmed:39483493,Influence of Temporal and Frequency Selective Patterns Combined with CSP Layers on Performance in Exoskeleton-Assisted Motor Imagery Tasks.,Cristian David Guerrero-Mendez;Cristian Felipe Blanco-Diaz;Hamilton Rivera-Flor;Pedro Henrique Fabriz-Ulhoa;Eduardo Antonio Fragoso-Dias;Rafhael Milanezi de Andrade;Denis Delisle-Rodriguez;Teodiano Freire Bastos-Filho,2024,10.1109/tbme.2015.2467312,"Common Spatial Pattern (CSP) has been recognized as a standard and powerful method for the identification of Electroencephalography (EEG)-based Motor Imagery (MI) tasks when implementing brain-computer interface (BCI) systems towards the motor rehabilitation of lost movements. The combination of BCI systems with robotic systems, such as upper limb exoskeletons, has proven to be a reliable tool for neuromotor rehabilitation. Therefore, in this study, the effects of temporal and frequency segmentation combined with layer increase for spatial filtering were evaluated, using three variations of the CSP method for the identification of passive movement vs. MI+passive movement. The passive movements were generated using a left upper-limb exoskeleton to assist flexion/extension tasks at two speeds (high-85 rpm and low-30 rpm). Ten healthy subjects were evaluated in two recording sessions using Linear Discriminant Analysis (LDA) as a classifier, and accuracy (ACC) and False Positive Rate (FPR) as metrics. The results allow concluding that the use of temporal, frequency or spatial selective information does not significantly ( ",https://pubmed.ncbi.nlm.nih.gov/39483493/,https://pubmed.ncbi.nlm.nih.gov/39483493/,English,Include,,Influence of Temporal and Frequency Selective Patterns Combined with CSP Layers on Performance in Exoskeleton-Assisted Motor Imagery Tasks.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39483271,pubmed:39483271,PubMed,pubmed:39483271,Single-Molecule Bioelectronic Sensors with AI-Aided Data Analysis: Convergence and Challenges.,Yuxin Yang;Yueqi Li;Longhua Tang;Jinghong Li,2024,10.1063/1.4964414,"Single-molecule bioelectronic sensing, a groundbreaking domain in biological research, has revolutionized our understanding of molecules by revealing deep insights into fundamental biological processes. The advent of emergent technologies, such as nanogapped electrodes and nanopores, has greatly enhanced this field, providing exceptional sensitivity, resolution, and integration capabilities. However, challenges persist, such as complex data sets with high noise levels and stochastic molecular dynamics. Artificial intelligence (AI) has stepped in to address these issues with its powerful data processing capabilities. AI algorithms effectively extract meaningful features, detect subtle changes, improve signal-to-noise ratios, and uncover hidden patterns in massive data. This review explores the synergy between AI and single-molecule bioelectronic sensing, focusing on how AI enhances signal processing and data analysis to boost accuracy and reliability. We also discuss current limitations and future directions for integrating AI, highlighting its potential to advance biological research and technological innovation.",,https://pubmed.ncbi.nlm.nih.gov/39483271/,English,Exclude,Review/survey papers,Single-Molecule Bioelectronic Sensors with AI-Aided Data Analysis: Convergence and Challenges.,,,,,0.95,0.6,
pubmed:39483194,pubmed:39483194,PubMed,pubmed:39483194,Understanding emotional influences on sustained attention: a study using virtual reality and neurophysiological monitoring.,Yang Shen;Huijia Zheng;Yu Li;Xuetao Tian,2024,10.1037/dev0001200,"Emotion and attention regulation significantly influence various aspects of human functioning and behavior. However, the interaction between emotion and attention in affecting performance remains underexplored. This study aims to investigate how individual differences in sustained attention, influenced by varying emotional states. A total of 12 participants underwent emotion induction through Virtual Reality (VR) videos; completed an AX-CPT (continuous performance test) task to measure sustained attention, for which task performance is evaluated from two aspects, task accuracy and task reaction times; and reported their flow states. EEG and PPG data were collected throughout the sessions, as supporting evidence for sustained attention. Our findings suggest that emotional valence and arousal significantly influence task reaction times and sustained attention, when gender differences are accounted for, but do not significantly impact task accuracy. Specifically, males responded faster under high-arousal negative emotions, while females responded faster under high-arousal positive emotions. Additionally, we find that flow experience is not significantly impacted by emotions states or sustained attention. The study underscores the nuanced interplay between emotion, sustained attention, and task performance, suggesting that emotional states can differentially impact cognitive processes. Also, it support the use of VR, EEG, and PPG technologies in future research on related topics. Future research could expand upon this study by including larger sample sizes and a wider range of emotional inductions to generalize the findings.",https://pubmed.ncbi.nlm.nih.gov/39483194/,https://pubmed.ncbi.nlm.nih.gov/39483194/,English,Include,,Understanding emotional influences on sustained attention: a study using virtual reality and neurophysiological monitoring.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39488110,pubmed:39488110,PubMed,pubmed:39488110,Support matrix machine: A review.,Anuradha Kumari;Mushir Akhtar;Rupal Shah;M Tanveer,2025,10.1016/j.neunet.2024.106767,"Support vector machine (SVM) is one of the most studied paradigms in the realm of machine learning for classification and regression problems. It relies on vectorized input data. However, a significant portion of the real-world data exists in matrix format, which is given as input to SVM by reshaping the matrices into vectors. The process of reshaping disrupts the spatial correlations inherent in the matrix data. Also, converting matrices into vectors results in input data with a high dimensionality, which introduces significant computational complexity. To overcome these issues in classifying matrix input data, support matrix machine (SMM) is proposed. It represents one of the emerging methodologies tailored for handling matrix input data. SMM preserves the structural information of the matrix data by using the spectral elastic net property which is a combination of the nuclear norm and Frobenius norm. This article provides the first in-depth analysis of the development of the SMM model, which can be used as a thorough summary by both novices and experts. We discuss numerous SMM variants, such as robust, sparse, class-imbalance, and multi-class classification models. We also analyze the applications of the SMM and conclude the article by outlining potential future research avenues and possibilities that may motivate researchers to advance the SMM algorithm.",,https://pubmed.ncbi.nlm.nih.gov/39488110/,English,Exclude,Outside date range,Support matrix machine: A review.,,,,,0.95,0.6,
pubmed:39488107,pubmed:39488107,PubMed,pubmed:39488107,CNN-Informer: A hybrid deep learning model for seizure detection on long-term EEG.,Chuanyu Li;Haotian Li;Xingchen Dong;Xiangwen Zhong;Haozhou Cui;Dezan Ji;Landi He;Guoyang Liu;Weidong Zhou,2025,10.1016/j.neunet.2024.106855,"Timely detecting epileptic seizures can significantly reduce accidental injuries of epilepsy patients and offer a novel intervention approach to improve their quality of life. Investigation on seizure detection based on deep learning models has achieved great success. However, there still remain challenging issues, such as the high computational complexity of the models and overfitting caused by the scarce availability of ictal electroencephalogram (EEG) signals for training. Therefore, we propose a novel end-to-end automatic seizure detection model named CNN-Informer, which leverages the capability of Convolutional Neural Network (CNN) to extract EEG local features of multi-channel EEGs, and the low computational complexity and memory usage ability of the Informer to capture the long-range dependencies. In view of the existence of various artifacts in long-term EEGs, we filter those raw EEGs using Discrete Wavelet Transform (DWT) before feeding them into the proposed CNN-Informer model for feature extraction and classification. Post-processing operations are further employed to achieve the final detection results. Our method is extensively evaluated on the CHB-MIT dataset and SH-SDU dataset with both segment-based and event-based criteria. The experimental outcomes demonstrate the superiority of the proposed CNN-Informer model and its strong generalization ability across two EEG datasets. In addition, the lightweight architecture of CNN-Informer makes it suitable for real-time implementation.",,https://pubmed.ncbi.nlm.nih.gov/39488107/,English,Exclude,Outside date range,CNN-Informer: A hybrid deep learning model for seizure detection on long-term EEG.,,,,,0.95,0.8,overfit_terms_found
pubmed:39488104,pubmed:39488104,PubMed,pubmed:39488104,Intensive treatment course to identify pseudoresistant epilepsy and expedite surgery referrals - A prospective intervention study.,Line Harboe;Ole Abildgaard Hansen;Maria Kjerside Døssing;Marianne Juel Kjeldsen;Christoph Patrick Beier,2024,10.1016/j.seizure.2024.10.008,"A significant proportion of patients do not achieve seizure freedom despite treatment attempts with two different anti-seizure medications (ASMs). A subset may not truly have drug-resistant epilepsy (""pseudoresistant""), while rapid referral of patients with genuine drug-resistant epilepsy to surgery is mandated. This study was designed to evaluate a structured and intensive treatment course with the objective of promptly identifying cases of pseudoresistance and accelerating the time to referral to epilepsy surgery. From May 2017 to February 2021, this prospective interventional study recruited consecutive adult patients with epilepsy treated at Odense University Hospital, Denmark, who had at least one seizure per month despite attempts with two or more ASMs. The predefined endpoint was improvement in seizure activity. Secondary endpoints were referral to epilepsy surgery, patients with pseudoresistance, and achievement of seizure freedom. Of the 41 patients enrolled, 39 completed the study. The intervention comprised a initial seizure documentation, specialist evaluation, EEG monitoring as required, and an individualized plan for intensive treatment. The plans included e.g., optimization of medical treatment, seizure classification, and improvement of medication adherence. The subsequent intensive treatment (1-4 contacts/month; 1-13 contacts in total) was led by epilepsy nurses that executed the treatment plan. The intervention significantly improved seizure control, with 41.1 % of patients achieving seizure freedom and an additional 17.8 % of patients experiencing reduced seizure frequency. One-third of the patients turned out to be ""pseudoresistant"" due to various reasons, including wrong classification of seizures and inadequate adherence to ASMs. Ten patients were offered a referral for epilepsy surgery at the end of the study after an average of 34.8 weeks. This study demonstrates the efficacy of a standardized, intensive treatment course involving epilepsy nurses in identifying and managing patients with persisting seizures despite treatment attempts with two ASMs. This approach led to favourable seizure outcomes and facilitated expedited referrals for epilepsy surgery where appropriate.",https://pubmed.ncbi.nlm.nih.gov/39488104/,https://pubmed.ncbi.nlm.nih.gov/39488104/,English,Include,,Intensive treatment course to identify pseudoresistant epilepsy and expedite surgery referrals - A prospective intervention study.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39488095,pubmed:39488095,PubMed,pubmed:39488095,Tonic and tonic-clonic seizures in the first year of life: Insights from electrographic features.,Marta Conti;Mattia Mercier;Domenico Serino;Ludovica M Piscitello;Marta E Santarone;Federico Vigevano;Nicola Specchio;Lucia Fusco,2024,10.1016/j.yebeh.2024.110120,"We studied the electrographic features of tonic seizures (TS) with bilateral contraction and tonic-clonic seizures (TCS) without focal signs occurring during the first year of life to evaluate if there is a correlation with outcome. We retrospectively reviewed patients aged 1 to 12 months with at least one TS or TCS recorded with video-EEG between 2011 and 2021 in our Epilepsy Monitoring Unit. We analyzed the following electrographic features: seizure duration, presence and duration of focal ictal EEG onset, and post-ictal generalized EEG suppression (PGES). Among clinical variables, we collected age at epilepsy onset, age at TS and TCS recording, response to anti-seizure medications, genetic and neuroimaging findings, epileptic syndrome classification. Overall, we recorded 2577 seizures in 1769 patients. One-hundred-twenty-eight seizures (5%) were clinically labeled either as TS or TCS in 41 patients (2%). Out of 41 patients, 17 (41%) presented with TS, and 24 (59%) with TCS. Thirteen patients (32%) had a Self-limited Epilepsy, and 28 (68%) a Developmental and Epileptic Encephalopathy (DEE). Seventy-two percent of genetically tested patients had pathogenic gene variants. None had structural epilepsy. Mean age at epilepsy onset was 4.48 months (range 3 days-12 months). Age at seizure onset was earlier in patients presenting with TS versus patients presenting with TCS (2.31 months vs. 6.01 months; p = 0.001) and in DEEs versus Self-limited Epilepsies (3.23 months vs. 7.16 months; p = 0.001). TS were exclusively present in DEEs (p = 0.001), and TCS were recorded in both DEEs and Self-limited Epilepsies. Focal ictal EEG onset was evident in 92 % of TCS, and in none of TS. Generalized ictal EEG onset was documented in 100 % of TS, and in 8 % of TCS. Focal ictal EEG onset occurred more frequently (100 % vs. 32 %; p = 0.000) and was significantly longer (30.61 s vs. 16.22 s; p = 0.020) in Self-limited Epilepsies versus DEEs. PGES was observed in 18 out of 41 (44 %) and was more frequent in Self-limited Epilepsies (p = 0.026). This study provides insights into the electroclinical features of TS and TCS in infants that may help distinguish Self-limited Epilepsies from DEEs soon after epilepsy onset.",,https://pubmed.ncbi.nlm.nih.gov/39488095/,English,Exclude,Review/survey papers,Tonic and tonic-clonic seizures in the first year of life: Insights from electrographic features.,,,,,0.95,0.6,
pubmed:39487958,pubmed:39487958,PubMed,pubmed:39487958,Direct visualization of microwires in hybrid depth electrodes using high-resolution photon-counting CT.,Steven Smeijers;Walter Coudyzer;Elina Keirse;Vasiliki Bougou;Thomas Decramer;Tom Theys,2024,10.1016/j.brs.2023.08.015,"Hybrid depth electrodes are increasingly being used for epilepsy monitoring and human neurophysiology research. Microwires extending from the tip of the Behnke-Fried (BF) electrode into (sub)cortical areas allow to isolate single neurons and perform microstimulation. Conventional CT or MRI visualize the entire microwire bundle as an artifact extending from the BF electrode tip with low resolution, without proper identification of individual microwires. We illustrate the first direct visualization method of individual microwires using high-resolution photon-counting CT (PCCT). Coregistration of the PCCT scan with a preoperative MRI can visualize individual wires directly in cortex, which is an advantage as it provides feedback on the accuracy of the implantation method and can guide future implantations. This PCCT technique allows for accurately depicting individual microwires which could be relevant for neuroscientific research through improved visualization and implantation of specific cortical and subcortical brain areas. PLAIN LANGUAGE SUMMARY: Researchers are using hybrid depth electrodes to study epilepsy and brain activity. These electrodes, called Behnke-Fried (BF) electrodes, have microwires at the tip that can record single neurons and stimulate brain areas. Regular CT or MRI scans do not show the individual microwires clearly. The authors use a new high-resolution photon-counting CT (PCCT) technique, which can show each individual microwire in the brain. By combining PCCT with MRI, the authors can precisely see where the microwires are located. This could improve future implantation surgeries and brain research.",,https://pubmed.ncbi.nlm.nih.gov/39487958/,English,Exclude,Not EEG-BCI focused,Direct visualization of microwires in hybrid depth electrodes using high-resolution photon-counting CT.,,,,,0.9,0.6,
pubmed:39480866,pubmed:39480866,PubMed,pubmed:39480866,Heart rate variability analysis for the prediction of pre-arousal during propofol-remifentanil general anaesthesia: A feasibility study.,Anne Wojtanowski;Maxence Hureau;Camille Ternynck;Benoit Tavernier;Mathieu Jeanne;Julien de Jonckheere,2024,10.3389/fpubh.2017.00258,"Accidental awareness during general anaesthesia is a major complication. Despite the routine use of continuous electroencephalographic monitoring, accidental awareness during general anaesthesia remains relatively frequent and constitutes a significant additional cost. The prediction of patients' arousal during general anaesthesia could help preventing accidental awareness and some researchers have suggested that heart rate variability (HRV) analysis contains valuable information about the patient arousal during general anaesthesia. We conducted pilot study to investigate HRV ability to detect patient arousal. RR series and the Bispectral IndexTM (BISTM) were recorded during general anaesthesia. The pre-arousal period T0 was defined as the time at which the BISTM exceeded 60 at the end of surgery. HRV parameters were computed over several time periods before and after T0 and classified as ""BISTM<60"" or ""BISTM≥60"". A multivariate logistic regression model and a classification and regression tree algorithm were used to evaluate the HRV variables' ability to detect ""BISTM≥60"". All the models gave high specificity but poor sensitivity. Excluding T0 from the classification increased the sensitivity for all the models and gave AUCROC>0.7. In conclusion, we found that HRV analysis provided encouraging results to predict arousal at the end of general anaesthesia.",,https://pubmed.ncbi.nlm.nih.gov/39480866/,English,Exclude,Not EEG-BCI focused,Heart rate variability analysis for the prediction of pre-arousal during propofol-remifentanil general anaesthesia: A feasibility study.,,,,,0.9,0.6,
pubmed:39486757,pubmed:39486757,PubMed,pubmed:39486757,Working memory load increases movement-related alpha and beta desynchronization.,Aoki Takahashi;Shugo Iuchi;Taisei Sasaki;Yuhei Hashimoto;Riku Ishizaka;Kodai Minami;Tatsunori Watanabe,2024,10.1016/j.neuropsychologia.2024.109030,"Working memory (WM) load has been well-documented to impair selective attention and inhibitory control. However, its effects on motor function remain insufficiently explored. To extend the existing literature, we investigated the impact of WM load on force control and movement-related brain activity. Sixteen healthy young participants performed a visual static force matching task using a pinch grip under varying WM loads. The task included low and high WM load conditions (memorizing one digit or six digits), and the precision level required to control force was adjusted by manipulating visual gain (low vs. high visual gains), with higher visual gain necessitating more precise force control. Peri-movement alpha and beta event-related desynchronization (ERD), along with force accuracy and steadiness, were measured using electroencephalography recorded over the central areas during the force control task. Results indicated that while force accuracy and steadiness significantly improved with higher visual gain, there was no significant effect of WM load on these measures. Alpha and beta ERD were greater under high than low visual gain, and also greater under high than low WM load. These findings suggest that in young adults, increased WM load leads to compensatory increases in sensorimotor cortical activity to mitigate potential declines in static force control performance that may result from the depletion of neural resources caused by WM load. Our findings extend current understanding of the interaction between WM and sensorimotor processes by offering new insights into how movement-related brain activity is influenced by heightened WM load.",https://pubmed.ncbi.nlm.nih.gov/39486757/,https://pubmed.ncbi.nlm.nih.gov/39486757/,English,Include,,Working memory load increases movement-related alpha and beta desynchronization.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39486463,pubmed:39486463,PubMed,pubmed:39486463,EEG microstate in people with different degrees of fear of heights during virtual high-altitude exposure.,Chaolin Teng;Lin Cong;Qiumei Tian;Ke Liu;Shan Cheng;Taihui Zhang;Weitao Dang;Yajing Hou;Jin Ma;Duoduo Hui;Wendong Hu,2024,10.1016/j.brainresbull.2024.111112,"Previous neuroimaging studies based on electroencephalography (EEG) microstate analysis have identified abnormal neural electric activity in patients with psychiatric diseases. However, the microstate information in individuals with different degrees of fear of heights (FoH) remains unknown so far. The aim of the study was therefore to explore the changes of EEG microstate characteristics in different FoH individuals when exposed to high-altitude stimulated by virtual reality (VR). First, acrophobia questionnaire (AQ) before the experiment and 32-channel EEG signals under the virtual high-altitude exposure were collected from 69 subjects. Second, each subject was divided into one of three levels of FoH including no-FoH, mild or moderate FoH (m-FoH) and severe FoH (s-FoH) groups according to their AQ scores. Third, using microstate analysis, we transformed EEG data into sequences of characteristic topographic maps and computed EEG microstate features including microstate basic parameters, microstate sequences complexity and microstate energy. Finally, the extracted features as inputs were sent to train and test an support vector machine (SVM) for classifying different FoH groups. The results demonstrated that five types of microstates (labeled as A, B, C, D and F) were identified across all subjects, of which microstates A-D resembled the four typical microstate classes and microstate F was a non-canonical microstate. Significantly decreased occurrence, coverage and duration of microstate F and transition probabilities from other microstates to microstate F in m-FoH and s-FoH groups were observed compared to no-FoH group. It was also demonstrated that both m-FoH and s-FoH groups showed a notable reduction in sample entropy and Lempel-Ziv complexity. Moreover, energies of microstate D for m-FoH group and microstate B for s-FoH group in right parietal, parietooccipital and occipital regions exhibited prominent decreases as comparison to people without FoH. But, no significant differences were found between m-FoH and s-FoH groups. Additionally, the results indicated that AQ-anxiety scores were negatively correlated with microstate basic metrics as well as microstate energy. For classification, the performance of SVM reached a relatively high accuracy of 89 % for distinguishing no-FoH from m-FoH. In summary, the findings highlight the alterations of EEG microstates in people with fear of heights induced by virtual high-altitude, reflecting potentially underlying abnormalities in the allocation of neural assemblies. Therefore, the combination of EEG microstate analysis and VR may be a potential valuable approach for the diagnosis of fear of heights.",https://pubmed.ncbi.nlm.nih.gov/39486463/,https://pubmed.ncbi.nlm.nih.gov/39486463/,English,Include,,EEG microstate in people with different degrees of fear of heights during virtual high-altitude exposure.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39486306,pubmed:39486306,PubMed,pubmed:39486306,Refining ADHD diagnosis with EEG: The impact of preprocessing and temporal segmentation on classification accuracy.,Sandra García-Ponsoda;Alejandro Maté;Juan Trujillo,2024,10.1016/j.compbiomed.2024.109305,"EEG signals are commonly used in ADHD diagnosis, but they are often affected by noise and artifacts. Effective preprocessing and segmentation methods can significantly enhance the accuracy and reliability of ADHD classification. We applied filtering, ASR, and ICA preprocessing techniques to EEG data from children with ADHD and neurotypical controls. The EEG recordings were segmented, and features were extracted and selected based on statistical significance. Classification was performed using various EEG segments and channels with Machine Learning models (SVM, KNN, and XGBoost) to identify the most effective combinations for accurate ADHD diagnosis. Our findings show that models trained on later EEG segments achieved significantly higher accuracy, indicating the potential role of cognitive fatigue in distinguishing ADHD. The highest classification accuracy (86.1%) was achieved using data from the P3, P4, and C3 channels, with key features such as Kurtosis, Katz fractal dimension, and power spectrums in the Delta, Theta, and Alpha bands contributing to the results. This study highlights the importance of preprocessing and segmentation in improving the reliability of ADHD diagnosis through EEG. The results suggest that further research on cognitive fatigue and segmentation could enhance diagnostic accuracy in ADHD patients.",https://pubmed.ncbi.nlm.nih.gov/39486306/,https://pubmed.ncbi.nlm.nih.gov/39486306/,English,Include,,Refining ADHD diagnosis with EEG: The impact of preprocessing and temporal segmentation on classification accuracy.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39486098,pubmed:39486098,PubMed,pubmed:39486098,"Is lateralization concordance between preoperative video-EEG, ictal SPECT, and MRI to be associated with positive psychiatric outcomes after cortico-amygdalohippocampectomy in patients with pharmacoresistant temporal lobe epilepsy associated to mesial temporal sclerosis? A retrospective cohort study.",Bruna de Faria Dutra Andrade Karam;Michael Peres de Medeiros;Lucia Helena Neves Marques;Gerardo Maria de Araújo Filho,2024,10.1016/j.yebeh.2024.110115,"The occurrence of comorbid psychiatric disorders (PD) in patients with pharmacoresistant temporal lobe epilepsy (TLE) associated to mesial temporal sclerosis (MTS) can be considered as a result of the complex interaction between biological and psychosocial factors, as well as the effects of antiseizure medications (ASM). Regarding biological aspects, despite the growing amount of knowledge, there is still a scarcity of data in literature clarifying whether a more precise definition of the seizure onset zone (SOZ) could be associated with a more favorable post-surgical psychiatric outcome. In the present study, the clinical and sociodemographic pre-surgical variables, including the results of neurophysiological and neuroimaging exams, were evaluated in patients with pharmacoresistant TLE-MTS aiming to investigate possible risk factors for the presence of PD after cortico-amygdalohippocampectomy (CAH). A retrospective cohort analysis of medical records from initially 106 pre-surgical patients with pharmacoresistant TLE-MTS with PD (n = 51; 48.1 %) and without PD (n = 55; 51.9 %) proceeded. Pre-surgical clinical and sociodemographic data were compared between both groups and the predictors for the presence of post-surgical PD were characterized up to one and two years after CAH. Seventeen patients (16 %) had lost their follow-up in the first year after surgery, and 89 (84 %) had completed the study. No clinical and sociodemographic differences were observed between both groups of patients (p > 0.05), except for a history of previous psychiatric treatment (p = 0.001). Eighteen patients (35.29 %) with pre-surgical history of PD had remission of PD after CAH, while eight (14.5 %) developed de novo PD. The previous history of PD was directly associated with the development of post-surgical PD one year after CAH (p < 0.0001). Previous psychiatric treatment (p < 0.01), previous history of mood (p = 0.002) and anxiety (p = 0.03) disorder, as well as discordance in lateralization between MRI, SPECT, and EEG (p = 0.02), were predictors for the development of PD two years after CAH. Post-surgical psychiatric outcomes were associated to seizure outcome based on the Engel classification (p < 0,0001). The present data observed an association between lateralization concordance of results of pre-surgical investigative exams and positive postoperative psychiatric outcomes in patients with pharmacoresistant TLE-MTS. These results could suggest that a more precise definition of the SOZ could be associated with a more favorable post-surgical psychiatric outcome after CAH.",https://pubmed.ncbi.nlm.nih.gov/39486098/,https://pubmed.ncbi.nlm.nih.gov/39486098/,English,Include,,"Is lateralization concordance between preoperative video-EEG, ictal SPECT, and MRI to be associated with positive psychiatric outcomes after cortico-amygdalohippocampectomy in patients with pharmacoresistant temporal lobe epilepsy associated to mesial temporal sclerosis? A retrospective cohort study.",Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39485790,pubmed:39485790,PubMed,pubmed:39485790,A brain-to-text framework for decoding natural tonal sentences.,Daohan Zhang;Zhenjie Wang;Youkun Qian;Zehao Zhao;Yan Liu;Xiaotao Hao;Wanxin Li;Shuo Lu;Honglin Zhu;Luyao Chen;Kunyu Xu;Yuanning Li;Junfeng Lu,2024,10.1016/j.celrep.2024.114924,"Speech brain-computer interfaces (BCIs) directly translate brain activity into speech sound and text. Despite successful applications in non-tonal languages, the distinct syllabic structures and pivotal lexical information conveyed through tonal nuances present challenges in BCI decoding for tonal languages like Mandarin Chinese. Here, we designed a brain-to-text framework to decode Mandarin sentences from invasive neural recordings. Our framework dissects speech onset, base syllables, and lexical tones, integrating them with contextual information through Bayesian likelihood and a Viterbi decoder. The results demonstrate accurate tone and syllable decoding during naturalistic speech production. The overall word error rate (WER) for 10 offline-decoded tonal sentences with a vocabulary of 40 high-frequency Chinese characters is 21% (chance: 95.3%) averaged across five participants, and tone decoding accuracy reaches 93% (chance: 25%), surpassing previous intracranial Mandarin tonal syllable decoders. This study provides a robust and generalizable approach for brain-to-text decoding of continuous tonal speech sentences.",https://pubmed.ncbi.nlm.nih.gov/39485790/,https://pubmed.ncbi.nlm.nih.gov/39485790/,English,Include,,A brain-to-text framework for decoding natural tonal sentences.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39483100,pubmed:39483100,PubMed,pubmed:39483100,Multi-modal feature fusion with multi-head self-attention for epileptic EEG signals.,Ning Huang;Zhengtao Xi;Yingying Jiao;Yudong Zhang;Zhuqing Jiao;Xiaona Li,2024,10.3934/mbe.2024304,"It is important to classify electroencephalography (EEG) signals automatically for the diagnosis and treatment of epilepsy. Currently, the dominant single-modal feature extraction methods cannot cover the information of different modalities, resulting in poor classification performance of existing methods, especially the multi-classification problem. We proposed a multi-modal feature fusion (MMFF) method for epileptic EEG signals. First, the time domain features were extracted by kernel principal component analysis, the frequency domain features were extracted by short-time Fourier extracted transform, and the nonlinear dynamic features were extracted by calculating sample entropy. On this basis, the features of these three modalities were interactively learned through the multi-head self-attention mechanism, and the attention weights were trained simultaneously. The fused features were obtained by combining the value vectors of feature representations, while the time, frequency, and nonlinear dynamics information were retained to screen out more representative epileptic features and improve the accuracy of feature extraction. Finally, the feature fusion method was applied to epileptic EEG signal classifications. The experimental results demonstrated that the proposed method achieves a classification accuracy of 92.76 ± 1.64% across the five-category classification task for epileptic EEG signals. The multi-head self-attention mechanism promotes the fusion of multi-modal features and offers an efficient and novel approach for diagnosing and treating epilepsy.",https://pubmed.ncbi.nlm.nih.gov/39483100/,https://pubmed.ncbi.nlm.nih.gov/39483100/,English,Include,,Multi-modal feature fusion with multi-head self-attention for epileptic EEG signals.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39483077,pubmed:39483077,PubMed,pubmed:39483077,Depression-induced changes in directed functional brain networks: A source-space resting-state EEG study.,Zhongwen Jia;Lihan Tang;Jidong Lv;Linhong Deng;Ling Zou,2024,10.3934/mbe.2024315,"Current research confirms abnormalities in resting-state electroencephalogram (EEG) power and functional connectivity (FC) patterns in specific brain regions of individuals with depression. To study changes in the flow of information between cortical regions of the brain in patients with depression, we used 64-channel EEG to record neural oscillatory activity in 68 relevant cortical regions in 22 depressed patients and 22 healthy adolescents using source-space EEG. The direction and strength of information flow between brain regions was investigated using directional phase transfer entropy (PTE). Compared to healthy controls, we observed an increased intensity of PTE information flow between the left and right hemispheres in the theta and alpha frequency bands in depressed subjects. The intensity of information flow between anterior and posterior regions within each hemisphere was reduced. Significant differences were found in the left supramarginal gyrus, right delta in the theta frequency band and bilateral lateral occipital lobe, and paracentral gyrus and parahippocampal gyrus in the alpha frequency band. The accuracy of cross-classification of directed PTE values with significant differences between groups was 91%. These findings suggest that altered information flow in the brains of depressed patients is related to the pathogenesis of depression, providing insights for patient identification and pathological studies.",https://pubmed.ncbi.nlm.nih.gov/39483077/,https://pubmed.ncbi.nlm.nih.gov/39483077/,English,Include,,Depression-induced changes in directed functional brain networks: A source-space resting-state EEG study.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39482204,pubmed:39482204,PubMed,pubmed:39482204,Novel multimodal sensing and machine learning strategies to classify cognitive workload in laparoscopic surgery.,Ravi Naik;Adrian Rubio-Solis;Kaizhe Jin;George Mylonas,2025,10.1016/j.ejso.2024.108735,"Surgeons can experience elevated cognitive workload (CWL) during surgery due to various factors including operative technicalities and the environmental demands of the operating theatre. This can result in poorer outcomes and have a detrimental effect on surgeon well-being. The objective measurement of CWL provides a potential solution to facilitate classification of workload levels, however results are variable when physiological measures are used in isolation. The aim of this study is to develop and propose a multimodal machine learning (ML) approach to classify CWL levels using a bespoke sensor platform and to develop a ML approach to impute missing pupil diameter measures due to the effect of blinking or noise. Ten surgical trainees performed a simulated laparoscopic cholecystectomy under cognitive conditions of increasing difficulty, namely a modified auditory N-back task with increasing difficulty and a verbal clinical scenario. Physiological measures were recorded using a novel platform (MAESTRO). Electroencephalography (EEG) and functional near-infrared spectroscopy (fNIRS) were used as direct measures of CWL. Indirect measures included electromyography (EMG), electrocardiography (ECG) and pupil diameter (PD). A reference point for validation was provided by subjective assessment of perceived CWL using the SURG-TLX. A multimodal machine learning approach that systematically implements a CNN-BiLSTM, a binary version of the metaheuristic Manta Ray Foraging Optimisation (BMRFO) and a version of Fuzzy C-Means (FCM) called Optimal Completion Strategy (OCS) was used to classify the associated perceived CWL state. Compared to other state of the art classification techniques, cross-validation results for the classification of CWL levels suggest that the CNN-BLSTM and BMRFO approach provides an average accuracy of 97 % based on the confusion matrix. Additionally, OCS demonstrated a superior average performance of 9.15 % in terms of Root-Mean-Square-Error (RMSE) when compared to other PD imputation methods. Perceived CWL levels were correctly classified using a multimodal ML approach. This approach provides a potential route to accurately classify CWL levels, which may have application in future surgical training and assessment programs as well as the development of cognitive support systems in the operating room.",,https://pubmed.ncbi.nlm.nih.gov/39482204/,English,Exclude,Outside date range,Novel multimodal sensing and machine learning strategies to classify cognitive workload in laparoscopic surgery.,,,,,0.95,0.25,cv_reported
pubmed:39481258,pubmed:39481258,PubMed,pubmed:39481258,Attention allocation in foreign language reading anxiety during lexical processing - An ERP study with cue-target paradigm.,Lina Li;Qianqian Yu;Qing Guan;Hehui Li;Yue-Jia Luo,2024,10.1016/j.bandc.2024.106225,"Extensive behavioral and pedagogical studies emphasize the negative impact of foreign language reading anxiety on foreign language reading. This study investigated whether foreign language reading anxiety is correlated with dysregulation of attentional allocation while foreign language reading. We used event-related potential (ERP) indices as biomarkers to examine attention allocation between groups with high foreign language reading anxiety (HFLRA) and low foreign language reading anxiety (LFLRA) using a cue-target paradigm under conditions that posed high (valid condition) or low (invalid condition) expectations on target location. Behavioral results indicated that HFLRA individuals exhibited significantly lower accuracy compared to LFLRA individuals in both valid and invalid conditions. ERP analyses demonstrated that HFLRA individuals showed significant differences in attentional allocation compared to LFLRA individuals, as reflected by later N2 latency and stronger LPC amplitude, particularly in the invalid condition. Additionally, LFLRA individuals demonstrated a significant difference in N2 latency between valid and invalid conditions, which was not observed in HFLRA individuals. These findings suggest that HFLRA individuals experience inefficient attentional allocation during foreign language reading.",,https://pubmed.ncbi.nlm.nih.gov/39481258/,English,Exclude,Not EEG-BCI focused,Attention allocation in foreign language reading anxiety during lexical processing - An ERP study with cue-target paradigm.,,,,,0.9,0.6,
pubmed:39475113,pubmed:39475113,PubMed,pubmed:39475113,Investigating the role of auditory cues in modulating motor timing: insights from EEG and deep learning.,Ali Rahimpour Jounghani;Kristina C Backer;Amirali Vahid;Daniel C Comstock;Jafar Zamani;Hadi Hosseini;Ramesh Balasubramaniam;Heather Bortfeld,2024,10.1093/cercor/bhae427,"Research on action-based timing has shed light on the temporal dynamics of sensorimotor coordination. This study investigates the neural mechanisms underlying action-based timing, particularly during finger-tapping tasks involving synchronized and syncopated patterns. Twelve healthy participants completed a continuation task, alternating between tapping in time with an auditory metronome (pacing) and continuing without it (continuation). Electroencephalography data were collected to explore how neural activity changes across these coordination modes and phases. We applied deep learning methods to classify single-trial electroencephalography data and predict behavioral timing conditions. Results showed significant classification accuracy for distinguishing between pacing and continuation phases, particularly during the presence of auditory cues, emphasizing the role of auditory input in motor timing. However, when auditory components were removed from the electroencephalography data, the differentiation between phases became inconclusive. Mean accuracy asynchrony, a measure of timing error, emerged as a superior predictor of performance variability compared to inter-response interval. These findings highlight the importance of auditory cues in modulating motor timing behaviors and present the challenges of isolating motor activation in the absence of auditory stimuli. Our study offers new insights into the neural dynamics of motor timing and demonstrates the utility of deep learning in analyzing single-trial electroencephalography data.",https://pubmed.ncbi.nlm.nih.gov/39475113/,https://pubmed.ncbi.nlm.nih.gov/39475113/,English,Include,,Investigating the role of auditory cues in modulating motor timing: insights from EEG and deep learning.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39473791,pubmed:39473791,PubMed,pubmed:39473791,"A flexible, stable, semi-dry electrode with low impedance for electroencephalography recording.",Yiyan Zhu;Caicaike Bayin;Hongjie Li;Xiaokang Shu;Jiangnan Deng;Haowen Yuan;Huyan Shen;Zhou Liang;Yao Li,2024,10.1039/d4ra05560h,"Brain-computer interfaces (BCIs) provide promising prospects for the field of healthcare and rehabilitation, presenting significant advantages for humanity. The development of electrodes that exhibit satisfactory performance characteristics, including high electrical conductivity, optimal comfort, and exceptional stability, is crucial for the effective implementation of electroencephalography (EEG) recording in BCI systems. The present study introduces a novel EEG electrode design that utilizes a composite material consisting of reduced graphene oxide (RGO) and polyurethane (PU) sponge. This electrode is characterized by its low impedance, stability, and flexibility. This work offers a high level of comfort while in touch with the skin and is designed to be user-friendly. Due to its notable moisturizing capacity, adaptable structure, and the presence of conductive RGO networks, the RGOPU semi-dry electrode exhibits a skin-contact impedance of less than 5.6 kΩ. This value is equivalent to that of a wet electrode and lower than that of a commercially available semi-dry electrode. The stability tests have demonstrated the outstanding electrical and mechanical performance of the material, hence confirming its suitability for long-term EEG recording. Additionally, the RGOPU semi-dry electrode demonstrates stable recording of EEG data and accurate detection of action potentials. Furthermore, the correlation coefficient between the RGOPU semi-dry electrode and wet electrodes exceeds 0.9. Additionally, it acquires electroencephalogram signals characterized by high signal-to-noise ratios (SNRs) in the context of alpha-wave and steady-state visual evoked potential (SSVEP) tests. The accuracy of the BCI is similar to that of wet electrodes, indicating a potential capability for sensing EEG in BCI applications.",https://pubmed.ncbi.nlm.nih.gov/39473791/,https://pubmed.ncbi.nlm.nih.gov/39473791/,English,Include,,"A flexible, stable, semi-dry electrode with low impedance for electroencephalography recording.",Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39472526,pubmed:39472526,PubMed,pubmed:39472526,Fusing convolutional learning and attention-based Bi-LSTM networks for early Alzheimer's diagnosis from EEG signals towards IoMT.,Mohamadreza Khosravi;Hossein Parsaei;Khosro Rezaee;Mohammad Sadegh Helfroush,2024,10.1038/s41598-024-77876-8,"The Internet of Medical Things (IoMT) is poised to play a pivotal role in future medical support systems, enabling pervasive health monitoring in smart cities. Alzheimer's disease (AD) afflicts millions globally, and this paper explores the potential of electroencephalogram (EEG) data in addressing this challenge. We propose the Convolutional Learning Attention-Bidirectional Time-Aware Long-Short-Term Memory (CL-ATBiLSTM) model, a deep learning approach designed to classify different AD phases through EEG data analysis. The model utilizes Discrete Wavelet Transform (DWT) to decompose EEG data into distinct frequency bands, allowing for targeted analysis of AD-related brain activity patterns. Additionally, the data is segmented into smaller windows to handle the dynamic nature of EEG signals, and these segments are transformed into spectrogram images, visually depicting brain activity distribution over time and frequency. The CL-ATBiLSTM model incorporates convolutional layers to capture spatial features, attention mechanisms to emphasize crucial data, and BiLSTM networks to explore temporal relationships within the sequences. To optimize the model's performance, Bayesian optimization is employed to fine-tune the hyperparameters of the ATBiLSTM network, enhancing its ability to generalize and accurately classify AD stages. Incorporating Bayesian learning ensures the most effective model configuration, improving sensitivity and specificity for identifying AD-related patterns. Our model extracts discriminative features from EEG data to differentiate between AD, Mild Cognitive Impairment (MCI), and healthy controls (CO), offering a more comprehensive approach than existing two-class detection algorithms. By including the MCI category, our method facilitates earlier identification and potentially more impactful therapy interventions. Achieving a 96.52% accuracy on Figshare datasets containing AD, MCI, and CO groups, our approach demonstrates strong potential for practical use, accelerating AD identification, enhancing patient care, and contributing to the development of targeted treatments for this debilitating condition.",https://pubmed.ncbi.nlm.nih.gov/39472526/,https://pubmed.ncbi.nlm.nih.gov/39472526/,English,Include,,Fusing convolutional learning and attention-based Bi-LSTM networks for early Alzheimer's diagnosis from EEG signals towards IoMT.,Include,,"ach than existing two-class detection algorithms. By including the MCI category, our method facilitates earlier identification and potentially more impactful therapy interventions. Achieving a 96.52% accuracy on Figshare datasets containing AD, MCI, and CO groups, our approach demonstrates strong potential for practical use, accelerating AD identification, enhancing patient care, and contributing ",,0.95,0.6,
pubmed:39471684,pubmed:39471684,PubMed,pubmed:39471684,Combination of magnetoencephalographic and clinical features to identify atypical self-limited epilepsy with centrotemporal spikes.,Yihan Li;Yingfan Wang;Fengyuan Xu;Teng Jiang;Xiaoshan Wang,2024,10.1016/j.yebeh.2024.110095,"Our aim was to use magnetoencephalography (MEG) and clinical features to early identify self-limited epilepsy with centrotemporal spikes (SeLECTS) patients who evolve into atypical SeLECTS (AS). The baseline clinical and MEG data of 28 AS and 33 typical SeLECTS (TS) patients were collected. Based on the triple-network model, MEG analysis included power spectral density representing spectral power and corrected amplitude envelope correlation representing functional connectivity (FC). Based on the clinical and MEG features of AS patients, the linear support vector machine (SVM) classifier was used to construct the prediction model. The spectral power transferred from the alpha band to the delta band in the bilateral posterior cingulate cortex, and the inactivation of the beta band in both the right anterior cingulate cortex and left middle frontal gyrus were distinctive features of the AS group. The FC network in the AS group was characterized by attenuated intrinsic FC within the salience network in the alpha band, as well as attenuated FC interactions between the salience network and both the default mode network and central executive network in the beta band. The prediction model that integrated MEG and clinical features had a high prediction efficiency, with an accuracy of 0.80 and an AUC of 0.84. The triple-network model of early AS patients has band-dependent MEG alterations. These MEG features combined with clinical features can efficiently predict AS at an early stage.",,https://pubmed.ncbi.nlm.nih.gov/39471684/,English,Exclude,Not EEG-BCI focused,Combination of magnetoencephalographic and clinical features to identify atypical self-limited epilepsy with centrotemporal spikes.,,,,,0.9,0.6,
pubmed:39471577,pubmed:39471577,PubMed,pubmed:39471577,Graph neural networks for electroencephalogram analysis: Alzheimer's disease and epilepsy use cases.,Sergi Abadal;Pablo Galván;Alberto Mármol;Nadia Mammone;Cosimo Ieracitano;Michele Lo Giudice;Alessandro Salvini;Francesco Carlo Morabito,2025,10.1016/j.neunet.2024.106792,"Electroencephalography (EEG) is widely used as a non-invasive technique for the diagnosis of several brain disorders, including Alzheimer's disease and epilepsy. Until recently, diseases have been identified over EEG readings by human experts, which may not only be specific and difficult to find, but are also subject to human error. Despite the recent emergence of machine learning methods for the interpretation of EEGs, most approaches are not capable of capturing the underlying arbitrary non-Euclidean relations between signals in the different regions of the human brain. In this context, Graph Neural Networks (GNNs) have gained attention for their ability to effectively analyze complex relationships within different types of graph-structured data. This includes EEGs, a use case still relatively unexplored. In this paper, we aim to bridge this gap by presenting a study that applies GNNs for the EEG-based detection of Alzheimer's disease and discrimination of two different types of seizures. To this end, we demonstrate the value of GNNs by showing that a single GNN architecture can achieve state-of-the-art performance in both use cases. Through design space explorations and explainability analysis, we develop a graph-based transformer that achieves cross-validated accuracies over 89% and 96% in the ternary classification variants of Alzheimer's disease and epilepsy use cases, respectively, matching the intuitions drawn by expert neurologists. We also argue about the computational efficiency, generalizability and potential for real-time operation of GNNs for EEGs, positioning them as a valuable tool for classifying various neurological pathologies and opening up new prospects for research and clinical practice.",,https://pubmed.ncbi.nlm.nih.gov/39471577/,English,Exclude,Outside date range,Graph neural networks for electroencephalogram analysis: Alzheimer's disease and epilepsy use cases.,,,,,0.95,0.6,
pubmed:39470955,pubmed:39470955,PubMed,pubmed:39470955,Comparison of time-series models for predicting physiological metrics under sedation.,Zheyan Tu;Sean D Jeffries;Joshua Morse;Thomas M Hemmerling,2025,10.1007/s10877-016-9858-0,"This study presents a comprehensive comparison of multiple time-series models applied to physiological metric predictions. It aims to explore the effectiveness of both statistical prediction models and pharmacokinetic-pharmacodynamic prediction model and modern deep learning approaches. Specifically, the study focuses on predicting the bispectral index (BIS), a vital metric in anesthesia used to assess the depth of sedation during surgery, using datasets collected from real-life surgeries. The goal is to evaluate and compare model performance considering both univariate and multivariate schemes. Accurate BIS prediction is essential for avoiding under- or over-sedation, which can lead to adverse outcomes. The study investigates a range of models: The traditional mathematical models include the pharmacokinetic-pharmacodynamic model and statistical models such as autoregressive integrated moving average (ARIMA) and vector autoregression (VAR). The deep learning models encompass recurrent neural networks (RNNs), specifically Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRU), as well as Temporal Convolutional Networks (TCNs) and Transformer models. The analysis focuses on evaluating model performance in predicting the BIS using two distinct datasets of physiological metrics collected from actual surgical procedures. It explores both univariate and multivariate prediction schemes and investigates how different combinations of features and input sequence lengths impact model accuracy. The experimental findings reveal significant performance differences among the models: In univariate prediction scenarios for predicting BIS, the LSTM model demonstrates a 2.88% improvement over the second-best performing model. For multivariate predictions, the LSTM model outperforms others by 6.67% compared to the next best model. Furthermore, the addition of Electromyography (EMG) and Mean Arterial Pressure (MAP) brings significant accuracy improvement when predicting BIS. The study emphasizes the importance of selecting and building appropriate time-series models to achieve accurate predictions in biomedical applications. This research provides insights to guide future efforts in improving vital sign prediction methodologies for clinical and research purposes. Clinically, with improvements in the prediction of physiological parameters, clinicians can be informed of interventions if an anomaly is detected or predicted.",,https://pubmed.ncbi.nlm.nih.gov/39470955/,English,Exclude,Outside date range,Comparison of time-series models for predicting physiological metrics under sedation.,,,,,0.95,0.6,
pubmed:39469882,pubmed:39469882,PubMed,pubmed:39469882,Neural encoding of melodic expectations in music across EEG frequency bands.,Juan-Daniel Galeano-Otálvaro;Jordi Martorell;Lars Meyer;Lorenzo Titone,2024,10.1126/sciadv.adi2525,"The human brain tracks regularities in the environment and extrapolates these to predict future events. Prior work on music cognition suggests that low-frequency (1-8 Hz) brain activity encodes melodic predictions beyond the stimulus acoustics. Building on this work, we aimed to disentangle the frequency-specific neural dynamics linked to melodic prediction uncertainty (modelled as entropy) and prediction error (modelled as surprisal) for temporal (note onset) and content (note pitch) information. By using multivariate temporal response function (TRF) models, we re-analysed the electroencephalogram (EEG) from 20 subjects (10 musicians) who listened to Western tonal music. Our results show that melodic expectation metrics improve the EEG reconstruction accuracy in all frequency bands below the gamma range (< 30 Hz). Crucially, we found that entropy contributed more strongly to the reconstruction accuracy enhancement compared to surprisal in all frequency bands. Additionally, we found that the encoding of temporal, but not content, information metrics was not limited to low frequencies, rather it extended to higher frequencies (> 8 Hz). An analysis of the TRF weights revealed that the temporal predictability of a note (entropy of note onset) may be encoded in the delta- (1-4 Hz) and beta-band (12-30 Hz) brain activity prior to the stimulus, suggesting that these frequency bands associate with temporal predictions. Strikingly, we also revealed that melodic expectations selectively enhanced EEG reconstruction accuracy in the beta band for musicians, and in the alpha band (8-12 Hz) for non-musicians, suggesting that musical expertise influences the neural dynamics underlying predictive processing in music cognition.",https://pubmed.ncbi.nlm.nih.gov/39469882/,https://pubmed.ncbi.nlm.nih.gov/39469882/,English,Include,,Neural encoding of melodic expectations in music across EEG frequency bands.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39469033,pubmed:39469033,PubMed,pubmed:39469033,HASTF: a hybrid attention spatio-temporal feature fusion network for EEG emotion recognition.,Fangzhou Hu;Fei Wang;Jinying Bi;Zida An;Chao Chen;Gangguo Qu;Shuai Han,2024,10.1007/s10489-022-04228-2,"EEG-based emotion recognition has gradually become a new research direction, known as affective Brain-Computer Interface (aBCI), which has huge application potential in human-computer interaction and neuroscience. However, how to extract spatio-temporal fusion features from complex EEG signals and build learning method with high recognition accuracy and strong interpretability is still challenging. In this paper, we propose a hybrid attention spatio-temporal feature fusion network for EEG-based emotion recognition. First, we designed a spatial attention feature extractor capable of merging shallow and deep features to extract spatial information and adaptively select crucial features under different emotional states. Then, the temporal feature extractor based on the multi-head attention mechanism is integrated to perform spatio-temporal feature fusion to achieve emotion recognition. Finally, we visualize the extracted spatial attention features using feature maps, further analyzing key channels corresponding to different emotions and subjects. Our method outperforms the current state-of-the-art methods on two public datasets, SEED and DEAP. The recognition accuracy are 99.12% ± 1.25% (SEED), 98.93% ± 1.45% (DEAP-arousal), and 98.57% ± 2.60% (DEAP-valence). We also conduct ablation experiments, using statistical methods to analyze the impact of each module on the final result. The spatial attention features reveal that emotion-related neural patterns indeed exist, which is consistent with conclusions in the field of neurology. The experimental results show that our method can effectively extract and fuse spatial and temporal information. It has excellent recognition performance, and also possesses strong robustness, performing stably across different datasets and experimental environments for emotion recognition.",https://pubmed.ncbi.nlm.nih.gov/39469033/,https://pubmed.ncbi.nlm.nih.gov/39469033/,English,Include,,HASTF: a hybrid attention spatio-temporal feature fusion network for EEG emotion recognition.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39468790,pubmed:39468790,PubMed,pubmed:39468790,Identification of drug use degree by integrating multi-modal features with dual-input deep learning method.,Yuxing Zhou;Xuelin Gu;Zhen Wang;Xiaoou Li,2024,10.1080/10255842.2024.2417206,"Most of studies on drug use degree are based on subjective judgments without objective quantitative assessment, in this paper, a dual-input bimodal fusion algorithm is proposed to study drug use degree by using electroencephalogram (EEG) and near-infrared spectroscopy (NIRS). Firstly, this paper uses the optimized dual-input multi-modal TiCBnet for extracting the deep encoding features of the bimodal signal, then fuses and screens the features using different methods, and finally fused deep encoding features are classified. The classification accuracy of bimodal is found to be higher than that of single modal, and the classification accuracy is up to 89.9%.",https://pubmed.ncbi.nlm.nih.gov/39468790/,https://pubmed.ncbi.nlm.nih.gov/39468790/,English,Include,,Identification of drug use degree by integrating multi-modal features with dual-input deep learning method.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39468471,pubmed:39468471,PubMed,pubmed:39468471,Altered brainstem-cortex activation and interaction in migraine patients: somatosensory evoked EEG responses with machine learning.,Fu-Jung Hsiao;Wei-Ta Chen;Hung-Yu Liu;Yu-Te Wu;Yen-Feng Wang;Li-Ling Hope Pan;Kuan-Lin Lai;Shih-Pin Chen;Gianluca Coppola;Shuu-Jiun Wang,2024,10.1186/s10194-024-01892-2,"To gain a comprehensive understanding of the altered sensory processing in patients with migraine, in this study, we developed an electroencephalography (EEG) protocol for examining brainstem and cortical responses to sensory stimulation. Furthermore, machine learning techniques were employed to identify neural signatures from evoked brainstem-cortex activation and their interactions, facilitating the identification of the presence and subtype of migraine. This study analysed 1,000-epoch-averaged somatosensory evoked responses from 342 participants, comprising 113 healthy controls (HCs), 106 patients with chronic migraine (CM), and 123 patients with episodic migraine (EM). Activation amplitude and effective connectivity were obtained using weighted minimum norm estimates with spectral Granger causality analysis. This study used support vector machine algorithms to develop classification models; multimodal data (amplitude, connectivity, and scores of psychometric assessments) were applied to assess the reliability and generalisability of the identification results from the classification models. The findings revealed that patients with migraine exhibited reduced amplitudes for responses in both the brainstem and cortical regions and increased effective connectivity between these regions in the gamma and high-gamma frequency bands. The classification model with characteristic features performed well in distinguishing patients with CM from HCs, achieving an accuracy of 81.8% and an area under the curve (AUC) of 0.86 during training and an accuracy of 76.2% and an AUC of 0.89 during independent testing. Similarly, the model effectively identified patients with EM, with an accuracy of 77.5% and an AUC of 0.84 during training and an accuracy of 87% and an AUC of 0.88 during independent testing. Additionally, the model successfully differentiated patients with CM from patients with EM, with an accuracy of 70.5% and an AUC of 0.73 during training and an accuracy of 72.7% and an AUC of 0.74 during independent testing. Altered brainstem-cortex activation and interaction are characteristic of the abnormal sensory processing in migraine. Combining evoked activity analysis with machine learning offers a reliable and generalisable tool for identifying patients with migraine and for assessing the severity of their condition. Thus, this approach is an effective and rapid diagnostic tool for clinicians.",https://pubmed.ncbi.nlm.nih.gov/39468471/,https://pubmed.ncbi.nlm.nih.gov/39468471/,English,Include,,Altered brainstem-cortex activation and interaction in migraine patients: somatosensory evoked EEG responses with machine learning.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.55,external_test_reported;small_sample_mentioned
pubmed:39468119,pubmed:39468119,PubMed,pubmed:39468119,Compact convolutional transformer for subject-independent motor imagery EEG-based BCIs.,Aigerim Keutayeva;Nail Fakhrutdinov;Berdakh Abibullaev,2024,10.1038/s41598-024-73755-4,"Motor imagery electroencephalography (EEG) analysis is crucial for the development of effective brain-computer interfaces (BCIs), yet it presents considerable challenges due to the complexity of the data and inter-subject variability. This paper introduces EEGCCT, an application of compact convolutional transformers designed specifically to improve the analysis of motor imagery tasks in EEG. Unlike traditional approaches, EEGCCT model significantly enhances generalization from limited data, effectively addressing a common limitation in EEG datasets. We validate and test our models using the open-source BCI Competition IV datasets 2a and 2b, employing a Leave-One-Subject-Out (LOSO) strategy to ensure subject-independent performance. Our findings demonstrate that EEGCCT not only outperforms conventional models like EEGNet in standard evaluations but also achieves better performance compared to other advanced models such as Conformer, Hybrid s-CViT, and Hybrid t-CViT, while utilizing fewer parameters and achieving an accuracy of 70.12%. Additionally, the paper presents a comprehensive ablation study that includes targeted data augmentation, hyperparameter optimization, and architectural improvements.",https://pubmed.ncbi.nlm.nih.gov/39468119/,https://pubmed.ncbi.nlm.nih.gov/39468119/,English,Include,,Compact convolutional transformer for subject-independent motor imagery EEG-based BCIs.,Include,,"t in standard evaluations but also achieves better performance compared to other advanced models such as Conformer, Hybrid s-CViT, and Hybrid t-CViT, while utilizing fewer parameters and achieving an accuracy of 70.12%. Additionally, the paper presents a comprehensive ablation study that includes targeted data augmentation, hyperparameter optimization, and architectural improvements.",,0.95,0.25,cv_reported
pubmed:39464626,pubmed:39464626,PubMed,pubmed:39464626,Fusion of Multi-Task Neurophysiological Data to Enhance the Detection of Attention- Deficit/Hyperactivity Disorder.,Kai-Feng Zhang;Shih-Ching Yeh;Eric Hsiao-Kuang Wu;Xiu Xu;Ho-Jung Tsai;Chun-Chuan Chen,2024,10.1109/jtehm.2024.3435553,"Attention-deficit/hyperactivity disorder (ADHD) is a childhood-onset neurodevelopmental disorder with a prevalence ranging from 6.1 to 9.4%. The main symptoms of ADHD are inattention, hyperactivity, impulsivity, and even destructive behaviors that may have a long-term negative influence on learning performance or social relationships. Early diagnosis and treatment provide the best chance of reducing and managing symptoms. Currently, ADHD diagnosis relies on behavioral observations and ratings by clinicians and parents. Medical diagnosis of ADHD was reported to be delayed because of a global shortage of well-trained clinicians, the heterogeneous nature of ADHD, and combined comorbidities. Therefore, alternative ways to increase the efficiency of early diagnosis are needed. Previous studies used behavioral and neurophysiological data to assess patients with ADHD, yielding an accuracy range from 56.6% to 92%. Several factors were shown to affect the detection rate, including methods and tasks used and the number of electroencephalogram (EEG) channels. Given that children with ADHD have difficulty sustaining attention, in this study, we tested whether data from multiple tasks with different difficulties and prolonged experiment times can probe the levels of brain resources engaged during task performance and increase ADHD detection. Specifically, we proposed a Deep Neural Network-based (DNN) fusion model of multiple tasks to enhance the detection of ADHD. Forty-nine children with ADHD and thirty-two typically developing children were recruited. Analytic results show that the fusion of multi-task neurophysiological data can increase the separation rate to 89%, whereas a single data type can only achieve a best accuracy of 81%. Moreover, the use of multiple tasks helps distinguish between children with ADHD and typically developing children. Our results suggest that different neurophysiological models from multiple tasks can provide essential information to assist in ADHD screening. In conclusion, the proposed model offers a more efficient, and accurate alternative for early clinical diagnosis and management of ADHD. The application of artificial intelligence and multimodal neurophysiological data in clinical settings sets a precedent for digital health, paving the way for future advancements in the field.",https://pubmed.ncbi.nlm.nih.gov/39464626/,https://pubmed.ncbi.nlm.nih.gov/39464626/,English,Include,,Fusion of Multi-Task Neurophysiological Data to Enhance the Detection of Attention- Deficit/Hyperactivity Disorder.,Include,,"rbidities. Therefore, alternative ways to increase the efficiency of early diagnosis are needed. Previous studies used behavioral and neurophysiological data to assess patients with ADHD, yielding an accuracy range from 56.6% to 92%. Several factors were shown to affect the detection rate, including methods and tasks used and the number of electroencephalogram (EEG) channels. Given that children w",,0.95,0.6,
pubmed:39464623,pubmed:39464623,PubMed,pubmed:39464623,A 4-DOF Exosuit Using a Hybrid EEG-Based Control Approach for Upper-Limb Rehabilitation.,Zhichuan Tang;Zhixuan Cui;Hang Wang;Pengcheng Liu;Xuan Xu;Keshuai Yang,2024,10.1109/jtehm.2024.3454077,"Rehabilitation devices, such as traditional rigid exoskeletons or exosuits, have been widely used to rehabilitate upper limb function post-stroke. In this paper, we have developed an exosuit with four degrees of freedom to enable users to involve more joints in the rehabilitation process. Additionally, a hybrid electroencephalogram-based (EEG-based) control approach has been developed to promote active user engagement and provide more control commands.The hybrid EEG-based control approach includes steady-state visual evoked potential (SSVEP) paradigm and motor imagery (MI) paradigm. Firstly, the rehabilitation movement was selected by SSVEP paradigm, and the multivariate variational mode decomposition (MVMD) and canonical correlation analysis (CCA) method was used for SSVEP EEG recognition; then, the motion intention was obtained by MI paradigm, and the convolutional neural network (CNN) and long short-term memory network (LSTM) were used to build a CNN-LSTM model for MI EEG recognition; finally, the recognition results were translated into control commands of Bowden cables to achieve multi-degree-of-freedom rehabilitation.Experimental results show that the average classification accuracy of the CNN-LSTM model reaches to 90.07% ± 2.23%, and the overall accuracy of the hybrid EEG-based control approach reaches to 85.26% ± 1.95%. The twelve subjects involved in the usability assessment demonstrated an average system usability scale (SUS) score of 81.25 ± 5.82. Additionally, four participants who underwent a 35-day rehabilitation training demonstrated an average 10.33% increase in range of motion (ROM) across 4 joints, along with a 11.35% increase in the average electromyography (EMG) amplitude of the primary muscle involved.The exosuit demonstrates good accuracy in control, exhibits favorable usability, and shows certain efficacy in multi-joint rehabilitation. Our study has taken into account the neuroplastic principles, aiming to achieve active user engagement while introducing additional degrees of freedom, offering novel ideas and methods for potential brain-computer interface (BCI)-based rehabilitation strategies and hardware development.Clinical impact: Our study presents an exosuit with four degrees of freedom for stroke rehabilitation, enabling multi-joint movement and improved motor recovery. The hybrid EEG-based control approach enhances active user engagement, offering a promising strategy for more effective and user-driven rehabilitation, potentially improving clinical outcomes.Clinical and Translational Impact Statement: By developing an exosuit and a hybrid EEG-based control approach, this study enhances stroke rehabilitation through better user engagement and multi-joint capabilities. These innovations consider neuroplasticity principles, integrating rehabilitation theory with rehabilitation device.",https://pubmed.ncbi.nlm.nih.gov/39464623/,https://pubmed.ncbi.nlm.nih.gov/39464623/,English,Include,,A 4-DOF Exosuit Using a Hybrid EEG-Based Control Approach for Upper-Limb Rehabilitation.,Include,,"on; finally, the recognition results were translated into control commands of Bowden cables to achieve multi-degree-of-freedom rehabilitation.Experimental results show that the average classification accuracy of the CNN-LSTM model reaches to 90.07% ± 2.23%, and the overall accuracy of the hybrid EEG-based control approach reaches to 85.26% ± 1.95%. The twelve subjects involved in the usability ass",,0.95,0.8,small_sample_mentioned
pubmed:39461914,pubmed:39461914,PubMed,pubmed:39461914,Advancing EEG prediction with deep learning and uncertainty estimation.,Mats Tveter;Thomas Tveitstøl;Christoffer Hatlestad-Hall;Ana S Pérez T;Erik Taubøll;Anis Yazidi;Hugo L Hammer;Ira R J Hebold Haraldsen,2024,10.1186/s40708-024-00239-6,"Deep Learning (DL) has the potential to enhance patient outcomes in healthcare by implementing proficient systems for disease detection and diagnosis. However, the complexity and lack of interpretability impede their widespread adoption in critical high-stakes predictions in healthcare. Incorporating uncertainty estimations in DL systems can increase trustworthiness, providing valuable insights into the model's confidence and improving the explanation of predictions. Additionally, introducing explainability measures, recognized and embraced by healthcare experts, can help address this challenge. In this study, we investigate DL models' ability to predict sex directly from electroencephalography (EEG) data. While sex prediction have limited direct clinical application, its binary nature makes it a valuable benchmark for optimizing deep learning techniques in EEG data analysis. Furthermore, we explore the use of DL ensembles to improve performance over single models and as an approach to increase interpretability and performance through uncertainty estimation. Lastly, we use a data-driven approach to evaluate the relationship between frequency bands and sex prediction, offering insights into their relative importance. InceptionNetwork, a single DL model, achieved 90.7% accuracy and an AUC of 0.947, and the best-performing ensemble, combining variations of InceptionNetwork and EEGNet, achieved 91.1% accuracy in predicting sex from EEG data using five-fold cross-validation. Uncertainty estimation through deep ensembles led to increased prediction performance, and the models were able to classify sex in all frequency bands, indicating sex-specific features across all bands.",https://pubmed.ncbi.nlm.nih.gov/39461914/,https://pubmed.ncbi.nlm.nih.gov/39461914/,English,Include,,Advancing EEG prediction with deep learning and uncertainty estimation.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.25,cv_reported
pubmed:39460240,pubmed:39460240,PubMed,pubmed:39460240,Thought-Controlled Computer Applications: A Brain-Computer Interface System for Severe Disability Support.,Kais Belwafi;Fakhreddine Ghaffari,2024,10.1155/2017/9816591,"This study introduces an integrated computational environment that leverages Brain-Computer Interface (BCI) technology to enhance information access for individuals with severe disabilities. Traditional assistive technologies often rely on physical interactions, which can be challenging for this demographic. Our innovation focuses on creating new assistive technologies that use novel Human-Computer interfaces to provide a more intuitive and accessible experience. The proposed system offers four key applications to users controlled by four thoughts: an email client, a web browser, an e-learning tool, and both command-line and graphical user interfaces for managing computer resources. The BCI framework translates ElectroEncephaloGraphy (EEG) signals into commands or events using advanced signal processing and machine learning techniques. These identified commands are then processed by an integrative strategy that triggers the appropriate actions and provides real-time feedback on the screen. Our study shows that our framework achieved an 82% average classification accuracy using four distinct thoughts of 62 subjects and a 95% recognition rate for P300 signals from two users, highlighting its effectiveness in translating brain signals into actionable commands. Unlike most existing prototypes that rely on visual stimulation, our system is controlled by thought, inducing brain activity to manage the system's Application Programming Interfaces (APIs). It switches to P300 mode for a virtual keyboard and text input. The proposed BCI system significantly improves the ability of individuals with severe disabilities to interact with various applications and manage computer resources. Our approach demonstrates superior performance in terms of classification accuracy and signal recognition compared to existing methods.",https://pubmed.ncbi.nlm.nih.gov/39460240/,https://pubmed.ncbi.nlm.nih.gov/39460240/,English,Include,,Thought-Controlled Computer Applications: A Brain-Computer Interface System for Severe Disability Support.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39460201,pubmed:39460201,PubMed,pubmed:39460201,Multi-Class Detection of Neurodegenerative Diseases from EEG Signals Using Lightweight LSTM Neural Networks.,Laura Falaschetti;Giorgio Biagetti;Michele Alessandrini;Claudio Turchetti;Simona Luzzi;Paolo Crippa,2024,10.1109/access.2023.3294618,"Neurodegenerative diseases severely impact the life of millions of patients worldwide, and their occurrence is more and more increasing proportionally to longer life expectancy. Electroencephalography has become an important diagnostic tool for these diseases, due to its relatively simple procedure, but it requires analyzing a large number of data, often carrying a small fraction of informative content. For this reason, machine learning tools have gained a considerable relevance as an aid to classify potential signs of a specific disease, especially in its early stages, when treatments can be more effective. In this work, long short-term memory-based neural networks with different numbers of units were properly designed and trained after accurate data pre-processing, in order to perform a multi-class detection. To this end, a custom dataset of EEG recordings from subjects affected by five neurodegenerative diseases (Alzheimer's disease, frontotemporal dementia, dementia with Lewy bodies, progressive supranuclear palsy, and vascular dementia) was acquired. Experimental results show that an accuracy up to 98% was achieved with data belonging to different classes of disease, up to six including the control group, while not requiring particularly heavy computational resources.",https://pubmed.ncbi.nlm.nih.gov/39460201/,https://pubmed.ncbi.nlm.nih.gov/39460201/,English,Include,,Multi-Class Detection of Neurodegenerative Diseases from EEG Signals Using Lightweight LSTM Neural Networks.,Include,,"odegenerative diseases (Alzheimer's disease, frontotemporal dementia, dementia with Lewy bodies, progressive supranuclear palsy, and vascular dementia) was acquired. Experimental results show that an accuracy up to 98% was achieved with data belonging to different classes of disease, up to six including the control group, while not requiring particularly heavy computational resources.",,0.95,0.6,
pubmed:39459990,pubmed:39459990,PubMed,pubmed:39459990,Diagnosis of Schizophrenia Using EEG Sensor Data: A Novel Approach with Automated Log Energy-Based Empirical Wavelet Reconstruction and Cepstral Features.,Sumair Aziz;Muhammad Umar Khan;Khushbakht Iqtidar;Raul Fernandez-Rojas,2024,10.1016/j.engappai.2022.105602,"Schizophrenia (SZ) is a severe mental disorder characterised by disruptions in cognition, behaviour, and perception, significantly impacting an individual's life. Traditional SZ diagnosis methods are labour-intensive and prone to errors. This study presents an innovative automated approach for detecting SZ acquired through electroencephalogram (EEG) sensor signals, aiming to improve diagnostic efficiency and accuracy. We utilised Fast Independent Component Analysis to remove artefacts from raw EEG sensor data. A novel Automated Log Energy-based Empirical Wavelet Reconstruction (ALEEWR) technique was introduced to reconstruct decomposed modes based on their variability, ensuring effective extraction of meaningful EEG signatures. Cepstral-based features-cepstral activity, cepstral mobility, and cepstral complexity-were used to capture the power, rate of change, and irregularity of the cepstrum of preprocessed EEG signals. ANOVA-based feature selection was applied to refine these features before classification using the K-Nearest Neighbour (KNN) algorithm. Our approach achieved an exceptional accuracy of 99.4%, significantly surpassing previous methods. The proposed ALEEWR and cepstral analysis demonstrated high precision, sensitivity, and specificity in the automated diagnosis of schizophrenia. This study introduces a highly accurate and efficient method for SZ detection using EEG technology. The proposed techniques offer significant improvements in diagnostic accuracy, with potential implications for enhancing SZ diagnosis and patient care through automated systems.",https://pubmed.ncbi.nlm.nih.gov/39459990/,https://pubmed.ncbi.nlm.nih.gov/39459990/,English,Include,,Diagnosis of Schizophrenia Using EEG Sensor Data: A Novel Approach with Automated Log Energy-Based Empirical Wavelet Reconstruction and Cepstral Features.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39456365,pubmed:39456365,PubMed,pubmed:39456365,The Use of Fluorescence Spectrometry Combined with Statistical Tools to Determine the Botanical Origin of Honeys.,Aleksandra Wilczyńska;Natalia Żak,2024,10.3390/app10051776,"At a time when the botanical origin of honey is being increasingly falsified, there is a need to find a quick, cheap and simple method of identifying its origin. Therefore, the aim of our work was to show that fluorescence spectrometry, together with statistical analysis, can be such a method. In total, 108 representative samples with 10 different botanic origins (9 unifloral and 1 multifloral), obtained in 2020-2022 from local apiaries, were analyzed. The fluorescence spectra of those samples were determined using a F-7000 Hitachi fluorescence spectrophotometer, Tokyo, Japan. It is shown that each honey variety produces a unique emission spectrum, which allows for the determination of its botanical origin. Taking into account the difficulties in analyzing these spectra, it was found that the most information regarding botanical differences and their identification is provided by synchronous cross-sections of these spectra obtained at Δλ = 100 nm. In addition, this analysis was supported by discriminant and canonical analysis, which allowed for the creation of mathematical models, allowing for the correct classification of each type of honey (except dandelion) with an accuracy of over 80%. The application of the method is universal (in accordance with the methodology described in this paper), but its use requires the creation of fluorescence spectral matrices (EEG) characteristic of a given geographical and botanical origin.",https://pubmed.ncbi.nlm.nih.gov/39456365/,https://pubmed.ncbi.nlm.nih.gov/39456365/,English,Include,,The Use of Fluorescence Spectrometry Combined with Statistical Tools to Determine the Botanical Origin of Honeys.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39455586,pubmed:39455586,PubMed,pubmed:39455586,A multiple session dataset of NIRS recordings from stroke patients controlling brain-computer interface.,Mikhail R Isaev;Olesya A Mokienko;Roman Kh Lyukmanov;Ekaterina S Ikonnikova;Anastasiia N Cherkasova;Natalia A Suponeva;Michael A Piradov;Pavel D Bobrov,2024,10.1038/s41597-024-04012-6,"This paper presents an open dataset of over 50 hours of near infrared spectroscopy (NIRS) recordings. Fifteen stroke patients completed a total of 237 motor imagery brain-computer interface (BCI) sessions. The BCI was controlled by imagined hand movements; visual feedback was presented based on the real-time data classification results. We provide the experimental records, patient demographic profiles, clinical scores (including ARAT and Fugl-Meyer), online BCI performance, and a simple analysis of hemodynamic response. We assume that this dataset can be useful for evaluating the effectiveness of various near-infrared spectroscopy signal processing and analysis techniques in patients with cerebrovascular accidents.",https://pubmed.ncbi.nlm.nih.gov/39455586/,https://pubmed.ncbi.nlm.nih.gov/39455586/,English,Include,,A multiple session dataset of NIRS recordings from stroke patients controlling brain-computer interface.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39454613,pubmed:39454613,PubMed,pubmed:39454613,Clustering for mitigating subject variability in driving fatigue classification using electroencephalography source-space functional connectivity features.,Khanh Ha Nguyen;Yvonne Tran;Ashley Craig;Hung Nguyen;Rifai Chai,2024,10.1088/1741-2552/ad8b6d,,https://pubmed.ncbi.nlm.nih.gov/39454613/,https://pubmed.ncbi.nlm.nih.gov/39454613/,English,Include,,Clustering for mitigating subject variability in driving fatigue classification using electroencephalography source-space functional connectivity features.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39454219,pubmed:39454219,PubMed,pubmed:39454219,Preoperative interhemispheric coherence as a potential predictive marker for seizure outcome after total corpus callosotomy in nonlesional generalized epilepsy: a scalp EEG study.,Vich Yindeedej;Takehiro Uda;Shugo Nishijima;Takeshi Inoue;Ichiro Kuki;Masataka Fukuoka;Megumi Nukui;Shin Okazaki;Noritsugu Kunihiro;Ryoko Umaba;Takeo Goto,2025,10.3171/2024.7.peds24246,"Corpus callosotomy (CC) is one of the palliative epilepsy surgical procedures available for nonlesional generalized epilepsy, but it is more invasive than other palliative surgical procedures. The main challenge is proper selection of suitable patients for CC. Coherence analysis is a method for evaluating brain connectivity, but the correlation between preoperative coherence and surgical outcomes has not previously been clarified. The authors aimed to evaluate correlations between preoperative interhemispheric coherence and surgical outcome in patients with nonlesional generalized epilepsy. This retrospective study investigated patients with nonlesional generalized epilepsy who underwent total CC. The authors collected data for patients with good seizure outcome (Oguni classification A or B) and bad seizure outcome (Oguni classification D). For coherence analysis, the authors selected a period without interictal discharges. Preoperative interhemispheric coherence values from 8 pairs of symmetrically opposite scalp electrodes were computed across 5 frequency bands. Then, the authors evaluated correlations between coherence and surgical outcomes. Forty patients were included (19 males and 21 females). The mean (range) age at the time of surgery was 5.1 (1-18) years. Seizure outcomes were good in 15 patients and bad in the other 25 patients. Age at onset of epilepsy, duration of epilepsy before surgery, age at time of surgery, and presence of epileptic spasm did not differ significantly between patients with good and bad seizure outcomes (p = 0.36, p = 0.14, p = 0.10, and p = 0.20, respectively). Significant correlations were identified between higher Fp1-Fp2 interhemispheric coherence values in the delta, theta, and alpha frequency bands and bad surgical outcomes (p = 0.0397, p = 0.0322, and p = 0.0476, respectively). The receiver operating characteristic curves of the Fp1-Fp2 coherence values in these frequency bands showed areas under the curve of 67%, 69%, and 67%, respectively. The optimal cutoff values for Fp1-Fp2 interhemispheric coherence to predict surgical outcomes were 55.6 for delta (66.7% sensitivity and 72.0% specificity), 55.9 for theta (60.0% sensitivity and 76.0% specificity), and 50.3 for alpha (53.3% sensitivity and 84.0% specificity). This is the first study to identify potential predictive factors for surgical outcomes based on preoperative interhemispheric coherence in nonlesional generalized epilepsy. Higher coherence between Fp1-Fp2 in the delta, theta, and alpha frequencies correlated with bad seizure outcome after CC.",,https://pubmed.ncbi.nlm.nih.gov/39454219/,English,Exclude,Outside date range,Preoperative interhemispheric coherence as a potential predictive marker for seizure outcome after total corpus callosotomy in nonlesional generalized epilepsy: a scalp EEG study.,,,,,0.95,0.25,cv_reported
pubmed:39453797,pubmed:39453797,PubMed,pubmed:39453797,Enhancing ERD Activation and Functional Connectivity via the Sixth-Finger Motor Imagery in Stroke Patients.,Zhuang Wang;Yuan Liu;Shuaifei Huang;Huimin Huang;Wenlai Wu;Yuyang Wang;Xingwei An;Dong Ming,2024,10.1109/tnsre.2024.3486551,"Motor imagery (MI) is widely employed in stroke rehabilitation due to the event-related desynchronization (ERD) phenomenon in sensorimotor cortex induced by MI is similar to actual movement. However, the traditional BCI paradigm, in which the patient imagines the movement of affected hand (AH-MI) with a weak ERD caused by the damaged brain regions, retards motor relearning process. In this work, we applied a novel MI paradigm based on the ""sixth-finger"" (SF-MI) in stroke patients and systematically uncovered the ERD pattern enhancement of novel MI paradigm compared to traditional MI paradigm. Twenty stroke patients were recruited for this experiment. Event-related spectral perturbation was adopted to supply details about ERD. Brain activation region, intensity and functional connectivity were compared between SF-MI and AH-MI to reveal the ERD enhancement performance of novel MI paradigm. A ""wider range, stronger intensity, greater connection"" ERD activation pattern was induced in stroke patients by novel SF-MI paradigm compared to traditional AH-MI paradigm. The bilateral sensorimotor and prefrontal modulation was found in SF-MI, which was different in AH-MI only weak sensorimotor modulation was exhibited. The ERD enhancement is mainly concentrated in mu rhythm. More synchronized and intimate neural activity between different brain regions was found during SF-MI tasks compared to AH-MI tasks. Classification results (>80% in SF-MI vs. REST) also indicated the feasibility of applying novel MI paradigm to clinical stroke rehabilitation. This work provides a novel MI paradigm and demonstrates its neural activation-enhancing performance, helping to develop more effective MI-based BCI system for stroke rehabilitation.",https://pubmed.ncbi.nlm.nih.gov/39453797/,https://pubmed.ncbi.nlm.nih.gov/39453797/,English,Include,,Enhancing ERD Activation and Functional Connectivity via the Sixth-Finger Motor Imagery in Stroke Patients.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39452032,pubmed:39452032,PubMed,pubmed:39452032,Multimodal Fusion of EEG and Audio Spectrogram for Major Depressive Disorder Recognition Using Modified DenseNet121.,Musyyab Yousufi;Robertas Damaševičius;Rytis Maskeliūnas,2024,10.3390/ijerph18126441,"This study investigates the classification of Major Depressive Disorder (MDD) using electroencephalography (EEG) Short-Time Fourier-Transform (STFT) spectrograms and audio Mel-spectrogram data of 52 subjects. The objective is to develop a multimodal classification model that integrates audio and EEG data to accurately identify depressive tendencies. We utilized the Multimodal open dataset for Mental Disorder Analysis (MODMA) and trained a pre-trained Densenet121 model using transfer learning. Features from both the EEG and audio modalities were extracted and concatenated before being passed through the final classification layer. Additionally, an ablation study was conducted on both datasets separately. The proposed multimodal classification model demonstrated superior performance compared to existing methods, achieving an Accuracy of 97.53%, Precision of 98.20%, F1 Score of 97.76%, and Recall of 97.32%. A confusion matrix was also used to evaluate the model's effectiveness. The paper presents a robust multimodal classification approach that outperforms state-of-the-art methods with potential application in clinical diagnostics for depression assessment.",https://pubmed.ncbi.nlm.nih.gov/39452032/,https://pubmed.ncbi.nlm.nih.gov/39452032/,English,Include,,Multimodal Fusion of EEG and Audio Spectrogram for Major Depressive Disorder Recognition Using Modified DenseNet121.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39452002,pubmed:39452002,PubMed,pubmed:39452002,A Lightweight Multi-Mental Disorders Detection Method Using Entropy-Based Matrix from Single-Channel EEG Signals.,Jiawen Li;Guanyuan Feng;Jujian Lv;Yanmei Chen;Rongjun Chen;Fei Chen;Shuang Zhang;Mang-I Vai;Sio-Hang Pun;Peng-Un Mak,2024,10.3389/fnins.2021.777183,,,https://pubmed.ncbi.nlm.nih.gov/39452002/,English,Exclude,Not classification-focused,A Lightweight Multi-Mental Disorders Detection Method Using Entropy-Based Matrix from Single-Channel EEG Signals.,,,,,0.85,0.6,
pubmed:39451420,pubmed:39451420,PubMed,pubmed:39451420,Remote Monitoring of Sympathovagal Imbalance During Sleep and Its Implications in Cardiovascular Risk Assessment: A Systematic Review.,Valerie A A van Es;Ignace L J de Lathauwer;Hareld M C Kemps;Giacomo Handjaras;Monica Betta,2024,10.3389/fnins.2021.642548,"Nocturnal sympathetic overdrive is an early indicator of cardiovascular (CV) disease, emphasizing the importance of reliable remote patient monitoring (RPM) for autonomic function during sleep. To be effective, RPM systems must be accurate, non-intrusive, and cost-effective. This review evaluates non-invasive technologies, metrics, and algorithms for tracking nocturnal autonomic nervous system (ANS) activity, assessing their CV relevance and feasibility for integration into RPM systems. A systematic search identified 18 relevant studies from an initial pool of 169 publications, with data extracted on study design, population characteristics, technology types, and CV implications. Modalities reviewed include electrodes (e.g., electroencephalography (EEG), electrocardiography (ECG), polysomnography (PSG)), optical sensors (e.g., photoplethysmography (PPG), peripheral arterial tone (PAT)), ballistocardiography (BCG), cameras, radars, and accelerometers. Heart rate variability (HRV) and blood pressure (BP) emerged as the most promising metrics for RPM, offering a comprehensive view of ANS function and vascular health during sleep. While electrodes provide precise HRV data, they remain intrusive, whereas optical sensors such as PPG demonstrate potential for multimodal monitoring, including HRV, SpO2, and estimates of arterial stiffness and BP. Non-intrusive methods like BCG and cameras are promising for heart and respiratory rate estimation, but less suitable for continuous HRV monitoring. In conclusion, HRV and BP are the most viable metrics for RPM, with PPG-based systems offering significant promise for non-intrusive, continuous monitoring of multiple modalities. Further research is needed to enhance accuracy, feasibility, and validation against direct measures of autonomic function, such as microneurography.",,https://pubmed.ncbi.nlm.nih.gov/39451420/,English,Exclude,Review/survey papers,Remote Monitoring of Sympathovagal Imbalance During Sleep and Its Implications in Cardiovascular Risk Assessment: A Systematic Review.,,,,,0.95,0.6,
pubmed:39451373,pubmed:39451373,PubMed,pubmed:39451373,Emotion Recognition Using EEG Signals and Audiovisual Features with Contrastive Learning.,Ju-Hwan Lee;Jin-Young Kim;Hyoung-Gook Kim,2024,10.1109/tmm.2024.3385180,"Multimodal emotion recognition has emerged as a promising approach to capture the complex nature of human emotions by integrating information from various sources such as physiological signals, visual behavioral cues, and audio-visual content. However, current methods often struggle with effectively processing redundant or conflicting information across modalities and may overlook implicit inter-modal correlations. To address these challenges, this paper presents a novel multimodal emotion recognition framework which integrates audio-visual features with viewers' EEG data to enhance emotion classification accuracy. The proposed approach employs modality-specific encoders to extract spatiotemporal features, which are then aligned through contrastive learning to capture inter-modal relationships. Additionally, cross-modal attention mechanisms are incorporated for effective feature fusion across modalities. The framework, comprising pre-training, fine-tuning, and testing phases, is evaluated on multiple datasets of emotional responses. The experimental results demonstrate that the proposed multimodal approach, which combines audio-visual features with EEG data, is highly effective in recognizing emotions, highlighting its potential for advancing emotion recognition systems.",https://pubmed.ncbi.nlm.nih.gov/39451373/,https://pubmed.ncbi.nlm.nih.gov/39451373/,English,Include,,Emotion Recognition Using EEG Signals and Audiovisual Features with Contrastive Learning.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39451362,pubmed:39451362,PubMed,pubmed:39451362,Ensemble Fusion Models Using Various Strategies and Machine Learning for EEG Classification.,Sunil Kumar Prabhakar;Jae Jun Lee;Dong-Ok Won,2024,10.3389/fnins.2016.00196,"Electroencephalography (EEG) helps to assess the electrical activities of the brain so that the neuronal activities of the brain are captured effectively. EEG is used to analyze many neurological disorders, as it serves as a low-cost equipment. To diagnose and treat every neurological disorder, lengthy EEG signals are needed, and different machine learning and deep learning techniques have been developed so that the EEG signals could be classified automatically. In this work, five ensemble models are proposed for EEG signal classification, and the main neurological disorder analyzed in this paper is epilepsy. The first proposed ensemble technique utilizes an equidistant assessment and ranking determination mode with the proposed Enhance the Sum of Connection and Distance (ESCD)-based feature selection technique for the classification of EEG signals; the second proposed ensemble technique utilizes the concept of Infinite Independent Component Analysis (I-ICA) and multiple classifiers with majority voting concept; the third proposed ensemble technique utilizes the concept of Genetic Algorithm (GA)-based feature selection technique and bagging Support Vector Machine (SVM)-based classification model. The fourth proposed ensemble technique utilizes the concept of Hilbert Huang Transform (HHT) and multiple classifiers with GA-based multiparameter optimization, and the fifth proposed ensemble technique utilizes the concept of Factor analysis with Ensemble layer K nearest neighbor (KNN) classifier. The best results are obtained when the Ensemble hybrid model using the equidistant assessment and ranking determination method with the proposed ESCD-based feature selection technique and Support Vector Machine (SVM) classifier is utilized, achieving a classification accuracy of 89.98%.",https://pubmed.ncbi.nlm.nih.gov/39451362/,https://pubmed.ncbi.nlm.nih.gov/39451362/,English,Include,,Ensemble Fusion Models Using Various Strategies and Machine Learning for EEG Classification.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39451342,pubmed:39451342,PubMed,pubmed:39451342,Integrating Electroencephalography Source Localization and Residual Convolutional Neural Network for Advanced Stroke Rehabilitation.,Sina Makhdoomi Kaviri;Ramana Vinjamuri,2024,10.1155/2011/156869,"Motor impairments caused by stroke significantly affect daily activities and reduce quality of life, highlighting the need for effective rehabilitation strategies. This study presents a novel approach to classifying motor tasks using EEG data from acute stroke patients, focusing on left-hand motor imagery, right-hand motor imagery, and rest states. By using advanced source localization techniques, such as Minimum Norm Estimation (MNE), dipole fitting, and beamforming, integrated with a customized Residual Convolutional Neural Network (ResNetCNN) architecture, we achieved superior spatial pattern recognition in EEG data. Our approach yielded classification accuracies of 91.03% with dipole fitting, 89.07% with MNE, and 87.17% with beamforming, markedly surpassing the 55.57% to 72.21% range of traditional sensor domain methods. These results highlight the efficacy of transitioning from sensor to source domain in capturing precise brain activity. The enhanced accuracy and reliability of our method hold significant potential for advancing brain-computer interfaces (BCIs) in neurorehabilitation. This study emphasizes the importance of using advanced EEG classification techniques to provide clinicians with precise tools for developing individualized therapy plans, potentially leading to substantial improvements in motor function recovery and overall patient outcomes. Future work will focus on integrating these techniques into practical BCI systems and assessing their long-term impact on stroke rehabilitation.",https://pubmed.ncbi.nlm.nih.gov/39451342/,https://pubmed.ncbi.nlm.nih.gov/39451342/,English,Include,,Integrating Electroencephalography Source Localization and Residual Convolutional Neural Network for Advanced Stroke Rehabilitation.,Include,,g the 55.57% to 72.21% range of traditional sensor domain methods. These results highlight the efficacy of transitioning from sensor to source domain in capturing precise brain activity. The enhanced accuracy and reliability of our method hold significant potential for advancing brain-computer interfaces (BCIs) in neurorehabilitation. This study emphasizes the importance of using advanced EEG clas,,0.95,0.6,
pubmed:39447056,pubmed:39447056,PubMed,pubmed:39447056,Behavioral and neurophysiological signatures of cognitive control in humans and rats.,Samantha R Linton;Ty Lees;Ann Iturra-Mena;Brian D Kangas;Genevieve Nowicki;Rachel Lobien;Gordana Vitaliano;Jack Bergman;William A Carlezon;Diego A Pizzagalli,2024,10.1093/ijnp/pyae050,"Deficits in cognitive control are implicated in numerous neuropsychiatric disorders. However, relevant pharmacological treatments are limited, likely due to weak translational validity of applicable preclinical models used. Neural indices derived from electroencephalography may prove useful in comparing and translating the effects of cognition-enhancing drugs between species. In the current study, we aimed to extend our previous cross-species results by examining if methylphenidate (MPH) modulates behavioral and neural indices of cognitive control in independent cohorts of humans and rats. We measured continuous electroencephalography data from healthy adults (n = 25; 14 female) and Long Evans rats (n = 22; 8 female) and compared both stimulus- and response-locked event-related potentials and spectral power measures across species, and their MPH-related moderation following treatment with vehicle (placebo) or 1 of 2 doses of MPH. Across both species, linear mixed effects modeling confirmed the expected Flanker interference effect on behavior (eg, accuracy) and response-related event-related potentials. Unexpectedly, in contrast to past work, we did not observe any task-related effects on the spectral power of rodents. Moreover, MPH generally did not modulate cognitive control of either species, although some species-specific patterns offer insight for future research. Collectively, these findings in independent human and rodent subjects replicate some of our previously reported behavioral and neurophysiological patterns partly consistent with the notion that similar neural mechanisms may regulate cognitive control in both species. Nonetheless, these results showcase an approach to accelerate translation using a coordinated between-species platform to evaluate pro-cognitive treatments.",https://pubmed.ncbi.nlm.nih.gov/39447056/,https://pubmed.ncbi.nlm.nih.gov/39447056/,English,Include,,Behavioral and neurophysiological signatures of cognitive control in humans and rats.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39443415,pubmed:39443415,PubMed,pubmed:39443415,Psychometrics of drift-diffusion model parameters derived from the Eriksen flanker task: Reliability and validity in two independent samples.,Brent Ian Rappaport;Stewart A Shankman;James E Glazer;Savannah N Buchanan;Anna Weinberg;Allison M Letkiewicz,2025,10.1016/j.neubiorev.2016.09.002,"The flanker task is a widely used measure of cognitive control abilities. Drift-diffusion modeling of flanker task behavior can yield separable parameters of cognitive control-related subprocesses, but the parameters' psychometrics are not well-established. We examined the reliability and validity of four behavioral measures: (1) raw accuracy, (2) reaction time (RT) interference, (3) NIH Toolbox flanker score, and (4) two drift-diffusion model (DDM) parameters-drift rate and boundary separation-capturing evidence accumulation efficiency and speed-accuracy trade-off, respectively. Participants from two independent studies - one cross-sectional (N = 381) and one with three timepoints (N = 83) - completed the flanker task while electroencephalography data were collected. Across both studies, drift rate and boundary separation demonstrated comparable split-half and test-retest reliability to accuracy, RT interference, and NIH Toolbox flanker score, but better incremental convergent validity with psychophysiological measures (i.e., the error-related negativity; ERN) and neuropsychological measures of cognitive control than the other behavioral indices. Greater drift rate (i.e., faster and more accurate responses) to congruent and incongruent stimuli, and smaller boundary separation to incongruent stimuli were related to 1) larger ERN amplitudes (in both studies) and 2) faster and more accurate inhibition and set-shifting over and above raw accuracy, reaction time, and NIH Toolbox flanker scores (in Study 1). Computational models, such as DDM, can parse behavioral performance into subprocesses that exhibit comparable reliability to other scoring approaches, but more meaningful relationships with other measures of cognitive control. The application of these computational models may be applied to existing data and enhance the identification of cognitive control deficits in psychiatric disorders.",,https://pubmed.ncbi.nlm.nih.gov/39443415/,English,Exclude,Outside date range,Psychometrics of drift-diffusion model parameters derived from the Eriksen flanker task: Reliability and validity in two independent samples.,,,,,0.95,0.8,small_sample_mentioned
pubmed:39443165,pubmed:39443165,PubMed,pubmed:39443165,Retrospective validation of automatic sleep analysis with grey areas model for human-in-the-loop scoring approach.,Matias Rusanen;Gabriel Jouan;Riku Huttunen;Sami Nikkonen;Sigríður Sigurðardóttir;Juha Töyräs;Brett Duce;Sami Myllymaa;Erna Sif Arnardottir;Timo Leppänen;Anna Sigridur Islind;Samu Kainulainen;Henri Korkalainen,2025,10.1007/s11325-014-0990-0,"State-of-the-art automatic sleep staging methods have demonstrated comparable reliability and superior time efficiency to manual sleep staging. However, fully automatic black-box solutions are difficult to adapt into clinical workflow due to the lack of transparency in decision-making processes. Transparency would be crucial for interaction between automatic methods and the work of sleep experts, i.e., in human-in-the-loop applications. To address these challenges, we propose an automatic sleep staging model (aSAGA) that effectively utilises both electroencephalography and electro-oculography channels while incorporating transparency of uncertainty in the decision-making process. We validated the model through extensive retrospective testing using a range of datasets, including open-access, clinical, and research-driven sources. Our channel-wise ensemble model, trained on both electroencephalography and electro-oculography signals, demonstrated robustness and the ability to generalise across various types of sleep recordings, including novel self-applied home polysomnography. Additionally, we compared model uncertainty with human uncertainty in sleep staging and studied various uncertainty mapping metrics to identify ambiguous regions, or ""grey areas"", that may require manual re-evaluation. The validation of this grey area concept revealed its potential to enhance sleep staging accuracy and to highlight regions in the recordings where sleep experts may struggle to reach a consensus. In conclusion, this study provides a technical basis and understanding of automatic sleep staging uncertainty. Our approach has the potential to improve the integration of automatic sleep staging into clinical practice; however, further studies are needed to test the model prospectively in real-world clinical settings and human-in-the-loop scoring applications.",,https://pubmed.ncbi.nlm.nih.gov/39443165/,English,Exclude,Outside date range,Retrospective validation of automatic sleep analysis with grey areas model for human-in-the-loop scoring approach.,,,,,0.95,0.6,
pubmed:39440187,pubmed:39440187,PubMed,pubmed:39440187,Investigating the effect of template head models on Event-Related Potential source localization: a simulation and real-data study.,Emma Depuydt;Yana Criel;Miet De Letter;Pieter van Mierlo,2024,10.1186/s12938-018-0463-y,"Event-Related Potentials (ERPs) are valuable for studying brain activity with millisecond-level temporal resolution. While the temporal resolution of this technique is excellent, the spatial resolution is limited. Source localization aims to identify the brain regions generating the EEG data, thus increasing the spatial resolution, but its accuracy depends heavily on the head model used. This study compares the performance of subject-specific and template-based head models in both simulated and real-world ERP localization tasks. Simulated data mimicking realistic ERPs was created to evaluate the impact of head model choice systematically, after which subject-specific and template-based head models were used for the reconstruction of the data. The different modeling approaches were also applied to a face recognition dataset. The results indicate that the template models capture the simulated activity less accurately, producing more spurious sources and identifying less true sources correctly. Furthermore, the results show that while creating more accurate and detailed head models is beneficial for the localization accuracy when using subject-specific head models, this is less the case for template head models. The main N170 source of the face recognition dataset was correctly localized to the fusiform gyrus, a known face processing area, using the subject-specific models. Apart from the fusiform gyrus, the template models also reconstructed several other sources, illustrating the localization inaccuracies. While template models allow researchers to investigate the neural generators of ERP components when no subject-specific MRIs are available, it could lead to misinterpretations. Therefore, it is important to consider a priori knowledge and hypotheses when interpreting results obtained with template head models, acknowledging potential localization errors.",https://pubmed.ncbi.nlm.nih.gov/39440187/,https://pubmed.ncbi.nlm.nih.gov/39440187/,English,Include,,Investigating the effect of template head models on Event-Related Potential source localization: a simulation and real-data study.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39438593,pubmed:39438593,PubMed,pubmed:39438593,Sensory-substitution based sound perception using a spinal computer-brain interface.,Gabriella Miklós;László Halász;Maximilian Hasslberger;Emilia Toth;Ljubomir Manola;Saman Hagh Gooie;Gijs van Elswijk;Bálint Várkuti;Loránd Erőss,2024,10.1038/s41598-024-75779-2,"Sensory substitution offers a promising approach to restore lost sensory functions. Here we show that spinal cord stimulation (SCS), typically used for chronic pain management, can potentially serve as a novel auditory sensory substitution device. We recruited 13 patients undergoing SCS implantation and translated everyday sound samples into personalized SCS patterns during their trial phase. In a sound identification task-where chance-level performance was 33.3%-participants ( ",,https://pubmed.ncbi.nlm.nih.gov/39438593/,English,Exclude,Not EEG-BCI focused,Sensory-substitution based sound perception using a spinal computer-brain interface.,,,,,0.9,0.8,small_sample_mentioned
pubmed:39438562,pubmed:39438562,PubMed,pubmed:39438562,Hybrid deep models for parallel feature extraction and enhanced emotion state classification.,Sivasankaran Pichandi;Gomathy Balasubramanian;Venkatesh Chakrapani,2024,10.1038/s41598-024-75850-y,"Emotions play a vital role in recognizing a person's thoughts and vary significantly with stress levels. Emotion and stress classification have gained considerable attention in robotics and artificial intelligence applications. While numerous methods based on machine learning techniques provide average classification performance, recent deep learning approaches offer enhanced results. This research presents a hybrid deep learning model that extracts features using AlexNet and DenseNet models, followed by feature fusion and dimensionality reduction via Principal Component Analysis (PCA). The reduced features are then classified using a multi-class Support Vector Machine (SVM) to categorize different types of emotions. The proposed model was evaluated using the DEAP and EEG Brainwave datasets, both well-suited for emotion analysis due to their comprehensive EEG signal recordings and diverse emotional stimuli. The DEAP dataset includes EEG signals from 32 participants who watched 40 one-minute music videos, while the EEG Brainwave dataset categorizes emotions into positive, negative, and neutral based on EEG recordings from participants exposed to six different film clips. The proposed model achieved an accuracy of 95.54% and 97.26% for valence and arousal categories in the DEAP dataset, respectively, and 98.42% for the EEG Brainwave dataset. These results significantly outperform existing methods, demonstrating the model's superior performance in terms of precision, recall, F1-score, specificity, and Mathew correlation coefficient. The integration of AlexNet and DenseNet, combined with PCA and multi-class SVM, makes this approach particularly effective for capturing the intricate patterns in EEG data, highlighting its potential for applications in human-computer interaction and mental health monitoring, marking a significant advancement over traditional methods.",https://pubmed.ncbi.nlm.nih.gov/39438562/,https://pubmed.ncbi.nlm.nih.gov/39438562/,English,Include,,Hybrid deep models for parallel feature extraction and enhanced emotion state classification.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39437806,pubmed:39437806,PubMed,pubmed:39437806,Classification of EEG evoked in 2D and 3D virtual reality: traditional machine learning versus deep learning.,MingLiang Zuo;BingBing Yu;Li Sui,2024,10.1088/2057-1976/ad89c5,,https://pubmed.ncbi.nlm.nih.gov/39437806/,https://pubmed.ncbi.nlm.nih.gov/39437806/,English,Include,,Classification of EEG evoked in 2D and 3D virtual reality: traditional machine learning versus deep learning.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39436882,pubmed:39436882,PubMed,pubmed:39436882,RSBagging: An ensemble classifier detecting the after-effects of ischemic stroke through EEG connectivity and microstates.,Fang Wang;Xueying Zhang;Peng Zhang;Fengyun Hu,2024,10.1109/10.391164,"Stroke can lead to significant after-effects, including motor function impairments, language impairments (aphasia), disorders of consciousness (DoC), and cognitive deficits. Computer-aided analysis of EEG connectivity matrices and microstates from bedside EEG monitoring can replace traditional clinical observation methods, offering an automatic approach to monitoring the progression of these after-effects. This EEG-based method also enables quicker and more efficient assessments for medical practitioners. In this study, we employed Functional Connectivity features that extract spatial representation and Microstate features that focus on the time domain representation to monitor the after-effects of ischemic stroke patients. As the dataset from stroke patients is heavily imbalanced across various clinical after-effects conditions, we designed an ensemble classifier, RSBagging, to address the issue of classifiers often favoring the majority classes in the classification of imbalanced datasets. The experimental results demonstrate that different connectivity matrices are effective for three classification tasks: consciousness level, motor disturbance, and stroke location. Using our RSBagging model, all three tasks achieve over 98% accuracy, sensitivity, specificity, and F1-score, significantly outperforming the existing classifiers SVM, XGBoost, and Random Forest. Therefore, the RSBagging classifier based on connectivity matrices offers an effective method for monitoring the after-effects in stroke patients.",https://pubmed.ncbi.nlm.nih.gov/39436882/,https://pubmed.ncbi.nlm.nih.gov/39436882/,English,Include,,RSBagging: An ensemble classifier detecting the after-effects of ischemic stroke through EEG connectivity and microstates.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39436529,pubmed:39436529,PubMed,pubmed:39436529,Multi-modal EEG NEO-FFI with Trained Attention Layer (MENTAL) for mental disorder prediction.,Garrett Greiner;Yu Zhang,2024,10.1186/s40708-024-00240-z,"Early detection and accurate diagnosis of mental disorders is difficult due to the complexity of the diagnostic process, resulting in conditions being left undiagnosed or misdiagnosed. Previous studies have demonstrated that features of Electroencephalogram (EEG) data, such as Power Spectral Density (PSD), are useful biomarkers for indicating the onset of various mental disorders. Existing models using EEG data are typically trained to distinguish between healthy and afflicted individuals, and they are unable to distinguish between individuals with different disorders. We propose MENTAL (Multi-modal EEG NEO-FFI with Trained Attention Layer) to predict an individual's mental state using both EEG and Neo-Five Factor Inventory (NEO-FFI) personality data. We include an attention layer that captures the interactions between personality traits and PSD features, and emphasizes the important PSD features. MENTAL features a Recurrent Neural Network (RNN) to model the temporal nature of EEG data. We train our model with the Two Decades Brainclinics Research Archive for Insights in Neuroscience (TDBRAIN) dataset, which consists of 1274 healthy and psychiatric individuals including over 30 different diagnoses. MENTAL is able to achieve 93.3% accuracy when trained to classify between healthy individuals and those with ADHD. When trained to identify individuals with ADHD from among 33 disorder classes, MENTAL improves accuracy from 70.5 to 81.7%. MENTAL also demonstrates over 20% improvement in predictive accuracy when trained for MDD prediction. For the multi-class classification task of three classes, MENTAL improves accuracy by 4%, and for five classes, by nearly 8%. MENTAL is the first multi-modal model that utilizes both EEG and NEO-FFI data for the task of mental disorder prediction. We are one of the first groups to utilize TDBRAIN for automated disorder classification. MENTAL is accessible and cost-effective, as EEG is more affordable than other neuroimaging methods such as MRI, and the NEO-FFI is a self- reported survey. Our model can lead to acceptance and support for individuals living with mental health challenges and improve quality of life in our society.",,https://pubmed.ncbi.nlm.nih.gov/39436529/,English,Exclude,Review/survey papers,Multi-modal EEG NEO-FFI with Trained Attention Layer (MENTAL) for mental disorder prediction.,,,,,0.95,0.6,
pubmed:39433073,pubmed:39433073,PubMed,pubmed:39433073,Task-oriented EEG denoising generative adversarial network for enhancing SSVEP-BCI performance.,Pu Zeng;Liangwei Fan;You Luo;Hui Shen;Dewen Hu,2024,10.1088/1741-2552/ad8963,,,https://pubmed.ncbi.nlm.nih.gov/39433073/,English,Exclude,Not classification-focused,Task-oriented EEG denoising generative adversarial network for enhancing SSVEP-BCI performance.,,,,,0.85,0.6,
pubmed:39433071,pubmed:39433071,PubMed,pubmed:39433071,Adversarial artifact detection in EEG-based brain-computer interfaces.,Xiaoqing Chen;Lubin Meng;Yifan Xu;Dongrui Wu,2024,10.1088/1741-2552/ad8964,,,https://pubmed.ncbi.nlm.nih.gov/39433071/,English,Exclude,Not classification-focused,Adversarial artifact detection in EEG-based brain-computer interfaces.,,,,,0.85,0.6,
pubmed:39431963,pubmed:39431963,PubMed,pubmed:39431963,Utility of Clinical Features in Identifying Electrographic Seizures in Hospitalized Patients Admitted for Non-Neurological Diagnoses.,Carolyn Tsai;Courtney Blodgett;Sunghyun Seo;Rizk Alghorazi;Lang Li;Bahjat Qaqish;William J Powers;Clio Rubinos,2024,10.1097/cce.0000000000001168,"Electrographic seizures (ESz) are seizures without prominent motor activity diagnosed with electroencephalogram and are a common complication in critically ill patients with alterations of consciousness. Previous studies suggested clinical signs, including ocular movement abnormalities, facial/periorbital twitching, or remote seizure risk factors, are sensitive for presence of ESz. To assess the utility of clinical features in identifying ESz in critically ill patients with alterations of consciousness. This is a retrospective case-control study of 50 patients admitted to the University of North Carolina (UNC) Medical Center and UNC Rex Hospital. Inpatients older than 18 years old undergoing continuous video electroencephalogram (cEEG) were included. Patients admitted for neurologic diagnoses were excluded. A total of 25 patients with ESz (Sz-EEG) were matched with 25 controls by electroencephalogram duration ± 12 hours (No-Sz-EEG). Elements of patient's history and physical findings previously shown to be sensitive for presence of ESz were collected. Descriptive statistical analyses were used. Most patients were admitted to medical ICUs (72%; n = 36). There was no difference between groups in clinical findings previously shown to be sensitive for ESz. Positive and negative likelihood ratios for these findings generally fell between 1-2 and 0.5-1, respectively, indicating they are inaccurate predictors for ESz. Patients with ESz had significantly higher mortality (p = 0.012). Our matched case-control study showed that in the critically ill patient population hospitalized in tertiary care centers and admitted for non-neurologic primary diagnoses, incidence of ocular movement abnormalities, facial/periorbital twitching, and presence of remote risk factors for seizures had low predictive accuracy for ESz. However, these findings are not generalizable to patients with neurologic diseases or to other practice settings with different levels of access to cEEG. We concluded that in this exploratory analysis of hospitalized critically ill patients with non-neurologic diagnoses, these clinical signs did not reliably stratify risk for ESz on cEEG. However, further prospective studies are needed to better evaluate these conclusions.",https://pubmed.ncbi.nlm.nih.gov/39431963/,https://pubmed.ncbi.nlm.nih.gov/39431963/,English,Include,,Utility of Clinical Features in Identifying Electrographic Seizures in Hospitalized Patients Admitted for Non-Neurological Diagnoses.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39429248,pubmed:39429248,PubMed,pubmed:39429248,Decoding the application of deep learning in neuroscience: a bibliometric analysis.,Yin Li;Zilong Zhong,2024,10.1016/j.neucom.2020.05.113,"The application of deep learning in neuroscience holds unprecedented potential for unraveling the complex dynamics of the brain. Our bibliometric analysis, spanning from 2012 to 2023, delves into the integration of deep learning in neuroscience, shedding light on the evolutionary trends and identifying pivotal research hotspots. Through the examination of 421 articles, this study unveils a significant growth in interdisciplinary research, marked by the burgeoning application of deep learning techniques in understanding neural mechanisms and addressing neurological disorders. Central to our findings is the critical role of classification algorithms, models, and neural networks in advancing neuroscience, highlighting their efficacy in interpreting complex neural data, simulating brain functions, and translating theoretical insights into practical diagnostics and therapeutic interventions. Additionally, our analysis delineates a thematic evolution, showcasing a shift from foundational methodologies toward more specialized and nuanced approaches, particularly in areas like EEG analysis and convolutional neural networks. This evolution reflects the field's maturation and its adaptation to technological advancements. The study further emphasizes the importance of interdisciplinary collaborations and the adoption of cutting-edge technologies to foster innovation in decoding the cerebral code. The current study provides a strategic roadmap for future explorations, urging the scientific community toward areas ripe for breakthrough discoveries and practical applications. This analysis not only charts the past and present landscape of deep learning in neuroscience but also illuminates pathways for future research, underscoring the transformative impact of deep learning on our understanding of the brain.",https://pubmed.ncbi.nlm.nih.gov/39429248/,https://pubmed.ncbi.nlm.nih.gov/39429248/,English,Include,,Decoding the application of deep learning in neuroscience: a bibliometric analysis.,Exclude,No performance metrics reported,No metrics found in full text,,0.9,0.6,
pubmed:39429223,pubmed:39429223,PubMed,pubmed:39429223,Multi-source domain transfer network based on subdomain adaptation and minimum class confusion for EEG emotion recognition.,Lei Zhu;Mengxuan Xu;Aiai Huang;Jianhai Zhang;Xufei Tan,2024,10.1080/10255842.2024.2417212,"Electroencephalogram (EEG) signals, which objectively reflect the state of the brain, are widely favored in emotion recognition research. However, the presence of cross-session and cross-subject variation in EEG signals has hindered the practical implementation of EEG-based emotion recognition technologies. In this article, we propose a multi-source domain transfer method based on subdomain adaptation and minimum class confusion (MS-SAMCC) in response to the addressed issue. First, we introduce the mix-up data augmentation technique to generate augmented samples. Next, we propose a minimum class confusion subdomain adaptation method (MCCSA) as a sub-module of the multi-source domain adaptation module. This approach enables global alignment between each source domain and the target domain, while also achieving alignment among individual subdomains within them. Additionally, we employ minimum class confusion (MCC) as a regularizer for this sub-module. We performed experiments on SEED, SEED IV, and FACED datasets. In the cross-subject experiments, our method achieved mean classification accuracies of 87.14% on SEED, 63.24% on SEED IV, and 42.07% on FACED. In the cross-session experiments, our approach obtained average classification accuracies of 94.20% on SEED and 71.66% on SEED IV. These results demonstrate that the MS-SAMCC approach proposed in this study can effectively address EEG-based emotion recognition tasks.",https://pubmed.ncbi.nlm.nih.gov/39429223/,https://pubmed.ncbi.nlm.nih.gov/39429223/,English,Include,,Multi-source domain transfer network based on subdomain adaptation and minimum class confusion for EEG emotion recognition.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39428077,pubmed:39428077,PubMed,pubmed:39428077,Quantifying population-level neural tuning functions using Ricker wavelets and the Bayesian bootstrap.,Laura Ahumada;Christian Panitz;Caitlin M Traiser;Faith E Gilbert;Mingzhou Ding;Andreas Keil,2025,10.1016/j.neuropsychologia.2014.07.009,"Experience changes visuo-cortical tuning. In humans, re-tuning has been studied during aversive generalization learning, in which the similarity of generalization stimuli (GSs) with a conditioned threat cue (CS+) is used to quantify tuning functions. Previous work utilized pre-defined tuning shapes (generalization and sharpening patterns). This approach may constrain the ways in which re-tuning can be characterized since the tuning patterns may not match the prototypical functions. The present study proposes a flexible and data-driven method for precisely quantifying changes in tuning based on the Ricker wavelet function and the Bayesian bootstrap. This method was applied to EEG and psychophysics data from an aversive generalization learning paradigm. The Ricker wavelet model fitted the steady-state visual event potentials (ssVEP), alpha-band power, and detection accuracy data well. A Morlet wavelet function was used for comparison and fit the data better in some situations, but was more challenging to interpret. The pattern of re-tuning in the EEG data, predicted by the Ricker model, resembled the shapes of the best fitting a-priori patterns. Although the re-tuning shape modeled by the Ricker function resembled the pre-defined shapes, the Ricker approach led to greater Bayes factors and more interpretable results compared to a-priori models. The Ricker approach was more easily fit and led to more interpretable results than a Morlet wavelet model. This work highlights the promise of the current method for capturing the precise nature of visuo-cortical tuning, unconstrained by the implementation of a-priori models.",,https://pubmed.ncbi.nlm.nih.gov/39428077/,English,Exclude,Outside date range,Quantifying population-level neural tuning functions using Ricker wavelets and the Bayesian bootstrap.,,,,,0.95,0.6,
pubmed:39428037,pubmed:39428037,PubMed,pubmed:39428037,Towards imagined speech: Identification of brain states from EEG signals for BCI-based communication systems.,Haresh M V;B Shameedha Begum,2025,10.1016/j.bbr.2024.115295,"The electroencephalogram (EEG) based brain-computer interface (BCI) system employing imagined speech serves as a mechanism for decoding EEG signals to facilitate control over external devices or communication with the external world at the moment the user desires. To effectively deploy such BCIs, it is imperative to accurately discern various brain states from continuous EEG signals when users initiate word imagination. This study involved the acquisition of EEG signals from 15 subjects engaged in four states: resting, listening, imagined speech, and actual speech, each involving a predefined set of 10 words. The EEG signals underwent preprocessing, segmentation, spatio-temporal and spectral analysis of each state, and functional connectivity analysis using the phase locking value (PLV) method. Subsequently, five features were extracted from the frequency and time-frequency domains. Classification tasks were performed using four machine learning algorithms in both pair-wise and multiclass scenarios, considering subject-dependent and subject-independent data. In the subject-dependent scenario, the random forest (RF) classifier achieved a maximum accuracy of 94.60 % for pairwise classification, while the artificial neural network (ANN) classifier achieved a maximum accuracy of 66.92 % for multiclass classification. In the subject-independent scenario, the random forest (RF) classifier achieved maximum accuracies of 81.02 % for pairwise classification and 55.58 % for multiclass classification. Moreover, EEG signals were classified based on frequency bands and brain lobes, revealing that the theta (θ) and delta (δ) bands, as well as the frontal and temporal lobes, are sufficient for distinguishing between brain states. The findings promise to develop a system capable of automatically segmenting imagined speech segments from continuous EEG signals.",,https://pubmed.ncbi.nlm.nih.gov/39428037/,English,Exclude,Outside date range,Towards imagined speech: Identification of brain states from EEG signals for BCI-based communication systems.,,,,,0.95,0.6,
pubmed:39426071,pubmed:39426071,PubMed,pubmed:39426071,Attention Induced Dual Convolutional-Capsule Network (AIDC-CN): A deep learning framework for motor imagery classification.,Ritesh Sur Chowdhury;Shirsha Bose;Sayantani Ghosh;Amit Konar,2024,10.1016/j.compbiomed.2024.109260,"In recent times, Electroencephalography (EEG)-based motor imagery (MI) decoding has garnered significant attention due to its extensive applicability in healthcare, including areas such as assistive robotics and rehabilitation engineering. Nevertheless, the decoding of EEG signals presents considerable challenges owing to their inherent complexity, non-stationary characteristics, and low signal-to-noise ratio. Notably, deep learning-based classifiers have emerged as a prominent focus for addressing the EEG signal decoding process. This study introduces a novel deep learning classifier named the Attention Induced Dual Convolutional-Capsule Network (AIDC-CN) with the specific aim of accurately categorizing various motor imagination class labels. To enhance the classifier's performance, a dual feature extraction approach leveraging spectrogram and brain connectivity networks has been employed, diversifying the feature set in the classification task. The main highlights of the proposed AIDC-CN classifier includes the introduction of a dual convolution layer to handle the brain connectivity and spectrogram features, addition of a novel self-attention module (SAM) to accentuate the relevant parts of the convolved spectrogram features, introduction of a new cross-attention module (CAM) to refine the outputs obtained from the dual convolution layers and incorporation of a Gaussian Error Linear Unit (GELU) based dynamic routing algorithm to strengthen the coupling among the primary and secondary capsule layers. Performance analysis undertaken on four public data sets depict the superior performance of the proposed model with respect to the state-of-the-art techniques. The code for this model is available at https://github.com/RiteshSurChowdhury/AIDC-CN.",https://pubmed.ncbi.nlm.nih.gov/39426071/,https://pubmed.ncbi.nlm.nih.gov/39426071/,English,Include,,Attention Induced Dual Convolutional-Capsule Network (AIDC-CN): A deep learning framework for motor imagery classification.,Include,," inherent complexity, non-stationary characteristics, and low signal-to-noise ratio. Notably, deep learning-based classifiers have emerged as a prominent focus for addressing the EEG signal decoding process. This study introduces a novel deep learning classifier named the Attention Induced Dual Convolutional-Capsule Network (AIDC-CN) with the specific aim of accurately categorizing various motor i",,0.95,0.6,
pubmed:39425602,pubmed:39425602,PubMed,pubmed:39425602,A brief survey on human activity recognition using motor imagery of EEG signals.,Seema Pankaj Mahalungkar;Rahul Shrivastava;Sanjeevkumar Angadi,2024,10.1080/15368378.2024.2415089,"Human being's biological processes and psychological activities are jointly connected to the brain. So, the examination of human activity is more significant for the well-being of humans. There are various models for brain activity detection considering neuroimaging for attaining decreased time requirement, increased control commands, and enhanced accuracy. Motor Imagery (MI)-based Brain-Computer Interface (BCI) systems create a way in which the brain can interact with the environment by processing Electroencephalogram (EEG) signals. Human Activity Recognition (HAR) deals with identifying the physiological activities of human beings based on sensory signals. This survey reviews the different methods available for HAR based on MI-EEG signals. A total of 50 research articles based on HAR from EEG signals are considered in this survey. This survey discusses the challenges faced by various techniques for HAR. Moreover, the papers are assessed considering various parameters, techniques, publication year, performance metrics, utilized tools, employed databases, etc. There were many techniques developed to solve the problem of HAR and they are classified as Machine Learning (ML) and Deep Learning (DL)models. At last, the research gaps and limitations of the techniques were discussed that contribute to developing an effective HAR. The brain plays a key role in connecting human biology and psychology, influencing our everyday activities. Understanding human activity is crucial for improving health and well-being. This study focuses on how the brain communicates with the outside world through brain signals, particularly using a method called Motor Imagery (MI) in Brain-Computer Interface (BCI) systems. These systems analyze brain signals, known as Electroencephalograms (EEGs), to detect and interpret human movements. Human Activity Recognition (HAR) is a field that identifies physical activities based on signals from the body. In this survey, we review 50 studies that use EEG signals to recognize human activities. We explore the different techniques that have been developed to tackle HAR and examine their performance based on factors like accuracy, speed, and tools used. These techniques are mainly classified into two categories: Machine Learning (ML) and Deep Learning (DL). This survey highlights the challenges that HAR systems face in recognizing activities from EEG signals. It also identifies gaps in the research and suggests areas for improvement to create more effective systems in the future. Ultimately, this research aims to help develop better technology for understanding human activity through brain signals, which could have important applications in health care and other areas.",,https://pubmed.ncbi.nlm.nih.gov/39425602/,English,Exclude,Review/survey papers,A brief survey on human activity recognition using motor imagery of EEG signals.,,,,,0.95,0.6,
pubmed:39424849,pubmed:39424849,PubMed,pubmed:39424849,EEG-based optimization of eye state classification using modified-BER metaheuristic algorithm.,Ahmed M Elshewey;Amel Ali Alhussan;Doaa Sami Khafaga;El-Sayed M Elkenawy;Zahraa Tarek,2024,10.1038/s41598-024-74475-5,"This article introduces the Modified Al-Biruni Earth Radius (MBER) algorithm, which seeks to improve the precision of categorizing eye states as either open (0) or closed (1). The evaluation of the proposed algorithm was assessed using an available EEG dataset that applied preprocessing techniques, including scaling, normalization, and elimination of null values. The MBER algorithm's binary format is specifically designed to select features that can significantly enhance the accuracy of classification. The proposed algorithm and competing ones, namely, Al-Biruni Earth Radius (BER), Particle Swarm Optimization (PSO), Whale Optimization Algorithm (WAO), Grey Wolf Optimizer (GWO) and Genetic Algorithm (GA) were evaluated using predefined sets of assessment criteria. The statistical analysis employed the ANOVA and Wilcoxon signed-rank tests and assessed the effectiveness and significance of the proposed algorithm compared to the other five algorithms. Furthermore, A series of visual depictions were presented to validate the effectiveness and robustness of the proposed algorithm. Thus, the MBER algorithm outperformed the other optimizers on the majority of the unimodal benchmark functions due to these considerations. Different ML models were used for classification, e.g., DT, RF, KNN, SGD, GNB, SVC, and LR. The KNN model achieved the highest values of Precision (PPV) (0.959425), Negative Predictive Value (NPV) (0.964969), FScore (0.963431), accuracy (0.9612), Sensitivity (0.970578) and Specificity (0.949711). Thus, KNN serves as a fitness function and is optimized by the utilization of Modified Al-Biruni earth radius (MBER). Finally, the accuracy of eye state classification achieved 96.12% using the proposed algorithm.",https://pubmed.ncbi.nlm.nih.gov/39424849/,https://pubmed.ncbi.nlm.nih.gov/39424849/,English,Include,,EEG-based optimization of eye state classification using modified-BER metaheuristic algorithm.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39423832,pubmed:39423832,PubMed,pubmed:39423832,Reducing power requirements for high-accuracy decoding in iBCIs.,Brianna M Karpowicz;Bareesh Bhaduri;Samuel R Nason-Tomaszewski;Brandon G Jacques;Yahia H Ali;Robert D Flint;Payton H Bechefsky;Leigh R Hochberg;Nicholas AuYong;Marc W Slutzky;Chethan Pandarinath,2024,10.1038/s41586-023-06714-0,,https://pubmed.ncbi.nlm.nih.gov/39423832/,https://pubmed.ncbi.nlm.nih.gov/39423832/,English,Include,,Reducing power requirements for high-accuracy decoding in iBCIs.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39423829,pubmed:39423829,PubMed,pubmed:39423829,Identification of perceived sentences using deep neural networks in EEG.,Carlos Valle;Carolina Mendez-Orellana;Christian Herff;Maria Rodriguez-Fernandez,2024,10.1088/1741-2552/ad88a3,,,https://pubmed.ncbi.nlm.nih.gov/39423829/,English,Exclude,Not classification-focused,Identification of perceived sentences using deep neural networks in EEG.,,,,,0.85,0.6,
pubmed:39423516,pubmed:39423516,PubMed,pubmed:39423516,Standardized Kalman filtering for dynamical source localization of concurrent subcortical and cortical brain activity.,Joonas Lahtinen;Paavo Ronni;Narayan Puthanmadam Subramaniyam;Alexandra Koulouri;Carsten Wolters;Sampsa Pursiainen,2024,10.1016/j.clinph.2024.09.021,"We introduce standardized Kalman filtering (SKF) as a new spatiotemporal method for tracking brain activity. Via the Kalman filtering scheme, the computational workload is low, and by spatiotemporal standardization, we reduce the depth bias of non-standardized Kalman filtering (KF). We describe the standardized KF methodology for spatiotemporal tracking from the Bayesian perspective. We construct a realistic simulation setup that resembles activity due to somatosensory evoked potential (SEP) to validate the proposed methodology before we run our tests using real SEP data. In the experiments, SKF was compared with standardized low-resolution brain electromagnetic tomography (sLORETA) and the non-standardized KF. SKF localized the cortical and subcortical SEP originators appropriately and tracked P20/N20 originators for investigated signal-to-noise ratios (25, 15, and 5 dB). sLORETA distinguished those for 25 and 15 dB suppressing the subcortical originators. KF tracked only the evolution of cortical activity but mislocalized it. The numerical results suggest that SKF inherits the estimation accuracy of sLORETA and traceability of KF while producing focal estimates for SEP originators. SKF could help study time-evolving brain activities and localize landmarks with a deep contributor or when there is no prior knowledge of evolution.",,https://pubmed.ncbi.nlm.nih.gov/39423516/,English,Exclude,Not EEG-BCI focused,Standardized Kalman filtering for dynamical source localization of concurrent subcortical and cortical brain activity.,,,,,0.9,0.6,
pubmed:39423425,pubmed:39423425,PubMed,pubmed:39423425,Electrocorticography and navigated transcranial magnetic stimulation-tailored supratotal resection for epileptogenic low-grade gliomas.,Francesca Battista;Giovanni Muscas;Alberto Parenti;Camilla Bonaudo;Davide Gadda;Cristiana Martinelli;Riccardo Carrai;Andrea Amadori;Antonello Grippo;Alessandro Della Puppa,2025,10.3171/2024.6.jns24597,"Epilepsy is commonly associated with low-grade gliomas (LGGs), impacting patients' well-being. While resection is the primary treatment, seizures can persist postoperatively in 27%-55% of cases. The authors aimed to evaluate an electrocorticography (ECoG) and navigated transcranial magnetic stimulation (nTMS)-tailored supratotal resection (ETT-SpTR) for LGG in controlling seizures, preserving neurological function, and enhancing treatment effectiveness. The authors retrospectively analyzed a prospectively enrolled cohort of patients with LGG presenting with epileptic seizures with ictal/interictal activity on electroencephalography (EEG) who underwent resective surgery. The authors performed preoperative nTMS to identify functional cortical areas. ECoG was used to guide the removal of the high-risk epilepsy cortical areas (HREAs). Patients were divided into two groups: group I, the control group, underwent gross-total resection alone, whereas group II patients underwent removal of HREAs identified by ECoG (ETT-SpTR). Resection avoided functionally eloquent areas as identified on nTMS, checked with cortical mapping. Postoperative seizure outcome was assessed using the Engel classification. Fifteen patients who underwent LGG resection between January and July 2023 were included. Among 24 identified nTMS-positive points, none were included in the resection. Overall, 73.3% of patients (11/15) showed positive intraoperative ECoG, with better outcomes in group II (85.7% Engel class IA) than in group I (25% Engel class IA) at the follow-up (p = 0.02, OR 0.5 [95% CI 0.035-7.10], RR 0.19 [95% CI 0.03-1.2]). Seizure control was significantly better in group II, with no notable differences in postoperative transient neurological deficits between the two groups (p = 0.45). No permanent neurological deficits were observed during follow-up. Statistical analysis revealed significant differences between the two groups (p < 0.05). This preliminary study affirms the predictive value of TMS for postoperative neurological status and safety in epileptic patients. Intraoperative ECoG effectively identified peritumoral HREAs. ETT-SpTR significantly improved epileptic outcomes, preserving functions without permanent neurological worsening. Additional resection targets the HREAs in the temporal, frontal, and parietal lobes.",,https://pubmed.ncbi.nlm.nih.gov/39423425/,English,Exclude,Outside date range,Electrocorticography and navigated transcranial magnetic stimulation-tailored supratotal resection for epileptogenic low-grade gliomas.,,,,,0.95,0.6,
pubmed:39423321,pubmed:39423321,PubMed,pubmed:39423321,Predicting the effectiveness of binaural beats on working memory.,Ahmad Zahid Rao;Muhammad Danish Mujib;Saad Ahmed Qazi;Ahmad O Alokaily;Ayesha Ikhlaq;Eraj Humayun Mirza;Ahmed Ali Aldohbeyb;Muhammad Abul Hasan,2024,10.1097/wnr.0000000000002101,"Working memory is vital for short-term information processing. Binaural beats can enhance working memory by improving attention and memory consolidation through neural synchronization. However, individual differences in cognitive and neuronal functioning affect effectiveness of binaural beats, necessitating personalized approaches. This study aimed to develop a machine learning model to predict binaural beats's effectiveness on working memory using electroencephalography. Sixty healthy participants underwent a 5-min electroencephalography recording, an initial working memory evaluation, 15 min of binaural beats stimulation, and a subsequent working memory evaluation using digit span tests of increasing difficulty. Recall accuracy and response times were measured. Differential scores from pre-evaluation and post-evaluation labeled participants as active or inactive to binaural beats stimulation. electroencephalography data, recorded using 14 electrodes, provided brain activity estimates across theta, alpha, beta, and gamma frequency bands, resulting in 56 features (14 channels × 4 bands) for the machine learning model. Several classifiers were tested to identify the most effective model. The weighted K-nearest neighbors model achieved the highest accuracy (90.0%) and area under the receiver operating characteristic curve (92.24%). Frontal and parietal electroencephalography channels in theta and alpha bands were crucial for classification. This study's findings offer significant clinical insights, enabling informed interventions and preventing resource inefficiency.",https://pubmed.ncbi.nlm.nih.gov/39423321/,https://pubmed.ncbi.nlm.nih.gov/39423321/,English,Include,,Predicting the effectiveness of binaural beats on working memory.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39423083,pubmed:39423083,PubMed,pubmed:39423083,Motor-Related EEG Analysis Using a Pole Tracking Approach.,Kyriaki Kostoglou;Gernot R Muller-Putz,2024,10.1109/tnsre.2024.3483294,"This study introduces an alternative approach to electroencephalography (EEG) time-frequency analysis based on time-varying autoregressive (TV-AR) models in a cascade configuration to independently monitor key EEG spectral components. The method is evaluated for its neurophysiological interpretation and effectiveness in motor-related brain-computer interface (BCI) applications. Specifically, we assess the ability of the tracked EEG poles to discriminate between rest, movement execution (ME) and movement imagination (MI) in healthy subjects, as well as movement attempts (MA) in individuals with spinal cord injury (SCI). Our results show that pole tracking effectively captures broad changes in EEG dynamics, such as transitions between rest and movement-related states. It outperformed traditional EEG-based features, increasing detection accuracy for ME by an average of 4.1% (with individual improvements reaching as high as 15%) and MI by an average of 4.5% (up to 13.8%) compared to time-domain low-frequency EEG features. Similarly, compared to alpha/beta band power, the method improved ME detection by an average of 5.9% (up to 10.4%) and MI by an average of 4.3% (up to 10.2%), with results averaged across 15 healthy participants. In one participant with SCI, pole tracking improved MA detection by 12.9% over low-frequency EEG features and 4.8% over alpha/beta band power. However, its ability to distinguish finer movement details within specific movement types was limited. Additionally, the temporal evolution of the extracted pole tracking features revealed event-related desynchronization phenomena, typically observed during ME, MA and MI, as well as increases in frequency, which are of neurophysiological interest.",https://pubmed.ncbi.nlm.nih.gov/39423083/,https://pubmed.ncbi.nlm.nih.gov/39423083/,English,Include,,Motor-Related EEG Analysis Using a Pole Tracking Approach.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39422820,pubmed:39422820,PubMed,pubmed:39422820,Improved ADHD Diagnosis Using EEG Connectivity and Deep Learning through Combining Pearson Correlation Coefficient and Phase-Locking Value.,Elham Ahmadi Moghadam;Farhad Abedinzadeh Torghabeh;Seyyed Abed Hosseini;Mohammad Hossein Moattar,2024,10.47577/tssj.v30i1.6266,"Attention Deficit Hyperactivity Disorder (ADHD) is a widespread neurobehavioral disorder affecting children and adolescents, requiring early detection for effective treatment. EEG connectivity measures can reveal the interdependencies between EEG recordings, highlighting brain network patterns and functional behavior that improve diagnostic accuracy. This study introduces a novel ADHD diagnostic method by combining linear and nonlinear brain connectivity maps with an attention-based convolutional neural network (Att-CNN). Pearson Correlation Coefficient (PCC) and Phase-Locking Value (PLV) are used to create fused connectivity maps (FCMs) from various EEG frequency subbands, which are then inputted into the Att-CNN. The attention module is strategically placed after the latest convolutional layer in the CNN. The performance of different optimizers (Adam and SGD) and learning rates are assessed. The suggested model obtained 98.88%, 98.41%, 98.19%, and 98.30% for accuracy, precision, recall, and F1 Score, respectively, using the SGD optimizer in the FCM of the theta band with a learning rate of 1e-1. With the use of FCM, Att-CNN, and advanced optimizers, the proposed technique has the potential to produce trustworthy instruments for the early diagnosis of ADHD, greatly enhancing both patient outcomes and diagnostic accuracy.",https://pubmed.ncbi.nlm.nih.gov/39422820/,https://pubmed.ncbi.nlm.nih.gov/39422820/,English,Include,,Improved ADHD Diagnosis Using EEG Connectivity and Deep Learning through Combining Pearson Correlation Coefficient and Phase-Locking Value.,Include,,"tection for effective treatment. EEG connectivity measures can reveal the interdependencies between EEG recordings, highlighting brain network patterns and functional behavior that improve diagnostic accuracy. This study introduces a novel ADHD diagnostic method by combining linear and nonlinear brain connectivity maps with an attention-based convolutional neural network (Att-CNN). Pearson Correla",,0.95,0.6,
pubmed:39421856,pubmed:39421856,PubMed,pubmed:39421856,The Effect of Jittered Stimulus Onset Interval on Electrophysiological Markers of Attention in a Brain-Computer Interface Rapid Serial Visual Presentation Paradigm.,Daniel Klee;Tab Memmott;Barry Oken,2024,10.1016/j.neuroscience.2020.02.011,"Brain responses to discrete stimuli are modulated when multiple stimuli are presented in sequence. These alterations are especially pronounced when the time course of an evoked response overlaps with responses to subsequent stimuli, such as in a rapid serial visual presentation (RSVP) paradigm used to control a brain-computer interface (BCI). The present study explored whether the measurement or classification of select brain responses during RSVP would improve through application of an established technique for dealing with overlapping stimulus presentations, known as irregular or ""jittered"" stimulus onset interval (SOI). EEG data were collected from 24 healthy adult participants across multiple rounds of RSVP calibration and copy phrase tasks with varying degrees of SOI jitter. Analyses measured three separate brain signals sensitive to attention: N200, P300, and occipitoparietal alpha attenuation. Presentation jitter visibly reduced intrusion of the SSVEP, but in general, it did not positively or negatively affect attention effects, classification, or system performance. Though it remains unclear whether stimulus overlap is detrimental to BCI performance overall, the present study demonstrates that single-trial classification approaches may be resilient to rhythmic intrusions like SSVEP that appear in the averaged EEG.",https://pubmed.ncbi.nlm.nih.gov/39421856/,https://pubmed.ncbi.nlm.nih.gov/39421856/,English,Include,,The Effect of Jittered Stimulus Onset Interval on Electrophysiological Markers of Attention in a Brain-Computer Interface Rapid Serial Visual Presentation Paradigm.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39420525,pubmed:39420525,PubMed,pubmed:39420525,Artificial intelligence for brain disease diagnosis using electroencephalogram signals.,Shunuo Shang;Yingqian Shi;Yajie Zhang;Mengxue Liu;Hong Zhang;Ping Wang;Liujing Zhuang,2024,10.1109/jbhi.2019.2933046,"Brain signals refer to electrical signals or metabolic changes that occur as a consequence of brain cell activity. Among the various non-invasive measurement methods, electroencephalogram (EEG) stands out as a widely employed technique, providing valuable insights into brain patterns. The deviations observed in EEG reading serve as indicators of abnormal brain activity, which is associated with neurological diseases. Brain‒computer interface (BCI) systems enable the direct extraction and transmission of information from the human brain, facilitating interaction with external devices. Notably, the emergence of artificial intelligence (AI) has had a profound impact on the enhancement of precision and accuracy in BCI technology, thereby broadening the scope of research in this field. AI techniques, encompassing machine learning (ML) and deep learning (DL) models, have demonstrated remarkable success in classifying and predicting various brain diseases. This comprehensive review investigates the application of AI in EEG-based brain disease diagnosis, highlighting advancements in AI algorithms. 大脑信号反映了脑细胞活动引起的电信号变化或代谢变化。在各种非侵入性测量方法中，脑电图作为一种广泛应用的技术可以帮助了解大脑模式。脑电图中的异常读数可作为与神经系统疾病相关的脑活动的指标。脑机接口（BCI）系统能够直接从人脑提取和传输信息，从而实现与外部设备的交互。人工智能（AI）的出现极大地提高了BCI技术精度和准确性，并拓宽了该领域的研究范围。AI技术包括机器学习（ML）和深度学习（DL）模型，可以利用脑信号对各种脑部疾病进行分类和预测。本文综述了AI在基于脑电图的脑部疾病诊断中的应用，特别是AI算法在该领域应用的进展。. 大脑信号反映了脑细胞活动引起的电信号变化或代谢变化。在各种非侵入性测量方法中，脑电图作为一种广泛应用的技术可以帮助了解大脑模式。脑电图中的异常读数可作为与神经系统疾病相关的脑活动的指标。脑机接口（BCI）系统能够直接从人脑提取和传输信息，从而实现与外部设备的交互。人工智能（AI）的出现极大地提高了BCI技术精度和准确性，并拓宽了该领域的研究范围。AI技术包括机器学习（ML）和深度学习（DL）模型，可以利用脑信号对各种脑部疾病进行分类和预测。本文综述了AI在基于脑电图的脑部疾病诊断中的应用，特别是AI算法在该领域应用的进展。",,https://pubmed.ncbi.nlm.nih.gov/39420525/,English,Exclude,Review/survey papers,Artificial intelligence for brain disease diagnosis using electroencephalogram signals.,,,,,0.95,0.6,
pubmed:39420009,pubmed:39420009,PubMed,pubmed:39420009,Differentiating neurodegenerative diseases based on EEG complexity.,Giovanni Mostile;Roberta Terranova;Giulia Carlentini;Federico Contrafatto;Claudio Terravecchia;Giulia Donzuso;Giorgia Sciacca;Calogero Edoardo Cicero;Antonina Luca;Alessandra Nicoletti;Mario Zappia,2024,10.1038/s41598-024-74035-x,"Neurodegenerative diseases are common causes of impaired mobility and cognition in the elderly. Among them, tauopathies and α-synucleinopathies were considered. The neurodegenerative processes and relative differential diagnosis were addressed through a qEEG non-linear analytic method. Study aims were to test accuracy of the power law exponent β applied to EEG in differentiating neurodegenerative diseases and to explore differences in neuronal connectivity among different neurodegenerative processes based on β. N = 230 patients with a diagnosis of tauopathy or α-synucleinopathy and at least one artifact-free EEG recording were selected. Periodogram was applied to EEG signal epochs from continuous recordings. Power law exponent β was determined by the slope of the signal power spectrum versus frequency in logarithmic scale. A data-driven clustering based on β values was performed to identify independent subgroups. Data-driven clustering based on β differentiated tauopathies (overall lower β values) from α-synucleinopathies (higher β values) with high sensitivity and specificity. Tauopathies also presented lower values in the correlation coefficients matrix among frontal sites of recording. In conclusion, significant differences in β values were found between tauopathies and α-synucleinopathies. Hence, β is proposed as a possible biomarker of differential diagnosis and neuronal connectivity.",https://pubmed.ncbi.nlm.nih.gov/39420009/,https://pubmed.ncbi.nlm.nih.gov/39420009/,English,Include,,Differentiating neurodegenerative diseases based on EEG complexity.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39419923,pubmed:39419923,PubMed,pubmed:39419923,Electrophysiological signature of interoceptive attention: a spectral and source localization analysis.,Davide Crivelli;Michela Balconi,2025,10.1073/pnas.97.26.14748,"The ability to attend to and consciously process interoceptive signals is deemed critical for the development of minimal self, adaptive self-regulation and affective experience, and optimal expression of both instrumental and executive cognitive functions. Yet, notwithstanding the richness of theoretical proposals concerning inferential accounts of interoception, empirical evidence is still scarce. Building on such premises, this study was designed to investigate the electrophysiological signature of cognitive processes leading to aware coding of interoceptive signals via EEG source localization. Thirty-six healthy participants completed an interoceptive accuracy task, i.e., the Heartbeat Counting Task (HCT), while we collected task-related and resting state electrophysiological activity. eLORETA modelling and statistical nonparametric mapping were used to estimate intracortical current density and link such estimates to participants' performance at the task. Source analysis highlighted higher current density estimates for alpha frequencies during HCT with respect to rest, with the primary cortical generator in the right parahippocampal gyrus. Also, a set of medial cortical structures-primarily represented by the cingulate gyrus-showed significant relation between task-related changes in current density estimates for beta oscillations and HCT scores. Findings suggest the informativity of EEG task-related measures of neural activation when used to assess interoceptive skills, as well as of the potential of metrics and analysis based on source localization in the quest to improve our understanding of interoceptive accuracy and neurofunctional correlates of related active inferences.",,https://pubmed.ncbi.nlm.nih.gov/39419923/,English,Exclude,Outside date range,Electrophysiological signature of interoceptive attention: a spectral and source localization analysis.,,,,,0.95,0.8,small_sample_mentioned
pubmed:39419239,pubmed:39419239,PubMed,pubmed:39419239,Do prolonged social media use or cognitive tasks impair neuroelectric and visuomotor performance in taekwondo athletes? A randomized and controlled trial.,Heloiana Faro;Emerson Franchini;Douglas Cavalcante-Silva;Rodrigo Diego Morais da Silva;Bruno Teixeira Barbosa;Daniel Gomes da Silva Machado;Leonardo de Sousa Fortes,2025,10.1016/j.psychsport.2024.102768,"We aimed to compare whether: (1) social media use (SMU) would induce a similar state of mental fatigue compared to the Modified Stroop task (MST); (2) the SMU and the MST would affect neuroelectric responses; and (3) sport-specific visuomotor performance in the taekwondo (TKD) athletes was impaired by mental fatigue. Fifteen TKD athletes underwent a 60-min Modified Stroop Task (MST), engaged in SMU, or watched a documentary (CON) in a randomized order. Pre and post-each conditions they responded to a Stroop task (ST) while the event-related potentials (ERP) were measured. The Visual Analogue Scale for mental tiredness (VAS-MT) was used to measure subjective feelings of mental fatigue Then, the athletes completed TKD-specific visuomotor tests. The VAS-MT response increases progressively in the MST condition (p < 0.001). The response time of ST was slower in the MST than in SMU (p = 0.04). The accuracy dropped in MST comparing pre- and post-manipulation (p < 0.001) and was lower than post-CON (p = 0.005). The peak amplitude for N200 ERP was higher post-than pre for all conditions (p < 0.001) on the Fz channel. N200 amplitude was higher on CON than MST on post-manipulation (p = 0.02). The amplitude increased significantly from pre-to post in the CON condition (p = 0.009) on the Cz channel. There was no difference in visuomotor performance among conditions (all ps > 0.05). Prolonged performance of the MST, but not SMU, induces a state of mental fatigue. Neuroelectric and cognitive responses were impaired by mental fatigue induced by MST, but the visuomotor performance remained unaffected by any condition.",,https://pubmed.ncbi.nlm.nih.gov/39419239/,English,Exclude,Outside date range,Do prolonged social media use or cognitive tasks impair neuroelectric and visuomotor performance in taekwondo athletes? A randomized and controlled trial.,,,,,0.95,0.6,
pubmed:39419108,pubmed:39419108,PubMed,pubmed:39419108,Brain and muscle derived features to discriminate simple hand motor tasks for a rehabilitative BCI: comparative study on healthy and post-stroke individuals.,Valeria de Seta;Emma Colamarino;Floriana Pichiorri;Giulia Savina;Francesca Patarini;Angela Riccio;Febo Cincotti;Donatella Mattia;Jlenia Toppi,2024,10.1088/1741-2552/ad8838,,,https://pubmed.ncbi.nlm.nih.gov/39419108/,English,Exclude,Not classification-focused,Brain and muscle derived features to discriminate simple hand motor tasks for a rehabilitative BCI: comparative study on healthy and post-stroke individuals.,,,,,0.85,0.6,
pubmed:39419024,pubmed:39419024,PubMed,pubmed:39419024,Accurate neural control of a hand prosthesis by posture-related activity in the primate grasping circuit.,Andres Agudelo-Toro;Jonathan A Michaels;Wei-An Sheng;Hansjörg Scherberger,2024,10.1016/j.neuron.2024.09.018,"Brain-computer interfaces (BCIs) have the potential to restore hand movement for people with paralysis, but current devices still lack the fine control required to interact with objects of daily living. Following our understanding of cortical activity during arm reaches, hand BCI studies have focused primarily on velocity control. However, mounting evidence suggests that posture, and not velocity, dominates in hand-related areas. To explore whether this signal can causally control a prosthesis, we developed a BCI training paradigm centered on the reproduction of posture transitions. Monkeys trained with this protocol were able to control a multidimensional hand prosthesis with high accuracy, including execution of the very intricate precision grip. Analysis revealed that the posture signal in the target grasping areas was the main contributor to control. We present, for the first time, neural posture control of a multidimensional hand prosthesis, opening the door for future interfaces to leverage this additional information channel.",https://pubmed.ncbi.nlm.nih.gov/39419024/,https://pubmed.ncbi.nlm.nih.gov/39419024/,English,Include,,Accurate neural control of a hand prosthesis by posture-related activity in the primate grasping circuit.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39417111,pubmed:39417111,PubMed,pubmed:39417111,Quantitative EEG Spectral Features Differentiate Genetic Epilepsies and Predict Neurologic Outcomes.,Peter D Galer;Jillian L McKee;Sarah M Ruggiero;Michael C Kaufman;Ian McSalley;Shiva Ganesan;William K S Ojemann;Alexander K Gonzalez;Quy Cao;Brian Litt;Ingo Helbig;Erin C Conrad,2024,10.1088/1741-2552/aceca1,"EEG plays an integral part in the diagnosis and management of children with genetic epilepsies. Nevertheless, how quantitative EEG features differ between genetic epilepsies and neurological outcomes remains largely unknown. Here, we aimed to identify quantitative EEG biomarkers in children with epilepsy and a genetic diagnosis in ",,https://pubmed.ncbi.nlm.nih.gov/39417111/,English,Exclude,Not classification-focused,Quantitative EEG Spectral Features Differentiate Genetic Epilepsies and Predict Neurologic Outcomes.,,,,,0.85,0.6,
pubmed:39415942,pubmed:39415942,PubMed,pubmed:39415942,Generative AI with WGAN-GP for boosting seizure detection accuracy.,Lina Abou-Abbas;Khadidja Henni;Imene Jemal;Neila Mezghani,2024,10.1088/1741-2552/aca04f,"Imbalanced datasets pose challenges for developing accurate seizure detection systems based on electroencephalogram (EEG) data. Generative AI techniques may help augment minority class data to facilitate automatic epileptic seizure detection. This study investigates the impact of various data augmentation (DA) approaches, including Wasserstein Generative Adversarial Network with Gradient Penalty (WGAN-GP), Vanilla GAN, Conditional GAN (CGAN), and Cramer GAN, on classification performance with Random Forest models. The best-performing GAN variant, WGAN-GP, was then integrated with a bidirectional Long Short-Term Memory (LSTM) architecture and compared against traditional and synthetic oversampling methods. The evaluation of different GAN variants for data augmentation with Random Forest classifiers identified WGAN-GP as the most effective approach. The integration of WGAN-GP with bidirectional LSTM yielded substantial performance improvements, outperforming traditional oversampling methods and achieving an accuracy of 91.73% on the augmented data, compared to 86% accuracy on real data without augmentation. The proposed generative AI approach combining WGAN-GP and recurrent neural network models outperforms comparative synthetic oversampling methods on metrics relevant for reliable seizure detection from imbalanced EEG datasets. Incorporating the WGAN-GP generative AI technique for data augmentation and integrating it with bidirectional LSTM elevates seizure detection accuracy for imbalanced EEG datasets, surpassing the performance of traditional oversampling and class weight adjustment methods. This approach shows promise for improving epilepsy monitoring and management through enhanced automated detection system effectiveness.",https://pubmed.ncbi.nlm.nih.gov/39415942/,https://pubmed.ncbi.nlm.nih.gov/39415942/,English,Include,,Generative AI with WGAN-GP for boosting seizure detection accuracy.,Include,,"GAN-GP as the most effective approach. The integration of WGAN-GP with bidirectional LSTM yielded substantial performance improvements, outperforming traditional oversampling methods and achieving an accuracy of 91.73% on the augmented data, compared to 86% accuracy on real data without augmentation. The proposed generative AI approach combining WGAN-GP and recurrent neural network models outperfo",,0.95,0.6,
pubmed:39415264,pubmed:39415264,PubMed,pubmed:39415264,Brain-to-brain synchrony increased during interpersonal touch in romantic lovers: an EEG-based hyperscanning study.,Chenghao Zhou;Xiaowei Jiang;Yanan Chen;Chunlei Ge;Na Ao;Feng Du,2024,10.1186/s40359-024-02051-7,"Interpersonal touch is an essential element of human social life. It's unclear whether the neural patterns of interpersonal touch are specific to intimate relationships or generally apply to other social relationships. Romantic lovers are typically intimate and have a high level of interpersonal touch. Currently, researchers focused on the neurobiological basis and neural processes of romantic love. 110 participants finished two resting-state blocks, no-handholding and handholding conditions, with Electroencephalogram (EEG). We aimed to explore the differences in the brain-brain synchrony pattern of interpersonal touch between romantic lovers and strangers by calculating dynamic interpersonal functional connectivity (dIFC) via EEG-based hyperscanning. Our results supported that the neural processing of interpersonal touch is a dynamic process. At first half, both groups tended to adapt, and then interpersonal touch increased the dIFC between romantic lovers and decreased the dIFC between strangers. Finally, we employed Support Vector Machine (SVM) to classify EEG signals into two different relationships. SVM recognized two relationships with an accuracy of 71% and 0.77 AUC of ROC at the first half, a 73% accuracy and 0.8 AUC of ROC at the second half. Our study indicates that interpersonal touch may have different meanings between romantic lovers and strangers. Specifically, interpersonal touch enhances the dIFC between romantic lovers while reducing the dIFC between strangers. The research has important implications for planning touch-based interventions in social and medical care.",https://pubmed.ncbi.nlm.nih.gov/39415264/,https://pubmed.ncbi.nlm.nih.gov/39415264/,English,Include,,Brain-to-brain synchrony increased during interpersonal touch in romantic lovers: an EEG-based hyperscanning study.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39415245,pubmed:39415245,PubMed,pubmed:39415245,Theta-gamma-coupling as predictor of working memory performance in young and elderly healthy people.,Mohammed Abubaker;Wiam Al Qasem;Kateřina Pilátová;Petr Ježdík;Eugen Kvašňák,2024,10.1186/s13041-024-01149-8,"The relationship between working memory (WM) and neuronal oscillations can be studied in detail using brain stimulation techniques, which provide a method for modulating these oscillations and thus influencing WM. The endogenous coupling between the amplitude of gamma oscillations and the phase of theta oscillations is crucial for cognitive control. Theta/gamma peak-coupled transcranial alternating current stimulation (TGCp-tACS) can modulate this coupling and thus influence WM performance. This study investigated the effects of TGCp-tACS on WM in older adults and compared their responses with those of younger participants from our previous work who underwent the same experimental design. Twenty-eight older subjects underwent both TGCp-tACS and sham stimulation sessions at least 72 h apart. Resting-state electroencephalography (EEG) was recorded before and after the interventions, and a WM task battery with five different WM tasks was performed during the interventions to assess various WM components. Outcomes measured included WM task performance (e.g., accuracy, reaction time (RT)) and changes in power spectral density (PSD) in different frequency bands. TGCp-tACS significantly decreased accuracy and RT on the 10- and 14-point Sternberg tasks and increased RT on the Digit Symbol Substitution Test in older adults. In contrast, younger participants showed a significant increase in accuracy only on the 14-item Sternberg task. Electrophysiological analysis revealed a decrease in delta and theta PSD and an increase in high gamma PSD in both younger and older participants after verum stimulation. In conclusion, theta-gamma coupling is essential for WM and modulation of this coupling affects WM performance. The effects of TGCp-tACS on WM vary with age due to natural brain changes. To better support older adults, the study suggests several strategies to improve cognitive function, including: Adjusting stimulation parameters, applying stimulation to two sites, conducting multiple sessions, and using brain imaging techniques for precise targeting.",https://pubmed.ncbi.nlm.nih.gov/39415245/,https://pubmed.ncbi.nlm.nih.gov/39415245/,English,Include,,Theta-gamma-coupling as predictor of working memory performance in young and elderly healthy people.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39414816,pubmed:39414816,PubMed,pubmed:39414816,Exploring neural markers of dereification in meditation based on EEG and personalized models of electrophysiological brain states.,Tamas Madl,2024,10.1038/s41598-024-73789-8,"With mounting evidence for the benefits of meditation, there has been a growing interest in measuring and quantifying meditative states. This study introduces the Inner Dereification Index (IDI), a class of personalized models designed to quantify the distance from non-meditative states such as mind wandering based on a single individual's neural activity. In addition to demonstrating high classification accuracy (median AUC: 0.996) at distinguishing meditation from thinking states moment by moment, IDI can accurately stratify meditator cohorts by experience, and correctly identify the practices most effective at training the dereification aspect of meditation (decentering from immersion with thoughts and perceptions and recognizing them as mental constructs). These results suggest that IDI models may be a useful real-time proxy for dereification and meditation progress, requiring only 1 min of mind wandering data (and no meditation data) during model training. Thus, they show promise for applications such as real-time meditation feedback, progress tracking, personalization of practices, and potential therapeutic applications of neurofeedback-assisted generation of positive states of consciousness.",https://pubmed.ncbi.nlm.nih.gov/39414816/,https://pubmed.ncbi.nlm.nih.gov/39414816/,English,Include,,Exploring neural markers of dereification in meditation based on EEG and personalized models of electrophysiological brain states.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39413626,pubmed:39413626,PubMed,pubmed:39413626,Real-time sub-milliwatt epilepsy detection implemented on a spiking neural network edge inference processor.,Ruixin Li;Guoxu Zhao;Dylan Richard Muir;Yuya Ling;Karla Burelo;Mina Khoe;Dong Wang;Yannan Xing;Ning Qiao,2024,10.1016/j.compbiomed.2024.109225,"Analyzing electroencephalogram (EEG) signals to detect the epileptic seizure status of a subject presents a challenge to existing technologies aimed at providing timely and efficient diagnosis. In this study, we aimed to detect interictal and ictal periods of epileptic seizures using a spiking neural network (SNN). Our proposed approach provides an online and real-time preliminary diagnosis of epileptic seizures and helps to detect possible pathological conditions. To validate our approach, we conducted experiments using multiple datasets. We utilized a trained SNN to identify the presence of epileptic seizures and compared our results with those of related studies. The SNN model was deployed on Xylo, a digital SNN neuromorphic processor designed to process temporal signals. Xylo efficiently simulates spiking leaky integrate-and-fire neurons with exponential input synapses. Xylo has much lower energy requirements than traditional approaches to signal processing, making it an ideal platform for developing low-power seizure detection systems. Our proposed method has a high test accuracy of 93.3% and 92.9% when classifying ictal and interictal periods. At the same time, the application has an average power consumption of 87.4 μW (IO power) + 287.9 μW (compute power) when deployed to Xylo. Our method demonstrates excellent low-latency performance when tested on multiple datasets. Our work provides a new solution for seizure detection, and it is expected to be widely used in portable and wearable devices in the future.",https://pubmed.ncbi.nlm.nih.gov/39413626/,https://pubmed.ncbi.nlm.nih.gov/39413626/,English,Include,,Real-time sub-milliwatt epilepsy detection implemented on a spiking neural network edge inference processor.,Include,,"as much lower energy requirements than traditional approaches to signal processing, making it an ideal platform for developing low-power seizure detection systems. Our proposed method has a high test accuracy of 93.3% and 92.9% when classifying ictal and interictal periods. At the same time, the application has an average power consumption of 87.4 μW (IO power) + 287.9 μW (compute power) when depl",,0.95,0.6,
pubmed:39412979,pubmed:39412979,PubMed,pubmed:39412979,MASER: Enhancing EEG Spatial Resolution With State Space Modeling.,Yifan Zhang;Yang Yu;Hao Li;Anqi Wu;Ling-Li Zeng;Dewen Hu,2024,10.1109/tnsre.2024.3481886,"Consumer-grade Electroencephalography (EEG) devices equipped with few electrodes often suffer from low spatial resolution, hindering the accurate capture of intricate brain activity patterns. To address this issue, we propose MASER, a novel super-resolution approach for EEG recording. In MASER, we design the eMamba block for extracting EEG features based on the principles of state space models (SSMs). We further stack eMamba blocks to form a low-resolution feature extractor and a high-resolution signal predictor, which enhances the feature representation. During the training of MASER, we fully consider the characteristics of multidimensional biological series signals, incorporating a smoothness constraint loss to achieve more consistent high-resolution reconstructions. MASER pioneers EEG-oriented state space modeling, effectively capturing the temporal dynamics and latent states, thereby revealing complex neural interactions over time. Extensive experiments show that the proposed MASER outperforms the state-of-the-art methods in super-resolution quality on two public EEG datasets, with normalized mean square error reduced by 16.25% and Pearson correlation improved by 1.13%. Moreover, a case study of motor imagery recognition highlights the advantages conferred by high-resolution EEG signals. With a 4x increase in spatial resolution by MASER, the recognition accuracy improves by 5.74%, implying a significant performance elevation in brain-computer interface (BCI) command mapping. By enhancing the spatial resolution of EEG signals, MASER makes EEG-based applications more accessible, reducing cost and setup time while maintaining high performance across various domains such as gaming, education, and healthcare.",https://pubmed.ncbi.nlm.nih.gov/39412979/,https://pubmed.ncbi.nlm.nih.gov/39412979/,English,Include,,MASER: Enhancing EEG Spatial Resolution With State Space Modeling.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39410593,pubmed:39410593,PubMed,pubmed:39410593,Classification of Alzheimer's Disease and Frontotemporal Dementia Using Electroencephalography to Quantify Communication between Electrode Pairs.,Yuan Ma;Jeffrey Keith Spaneas Bland;Tsutomu Fujinami,2024,10.1001/archneurol.2007.38,"Accurate diagnosis of dementia subtypes is crucial for optimizing treatment planning and enhancing caregiving strategies. To date, the accuracy of classifying Alzheimer's disease (AD) and frontotemporal dementia (FTD) using electroencephalogram (EEG) data has been lower than that of distinguishing individuals with these diseases from healthy elderly controls (HCs). This limitation has impeded the feasibility of a cost-effective differential diagnosis for the two subtypes in clinical settings. This study addressed this issue by quantifying communication between electrode pairs in EEG data, along with demographic information, as features to train machine learning (support vector machine) models. Our focus was on refining the feature set specifically for AD-FTD classification. Using our initial feature set, we achieved classification accuracies of 76.9% for AD-HC, 90.4% for FTD-HC, and 91.5% for AD-FTD. Notably, feature importance analyses revealed that the features influencing AD-HC classification are unnecessary for distinguishing between AD and FTD. Eliminating these unnecessary features improved the classification accuracy of AD-FTD to 96.6%. We concluded that communication between electrode pairs specifically involved in the neurological pathology of FTD, but not AD, enables highly accurate EEG-based AD-FTD classification.",https://pubmed.ncbi.nlm.nih.gov/39410593/,https://pubmed.ncbi.nlm.nih.gov/39410593/,English,Include,,Classification of Alzheimer's Disease and Frontotemporal Dementia Using Electroencephalography to Quantify Communication between Electrode Pairs.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39410227,pubmed:39410227,PubMed,pubmed:39410227,Application of 2D Extension of Hjorth's Descriptors to Distinguish Defined Groups of Bee Pollen Images.,Ewaryst Tkacz;Przemysław Rujna;Wojciech Więcławek;Bartosz Lewandowski;Barbara Mika;Szymon Sieciński,2024,10.1016/j.ymssp.2021.108247,"Adulteration of food products is a serious problem in the current economy. Honey has become the third most counterfeit food product in the world and requires effective authentication methods. This article presents a new approach to the differentiation of bee pollen, which can support the development of a methodology to test honey quality based on the analysis of bee pollen. The proposed method is built on applying the Hjorth descriptors-Activity, Mobility, and Complexity-known from electroencephalography (EEG) analysis, for 2D bee pollen images. The sources for extracting the bee pollen images were the photos of honey samples, which were taken using a digital camera with a resolution of 5 megapixels connected to the tube of an optical microscope. The honey samples used were prepared according to the Polish standard PN-88/A-77626 (related to the European standard CELEX-32001L0110-PL-TXT). The effectiveness of the proposed method was positively verified for three selected groups of bee pollen-",,https://pubmed.ncbi.nlm.nih.gov/39410227/,English,Exclude,Not classification-focused,Application of 2D Extension of Hjorth's Descriptors to Distinguish Defined Groups of Bee Pollen Images.,,,,,0.85,0.6,
pubmed:39409506,pubmed:39409506,PubMed,pubmed:39409506,Transforming Motor Imagery Analysis: A Novel EEG Classification Framework Using AtSiftNet Method.,Haiqin Xu;Waseem Haider;Muhammad Zulkifal Aziz;Youchao Sun;Xiaojun Yu,2024,10.1109/tnnls.2019.2946869,"This paper presents an innovative approach for the Feature Extraction method using Self-Attention, incorporating various Feature Selection techniques known as the AtSiftNet method to enhance the classification performance of motor imaginary activities using electrophotography (EEG) signals. Initially, the EEG signals were sorted and then denoised using multiscale principal component analysis to obtain clean EEG signals. However, we also conducted a non-denoised experiment. Subsequently, the clean EEG signals underwent the Self-Attention feature extraction method to compute the features of each trial (i.e., 350×18). The best 1 or 15 features were then extracted through eight different feature selection techniques. Finally, five different machine learning and neural network classification models were employed to calculate the accuracy, sensitivity, and specificity of this approach. The BCI competition III dataset IV-a was utilized for all experiments, encompassing the datasets of five volunteers who participated in the competition. The experiment findings reveal that the average accuracy of classification is highest among ReliefF (i.e., 99.946%), Mutual Information (i.e., 98.902%), Independent Component Analysis (i.e., 99.62%), and Principal Component Analysis (i.e., 98.884%) for both 1 and 15 best-selected features from each trial. These accuracies were obtained for motor imagery using a Support Vector Machine (SVM) as a classifier. In addition, five-fold validation was performed in this paper to assess the fair performance estimation and robustness of the model. The average accuracy obtained through five-fold validation is 99.89%. The experiments' findings indicate that the suggested framework provides a resilient biomarker with minimal computational complexity, making it a suitable choice for advancing Motor Imagery Brain-Computer Interfaces (BCI).",https://pubmed.ncbi.nlm.nih.gov/39409506/,https://pubmed.ncbi.nlm.nih.gov/39409506/,English,Include,,Transforming Motor Imagery Analysis: A Novel EEG Classification Framework Using AtSiftNet Method.,Include,," 15 features were then extracted through eight different feature selection techniques. Finally, five different machine learning and neural network classification models were employed to calculate the accuracy, sensitivity, and specificity of this approach. The BCI competition III dataset IV-a was utilized for all experiments, encompassing the datasets of five volunteers who participated in the com",,0.95,0.6,
pubmed:39409418,pubmed:39409418,PubMed,pubmed:39409418,The Development of a Multicommand Tactile Event-Related Potential-Based Brain-Computer Interface Utilizing a Low-Cost Wearable Vibrotactile Stimulator.,Manorot Borirakarawin;Nannaphat Siribunyaphat;Si Thu Aung;Yunyong Punsawad,2024,10.1371/journal.pone.0269001,"A tactile event-related potential (ERP)-based brain-computer interface (BCI) system is an alternative for enhancing the control and communication abilities of quadriplegic patients with visual or auditory impairments. Hence, in this study, we proposed a tactile stimulus pattern using a vibrotactile stimulator for a multicommand BCI system. Additionally, we observed a tactile ERP response to the target from random vibrotactile stimuli placed in the left and right wrist and elbow positions to create commands. An experiment was conducted to explore the location of the proposed vibrotactile stimulus and to verify the multicommand tactile ERP-based BCI system. Using the proposed features and conventional classification methods, we examined the classification efficiency of the four commands created from the selected EEG channels. The results show that the proposed vibrotactile stimulation with 15 stimulus trials produced a prominent ERP response in the Pz channels. The average classification accuracy ranged from 61.9% to 79.8% over 15 stimulus trials, requiring 36 s per command in offline processing. The P300 response in the parietal area yielded the highest average classification accuracy. The proposed method can guide the development of a brain-computer interface system for physically disabled people with visual or auditory impairments to control assistive and rehabilitative devices.",https://pubmed.ncbi.nlm.nih.gov/39409418/,https://pubmed.ncbi.nlm.nih.gov/39409418/,English,Include,,The Development of a Multicommand Tactile Event-Related Potential-Based Brain-Computer Interface Utilizing a Low-Cost Wearable Vibrotactile Stimulator.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39409342,pubmed:39409342,PubMed,pubmed:39409342,Neural Signature and Decoding of Unmanned Aerial Vehicle Operators in Emergency Scenarios Using Electroencephalography.,Manyu Liu;Ying Liu;Aberham Genetu Feleke;Weijie Fei;Luzheng Bi,2024,10.1016/j.concog.2021.103150,"Brain-computer interface (BCI) offers a novel means of communication and control for individuals with disabilities and can also enhance the interactions between humans and machines for the broader population. This paper explores the brain neural signatures of unmanned aerial vehicle (UAV) operators in emergencies and develops an operator's electroencephalography (EEG) signals-based detection method for UAV emergencies. We found regularity characteristics similar to classic event-related potential (ERP) components like visual mismatch negativity (vMMN) and contingent negative variation (CNV). Source analysis revealed a sequential activation of the occipital, temporal, and frontal lobes following the onset of emergencies, corresponding to the processing of attention, emotion, and motor intention triggered by visual stimuli. Furthermore, an online detection system was implemented and tested. Experimental results showed that the system achieved an average accuracy of over 88% in detecting emergencies with a detection latency of 431.95 ms from the emergency onset. This work lays a foundation for understanding the brain activities of operators in emergencies and developing an EEG-based detection method for emergencies to assist UAV operations.",https://pubmed.ncbi.nlm.nih.gov/39409342/,https://pubmed.ncbi.nlm.nih.gov/39409342/,English,Include,,Neural Signature and Decoding of Unmanned Aerial Vehicle Operators in Emergency Scenarios Using Electroencephalography.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39407806,pubmed:39407806,PubMed,pubmed:39407806,MEG in MRI-Negative Patients with Focal Epilepsy.,Rudolf Kreidenhuber;Kai-Nicolas Poppert;Matthias Mauritz;Hajo M Hamer;Daniel Delev;Oliver Schnell;Stefan Rampp,2024,10.1016/j.clinph.2020.06.026,"To review the evidence on the clinical value of magnetic source imaging (MSI) in patients with refractory focal epilepsy without evidence for an epileptogenic lesion on magnetic resonance imaging (""MRI-negative"" or ""non-lesional MRI""). We conducted a systematic literature search on PUBMED, which was extended by researchrabbit.ai using predefined criteria to identify studies that applied MSI in MRI-negative patients with epilepsy. We extracted data on patient characteristics, MSI methods, localization results, surgical outcomes, and correlation with other modalities. We included 23 studies with a total of 512 non-lesional epilepsy patients who underwent MSI. Most studies used equivalent current dipole (ECD) models to estimate the sources of interictal epileptic discharges (IEDs). MEG detected IEDs in 32-100% of patients. MSI results were concordant with other modalities, such as EEG, PET, and SPECT, in 3892% of cases. If MSI concordant surgery was performed, 52-89% of patients achieved seizure freedom. MSI contributed to the decision-making process in 28-75% of cases and altered the surgical plan in 5-33% of cases. MSI is a valuable diagnostic tool for MRI-negative patients with epilepsy, as it can detect and localize IEDs with high accuracy and sensitivity, and provides useful information for surgical planning and predicts outcomes. MSI can also complement and refine the results of other modalities, such as EEG and PET, and optimize the use of invasive recordings. MSI should be considered as part of the presurgical evaluation, especially in patients with non-lesional refractory epilepsy.",,https://pubmed.ncbi.nlm.nih.gov/39407806/,English,Exclude,Review/survey papers,MEG in MRI-Negative Patients with Focal Epilepsy.,,,,,0.95,0.6,
pubmed:39406630,pubmed:39406630,PubMed,pubmed:39406630,Automatic sleep staging based on 24/7 EEG SubQ (UNEEG medical) data displays strong agreement with polysomnography in healthy adults.,Esben Ahrens;Poul Jennum;Jonas Duun-Henriksen;Bjarki Djurhuus;Preben Homøe;Troels W Kjær;Martin Christian Hemmsen,2024,10.1016/j.sleh.2024.08.007,"Performance evaluation of automatic sleep staging on two-channel subcutaneous electroencephalography. UNEEG medical's 24/7 electroencephalography SubQ (the SubQ device) with deep learning model U-SleepSQ. Manually scored hypnograms from polysomnographic recordings. Twenty-two healthy adults with 1-6 recordings per participant. The clinical study was registered at ClinicalTrials.gov with the identifier NCT04513743. Fine-tuning of U-Sleep in 11-fold cross-participant validation on 22 healthy adults. The resultant model was called U-SleepSQ. Bland-Altman analysis of sleep parameters. Advanced multiclass model performance metrics: stage-specific accuracy, specificity, sensitivity, kappa (κ), and F1 score. Additionally, Cohen's κ coefficient and macro F1 score. Longitudinal and participant-level performance evaluation. Exploration of model confidence quantification. Performance vs. age, sex, body mass index, SubQ implantation hemisphere, normalized entropy, transition index, and scores from the following three questionnaires: Morningness-Eveningness Questionnaire, World Health Organization's 5-item Well-being Index, and Major Depression Inventory. There was a strong agreement between the focus and reference method/technology. The confidence score was a promising metric for estimating the reliability of each hypnogram classified by the system. The U-SleepSQ model classified hypnograms for healthy participants soon after implantation and longitudinally with a strong agreement with the gold standard of manually scored polysomnographics, exhibiting negligible temporal variation.",https://pubmed.ncbi.nlm.nih.gov/39406630/,https://pubmed.ncbi.nlm.nih.gov/39406630/,English,Include,,Automatic sleep staging based on 24/7 EEG SubQ (UNEEG medical) data displays strong agreement with polysomnography in healthy adults.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39406075,pubmed:39406075,PubMed,pubmed:39406075,EEG spatial inter-channel connectivity analysis: A GCN-based dual stream approach to distinguish mental fatigue status.,Kun Chen;Shulong Chai;Tianli Xie;Quan Liu;Li Ma,2024,10.1016/j.artmed.2024.102996,"Mental fatigue is defined as a decline in the ability and efficiency of mental activities. A lot of research suggests that the transition from alertness to fatigue is accompanied by alterations in correlation patterns among various brain regions. However, conventional methods for detecting mental fatigue seldom emphases inter-channel connectivity in the spatial domain. To fill this gap, this paper explores the spatial inter-channel connectivity in alertness and fatigue, employing spectral graph convolutional networks (GCN) for mental fatigue detection. We utilized Pearson correlation coefficients (PCC) to establish temporal connections and magnitude-squared coherence (MSC) for spectral connections. Topological features of the brain network were then analysed. To enhance the learning of spatial inter-channel connectivity, a dual-graph strategy transforms edge features into node features, serving as inputs to the spectral GCN. By simultaneously learning PCC and MSC features, the model results indicate significant differences in some brain network characteristics between alert and fatigue states. It confirms that the synchronicity of brain operations differs in the alert state compared to mental fatigue, and indicates that fatigue states can influence correlation patterns among different brain regions. Our approach is evaluated on a self-designed experimental dataset containing 7 subjects, demonstrating a classification accuracy of 89.59 % in group-level experiments and 95.24 % at the subject level. Additionally, on the public dataset SEED-VIG containing 23 subjects, our method achieves an accuracy of 86.58 %. In summary, this paper proposes a neural network approach based on a dynamic functional connectivity network. The network integrates both temporal and spectral connections with the goal of simultaneously learning spatial inter-channel connectivity in time and frequency domains. This effectively accomplishes fatigue state detection, highlighting that fatigue significantly influences correlations among different brain regions.",https://pubmed.ncbi.nlm.nih.gov/39406075/,https://pubmed.ncbi.nlm.nih.gov/39406075/,English,Include,,EEG spatial inter-channel connectivity analysis: A GCN-based dual stream approach to distinguish mental fatigue status.,Include,,"atigue states can influence correlation patterns among different brain regions. Our approach is evaluated on a self-designed experimental dataset containing 7 subjects, demonstrating a classification accuracy of 89.59 % in group-level experiments and 95.24 % at the subject level. Additionally, on the public dataset SEED-VIG containing 23 subjects, our method achieves an accuracy of 86.58 %. In sum",,0.95,0.6,
pubmed:39405153,pubmed:39405153,PubMed,pubmed:39405153,Deep Optimized Broad Learning System for Applications in Tabular Data Recognition.,Wandong Zhang;Yimin Yang;Q M Jonathan Wu;Tianlong Liu,2024,10.1109/tcyb.2024.3473809,"The broad learning system (BLS) is a versatile and effective tool for analyzing tabular data. However, the rapid expansion of big data has resulted in an overwhelming amount of tabular data, necessitating the development of specialized tools for effective management and analysis. This article introduces an optimized BLS (OBLS) specifically tailored for big data analysis. In addition, a deep-optimized BLS (DOBLS) network is developed further to enhance the performance and efficiency of the OBLS. The main contributions of this article are: 1) by retracing the network's error from the output space to the latent space, the OBLS adjusts parameters in the feature and enhancement node layers. This process aims to achieve more resilient representations, resulting in improved performance; 2) the DOBLS is a multilayered structure consisting of multiple OBLSs, wherein each OBLS connects to the input and output layers, enabling direct data propagation. This design helps reduce information loss between layers, ensuring an efficient flow of information throughout the network; and 3) the proposed methods demonstrate robustness across various applications, including multiview feature embedding, one-class classification (OCC), camera model identification, electroencephalogram (EEG) signal processing, and radar signal analysis. Experimental results validate the effectiveness of the proposed models. To ensure reproducibility, the source code is available at https://github.com/1027051515/OBLS_DOBLS.",https://pubmed.ncbi.nlm.nih.gov/39405153/,https://pubmed.ncbi.nlm.nih.gov/39405153/,English,Include,,Deep Optimized Broad Learning System for Applications in Tabular Data Recognition.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39403498,pubmed:39403498,PubMed,pubmed:39403498,Feedback matters: EEG correlates of empathy involved in the naturalistic communication of emotions.,Ruei-Jyun Hung;Intan Low;Hung-Chun Yeh;Po-Yu Wang;Yong-Sheng Chen;Li-Fen Chen,2024,10.1155/2018/4283427,"Empathy involves the processing of complex information related to dynamic interactions between the empathizer and target. One neural signature of empathy is the suppression of electroencephalographic mu rhythm (8-13 Hz) over the sensorimotor region. It is important to consider that few researchers have studied the effects of empathizer feedback on empathy and its underlying neural mechanism, and most previous research has lacked ecological validity due to standardized emotional stimuli and constraints on the experiment environment. Our objective in this study was to investigate the means by which empathizer feedback influences one's own empathy in naturalistic social situations. Our results revealed that empathizer feedback decreases empathic accuracy but does not affect the emotional contagion nor the emotional intensity of the empathizer. We also found that the ability to accurately infer sadness is hindered by empathizer feedback. Empathizers presented lower alpha activity in the sensorimotor cortical areas only while receiving sad narratives and not providing feedback. This study contributes to the emerging research on the influence of empathizer feedback in naturalistic social settings.",https://pubmed.ncbi.nlm.nih.gov/39403498/,https://pubmed.ncbi.nlm.nih.gov/39403498/,English,Include,,Feedback matters: EEG correlates of empathy involved in the naturalistic communication of emotions.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39403356,pubmed:39403356,PubMed,pubmed:39403356,Feature Extraction With Stacked Autoencoders for EEG Channel Reduction in Emotion Recognition.,Elnaz Vafaei;Fereidoun Nowshiravan Rahatabad;Seyed Kamaledin Setarehdan;Parviz Azadfallah,2024,10.1016/j.cogr.2022.06.001,"Emotion recognition by electroencephalogram (EEG) signals is one of the complex methods because the extraction and recognition of the features hidden in the signal are sophisticated and require a significant number of EEG channels. Presenting a method for feature analysis and an algorithm for reducing the number of EEG channels fulfills the need for research in this field. Accordingly, this study investigates the possibility of utilizing deep learning to reduce the number of channels while maintaining the quality of the EEG signal. A stacked autoencoder network extracts optimal features for emotion classification in valence and arousal dimensions. Autoencoder networks can extract complex features to provide linear and non- linear features which are a good representative of the signal. The accuracy of a conventional emotion recognition classifier (support vector machine) using features extracted from SAEs was obtained at 75.7% for valence and 74.4% for arousal dimensions, respectively. Further analysis also illustrates that valence dimension detection with reduced EEG channels has a different composition of EEG channels compared to the arousal dimension. In addition, the number of channels is reduced from 32 to 12, which is an excellent development for designing a small-size EEG device by applying these optimal features.",https://pubmed.ncbi.nlm.nih.gov/39403356/,https://pubmed.ncbi.nlm.nih.gov/39403356/,English,Include,,Feature Extraction With Stacked Autoencoders for EEG Channel Reduction in Emotion Recognition.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39402190,pubmed:39402190,PubMed,pubmed:39402190,EEG-based emotional valence and emotion regulation classification: a data-centric and explainable approach.,Linda Fiorini;Francesco Bossi;Francesco Di Gruttola,2024,10.1038/s41598-024-75263-x,"Emotion classification using electroencephalographic (EEG) data is a challenging task in the field of Artificial Intelligence. While many researchers have focused on finding the best model or feature extraction technique to achieve optimal results, few have attempted to select the best methodological steps for working with the dataset. In this study, we applied two different theoretical approaches based on the noise of the dataset: curriculum learning and confident learning. Curriculum learning involves presenting training examples to the model in a specific order, starting with easier examples and gradually increasing in difficulty. This approach has been shown to improve model performance. Confident learning is a method for identifying and correcting label errors in datasets. By identifying and correcting these errors, confident learning can improve the performance of machine learning models trained on noisy datasets. We then applied the Integrated Gradient technique in order to assess the explainability of each model. Our aim was to explore the impact of different models and methods on emotion classification performance using EEG data. We collected and used an EEG dataset in which participants rated the emotional valence of positive and negative pictures while performing an emotion regulation (ER) task, comparing a control condition (Look) with two ER strategies: cognitive reappraisal and expressive suppression. We performed a multilabel classification to identify emotional neutrality or polarization of emotional valence (both positive and negative) rated by participants and the emotion regulation strategy adopted during the task. We compared the performance of models trained on three datasets selected based on label noise and evaluated their suitability for this task. Our results suggest different patterns based on the architecture used for feature importance, highlighting both advantages and criticisms.",https://pubmed.ncbi.nlm.nih.gov/39402190/,https://pubmed.ncbi.nlm.nih.gov/39402190/,English,Include,,EEG-based emotional valence and emotion regulation classification: a data-centric and explainable approach.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39401806,pubmed:39401806,PubMed,pubmed:39401806,[Brian effects of electroacupuncture on sleep quality and cognitive function in patients with insomnia related to cerebral infarction].,Menglu Jiao;Dongyan Wang;Lei He;Liyuan Feng;Ruoyu Wang;Xue Sui,2024,10.13703/j.0255-2930.20230703-k0004,"To observe the effects of electroacupuncture (EA) on sleep quality, sleep structure, and cognitive function in patients with insomnia related to cerebral infarction, and to explore the brain effect mechanism of EA on insomnia related to cerebral infarction. Thirty-six patients with insomnia related to cerebral infarction were randomly divided into an EA group (18 cases, 1 case was eliminated and 1 case dropped out) and a sham acupuncture group (18 cases, 1 case was eliminated and 2 cases dropped out). Both groups received conventional treatment for cerebral infarction. The EA group received EA at Sishencong (EX-HN 1) with continuous waves at a frequency of 2 Hz, at an intensity tolerable to the patient. The sham acupuncture group received sham acupuncture at non-acupoints with the same EA parameters but electrical stimulation was interrupted after 30 s. Both groups were treated for 20 min each session, once daily, 5 days per week, for a total of 4 weeks. Pittsburgh sleep quality index (PSQI), Montreal cognitive assessment-basic (MoCA-B) scores, and short-term memory (STM) encoding test accuracy and average reaction time were observed before and after treatment in the two groups. Polysomnography (PSG) was used to evaluate sleep structure, and electroencephalogram (EEG) data were collected to observe the standardized power value of the Theta frequency band before and after treatment. Compared with before treatment, PSQI score was decreased and MoCA-B score was increased in the EA group after treatment ( EA could regulate sleep quality and structure in patients with insomnia related to cerebral infarction, and improve cognitive function, possibly related to the reduction of slow-wave activity in EEG. ",https://pubmed.ncbi.nlm.nih.gov/39401806/,https://pubmed.ncbi.nlm.nih.gov/39401806/,English,Include,,[Brian effects of electroacupuncture on sleep quality and cognitive function in patients with insomnia related to cerebral infarction].,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39401242,pubmed:39401242,PubMed,pubmed:39401242,The human olfactory bulb communicates perceived odor valence to the piriform cortex in the gamma band and receives a refined representation back in the beta band.,Frans Nordén;Behzad Iravani;Martin Schaefer;Anja L Winter;Mikael Lundqvist;Artin Arshamian;Johan N Lundström,2024,10.1002/hbm.25272,"A core function of the olfactory system is to determine the valence of odors. In humans, central processing of odor valence perception has been shown to take form already within the olfactory bulb (OB), but the neural mechanisms by which this important information is communicated to, and from, the olfactory cortex (piriform cortex, PC) are not known. To assess communication between the 2 nodes, we simultaneously measured odor-dependent neural activity in the OB and PC from human participants while obtaining trial-by-trial valence ratings. By doing so, we could determine when subjective valence information was communicated, what kind of information was transferred, and how the information was transferred (i.e., in which frequency band). Support vector machine (SVM) learning was used on the coherence spectrum and frequency-resolved Granger causality to identify valence-dependent differences in functional and effective connectivity between the OB and PC. We found that the OB communicates subjective odor valence to the PC in the gamma band shortly after odor onset, while the PC subsequently feeds broader valence-related information back to the OB in the beta band. Decoding accuracy was better for negative than positive valence, suggesting a focus on negative valence. Critically, we replicated these findings in an independent data set using additional odors across a larger perceived valence range. Combined, these results demonstrate that the OB and PC communicate levels of subjective odor pleasantness across multiple frequencies, at specific time points, in a direction-dependent pattern in accordance with a two-stage model of odor processing.",,https://pubmed.ncbi.nlm.nih.gov/39401242/,English,Exclude,Not EEG-BCI focused,The human olfactory bulb communicates perceived odor valence to the piriform cortex in the gamma band and receives a refined representation back in the beta band.,,,,,0.9,0.8,small_sample_mentioned
pubmed:39400359,pubmed:39400359,PubMed,pubmed:39400359,Clinical Utility of Neurophysiologic Classification (and Declassification) of Myoclonus.,Marcus N Callister;Molly C Klanderman;Alyssa Stockard;Charles Van Der Walt;Ashley B Pena;John N Caviness,2024,10.1016/s1389-9457(01)00123-x,"Movement clinical neurophysiology studies can distinguish myoclonus, tremor, and other jerky movements; however, there has been limited demonstration of their real-world clinical impact. The aim was to investigate movement study utility in clarifying movement classification and guiding patient management. A retrospective study of myoclonus-related movement studies was performed. Of 262 patients referred for consideration of myoclonus, 105 (40%) had myoclonus, 156 (59%) had no myoclonus (the commonest alternative classifications were functional jerks and tremor), and 1 was uncertain. An additional 29 studies identified myoclonus without prior clinical suspicion. A total of 119 of 134 (89%) myoclonus patients had a specific neurophysiologic subtype identified, most commonly cortical (64, 54%). Diagnostic differential narrowed in 60% of patients, and a new diagnosis was made in 42 (14%) patients. Medication changes were made in 151 patients (52%), with improvement in 35 of 51 (67%) with follow-up. Movement studies effectively determined movement classification and identified unsuspected myoclonus, leading to changes in diagnosis and management. © 2024 The Author(s). Movement Disorders published by Wiley Periodicals LLC on behalf of International Parkinson and Movement Disorder Society.",,https://pubmed.ncbi.nlm.nih.gov/39400359/,English,Exclude,Not EEG-BCI focused,Clinical Utility of Neurophysiologic Classification (and Declassification) of Myoclonus.,,,,,0.9,0.6,
pubmed:39399054,pubmed:39399054,PubMed,pubmed:39399054,A novel cortical biomarker signature predicts individual pain sensitivity.,Nahian S Chowdhury;Chuan Bi;Andrew J Furman;Alan Ki Chiang;Patrick Skippen;Emily Si;Samantha K Millard;Sarah M Margerison;Darrah Spies;Michael L Keaser;Joyce T Da Silva;Shuo Chen;Siobhan M Schabrun;David A Seminowicz,2024,10.1016/j.jpain.2021.08.003,"Biomarkers would greatly assist decision making in the diagnosis, prevention and treatment of chronic pain. The present study aimed to undertake analytical validation of a sensorimotor cortical biomarker signature for pain consisting of two measures: sensorimotor peak alpha frequency (PAF) and corticomotor excitability (CME). In this cohort study (recruitment period: November 2020-October 2022), participants experienced a model of prolonged temporomandibular pain with outcomes collected over 30 days. Electroencephalography (EEG) to assess PAF and transcranial magnetic stimulation (TMS) to assess CME were recorded on Days 0, 2 and 5. Pain was assessed twice daily from Days 1-30. Data collection occurred at a single centre: Neuroscience Research Australia. We enrolled 159 healthy participants (through notices placed online and at universities across Australia), aged 18-44 with no history of chronic pain, neurological or psychiatric condition. 150 participants completed the protocol. Participants received an injection of nerve growth factor (NGF) to the right masseter muscle on Days 0 and 2 to induce prolonged temporomandibular pain lasting up to 4 weeks. We determined the predictive accuracy of the PAF/CME biomarker signature using a nested control-test scheme: machine learning models were run on a training set (n = 100), where PAF and CME were predictors and pain sensitivity was the outcome. The winning classifier was assessed on a test set (n = 50) comparing the predicted pain labels against the true labels. The final sample consisted of 66 females and 84 males with a mean age of 25.1 ± 6.2. The winning classifier was logistic regression, with an outstanding area under the curve (AUC=1.00). The locked model assessed on the test set had excellent performance (AUC=0.88[0.78-0.99]). Results were reproduced across a range of methodological parameters. Moreover, inclusion of sex and pain catastrophizing as covariates did not improve model performance, suggesting the model including biomarkers only was more robust. PAF and CME biomarkers showed good-excellent test-retest reliability. This study provides evidence for a sensorimotor cortical biomarker signature for pain sensitivity. The combination of accuracy, reproducibility, and reliability, suggests the PAF/CME biomarker signature has substantial potential for clinical translation, including predicting the transition from acute to chronic pain.",https://pubmed.ncbi.nlm.nih.gov/39399054/,https://pubmed.ncbi.nlm.nih.gov/39399054/,English,Include,,A novel cortical biomarker signature predicts individual pain sensitivity.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39398346,pubmed:39398346,PubMed,pubmed:39398346,Psychiatric disorders from EEG signals through deep learning models.,Zaeem Ahmed;Aamir Wali;Saman Shahid;Shahid Zikria;Jawad Rasheed;Tunc Asuroglu,2024,10.1016/j.ibneur.2024.09.003,"Psychiatric disorders present diagnostic challenges due to individuals concealing their genuine emotions, and traditional methods relying on neurophysiological signals have limitations. Our study proposes an improved EEG-based diagnostic model employing Deep Learning (DL) techniques to address this. By experimenting with DL models on EEG data, we aimed to enhance psychiatric disorder diagnosis, offering promising implications for medical advancements. We utilized a dataset of 945 individuals, including 850 patients and 95 healthy subjects, focusing on six main and nine specific disorders. Quantitative EEG data were analyzed during resting states, featuring power spectral density (PSD) and functional connectivity (FC) across various frequency bands. Employing artificial neural networks (ANN), K nearest neighbors (KNN), Long short-term memory (LSTM), bidirectional Long short-term memory (Bi LSTM), and a hybrid CNN-LSTM model, we performed binary classification. Remarkably, all proposed models outperformed previous approaches, with the ANN achieving 96.83 % accuracy for obsessive-compulsive disorder using entire band features. CNN-LSTM attained the same accuracy for adjustment disorder, while KNN and LSTM achieved 98.94 % accuracy for acute stress disorder using specific feature sets. Notably, KNN and Bi-LSTM models reached 97.88 % accuracy for predicting obsessive-compulsive disorder. These findings underscore the potential of EEG as a cost-effective and accessible diagnostic tool for psychiatric disorders, complementing traditional methods like MRI. Our study's advanced DL models show promise in enhancing psychiatric disorder detection and monitoring, with significant implications for clinical application, inspiring hope for improved patient care and outcomes. The potential of EEG as a diagnostic tool for psychiatric disorders is substantial, as it can lead to improved patient care and outcomes in the field of psychiatry.",https://pubmed.ncbi.nlm.nih.gov/39398346/,https://pubmed.ncbi.nlm.nih.gov/39398346/,English,Include,,Psychiatric disorders from EEG signals through deep learning models.,Include,,"nal Long short-term memory (Bi LSTM), and a hybrid CNN-LSTM model, we performed binary classification. Remarkably, all proposed models outperformed previous approaches, with the ANN achieving 96.83 % accuracy for obsessive-compulsive disorder using entire band features. CNN-LSTM attained the same accuracy for adjustment disorder, while KNN and LSTM achieved 98.94 % accuracy for acute stress disord",,0.95,0.6,
pubmed:39397786,pubmed:39397786,PubMed,pubmed:39397786,ADT Network: A Novel Nonlinear Method for Decoding Speech Envelopes From EEG Signals.,Ruixiang Liu;Chang Liu;Dan Cui;Huan Zhang;Xinmeng Xu;Yuxin Duan;Yihu Chao;Xianzheng Sha;Limin Sun;Xiulan Ma;Shuo Li;Shijie Chang,2024,10.3389/fnins.2018.00531,"Decoding speech envelopes from electroencephalogram (EEG) signals holds potential as a research tool for objectively assessing auditory processing, which could contribute to future developments in hearing loss diagnosis. However, current methods struggle to meet both high accuracy and interpretability. We propose a deep learning model called the auditory decoding transformer (ADT) network for speech envelope reconstruction from EEG signals to address these issues. The ADT network uses spatio-temporal convolution for feature extraction, followed by a transformer decoder to decode the speech envelopes. Through anticausal masking, the ADT considers only the current and future EEG features to match the natural relationship of speech and EEG. Performance evaluation shows that the ADT network achieves average reconstruction scores of 0.168 and 0.167 on the SparrKULee and DTU datasets, respectively, rivaling those of other nonlinear models. Furthermore, by visualizing the weights of the spatio-temporal convolution layer as time-domain filters and brain topographies, combined with an ablation study of the temporal convolution kernels, we analyze the behavioral patterns of the ADT network in decoding speech envelopes. The results indicate that low- (0.5-8 Hz) and high-frequency (14-32 Hz) EEG signals are more critical for envelope reconstruction and that the active brain regions are primarily distributed bilaterally in the auditory cortex, consistent with previous research. Visualization of attention scores further validated previous research. In summary, the ADT network balances high performance and interpretability, making it a promising tool for studying neural speech envelope tracking.",https://pubmed.ncbi.nlm.nih.gov/39397786/,https://pubmed.ncbi.nlm.nih.gov/39397786/,English,Include,,ADT Network: A Novel Nonlinear Method for Decoding Speech Envelopes From EEG Signals.,Include,,"otential as a research tool for objectively assessing auditory processing, which could contribute to future developments in hearing loss diagnosis. However, current methods struggle to meet both high accuracy and interpretability. We propose a deep learning model called the auditory decoding transformer (ADT) network for speech envelope reconstruction from EEG signals to address these issues. The ",,0.95,0.6,
pubmed:39397592,pubmed:39397592,PubMed,pubmed:39397592,A hybrid capsule attention-based convolutional bi-GRU method for multi-class mental task classification based brain-computer Interface.,D Deepika;G Rekha,2025,10.1080/10255842.2024.2410221,Electroencephalography analysis is critical for brain computer interface research. The primary goal of brain-computer interface is to establish communication between impaired people and others ,,https://pubmed.ncbi.nlm.nih.gov/39397592/,English,Exclude,Outside date range,A hybrid capsule attention-based convolutional bi-GRU method for multi-class mental task classification based brain-computer Interface.,,,,,0.95,0.6,
pubmed:39396228,pubmed:39396228,PubMed,pubmed:39396228,Neuro connect: Integrating data-driven and BiGRU classification for enhanced autism prediction from fMRI data.,Pavithra Rajaram;Mohanapriya Marimuthu,2025,10.1080/0954898x.2024.2412679,"Autism Spectrum Disorder (ASD) poses a significant challenge in early diagnosis and intervention due to its multifaceted clinical presentation and lack of objective biomarkers. This research presents a novel approach, termed Neuro Connect, which integrates data-driven techniques with Bidirectional Gated Recurrent Unit (BiGRU) classification to enhance the prediction of ASD using functional Magnetic Resonance Imaging (fMRI) data. This study uses both structural and functional neuroimaging data to investigate the complex brain underpinnings of autism spectrum disorder (ASD). They use an Auto-Encoder (AE) to efficiently reduce dimensionality while retaining critical information by learning and compressing important characteristics from high-dimensional data. We treat the feature-extracted data using a BiGRU model for the classification task of predicting ASD. They provide a new optimization strategy, the Horse Herd Algorithm (HHA), and show that it outperforms other established optimizers, such SGD and Adam, in order to improve classification accuracy. The model's performance is greatly enhanced by the HHA's novel optimization technique, which more precisely refines weight modifications made during training. The proposed ASD and EEG dataset accuracy value is 99.5%, and 99.3 compared to the existing method the proposed has a high accuracy value.",,https://pubmed.ncbi.nlm.nih.gov/39396228/,English,Exclude,Outside date range,Neuro connect: Integrating data-driven and BiGRU classification for enhanced autism prediction from fMRI data.,,,,,0.95,0.6,
pubmed:39395635,pubmed:39395635,PubMed,pubmed:39395635,Simultaneous EEG recording of cortical tracking of speech and movement kinematics.,Gilles Naeije;Maxime Niesen;Marc Vander Ghinst;Mathieu Bourguignon,2024,10.1016/j.neuroscience.2024.10.013,"Cortical activity is coupled with streams of sensory stimulation. The coupling with the temporal envelope of heard speech is known as the cortical tracking of speech (CTS), and that with movement kinematics is known as the corticokinematic coupling (CKC). Simultaneous measurement of both couplings is desirable in clinical settings, but it is unknown whether the inherent dual-tasking condition has an impact on CTS or CKC. We aim to determine whether and how CTS and CKC levels are affected when recorded simultaneously. Twenty-three healthy young adults underwent 64-channel EEG recordings while listening to stories and while performing repetitive finger-tapping movements in 3 conditions: separately (audio- or tapping-only) or simultaneously (audio-tapping). CTS and CKC values were estimated using coherence analysis between each EEG signal and speech temporal envelope (CTS) or finger acceleration (CKC). CTS was also estimated as the reconstruction accuracy of a decoding model. Across recordings, CTS assessed with reconstruction accuracy was significant in 85 % of the subjects at phrasal frequency (0.5 Hz) and in 68 % at syllabic frequencies (4-8 Hz), and CKC was significant in over 85 % of the subjects at movement frequency and its first harmonic. Comparing CTS and CKC values evaluated in separate recordings to those in simultaneous recordings revealed no significant difference and moderate-to-high levels of correlation. Despite the subtle behavioral effects, CTS and CKC are not evidently altered by the dual-task setting inherent to recording them simultaneously and can be evaluated simultaneously using EEG in clinical settings.",https://pubmed.ncbi.nlm.nih.gov/39395635/,https://pubmed.ncbi.nlm.nih.gov/39395635/,English,Include,,Simultaneous EEG recording of cortical tracking of speech and movement kinematics.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39394849,pubmed:39394849,PubMed,pubmed:39394849,An SCA-based classifier for motor imagery EEG classification.,Zhihui Li;Ming Meng,2024,10.1080/10255842.2024.2414069,"Efficient and accurate multi-class classification of electroencephalogram (EEG) signals poses a significant challenge in the development of motor imagery-based brain-computer interface (MI-BCI). Drawing inspiration from the sine cosine algorithm (SCA), a widely employed swarm intelligence algorithm for optimization problems, we proposed a novel population-based classification algorithm for EEG signals in this article. To fully leverage the characteristics contained in EEG signals, multi-scale sub-signals were constructed in terms of temporal windows and spectral bands simultaneously, and the common spatial pattern (CSP) features were extracted from each sub-signal. Subsequently, we integrated the multi-center optimal vectors mechanism into the classical SCA, resulting in the development of a multi-center SCA (MCSCA) classifier. During the classification stage, the label was assigned to the test trials by evaluating the Euclidean distance between their feature vectors and each optimal vector in MCSCA. Additionally, the weights of feature vectors were exploited to select the sub-signal of specific temporal windows and spectral bands for feature reduction, thereby declining computational effort and eliminating data redundancy. To validate the performance of the MCSCA classifier, we conducted four-class classification experiments using the BCI Competition IV dataset 2a, achieving an average classification accuracy of 71.89%. The experimental results show that the proposed algorithm offers a novel and effective approach for EEG classification.",https://pubmed.ncbi.nlm.nih.gov/39394849/,https://pubmed.ncbi.nlm.nih.gov/39394849/,English,Include,,An SCA-based classifier for motor imagery EEG classification.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39389167,pubmed:39389167,PubMed,pubmed:39389167,Registered Report Stage II: Decoding the category information from evoked potentials to visible and invisible visual objects.,Bingbing Li;Shuhui Zhang,2024,10.1016/j.ijpsycho.2024.112446,"Previous studies that use decoding methods and EEG to investigate the neural representation of the category information of visual objects focused mainly on consciously processed visual objects. It remains unclear whether the category information of unconsciously processed visual objects can be decoded and whether the decoding performance is different for consciously and unconsciously processed visual objects. The present study compared the neural decoding of the animacy category of visible and invisible visual objects via EEG and decoding methods. The results revealed that the animacy of visible visual objects could be decoded above the chance level by the P200, N300, and N400, but not by the early N/P100. However, the animacy of invisible visual objects could not be decoded above the chance level by neither early nor late ERP components. The decoding accuracy was greater for visible visual objects than that for invisible visual objects for the P200, N300 and N400. These results suggested that access to animacy category information for visual objects requires conscious processing.",https://pubmed.ncbi.nlm.nih.gov/39389167/,https://pubmed.ncbi.nlm.nih.gov/39389167/,English,Include,,Registered Report Stage II: Decoding the category information from evoked potentials to visible and invisible visual objects.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39386391,pubmed:39386391,PubMed,pubmed:39386391,Significance of EEG-electrode combinations while calculating filters with common spatial patterns.,Dominik Wetzel;Paul-Philipp Jacobs;Dirk Winkler;Ronny Grunert,2024,10.13026/c28g6p,"Common spatial pattern (CSP) is a common filter technique used for pre-processing of electroencephalography (EEG) signals for imaginary movement classification tasks. It is crucial to reduce the amount of features especially in cases where few data is available. Therefore, different approaches to reduce the amount of electrodes used for CSP calculation are tried in this research. Freely available EEG datasets are used for the evaluation. To evaluate the approaches a simple classification pipeline consisting mainly of the CSP calculation and linear discriminant analysis for classification is used. A baseline over all electrodes is calculated and compared against the results of the approaches. The most promising approach is to use the ability of CSP to provide information about the origin of the created filter. An algorithm that extracts the important electrodes from the CSP utilizing these information is proposed.The results show that using subject specific electrode positions has a positive impact on accuracy for the classification task. Further, it is shown that good performing electrode combinations in one session are not necessarily good performing electrodes in another session of the same subject. In addition to the combinations calculated using the developed algorithm, 26 additional electrode combinations are proposed. These can be taken into account when selecting well-performing electrode combinations. In this research we could achieve an accuracy improvement of over 10%. Carefully selecting the correct electrode combination can improve accuracy for classifying an imaginary movement task. Common Spatial Patterns (CSP) ist eine gängige Filtertechnik, die für die Vorverarbeitung von Elektroenzephalographie-Signalen (EEG) zur Klassifizierung gedachter Bewegungen verwendet wird. Besonders in Fällen, in denen nur wenige Daten verfügbar sind, ist es wichtig, die Anzahl der Merkmale zu reduzieren. In dieser Forschungsarbeit werden verschiedene Ansätze zur Reduzierung der Anzahl der für die CSP-Berechnung verwendeten Elektroden untersucht. Frei verfügbare EEG-Datensätze werden für die Evaluierung genutzt. Dazu wird eine einfache Klassifizierungspipeline bestehend aus CSP und linearer Diskriminanzanalyse zur Klassifizierung genutzt. Es wird eine Basislinie unter Nutzung aller Elektroden berechnet und diese mit den Ergebnissen der verschiedenen Ansätze verglichen. Der vielversprechendste Ansatz besteht darin, die Fähigkeit von CSP zu nutzen, Informationen über den Ursprung des erstellten Filters zu liefern. Es wird ein Algorithmus vorgeschlagen, der diese Fähigkeit ausnutzt und so wichtige Elektroden aus dem CSP extrahiert.Die Ergebnisse zeigen, dass die Verwendung von probandenspezifischen Elektrodenpositionen eine positive Auswirkung auf die Genauigkeit der Klassifizierungsaufgabe hat. Außerdem wird gezeigt, dass Elektrodenkombinationen, die in einem Versuch gut funktionieren, nicht unbedingt auch in einem anderen Versuch desselben Probanden gut abschneiden. Zusätzlich zu den mit Hilfe des entwickelten Algorithmus berechneten Kombinationen werden 26 weitere Elektrodenkombinationen vorgeschlagen. Diese können bei der Auswahl gut funktionierender Elektrodenkombinationen berücksichtigt werden. In dieser Arbeit konnten wir damit eine Verbesserung der Genauigkeit von über 10% erzielen. Die sorgfältige Auswahl der richtigen Elektrodenkombination kann die Genauigkeit bei der Klassifizierung von einer gedachten Bewegung verbessern.",https://pubmed.ncbi.nlm.nih.gov/39386391/,https://pubmed.ncbi.nlm.nih.gov/39386391/,English,Include,,Significance of EEG-electrode combinations while calculating filters with common spatial patterns.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39384601,pubmed:39384601,PubMed,pubmed:39384601,Joint hybrid recursive feature elimination based channel selection and ResGCN for cross session MI recognition.,Duan Li;Keyun Li;Yongquan Xia;Jianhua Dong;Ronglei Lu,2024,10.1038/s41598-024-73536-z,"In the field of brain-computer interface (BCI) based on motor imagery (MI), multi-channel electroencephalography (EEG) data is commonly utilized for MI task recognition to achieve sensory compensation or precise human-computer interaction. However, individual physiological differences, environmental variations, or redundant information and noise in certain channels can pose challenges and impact the performance of BCI systems. In this study, we introduce a channel selection method utilizing Hybrid-Recursive Feature Elimination (H-RFE) combined with residual graph neural networks for MI recognition. This channel selection method employs a recursive feature elimination strategy and integrates three classification methods, namely random forest, gradient boosting, and logistic regression, as evaluators for adaptive channel selection tailored to specific subjects. To fully exploit the spatiotemporal information of multi-channel EEG, this study employed a graph neural network embedded with residual blocks to achieve precise recognition of motor imagery. We conducted algorithm testing using the SHU dataset and the PhysioNet dataset. Experimental results show that on the SHU dataset, utilizing 73.44% of the total channels, the cross-session MI recognition accuracy is 90.03%. Similarly, in the PhysioNet dataset, using 72.5% of the channel data, the classification result also reaches 93.99%. Compared to traditional strategies such as selecting three specific channels, correlation-based channel selection, mutual information-based channel selection, and adaptive channel selection based on Pearson coefficients and spatial positions, the proposed method improved classification accuracy by 34.64%, 10.8%, 3.25% and 2.88% on the SHU dataset, and by 46.96%, 5.04%, 5.81% and 2.32% on the PhysioNet dataset, respectively.",https://pubmed.ncbi.nlm.nih.gov/39384601/,https://pubmed.ncbi.nlm.nih.gov/39384601/,English,Include,,Joint hybrid recursive feature elimination based channel selection and ResGCN for cross session MI recognition.,Include,,"onducted algorithm testing using the SHU dataset and the PhysioNet dataset. Experimental results show that on the SHU dataset, utilizing 73.44% of the total channels, the cross-session MI recognition accuracy is 90.03%. Similarly, in the PhysioNet dataset, using 72.5% of the channel data, the classification result also reaches 93.99%. Compared to traditional strategies such as selecting three spec",,0.95,0.6,
pubmed:39384320,pubmed:39384320,PubMed,pubmed:39384320,Amplitude-Integrated Electroencephalogram in Premature Infants: A Prospective Cohort Study.,Gayathri G Vinnakota;Leslie E Lewis;Shruthi K Bharadwaj;Jayashree Purkayastha;Anand K Patil,2025,10.1055/a-2436-8767,"The study aimed to interpret and establish patterns of amplitude-integrated electroencephalogram (aEEG) in stable preterm neonates and compare the aEEG among different gestational age groups using three standard classifications. This prospective cohort study included stable preterm neonates between 24 A total of 76 aEEG recordings were analyzed from 45 preterm neonates. In the first week, 60% of the neonates had normal voltage patterns, which increased to 80% in the second week. All infants ≤30 weeks displayed discontinuous wave patterns during the first week, and half transitioned to continuous waves in the second week. The lower margin amplitude increased, and the upper margin amplitude decreased with increased gestational age. Additionally, 65% of neonates had a mature sleep-wake cycle in the second week compared with 22% in the first week. The median (interquartile range) CFM score in the second week was 12 (4.5) compared with 8 (4) in the first week, and the CFM score positively correlated with gestation (Spearman correlation coefficient, 0.8; 95% confidence interval, 0.7-0.86). Magalhães grading in both groups was predominantly normal. aEEG is predominantly a continuous normal voltage pattern in >30 weeks' gestation and discontinuous in ≤30 weeks' gestation. CFM score correlates positively with advancing gestation gestational age.",,https://pubmed.ncbi.nlm.nih.gov/39384320/,English,Exclude,Outside date range,Amplitude-Integrated Electroencephalogram in Premature Infants: A Prospective Cohort Study.,,,,,0.95,0.6,
pubmed:39383471,pubmed:39383471,PubMed,pubmed:39383471,Visual placebo and nocebo effects.,Alessandro Piedimonte;Valeria Volpino;Francesco Campaci;Martina Deplano;Francesca Borghesi;Antonella Pollo;Elisa Carlino,2024,10.1113/jp287222,"Placebo and nocebo effects modulate symptom perception through expectations and learning processes in various domains. Predominantly, their impact has been investigated on pain and physical performance. However, the influence of placebos and nocebos on visual system functionality has yet to be explored. The present study aimed to test whether placebo and nocebo effects can intervene in altering participants' performance outcomes during a novel visual accuracy task and to examine the underlying neural mechanisms through EEG. After performing a baseline session, visual accuracy was said to be enhanced or disrupted by a sham transcranial electrical stimulation over the occipital lobe. Behavioural results showed a significant increase in visual accuracy for the placebo group, from the baseline session to the test session, whereas the nocebo group showed a decrease in visual accuracy. EEG analyses on the event-related potential P300 component, conducted on both a centro-parietal electrode patch and a parieto-occipital, one displayed an increase in the amplitude of P300 for the placebo group, and a decrease in the nocebo group. These findings suggest for the first time that placebo and nocebo effects can influence visual perception and attentional processes linked to it. Overall, the present study contributes to understanding how expectations affect sensory perception beyond pain and the motor system, paving the way for investigating these phenomena in other sensory modalities such as auditory or olfactory perception. KEY POINTS: Placebo and nocebo effects have been studied predominantly in pain and motor performance fields. In a novel visual task, the impact of placebo and nocebo effects on the visual system has been evaluated, in both early components (stimuli-related) and late components (attention-related). The placebo group showed an increase in visual accuracy and EEG-evoked potential amplitudes, whereas the nocebo group showed a decrease in both. This study shows how expectations and the related placebo and nocebo effects can shape basic stimuli sensory perception in the visual domain.",https://pubmed.ncbi.nlm.nih.gov/39383471/,https://pubmed.ncbi.nlm.nih.gov/39383471/,English,Include,,Visual placebo and nocebo effects.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39381810,pubmed:39381810,PubMed,pubmed:39381810,A sustainable artificial-intelligence-augmented digital care pathway for epilepsy: Automating seizure tracking based on electroencephalogram data using artificial intelligence.,Pantea Keikhosrokiani;Minna Isomursu;Johanna Uusimaa;Jukka Kortelainen,2024,10.1177/20552076241287356,"Scalp electroencephalograms (EEGs) are critical for neurological evaluations, particularly in epilepsy, yet they demand specialized expertise that is often lacking in many regions. Artificial intelligence (AI) offers potential solutions to this gap. While existing AI models address certain aspects of EEG analysis, a fully automated system for routine EEG interpretation is required for effective epilepsy management and healthcare professionals' decision-making. This study aims to develop an AI-augmented model for automating EEG seizure tracking, thereby supporting a sustainable digital care pathway for epilepsy (DCPE). The goal is to improve patient monitoring, facilitate collaborative decision-making, ensure timely medication adherence, and promote patient compliance. The study proposes an AI-augmented framework using machine learning, focusing on quantitative analysis of EEG data to automate DCPE. A focus group discussion was conducted with healthcare professionals to find the problem of the current digital care pathway and assess the feasibility, usability, and sustainability of the AI-augmented system in the digital care pathway. The study found that a combination of random forest with principal component analysis and support vector machines with KBest feature selection achieved high accuracy rates of 96.52% and 95.28%, respectively. Additionally, the convolutional neural networks model outperformed other deep learning algorithms with an accuracy of 97.65%. The focus group discussion revealed that automating the diagnostic process in digital care pathway could reduce the time needed to diagnose epilepsy. However, the sustainability of the AI-integrated framework depends on factors such as technological infrastructure, skilled personnel, training programs, patient digital literacy, financial resources, and regulatory compliance. The proposed AI-augmented system could enhance epilepsy management by optimizing seizure tracking accuracy, improving monitoring and timely interventions, facilitating collaborative decision-making, and promoting patient-centered care, thereby making the digital care pathway more sustainable.",https://pubmed.ncbi.nlm.nih.gov/39381810/,https://pubmed.ncbi.nlm.nih.gov/39381810/,English,Include,,A sustainable artificial-intelligence-augmented digital care pathway for epilepsy: Automating seizure tracking based on electroencephalogram data using artificial intelligence.,Include,,"mented system in the digital care pathway. The study found that a combination of random forest with principal component analysis and support vector machines with KBest feature selection achieved high accuracy rates of 96.52% and 95.28%, respectively. Additionally, the convolutional neural networks model outperformed other deep learning algorithms with an accuracy of 97.65%. The focus group discuss",,0.95,0.6,
pubmed:39381774,pubmed:39381774,PubMed,pubmed:39381774,Human in the collaborative loop: a strategy for integrating human activity recognition and non-invasive brain-machine interfaces to control collaborative robots.,Artur Pilacinski;Lukas Christ;Marius Boshoff;Ioannis Iossifidis;Patrick Adler;Michael Miro;Bernd Kuhlenkötter;Christian Klaes,2024,10.1109/tbme.2014.2312397,"Human activity recognition (HAR) and brain-machine interface (BMI) are two emerging technologies that can enhance human-robot collaboration (HRC) in domains such as industry or healthcare. HAR uses sensors or cameras to capture and analyze the movements and actions of humans, while BMI uses human brain signals to decode action intentions. Both technologies face challenges impacting accuracy, reliability, and usability. In this article, we review the state-of-the-art techniques and methods for HAR and BMI and highlight their strengths and limitations. We then propose a hybrid framework that fuses HAR and BMI data, which can integrate the complementary information from the brain and body motion signals and improve the performance of human state decoding. We also discuss our hybrid method's potential benefits and implications for HRC.",,https://pubmed.ncbi.nlm.nih.gov/39381774/,English,Exclude,Review/survey papers,Human in the collaborative loop: a strategy for integrating human activity recognition and non-invasive brain-machine interfaces to control collaborative robots.,,,,,0.95,0.6,
pubmed:39379545,pubmed:39379545,PubMed,pubmed:39379545,A double-layered fully automated insomnia identification model employing synthetic data generation using MCSA and CTGAN with single-channel EEG signals.,Steffi Philip Mulamoottil;T Vigneswaran,2024,10.1038/s41598-024-74706-9,"Insomnia was diagnosed by analyzing sleep stages obtained during polysomnography (PSG) recording. The state-of-the-art insomnia detection models that used physiological signals in PSG were successful in classification. However, the sleep stages of unbalanced data in small-time intervals were fed for classification in previous studies. This can be avoided by analyzing the insomnia detection structure in different frequency bands with artificially generated data from the existing one at the preprocessing and post-processing stages. Hence, the paper proposes a double-layered augmentation model using Modified Conventional Signal Augmentation (MCSA) and a Conditional Tabular Generative Adversarial Network (CTGAN) to generate synthetic signals from raw EEG and synthetic data from extracted features, respectively, in creating training data. The presented work is independent of sleep stage scoring and provides double-layered data protection with the utility of augmentation methods. It is ideally suited for real-time detection using a single-channel EEG provides better mobility and comfort while recording. The work analyzes each augmentation layer's performance individually, and better accuracy was observed when merging both. It also evaluates the augmentation performance in various frequency bands, which are decomposed using discrete wavelet transform, and observed that the alpha band contributes more to detection. The classification is performed using Decision Tree (DT), Ensembled Bagged Decision Tree (EBDT), Gradient Boosting (GB), Random Forest (RF), and Stacking classifier (SC), attaining the highest classification accuracy of 94% using RF with a greater Area Under Curve (AUC) value of 0.97 compared to the existing works and is best suited for small datasets.",https://pubmed.ncbi.nlm.nih.gov/39379545/,https://pubmed.ncbi.nlm.nih.gov/39379545/,English,Include,,A double-layered fully automated insomnia identification model employing synthetic data generation using MCSA and CTGAN with single-channel EEG signals.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39374625,pubmed:39374625,PubMed,pubmed:39374625,E-SAT: An extreme learning machine based self attention approach for decoding motor imagery EEG in subject-speciﬁc tasks.,Muhammad Ahmed Ahmed Abbasi;Hafza Faiza Abbasi;Xiaojun Yu;Muhammad Zulkifal Aziz;Nicole Tye June Yih Yih;Zeming Fan,2024,10.1088/1741-2552/ad83f4,"The advancements in Brain-Computer Interface (BCI) have substantially evolved people's lives by enabling direct communication between the human brain and external peripheral devices. In recent years, the integration of machine larning (ML) and deep learning (DL) models have considerably imrpoved the performances of BCIs for decoding the motor imagery (MI) tasks. However, there still exist several limitations, e.g., extensive training time and high sensitivity to noises or outliers with those existing models, which largely hinder the rapid developments of BCIs. To address such issues, this paper proposes a novel extreme learning machine (ELM) based self-attention (E-SAT) mechanism to enhance subject-speciﬁc classiﬁcation performances. Speciﬁcally, for E-SAT, ELM is employed both to imrpove self-attention module generalization ability for feature extraction and to optimize the model's parameter initialization process. Meanwhile, the extracted features are also classiﬁed using ELM, and the end-to-end ELM based setup is used to evaluate E-SAT performances on diﬀerent MI EEG signals. Extensive experiments with diﬀerent datasets, such as BCI Competition III Dataset IV-a, IV-b and BCI Competition IV Datasets 1,2a,2b,3, are conducted to verify the eﬀectiveness of proposed E-SAT strategy. Results show that E-SAT outperforms several state-of-the-art (SOTA) existing methods in subject-speciﬁc classiﬁcation on all the datasets, with an average classiﬁcation accuracy of 99.8%,99.1%,98.9%,75.8%, 90.8%, and 95.4%, being achieved for each datasets, respectively. The experimental results not only show outstanding performance of E-SAT in feature extractions, but also demonstrate that it helps achieves the best results among nine other robust ones. In addition, results in this study also demonstrate that E-SAT achieves exceptional performance in both binary and multi-class classiﬁcation tasks, as well as for noisy and non-noisy datatsets.&#xD.",https://pubmed.ncbi.nlm.nih.gov/39374625/,https://pubmed.ncbi.nlm.nih.gov/39374625/,English,Include,,E-SAT: An extreme learning machine based self attention approach for decoding motor imagery EEG in subject-speciﬁc tasks.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39374038,pubmed:39374038,PubMed,pubmed:39374038,Exploration of epileptic networks in temporal lobe encephaloceles with stereotactic EEG: Electroclinical characteristics and surgical outcomes.,Andrew J Zillgitt;Eric R Mong;Angelique M Manasseh;Hannah C Guider;Nour Baki;Michael D Staudt,2024,10.1002/epi4.13063,"Temporal lobe encephaloceles (TLEN) have been implicated as a cause of temporal lobe epilepsy (TLE), the treatment which is primarily surgical; however, there is no clear consensus on the optimal surgical approach, because it is unclear whether TLE related to TLEN can be addressed by a restricted encephalocele resection or if a more extensive resection is required. The aim of the current article is to report the clinical and electrophysiological profile of patients with TLE secondary to TLEN who underwent stereotactic electroencephalography (SEEG) implantation to identify the epileptogenic network. A retrospective review was performed of patients with TLE related to TLEN who underwent SEEG implantation. Medical charts were reviewed for demographic data, the results of noninvasive and invasive investigations, and operative details. Surgical outcomes were based on Engel classification with at least 6 months follow-up. Nine patients were identified. The mean age at epilepsy onset was 28 years (range, 15-41 years), and 7/9 patients were female. Scalp EEG revealed interictal epileptiform activity most often maximum in the frontotemporal and/or temporal regions. A discrete TLEN was often not identified on initial imaging, but was identified during re-review or at the time of surgery. Seizure onset zones during SEEG were localized to the mesial temporal structures, the temporal pole, or both. One patient became seizure-free following SEEG and another refused further surgery. Of the 7 patients who underwent epilepsy surgery, 5/7 underwent an anterior temporal lobectomy-surgical outcomes were favorable, with 5/7 achieving Engel I outcomes. Invasive SEEG monitoring demonstrated ictal onsets may not be restricted to the TLEN, and often the temporal pole and mesial structures are involved at seizure onset. Ictal propagation patterns vary significantly, which may be related to the underlying pathology and explain the variability in semiology. These findings may inform surgical treatment options. Temporal lobe encephaloceles can cause intractable epilepsy, although their presence may be missed on routine imaging. The management of encephaloceles is primarily surgical; however, the optimal surgical approach can be unclear. Invasive monitoring with SEEG may help characterize the epileptogenic network and result in more optimal surgical outcomes.",,https://pubmed.ncbi.nlm.nih.gov/39374038/,English,Exclude,Review/survey papers,Exploration of epileptic networks in temporal lobe encephaloceles with stereotactic EEG: Electroclinical characteristics and surgical outcomes.,,,,,0.95,0.6,
pubmed:39373494,pubmed:39373494,PubMed,pubmed:39373494,Electromagnetic Source Imaging in Presurgical Evaluation of Children with Drug-Resistant Epilepsy.,Ludovica Corona;Sakar Rijal;Omer Tanritanir;Sadra Shahdadian;Cynthia G Keator;Linh Tran;Saleem I Malik;Madhan Bosemani;Daniel Hansen;Dave Shahani;M Scott Perry;Christos Papadelis,2024,10.3791/66494,"For children with drug-resistant epilepsy (DRE), seizure freedom relies on the delineation and resection (or ablation/disconnection) of the epileptogenic zone (EZ) while preserving the eloquent brain areas. The development of a reliable and noninvasive localization method that provides clinically useful information for the localization of the EZ is, therefore, crucial to achieving successful surgical outcomes. Electric and magnetic source imaging (ESI and MSI) have been increasingly utilized in the presurgical evaluation of these patients showing promising findings in the delineation of epileptogenic as well as eloquent brain areas. Moreover, the combination of ESI and MSI into a single solution, namely electromagnetic source imaging (EMSI), performed on simultaneous high-density electroencephalography (HD-EEG) and magnetoencephalography (MEG) recordings has shown higher source localization accuracy than either modality alone. Despite these encouraging findings, such techniques are performed in only a few tertiary epilepsy centers, are rarely recorded simultaneously, and are underutilized in pediatric cohorts. This study illustrates the experimental setup for recording simultaneous MEG and HD-EEG data as well as the methodological framework for analyzing these data aiming to localize the irritative zone, the seizure onset zone, and eloquent brain areas in children with DRE. More specifically, the experimental setups are presented for (i) recording and localizing interictal and ictal epileptiform activity during sleep and (ii) recording visual-, motor-, auditory-, and somatosensory-evoked responses and mapping relevant eloquent brain areas (i.e., visual, motor, auditory, and somatosensory) during visuomotor task, as well as auditory and somatosensory stimulations. Detailed steps of the data analysis pipeline are further presented for performing EMSI as well as individual ESI and MSI using equivalent current dipole (ECD) and dynamic statistical parametric mapping (dSPM).",https://pubmed.ncbi.nlm.nih.gov/39373494/,https://pubmed.ncbi.nlm.nih.gov/39373494/,English,Include,,Electromagnetic Source Imaging in Presurgical Evaluation of Children with Drug-Resistant Epilepsy.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39371640,pubmed:39371640,PubMed,pubmed:39371640,A comprehensive prediction model of drug-refractory epilepsy based on combined clinical-EEG microstate features.,Jinying Zhang;Chaofeng Zhu;Juan Li;Luyan Wu;Yuying Zhang;Huapin Huang;Wanhui Lin,2024,10.1007/s10548-023-01003-5,"Epilepsy is a chronic neurological disorder characterized by recurrent seizures that significantly impact patients' quality of life. Identifying predictors is crucial for early intervention. Electroencephalography (EEG) microstates effectively describe the resting state activity of the human brain using multichannel EEG. This study aims to develop a comprehensive prediction model that integrates clinical features with EEG microstates to predict drug-refractory epilepsy (DRE). Retrospective study. This study encompassed 226 patients with epilepsy treated at the epilepsy center of a tertiary hospital between October 2020 and May 2023. Patients were categorized into DRE and non-DRE groups. All patients were randomly divided into training and testing sets. Lasso regression combined with Stepglm [both] algorithms was used to screen independent risk factors for DRE. These risk factors were used to construct models to predict the DRE. Three models were constructed: a clinical feature model, an EEG microstate model, and a comprehensive prediction model (combining clinical-EEG microstates). A series of evaluation methods was used to validate the accuracy and reliability of the prediction models. Finally, these models were visualized for display. In the training and testing sets, the comprehensive prediction model achieved the highest area under the curve values, registering 0.99 and 0.969, respectively. It was significantly superior to other models in terms of the C-index, with scores of 0.990 and 0.969, respectively. Additionally, the model recorded the lowest Brier scores of 0.034 and 0.071, respectively, and the calibration curve demonstrated good consistency between the predicted probabilities and observed outcomes. Decision curve analysis revealed that the model provided significant clinical net benefit across the threshold range, underscoring its strong clinical applicability. We visualized the comprehensive prediction model by developing a nomogram and established a user-friendly website to enable easy application of this model (https://fydxh.shinyapps.io/CE_model_of_DRE/). A comprehensive prediction model for DRE was developed, showing excellent discrimination and calibration in both the training and testing sets. This model provided an intuitive approach for assessing the risk of developing DRE in patients with epilepsy.",https://pubmed.ncbi.nlm.nih.gov/39371640/,https://pubmed.ncbi.nlm.nih.gov/39371640/,English,Include,,A comprehensive prediction model of drug-refractory epilepsy based on combined clinical-EEG microstate features.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39370644,pubmed:39370644,PubMed,pubmed:39370644,RELAX-Jr: An Automated Pre-Processing Pipeline for Developmental EEG Recordings.,Aron T Hill;Peter G Enticott;Paul B Fitzgerald;Neil W Bailey,2024,10.1088/1741-2552/aaac92,"Automated EEG pre-processing pipelines provide several key advantages over traditional manual data cleaning approaches; primarily, they are less time-intensive and remove potential experimenter error/bias. Automated pipelines also require fewer technical expertise as they remove the need for manual artefact identification. We recently developed the fully automated Reduction of Electroencephalographic Artefacts (RELAX) pipeline and demonstrated its performance in cleaning EEG data recorded from adult populations. Here, we introduce the RELAX-Jr pipeline, which was adapted from RELAX and designed specifically for pre-processing of data collected from children. RELAX-Jr implements multi-channel Wiener filtering (MWF) and/or wavelet-enhanced independent component analysis (wICA) combined with the adjusted-ADJUST automated independent component classification algorithm to identify and reduce all artefacts using algorithms adapted to optimally identify artefacts in EEG recordings taken from children. Using a dataset of resting-state EEG recordings (N = 136) from children spanning early-to-middle childhood (4-12 years), we assessed the cleaning performance of RELAX-Jr using a range of metrics including signal-to-error ratio, artefact-to-residue ratio, ability to reduce blink and muscle contamination, and differences in estimates of alpha power between eyes-open and eyes-closed recordings. We also compared the performance of RELAX-Jr against four publicly available automated cleaning pipelines. We demonstrate that RELAX-Jr provides strong cleaning performance across a range of metrics, supporting its use as an effective and fully automated cleaning pipeline for neurodevelopmental EEG data.",https://pubmed.ncbi.nlm.nih.gov/39370644/,https://pubmed.ncbi.nlm.nih.gov/39370644/,English,Include,,RELAX-Jr: An Automated Pre-Processing Pipeline for Developmental EEG Recordings.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39369588,pubmed:39369588,PubMed,pubmed:39369588,"Classification of mindfulness experiences from gamma-band effective connectivity: Application of machine-learning algorithms on resting, breathing, and body scan.",Ai-Ling Hsu;Chun-Yu Wu;Hei-Yin Hydra Ng;Chun-Hsiang Chuang;Chih-Mao Huang;Changwei W Wu;Yi-Ping Chao,2024,10.1016/j.cmpb.2024.108446,"Practicing mindfulness is a mental process toward interoceptive awareness, achieving stress reduction and emotion regulation through brain-function alteration. Literature has shown that electroencephalography (EEG)-derived connectivity possesses the potential to differentiate brain functions between mindfulness naïve and mindfulness experienced, where such quantitative differentiation could benefit telediagnosis for mental health. However, there is no prior guidance in model selection targeting on the mindfulness-experience prediction. Here we hypothesized that the EEG effective connectivity could reach a good prediction performance in mindfulness experiences with brain interpretability. We aimed at probing direct Directed Transfer Function (dDTF) to classify the participants' history of mindfulness-based stress reduction (MBSR), and aimed at optimizing the prediction accuracy by comparing multiple machine learning (ML) algorithms. Targeting the gamma-band effective connectivity, we evaluated the EEG-based prediction of the mindfulness experiences across 7 machine learning (ML) algorithms and 3 sessions (i.e., resting, focus-breathing, and body-scan). The support vector machine and naïve Bayes classifiers exhibited significant accuracies above the chance level across all three sessions, and the decision tree algorithm reached the highest prediction accuracy of 91.7 % with the resting state, compared to the classification accuracies with the other two mindful states. We further conducted the analysis on essential EEG channels to preserve the classification accuracy, revealing that preserving just four channels (F7, F8, T7, and P7) out of 19 yielded the accuracy of 83.3 %. Delving into the contribution of connectivity features, specific connectivity features predominantly located in the frontal lobe contributed more to classifier construction, which aligned well with the existing mindfulness literature. In the present study, we initiated a milestone of developing an EEG-based classifier to detect a person's mindfulness experience objectively. The prediction accuracy of the decision tree was optimal to differentiate the mindfulness experiences using the local resting-state EEG data. The suggested algorithm and key channels on the mindfulness-experience prediction may provide guidance for predicting mindfulness experiences using the EEG-based classification embedded in future wearable neurofeedback systems or plausible digital therapeutics.",https://pubmed.ncbi.nlm.nih.gov/39369588/,https://pubmed.ncbi.nlm.nih.gov/39369588/,English,Include,,"Classification of mindfulness experiences from gamma-band effective connectivity: Application of machine-learning algorithms on resting, breathing, and body scan.",Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39369555,pubmed:39369555,PubMed,pubmed:39369555,Advancing epilepsy diagnosis: A meta-analysis of artificial intelligence approaches for interictal epileptiform discharge detection.,Jordana Borges Camargo Diniz;Laís Silva Santana;Marianna Leite;João Lucas Silva Santana;Sarah Isabela Magalhães Costa;Luiz Henrique Martins Castro;João Paulo Mota Telles,2024,10.1016/j.seizure.2024.09.019,"Interictal epileptiform discharges (IEDs) in electroencephalograms (EEGs) are an important biomarker for epilepsy. Currently, the gold standard for IED detection is the visual analysis performed by experts. However, this process is expert-biased, and time-consuming. Developing fast, accurate, and robust detection methods for IEDs based on EEG may facilitate epilepsy diagnosis. We aim to assess the performance of deep learning (DL) and classic machine learning (ML) algorithms in classifying EEG segments into IED and non-IED categories, as well as distinguishing whether the entire EEG contains IED or not. We systematically searched PubMed, Embase, and Web of Science following PRISMA guidelines. We excluded studies that only performed the detection of IEDs instead of binary segment classification. Risk of Bias was evaluated with Quality Assessment of Diagnostic Accuracy Studies (QUADAS-2). Meta-analysis with the overall area under the Summary Receiver Operating Characteristic (SROC), sensitivity, and specificity as effect measures, was performed with R software. A total of 23 studies, comprising 3,629 patients, were eligible for synthesis. Eighteen models performed discharge-level classification, and 6 whole-EEG classification. For the IED-level classification, 3 models were validated in an external dataset with more than 50 patients and achieved a sensitivity of 84.9 % (95 % CI: 82.3-87.2) and a specificity of 68.7 % (95 % CI: 7.9-98.2). Five studies reported model performance using both internal validation (cross-validation) and external datasets. The meta-analysis revealed higher performance for internal validation, with 90.4 % sensitivity and 99.6 % specificity, compared to external validation, which showed 78.1 % sensitivity and 80.1 % specificity. Meta-analysis showed higher performance for models validated with resampling methods compared to those using external datasets. Only a minority of models use more robust validation techniques, which often leads to overfitting.",,https://pubmed.ncbi.nlm.nih.gov/39369555/,English,Exclude,Review/survey papers,Advancing epilepsy diagnosis: A meta-analysis of artificial intelligence approaches for interictal epileptiform discharge detection.,,,,,0.95,0.2,cv_reported;external_test_reported;overfit_terms_found
pubmed:39369554,pubmed:39369554,PubMed,pubmed:39369554,Functional seizure semiology and classification in a public and private hospital.,Gabriele Vilyte;James Butler;Victoria Ives-Deliperi;Chrisma Pretorius,2024,10.1016/j.seizure.2024.09.020,"Our understanding of potential differences in seizure semiology among patients with functional seizures (FS), also known as psychogenic non-epileptic seizures (PNES), across socioeconomic contexts is currently limited. By examining the differences in seizure manifestations between different socioeconomic groups, we aim to enhance the understanding of how socioeconomic factors may influence FS presentation. This study aimed to describe FS semiology in patients from a private and public epilepsy monitoring units (EMUs) in Cape Town, South Africa. The study included patients with FS confirmed through video-electroencephalography (video-EEG) and without comorbid epilepsy. For this retrospective case-control study, data on seizure semiology was gathered from digital patient records, beginning with the earliest available record for each hospital. A total of 305 patients from a private hospital and 67 patients from a public hospital were eligible for the study (N = 372). The private hospital tended to report more akinetic and subjective seizure types when compared to the public hospital. Additionally, patients at the public hospital had higher odds of reporting emotional seizure triggers (aOR=2.57, 95% CI [1.03, 6.37]), loss of consciousness or awareness (aOR=2.58, 95% CI [1.07, 6.24]), and rapid post-event recovery (aOR=6.01, 95% CI [2.52, 14.34]). At the same time, they were less likely to report both short (<30 s) (aOR=0.21, 95% CI [0.08, 0.55]) and long (>5 min) seizures (aOR=0.73, 95% CI [0.13, 0.56]), amnesia for the event (aOR=0.19, 95% CI [0.09, 0.43]), ictal aphasia (aOR=0.33, 95% CI [0.14, 0.76]) or falls and drop attacks (aOR=0.43, 95% CI [0.18, 0.996]), when compared to the private hospital patients. While the seizure manifestations were largely consistent across the two socioeconomic cohorts of patients with FS, some subtle differences were observed and warrant further investigation.",https://pubmed.ncbi.nlm.nih.gov/39369554/,https://pubmed.ncbi.nlm.nih.gov/39369554/,English,Include,,Functional seizure semiology and classification in a public and private hospital.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39368159,pubmed:39368159,PubMed,pubmed:39368159,Machine-learning-based classification of obstructive sleep apnea using 19-channel sleep EEG data.,Dongyeop Kim;Ji Yong Park;Young Wook Song;Euijin Kim;Sungkean Kim;Eun Yeon Joo,2024,10.1016/j.sleep.2024.09.041,"This study aimed to investigate the neurophysiological effects of obstructive sleep apnea (OSA) using multi-channel sleep electroencephalography (EEG) through machine learning methods encompassing various analysis methodologies including power spectral analysis, network analysis, and microstate analysis. Twenty participants with apnea-hypopnea index (AHI) ≥ 15 and 18 participants with AHI <15 were recruited. Overnight polysomnography was conducted concurrently with 19-channel EEG. Preprocessed EEG data underwent computation of relative spectral power. A weighted network based on graph theory was generated; and indices of strength, path length, eigenvector centrality, and clustering coefficient were calculated. Microstate analysis was conducted to derive four topographic maps. Machine learning techniques were employed to assess EEG features capable of differentiating two groups. Among 71 features that showed significant differences between the two groups, seven exhibited good classification performance, achieving 88.3 % accuracy, 92 % sensitivity, and 84 % specificity. These features were power at C4 theta, P3 theta, P4 theta, and F8 gamma during NREM1 sleep and at Pz gamma during REM sleep from power spectral analysis; eigenvector centrality at F7 gamma during REM sleep from network analysis; and duration of microstate 4 during NREM2 sleep from microstate analysis. These seven EEG features were significantly correlated with polysomnographic parameters reflecting the severity of OSA. The application of machine learning techniques and various EEG analytical methods resulted in a model that showed good performance in classifying moderate to severe OSA and highlights the potential of EEG to serve as a biomarker of functional changes in OSA.",https://pubmed.ncbi.nlm.nih.gov/39368159/,https://pubmed.ncbi.nlm.nih.gov/39368159/,English,Include,,Machine-learning-based classification of obstructive sleep apnea using 19-channel sleep EEG data.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39366282,pubmed:39366282,PubMed,pubmed:39366282,Inhibitory deficits in Klinefelter syndrome are secondary to deficits in the auditory and motor domain.,René J Huster;Christina Thunberg;Anne-Kristin Solbakk;Claus H Gravholt;Krister Fjermestad,2024,10.1177/2167702619838466,"Deficits in several cognitive domains are prevalent in men with Klinefelter Syndrome (KS). Verbal deficits are among the most characteristic cognitive impairments of KS, yet other cognitive domains also exhibit deficits. Executive functions, especially working memory capacity and inhibitory control, are frequently affected as well. A common limitation of previous studies addressing potential deficits in inhibitory control is their potential conflation with language-related capabilities, as for example is the case with the Stroop task. Importantly, none of the prior studies utilized the best-accepted approach to study inhibition, namely the Stop Signal Task (SST). This study therefore tested for deficits in inhibitory control in individuals with KS and controls (HC) using a version of the SST with non-semantic auditory stimuli. In addition to the classic behavioral performance measures (e.g., the go reaction time, stopping accuracy, or stop signal reaction time), we also derived parameters of inhibition and attention from electromyography (EMG), electroencephalography (EEG), and Bayesian modeling. Men with KS exhibited prolonged stopping latencies (i.e., stop signal reaction times) and reduced stopping accuracies. Yet, whereas these model-based indices were indicative of attenuated inhibitory control, neither event-related brain potentials nor an EMG-measure of the stopping latency confirmed such deficits. Behavioral and EEG indices, however, provided evidence for deficits in motor response preparation and generation, as well as the early processing of auditory stimuli. In sum, the overall pattern of results does not support the existence of inhibitory deficits in KS per se, but rather suggests that behavioral indices of impaired inhibition may result from early low-level deficits in the auditory and motor domains, as well as a differential weighting in the processing of different aspects of the task.",https://pubmed.ncbi.nlm.nih.gov/39366282/,https://pubmed.ncbi.nlm.nih.gov/39366282/,English,Include,,Inhibitory deficits in Klinefelter syndrome are secondary to deficits in the auditory and motor domain.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39366070,pubmed:39366070,PubMed,pubmed:39366070,Pre-anesthetic brain network metrics as predictors of individual propofol sensitivity.,Yun Zhang;Fei Yan;Qiang Wang;Yubo Wang;Liyu Huang,2024,10.1016/j.cmpb.2024.108447,"Numerous factors, including demographic characteristics, have been implicated in modulating individual sensitivity to propofol; however, substantial inter-individual differences persist even after accounting for these factors. This study thus aimed to explore whether pre-anesthesia brain functional network metrics correlate with an individual's sensitivity to propofol. A total of 54 subjects, including 30 patients and 24 healthy volunteers, were enrolled. Propofol was administered via a target-controlled infusion device, and anesthesia depth was monitored using a bispectral index monitor. Sensitivity to propofol was quantified using the induction time, measured from infusion onset to the bispectral index, which reached 60. Brain functional network metrics indicative of functional integration and segregation, centrality, and network resilience were computed from pre-anesthetic 60-channel EEG recordings. Linear regression analysis and machine learning predictive models were applied to evaluate the contribution of pre-anesthesia network metrics in predicting individual sensitivity to propofol. Our analysis results revealed that subjects could be categorized into high- or low-sensitivity groups based on their induction time. Individuals with low sensitivity exhibited a greater network degree, clustering coefficient, global efficiency, and betweenness centrality, along with reduced modularity and assortativity coefficient in the alpha band. Furthermore, alpha band network metrics were significantly correlated with individual induction time. Leveraging these network metrics as features enabled the classification of individuals into high- or low-sensitivity groups with an accuracy of 94%. Using a clinically relevant endpoint that signifies the level of anesthesia suitable for surgical procedures, this study underscored the robust correlation between pre-anesthesia alpha-band network metrics and individual sensitivity to propofol in a cohort that included both patients and healthy volunteers. Our findings offer preliminary insights into the potential utility of pre-anesthetic brain status assessment to predict propofol sensitivity on an individual basis, which may help to develop a more accurate personalized anesthesia plan.",https://pubmed.ncbi.nlm.nih.gov/39366070/,https://pubmed.ncbi.nlm.nih.gov/39366070/,English,Include,,Pre-anesthetic brain network metrics as predictors of individual propofol sensitivity.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39367728,pubmed:39367728,PubMed,pubmed:39367728,Enhancing motor skill learning through multiple sessions of online high-definition transcranial direct current stimulation in healthy adults: insights from EEG power spectrum.,Feng Guo;Maolin Niu;Nicholas J Hanson;Jianrui Guo;Kuo Zhou;Tan Zhao;Yinghui Ren,2024,10.1093/cercor/bhae395,"The purpose of this study was to evaluate the influence of high-definition transcranial direct current stimulation (HD-tDCS) on finger motor skill acquisition. Thirty-one healthy adult males were randomly assigned to one of three groups: online HD-tDCS (administered during motor skill learning), offline HD-tDCS (delivered before motor skill learning), and a sham group. Participants engaged in a visual isometric pinch task for three consecutive days. Overall motor skill learning and speed-accuracy tradeoff function were used to evaluate the efficacy of tDCS. Electroencephalography was recorded and power spectral density was calculated. Both online and offline HD-tDCS total motor skill acquisition was significantly higher than the sham group (P < 0.001 and P < 0.05, respectively). Motor skill acquisition in the online group was higher than offline (P = 0.132, Cohen's d = 1.46). Speed-accuracy tradeoff function in the online group was higher than both offline and sham groups in the post-test. The online group exhibited significantly lower electroencephalography activity in the frontal, fronto-central, and centro-parietal alpha band regions compared to the sham (P < 0.05). The findings suggest that HD-tDCS application can boost finger motor skill acquisition, with online HD-tDCS displaying superior facilitation. Furthermore, online HD-tDCS reduces the power of alpha rhythms during motor skill execution, enhancing information processing and skill learning efficiency.",https://pubmed.ncbi.nlm.nih.gov/39367728/,https://pubmed.ncbi.nlm.nih.gov/39367728/,English,Include,,Enhancing motor skill learning through multiple sessions of online high-definition transcranial direct current stimulation in healthy adults: insights from EEG power spectrum.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39367475,pubmed:39367475,PubMed,pubmed:39367475,Epileptic seizure prediction via multidimensional transformer and recurrent neural network fusion.,Rong Zhu;Wen-Xin Pan;Jin-Xing Liu;Jun-Liang Shang,2024,10.1186/s12967-024-05678-7,"Epilepsy is a prevalent neurological disorder in which seizures cause recurrent episodes of unconsciousness or muscle convulsions, seriously affecting the patient's work, quality of life, and health and safety. Timely prediction of seizures is critical for patients to take appropriate therapeutic measures. Accurate prediction of seizures remains a challenge due to the complex and variable nature of EEG signals. The study proposes an epileptic seizure model based on a multidimensional Transformer with recurrent neural network(LSTM-GRU) fusion for seizure classification of EEG signals. Firstly, a short-time Fourier transform was employed in the extraction of time-frequency features from EEG signals. Second, the extracted time-frequency features are learned using the Multidimensional Transformer model. Then, LSTM and GRU are then used for further learning of the time and frequency characteristics of the EEG signals. Next, the output features of LSTM and GRU are spliced and categorized using the gating mechanism. Subsequently, seizure prediction is conducted. The model was tested on two datasets: the Bonn EEG dataset and the CHB-MIT dataset. On the CHB-MIT dataset, the average sensitivity and average specificity of the model were 98.24% and 97.27%, respectively. On the Bonn dataset, the model obtained about 99% and about 98% accuracy on the binary classification task and the tertiary upper classification task, respectively. The findings of the experimental investigation demonstrate that our model is capable of exploiting the temporal and frequency characteristics present within EEG signals.",https://pubmed.ncbi.nlm.nih.gov/39367475/,https://pubmed.ncbi.nlm.nih.gov/39367475/,English,Include,,Epileptic seizure prediction via multidimensional transformer and recurrent neural network fusion.,Include,,"MIT dataset. On the CHB-MIT dataset, the average sensitivity and average specificity of the model were 98.24% and 97.27%, respectively. On the Bonn dataset, the model obtained about 99% and about 98% accuracy on the binary classification task and the tertiary upper classification task, respectively. The findings of the experimental investigation demonstrate that our model is capable of exploiting ",,0.95,0.6,
pubmed:39363577,pubmed:39363577,PubMed,pubmed:39363577,A custom-built single-channel in-ear electroencephalography sensor for sleep phase detection: an interdependent solution for at-home sleep studies.,Daniel Filipe Borges;Joana Isabel Soares;Heloísa Silva;João Felgueiras;Carla Batista;Simão Ferreira;Nuno Barbosa Rocha;Alberto Leal,2025,10.1111/jsr.14368,"Sleep is vital for health. It has regenerative and protective functions. Its disruption reduces the quality of life and increases susceptibility to disease. During sleep, there is a cyclicity of distinct phases that are studied for clinical purposes using polysomnography (PSG), a costly and technically demanding method that compromises the quality of natural sleep. The search for simpler devices for recording biological signals at home addresses some of these issues. We have reworked a single-channel in-ear electroencephalography (EEG) sensor grounded to a commercially available memory foam earplug with conductive tape. A total of 14 healthy volunteers underwent a full night of simultaneous PSG, in-ear EEG and actigraphy recordings. We analysed the performance of the methods in terms of sleep metrics and staging. In another group of 14 patients evaluated for sleep-related pathologies, PSG and in-ear EEG were recorded simultaneously, the latter in two different configurations (with and without a contralateral reference on the scalp). In both groups, the in-ear EEG sensor showed a strong correlation, agreement and reliability with the 'gold standard' of PSG and thus supported accurate sleep classification, which is not feasible with actigraphy. Single-channel in-ear EEG offers compelling prospects for simplifying sleep parameterisation in both healthy individuals and clinical patients and paves the way for reliable assessments in a broader range of clinical situations, namely by integrating Level 3 polysomnography devices. In addition, addressing the recognised overestimation of the apnea-hypopnea index, due to the lack of an EEG signal, and the sparse information on sleep metrics could prove fundamental for optimised clinical decision making.",,https://pubmed.ncbi.nlm.nih.gov/39363577/,English,Exclude,Outside date range,A custom-built single-channel in-ear electroencephalography sensor for sleep phase detection: an interdependent solution for at-home sleep studies.,,,,,0.95,0.6,
pubmed:39362909,pubmed:39362909,PubMed,pubmed:39362909,EEG Dataset for the Recognition of Different Emotions Induced in Voice-User Interaction.,Ga-Young Choi;Jong-Gyu Shin;Ji-Yoon Lee;Jun-Seok Lee;In-Seok Heo;Ha-Yeong Yoon;Wansu Lim;Jin-Woo Jeong;Sang-Ho Kim;Han-Jeong Hwang,2024,10.1038/s41597-024-03887-9,"Electroencephalography (EEG)-based open-access datasets are available for emotion recognition studies, where external auditory/visual stimuli are used to artificially evoke pre-defined emotions. In this study, we provide a novel EEG dataset containing the emotional information induced during a realistic human-computer interaction (HCI) using a voice user interface system that mimics natural human-to-human communication. To validate our dataset via neurophysiological investigation and binary emotion classification, we applied a series of signal processing and machine learning methods to the EEG data. The maximum classification accuracy ranged from 43.3% to 90.8% over 38 subjects and classification features could be interpreted neurophysiologically. Our EEG data could be used to develop a reliable HCI system because they were acquired in a natural HCI environment. In addition, auxiliary physiological data measured simultaneously with the EEG data also showed plausible results, i.e., electrocardiogram, photoplethysmogram, galvanic skin response, and facial images, which could be utilized for automatic emotion discrimination independently from, as well as together with the EEG data via the fusion of multi-modal physiological datasets.",https://pubmed.ncbi.nlm.nih.gov/39362909/,https://pubmed.ncbi.nlm.nih.gov/39362909/,English,Include,,EEG Dataset for the Recognition of Different Emotions Induced in Voice-User Interaction.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39361934,pubmed:39361934,PubMed,pubmed:39361934,Density Spectral Array EEG for Sleep Staging in Pediatric Patients.,Robert J Rudock;Ashley D Turner;Michael Binkley;Rebekah Landre;Michael J Morrissey;Stuart R Tomko;Réjean M Guerriero,2025,10.1097/wnp.0000000000001117,"Sleep is an essential physiologic process, which is frequently disrupted in children with illness and/or injury. Accurate identification and quantification of sleep may provide insights to improve long-term clinical outcomes. Traditionally, however, the identification of sleep stages has relied on the resource-intensive and time-consuming gold standard polysomnogram. We sought to use limited EEG data, converted into density spectrum array EEG, to accurately identify sleep stages in a clinical pediatric population. We reviewed 87 clinically indicated pediatric polysomnographic studies with concurrent full montage EEG, between March 2017 and June 2020, of which 11 had normal polysomnogram and EEG interpretations. We then converted the EEG data of those normal studies into density spectral array EEG trends and had five blinded raters classify sleep stage (wakefulness, nonrapid eye movement [NREM] 1, NREM 2, NREM 3, and rapid eye movement) in 5-minute epochs. We compared the classified sleep stages from density spectral array EEG to the gold standard polysomnogram. Inter-rater reliability was highest ( κ = 0.745, P < 0.0001) when classifying state into wakefulness, NREM sleep, and rapid eye movement sleep. Agreement between group classification and polysomnogram was highest ( κ = 0.873, [0.819, 0.926], P < 0.0001) when state was classified into wakefulness and sleep and was lowest ( κ = 0.674 [0.645, 0.703], P < 0.0001) when classified into wakefulness, NREM 1, NREM 2, NREM 3, and rapid eye movement. The most common error that raters made was overscoring of NREM 1. Density spectral array EEG can be used to identify sleep stages in clinical pediatric patients without relying on traditional polysomnography.",,https://pubmed.ncbi.nlm.nih.gov/39361934/,English,Exclude,Outside date range,Density Spectral Array EEG for Sleep Staging in Pediatric Patients.,,,,,0.95,0.6,
pubmed:39359920,pubmed:39359920,PubMed,pubmed:39359920,Unconscious classification of quantitative electroencephalogram features from propofol versus propofol combined with etomidate anesthesia using one-dimensional convolutional neural network.,Pan Zhou;Haixia Deng;Jie Zeng;Haosong Ran;Cong Yu,2024,10.1016/j.neuron.2017.11.020,"Establishing a convolutional neural network model for the recognition of characteristic raw electroencephalogram (EEG) signals is crucial for monitoring consciousness levels and guiding anesthetic drug administration. This trial was conducted from December 2023 to March 2024. A total of 40 surgery patients were randomly divided into either a propofol group (1% propofol injection, 10 mL: 100 mg) (P group) or a propofol-etomidate combination group (1% propofol injection, 10 mL: 100 mg, and 0.2% etomidate injection, 10 mL: 20 mg, mixed at a 2:1 volume ratio) (EP group). In the P group, target-controlled infusion (TCI) was employed for sedation induction, with an initial effect site concentration set at 5-6 μg/mL. The EP group received an intravenous push with a dosage of 0.2 mL/kg. Six consciousness-related EEG features were extracted from both groups and analyzed using four prediction models: support vector machine (SVM), Gaussian Naive Bayes (GNB), artificial neural network (ANN), and one-dimensional convolutional neural network (1D CNN). The performance of the models was evaluated based on accuracy, precision, recall, and F1-score. The power spectral density (94%) and alpha/beta ratio (72%) demonstrated higher accuracy as indicators for assessing consciousness. The classification accuracy of the 1D CNN model for anesthesia-induced unconsciousness (97%) surpassed that of the SVM (83%), GNB (81%), and ANN (83%) models, with a significance level of  Large slow-wave oscillations, power spectral density, and the alpha/beta ratio are effective indicators of changes in consciousness during intravenous anesthesia with a propofol-etomidate combination. These indicators can aid anesthesiologists in evaluating the depth of anesthesia and adjusting dosages accordingly. The 1D CNN model, which incorporates consciousness-related EEG features, represents a promising tool for assessing the depth of anesthesia. https://www.chictr.org.cn/index.html.",https://pubmed.ncbi.nlm.nih.gov/39359920/,https://pubmed.ncbi.nlm.nih.gov/39359920/,English,Include,,Unconscious classification of quantitative electroencephalogram features from propofol versus propofol combined with etomidate anesthesia using one-dimensional convolutional neural network.,Include,,"port vector machine (SVM), Gaussian Naive Bayes (GNB), artificial neural network (ANN), and one-dimensional convolutional neural network (1D CNN). The performance of the models was evaluated based on accuracy, precision, recall, and F1-score. The power spectral density (94%) and alpha/beta ratio (72%) demonstrated higher accuracy as indicators for assessing consciousness. The classification accura",,0.95,0.6,
pubmed:39359319,pubmed:39359319,PubMed,pubmed:39359319,Education Research: Competency-Based EEG Education: An Online Routine EEG Examination for Adult and Child Neurology Residents.,Fábio A Nascimento;Hong Gao;Roohi Katyal;Rebecca Matthews;Samantha V Yap;Stefan Rampp;William O Tatum;Roy E Strowd;Sándor Beniczky,2023,10.1212/wnl.0000000000201670,"We recently published expert consensus-based curricular objectives for routine EEG (rEEG) interpretation for adult and child neurology residents. In this study, we used this curriculum framework to develop and validate an online, competency-based, formative and summative rEEG examination for neurology residents. We developed an online rEEG examination consisting of a brief survey and 30 multiple-choice questions covering EEG learning objectives for neurology residents in 4 domains: normal, abnormal, normal variants, and artifacts. Each question contained a deidentified EEG image, displayed in 2 montages (bipolar and average), reviewed and optimized by the authors to address the learning objectives. Respondents reported their level of confidence (LOC, 5-point Likert scale) with identifying 4 categories of EEG findings independently: states of wakefulness/sleep, sleep structures, normal variants, and artifacts. Accuracy and item discrimination were calculated for each question and LOC for each category. The test was disseminated by the International League Against Epilepsy and shared on social media. Of 2,080 responses, 922 were complete. Respondents comprised clinical neurophysiologists/experts (n = 41), EEG/epilepsy clinical fellows (n = 211), EEG technologists (n = 128), attending neurologists (n = 111), adult neurology residents (n = 227), child neurology residents (n = 108), medical students (n = 24), attending non-neurologists (n = 18), and others (n = 54). Mean overall scores (95% CI) were 82% (77-86) (clinical neurophysiologists), 81% (79-83) (clinical fellows), and 72% (70-73) (adult and child neurology residents). Experts were more confident than clinical fellows in all categories but sleep structures. Experts and clinical fellows were more confident than residents in all 4 categories. Among residents, accuracy and LOC increased as a function of prior EEG weeks of training. Accuracy improved from 67% (baseline/no prior EEG training) to 77% (>12 prior EEG weeks). More than 8 weeks of EEG training was needed to reach accuracy comparable with clinical neurophysiologists on this rEEG examination. Increase in LOC was slower and less robust than increase in accuracy. All but 3 questions had a high discrimination index (>0.25). This online, competency-based rEEG examination, mapped to a published EEG curriculum, has excellent psychometrics and differentiates experienced EEG readers from adult and child neurology residents. This online tool has the potential to improve resident EEG education worldwide.",,https://pubmed.ncbi.nlm.nih.gov/39359319/,English,Exclude,Review/survey papers,Education Research: Competency-Based EEG Education: An Online Routine EEG Examination for Adult and Child Neurology Residents.,,,,,0.95,0.6,
pubmed:39353350,pubmed:39353350,PubMed,pubmed:39353350,Classification of cyclic alternating patterns of sleep using EEG signals.,Megha Agarwal;Amit Singhal,2024,10.1016/j.sleep.2024.09.025,"Cyclic alternating patterns (CAP) occur in electroencephalogram (EEG) signals during non-rapid eye movement sleep. The analysis of CAP can offer insights into various sleep disorders. The first step is the identification of phases A and B for the CAP cycles. In this work, we develop an easy-to-implement accurate system to differentiate between CAP A and CAP B. Small segments of the EEG signal are processed using Gaussian filters to obtain sub-band components. Features are extracted using some statistical characteristics of these signal components. Minimum redundancy maximum relevance test is employed to identify the more significant features. Three different machine learning classifiers are considered and their performance is compared. The results are analyzed for both the balanced and unbalanced datasets. The k-nearest neighbour (kNN) classifier achieves 79.14 % accuracy and F-1 score of 79.24 % for the balanced dataset. The proposed method outperforms the existing methods for CAP classification. It is easy-to-implement and can be considered as a candidate for real-time deployment.",https://pubmed.ncbi.nlm.nih.gov/39353350/,https://pubmed.ncbi.nlm.nih.gov/39353350/,English,Include,,Classification of cyclic alternating patterns of sleep using EEG signals.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39353340,pubmed:39353340,PubMed,pubmed:39353340,Unveiling the neural mechanisms of acute aerobic exercise on inhibitory control among young adults with obesity: Insights from an ERP study.,Kun Wang;Shaobo Cai;Tao Huang;Zhangyan Deng;Jiali Qian;Yanxia Chen;Guozhuang Chen;Lei Xu;Peisi Wang;Yuhan Zhang;Yuhan Qiu;Chun Xie,2024,10.1016/j.actpsy.2024.104506,"Obesity has become a prominent public health concern worldwide and is associated with adverse cognitive function. Exercise, particularly aerobic exercise, is known to benefit for weight loss and cognitive function. However, whether acute aerobic exercise could yield benefits to obese individuals and the precise brain mechanisms of action remain poorly understood. The study aimed to investigate whether acute aerobic exercise could improve inhibitory control among obese individuals and what neuroelectric mechanisms are implicated. A 3 (session: control, low-intensity exercise, moderate-intensity exercise) × 2 (congruency: congruent, incongruent) within-subject design was conducted. 18 obese young male adults underwent three sessions of 30-min interventions in a counterbalanced order seperated by five days: moderate-intensity aerobic exercise (MIE), low-intensity aerobic exercise (LIE) and a control session (a sedentary period of seated rest). The Flanker task and EEG recordings (N2 and P3 amplitude) were investigated following exercise and the control treatment. Results showed that the N2 amplitude following MIE was larger than the control session, whereas a larger N2 and reduced congruent P3 amplitude was observed following MIE than LIE. However, no main effect of the session was found for reaction time and accuracy, but a significant main effect of congruency was observed. These findings suggest acute moderate-intensity aerobic exercise may modulate brain activity through enhanced recruitment of attentional resources for cognitive control and conflict monitoring in adults with obesity.",https://pubmed.ncbi.nlm.nih.gov/39353340/,https://pubmed.ncbi.nlm.nih.gov/39353340/,English,Include,,Unveiling the neural mechanisms of acute aerobic exercise on inhibitory control among young adults with obesity: Insights from an ERP study.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39356610,pubmed:39356610,PubMed,pubmed:39356610,Adapting Action Recognition Neural Networks for Automated Infantile Spasm Detection.,Samuel Diop;Nouha Essid;Francois Jouen;Jean Bergounioux;Imen Trabelsi,2024,10.1109/tnsre.2024.3472088,"Infantile spasms are a severe epileptic syndrome characterized by short muscular contractions lasting from 0.5 to 2 seconds. They are often misdiagnosed due to their atypical presentation, and treatment is frequently delayed, leading to stagnation or regression in psychomotor development and significant cognitive and motor sequelae. One promising approach to addressing this issue is the use of markerless computer vision techniques. In this paper, we introduce a novel approach for recognizing infantile spasms based exclusively on video data. We utilize an expanded 3D neural network pre-trained on an extensive human action recognition dataset called Kinetics. By employing this model, we extract features from short segments of varying sizes sampled from seizure videos, which allows us to effectively capture the spatio-temporal characteristics of infantile spasms. We then apply multiple classifiers to perform binary classification on these extracted features. The best system achieved an average area under the ROC curve of 0.813±0.058 for a 3-second window.",,https://pubmed.ncbi.nlm.nih.gov/39356610/,English,Exclude,Not EEG-BCI focused,Adapting Action Recognition Neural Networks for Automated Infantile Spasm Detection.,,,,,0.9,0.6,
pubmed:39354667,pubmed:39354667,PubMed,pubmed:39354667,"Classifying High-Frequency Oscillations by Morphologic Contrast to Background, With Surgical Outcome Correlates.",Kurt Qing;Erica Von Stein;Lisa Yamada;Adam Fogarty;Paul Nuyujukian,2025,10.1097/wnp.0000000000001121,"Ictal high-frequency oscillations (HFOs) are a reliable indicator of a seizure onset zone for intracranial EEG recordings. Interictal HFOs often are also observed and may be a useful biomarker to supplement ictal data, but distinguishing pathologic from physiologic HFOs continues to be a challenging task. We present a method of classifying HFOs based on morphologic contrast to the background. We retrospectively screened 31 consecutive patients who underwent intracranial recordings for epilepsy at Stanford Medical Center during a 2-year period, and 13 patients met the criteria for inclusion. Interictal EEG data were analyzed using an automated event detector followed by morphologic feature extraction and k-means clustering. Instead of only using event features, the algorithm also incorporated features of the background adjacent to the events. High-frequency oscillations with higher morphologic contrast to the background were labeled as pathologic, and ""hotspots"" with the most active pathologic HFOs were identified and compared with clinically determined seizure onset zones. Clustering with contrast features produced groups with better separation and more consistent boundaries. Eleven of the 13 patients proceeded to surgery, and patients whose hotspots matched seizure onset zones had better outcomes, with 4 out of 5 ""match"" patients having no disabling seizures at 1+ year postoperatively (Engel I or International League Against Epilepsy Class 1-2), while all ""mismatch"" patients continued to have disabling seizures (Fisher exact test P -value = 0.015). High-frequency oscillations with higher contrast to background more likely represent paroxysmal bursts of pathologic activity. Patients with HFO hotspots outside of identified seizure onset zones may not respond as well to surgery.",,https://pubmed.ncbi.nlm.nih.gov/39354667/,English,Exclude,Outside date range,"Classifying High-Frequency Oscillations by Morphologic Contrast to Background, With Surgical Outcome Correlates.",,,,,0.95,0.6,
pubmed:39354549,pubmed:39354549,PubMed,pubmed:39354549,Improving working memory by electrical stimulation and cross-frequency coupling.,Wiam Al Qasem;Mohammed Abubaker;Kateřina Pilátová;Petr Ježdík;Eugen Kvašňák,2024,10.1186/s13041-024-01142-1,"Working memory (WM) is essential for the temporary storage and processing of information required for complex cognitive tasks and relies on neuronal theta and gamma oscillations. Given the limited capacity of WM, researchers have investigated various methods to improve it, including transcranial alternating current stimulation (tACS), which modulates brain activity at specific frequencies. One particularly promising approach is theta-gamma peak-coupled-tACS (TGCp-tACS), which simulates the natural interaction between theta and gamma oscillations that occurs during cognitive control in the brain. The aim of this study was to improve WM in healthy young adults with TGCp-tACS, focusing on both behavioral and neurophysiological outcomes. Thirty-one participants completed five WM tasks under both sham and verum stimulation conditions. Electroencephalography (EEG) recordings before and after stimulation showed that TGCp-tACS increased power spectral density (PSD) in the high-gamma region at the stimulation site, while PSD decreased in the theta and delta regions throughout the cortex. From a behavioral perspective, although no significant changes were observed in most tasks, there was a significant improvement in accuracy in the 14-item Sternberg task, indicating an improvement in phonological WM. In conclusion, TGCp-tACS has the potential to promote and improve the phonological component of WM. To fully realize the cognitive benefits, further research is needed to refine the stimulation parameters and account for individual differences, such as baseline cognitive status and hormonal factors.",https://pubmed.ncbi.nlm.nih.gov/39354549/,https://pubmed.ncbi.nlm.nih.gov/39354549/,English,Include,,Improving working memory by electrical stimulation and cross-frequency coupling.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39354007,pubmed:39354007,PubMed,pubmed:39354007,Enhanced diagnostics for generalized anxiety disorder: leveraging differential channel and functional connectivity features based on frontal EEG signals.,Wei Liu;Bin Zhou;Gang Li;Xiaodong Luo,2024,10.1038/s41598-024-73615-1,"Generalized Anxiety Disorder (GAD) is a chronic anxiety condition characterized by persistent excessive worry, anxiety, and fear. Current diagnostic practices primarily rely on clinicians' subjective assessments and experience, highlighting a need for more objective and reliable methods. This study collected 10-minute resting-state electroencephalogram (EEG) from 45 GAD patients and 36 healthy controls (HC), focusing on six frontal EEG channels for preprocessing, data segmentation, and frequency band division. Innovatively, this study introduced the ""Differential Channel"" method, which enhances classification performance by enhancing the information related to anxiety from the data, thereby highlighting signal differences. Utilizing the preprocessed EEG signals, undirected functional connectivity features (Phase Lag Index, Pearson Correlation Coefficient, and Mutual Information) and directed functional connectivity features (Partial Directed Coherence) were extracted. Multiple machine learning models were applied to distinguish between GAD patients and HC. The results show that the Deep Forest classifier achieves excellent performance with a 12-second time window of DiffFeature. In particular, the classification of GAD and HC was successfully obtained by combining OriFeature and DiffFeature on Mutual Information with a maximum accuracy of 98.08%. Furthermore, it was observed that undirected functional connectivity features significantly outperformed directed functional connectivity when fewer frontal channels were used. Overall, the methodologies developed in this study offer accurate and practical identification strategies for the early screening and clinical diagnosis of GAD, offering the necessary theoretical and technical support for further enhancing the portability of EEG devices.",https://pubmed.ncbi.nlm.nih.gov/39354007/,https://pubmed.ncbi.nlm.nih.gov/39354007/,English,Include,,Enhanced diagnostics for generalized anxiety disorder: leveraging differential channel and functional connectivity features based on frontal EEG signals.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39353965,pubmed:39353965,PubMed,pubmed:39353965,Complex trade-offs in a dual-target visual search task are indexed by lateralised ERP components.,Dion T Henare;Jan Tünnermann;Ilja Wagner;Alexander C Schütz;Anna Schubö,2024,10.1038/s41598-024-72811-3,"In everyday tasks, the choices we make incorporate complex trade-offs between conflicting factors that affect how we will achieve our goals. Previous experimental research has used dual-target visual search to determine how people flexibly adjust their behaviour and make choices that optimise their decisions. In this experiment, we leveraged a visual search task that incorporates complex trade-offs, and electroencephalography (EEG), to understand how neural mechanisms of selective attention contribute to choice behaviour in these tasks. On each trial, participants could choose to respond to the gap location on either of two possible targets. Each target was colour coded such that colour indicated which of the two had the easier gap discrimination. Orthogonally, we manipulated the set size of coloured distractors to modulate how efficiently each target could be found. As a result, optimised task performance required participants to trade-off conflicts between the ease of finding a target given the current set size, and the ease of making its associated gap discrimination. Our results confirm that participants are able to flexibly adjust their behaviour, and trade-off these two factors to maintain their response speed and accuracy. Additionally, the N2pc and SPCN components elicited by search displays could reliably predict the choice that participants would ultimately make on a given trial. These results suggest that initial attentional processes may help to determine the choice participants make, highlighting the central role that attention may play in optimising performance on complex tasks.",https://pubmed.ncbi.nlm.nih.gov/39353965/,https://pubmed.ncbi.nlm.nih.gov/39353965/,English,Include,,Complex trade-offs in a dual-target visual search task are indexed by lateralised ERP components.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39352008,pubmed:39352008,PubMed,pubmed:39352008,Comparative analysis of electroencephalogram (EEG) data gathered from the frontal region with other brain regions affected by attention deficit hyperactivity disorder (ADHD) through multiresolution analysis and machine learning techniques.,Manjusha Deshmukh;Mahi Khemchandani;Paramjit Mahesh Thakur,2024,10.1080/21622965.2024.2405719,"Attention deficit hyperactivity disorder (ADHD) is a neurodevelopmental disorder characterized by repeated patterns of hyperactivity, impulsivity, and inattention that limit daily functioning and development. Electroencephalography (EEG) anomalies correspond to changes in brain connection and activity. The authors propose utilizing empirical mode decomposition (EMD) and discrete wavelet transform (DWT) for feature extraction and machine learning (ML) algorithms to categorize ADHD and control subjects. For this study, the authors considered freely accessible ADHD data obtained from the IEEE data site. Studies have demonstrated a range of EEG anomalies in ADHD patients, such as variations in power spectra, coherence patterns, and event-related potentials (ERPs). Some of the studies claimed that the brain's prefrontal cortex and frontal regions collaborate in intricate networks, and disorders in either of them exacerbate the symptoms of ADHD. , Based on the research that claimed the brain's prefrontal cortex and frontal regions collaborate in intricate networks, and disorders in either of them exacerbate the symptoms of ADHD, the proposed study examines the optimal position of EEG electrode for identifying ADHD and in addition to monitoring accuracy on frontal/ prefrontal and other regions of brain our study also investigates the position groupings that have the highest effect on accurateness in identification of ADHD. The results demonstrate that the dataset classified with AdaBoost provided values for accuracy, precision, specificity, sensitivity, and F1-score as 1.00, 0.70, 0.70, 0.75, and 0.71, respectively, whereas using random forest (RF) it is 0.98, 0.64, 0.60, 0.81, and 0.71, respectively, in detecting ADHD. After detailed analysis, it is observed that the most accurate results included all electrodes. The authors believe the processes can detect various neurodevelopmental problems in children utilizing EEG signals.",https://pubmed.ncbi.nlm.nih.gov/39352008/,https://pubmed.ncbi.nlm.nih.gov/39352008/,English,Include,,Comparative analysis of electroencephalogram (EEG) data gathered from the frontal region with other brain regions affected by attention deficit hyperactivity disorder (ADHD) through multiresolution analysis and machine learning techniques.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39349588,pubmed:39349588,PubMed,pubmed:39349588,Right visual field advantage in orientation discrimination is influenced by biased suppression.,Xinyu Chen;Liyu Cao;Barbara F Haendel,2024,10.1038/s41598-024-73967-8,"Visual input is not equally processed over space. In recent years, a right visual field advantage during free walking and standing in orientation discrimination and contrast detection task was reported. The current study investigated the underlying mechanism of the previously reported right visual field advantage. It particularly tested if the advantage is driven by a stronger suppression of distracting input from the left visual field or improved processing of targets from the right visual field. Combing behavioural and electrophysiological measurements in a mobile EEG and augmented reality setup, human participants (n = 30) in a standing and a walking condition performed a line orientation discrimination task with stimulus eccentricity and distractor status being manipulated. The right visual field advantage, as demonstrated in accuracy and reaction time, was influenced by the distractor status. Specifically, the right visual field advantage was only observed when the target had an incongruent line orientation with the distractor. Neural data further showed that the right visual field advantage was paralleled by a strong modulation of neural activity in the right hemisphere (i.e. contralateral to the distractor). A significant positive correlation between this right hemispheric event related potential (ERP) and behavioural measures (accuracy and reaction time) was found exclusively for trials in which a target was presented on the right and an incongruent distractor was presented on the left. The right hemispheric ERP component further predicted the strength of the right visual field advantage. Notably, the lateralised brain activity and the right visual field advantage were both independent of stimulus eccentricity and the movement state of participants. Overall, our findings suggest an important role of spatially biased suppression of left distracting input in the right visual field advantage as found in orientation discrimination.",https://pubmed.ncbi.nlm.nih.gov/39349588/,https://pubmed.ncbi.nlm.nih.gov/39349588/,English,Include,,Right visual field advantage in orientation discrimination is influenced by biased suppression.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39349492,pubmed:39349492,PubMed,pubmed:39349492,TMS-evoked potentials unveil occipital network involvement in patients diagnosed with Parkinson's disease within 5 years of inclusion.,Noa Zifman;Ofri Levy-Lamdan;Tal Hiller;Avner Thaler;Iftach Dolev;Anat Mirelman;Hilla Fogel;Mark Hallett;Inbal Maidan,2024,10.1038/s41531-024-00793-0,"Distinguishing Parkinson's disease (PD) subgroups may be achieved by observing network responses to external stimuli. We compared TMS-evoked potential (TEP) measures from stimulation of bilateral motor cortex (M1), dorsolateral prefrontal cortex (DLPFC), and visual cortex (V1) between 62 PD patients (age: 69.9 ± 7.5) and 76 healthy controls (age: 69.2 ± 4.3) using a TMS-EEG protocol. TEP measures were analyzed using two-way ANCOVA adjusted for MOCA. PD patients were divided into tremor dominant (TD), non-tremor dominant (NTD) and rapid disease progression (RDP) subgroups. PD patients showed lower wide-waveform adherence (wWFA) (p = 0.025) and interhemispheric connectivity (IHC",,https://pubmed.ncbi.nlm.nih.gov/39349492/,English,Exclude,Not classification-focused,TMS-evoked potentials unveil occipital network involvement in patients diagnosed with Parkinson's disease within 5 years of inclusion.,,,,,0.85,0.6,
pubmed:39349090,pubmed:39349090,PubMed,pubmed:39349090,A performance-based mental workload identification method for special vehicle crews.,Mingyang Guo;Peiyan Duan;Xiaoping Jin;Qingyang Huang;Yuning Wei,2025,10.1016/j.physbeh.2024.114706,"Detecting the mental workload state of armored vehicle crews is of great significance for monitoring the driving state of the crew and improving comprehensive combat effectiveness. In this manuscript, we propose a performance-based mental workload identification method and carry out experimental validation to improve the accuracy of crew mental workload identification and realize the effective classification of mental workload. Based on the virtual simulation system of the special vehicle crew task, this manuscript selects 20 subjects for the mental workload experiment of special vehicle crews. The experiment collected NASA-TLX scale, EEG, eye-tracking data, and performance data. The results show that the mental workload of the crews fluctuates in the segmented tasks of complex operations in typical scenes of special vehicles. The method of determining mental workload using NASA-TLX generates label noise in classification, which is not suitable for special vehicle tasks. Performance-based mental workload identification method is able to recognize fluctuations in the crew's mental workload during segmented tasks. Performance-based and NASA-TXL-based methods were classified using linear discriminant analysis. The results show that the accuracy of the method based on performance is improved by 15.72 %. This manuscript found the NASA-TXL scale is not suitable for the complex tasks of special vehicles, and proposed a performance-based identification method that can help to categorize the mental workload states of special vehicle crews.",,https://pubmed.ncbi.nlm.nih.gov/39349090/,English,Exclude,Outside date range,A performance-based mental workload identification method for special vehicle crews.,,,,,0.95,0.6,
pubmed:39348856,pubmed:39348856,PubMed,pubmed:39348856,A Novel Brain Network Analysis Method for Pediatric ADHD Using RFE-GA Feature Selection Strategy.,Xiang Gu;Chen Dang;Tianyu Shi;Lihan Tang;Kai Wang;Xiangsheng Luo;Yu Zhu;Yuan Feng;Guisen Wu;Ling Zou;Li Sun,2024,10.1088/2057-1976/ad8162,"Attention Deficit Hyperactivity Disorder (ADHD) is a highly prevalent childhood disorder, and related research has been increasing in recent years. However, it remains a challenging issue to accurately identify individuals with ADHD. The research proposes a method for ADHD detection using Recursive Feature Elimination-Genetic Algorithm (RFE-GA) for the feature selection of EEG data. Firstly, this study employed Transfer Entropy (TE) to construct brain networks from the EEG data of the ADHD and Normal groups, conducting an analysis of effective connectivity to unveil causal relationships in the brain's information exchange activities. Subsequently, a dual-layer feature selection method combining Recursive Feature Elimination (RFE) and Genetic Algorithm (GA) was proposed. Using the global search capability of GA and the feature selection ability of RFE, the performance of each feature subset is evaluated to find the optimal feature subset. Finally, a Support Vector Machine (SVM) classifier was employed to classify the ultimate feature set. The results revealed the control group exhibited lower connectivity strength in the left temporal alpha and beta bands, but higher frontal connectivity strength compared to the ADHD group. Additionally, in the gamma frequency band, the control group had higher top lobe connectivity strength than the ADHD group. Through the RFE-GA feature selection method, the optimized feature set was more concise, achieving classification accuracies of 91.3%, 94.1%, and 90.7% for the alpha, beta, and gamma frequency bands, respectively. The proposed RFE-GA feature selection method significantly reduced the number of features, thereby improving classification accuracy.&#xD.",https://pubmed.ncbi.nlm.nih.gov/39348856/,https://pubmed.ncbi.nlm.nih.gov/39348856/,English,Include,,A Novel Brain Network Analysis Method for Pediatric ADHD Using RFE-GA Feature Selection Strategy.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39347792,pubmed:39347792,PubMed,pubmed:39347792,Electrophysiological and hemodynamic mechanisms underlying load modulations in visuospatial working memory: A functional near-infrared spectroscopy (fNIRS) and electroencephalogram (EEG) study.,Lisa Zarantonello;Sabrina Brigadoi;Sami Schiff;Patrizia Silvia Bisiacchi;Simone Cutini;Sara Montagnese;Piero Amodio,2024,10.1037/bne0000604,"The n-back task has been widely used to study working memory. Previous studies investigating the electrophysiological (electroencephalogram [EEG]) and hemodynamic correlates (functional near-infrared spectroscopy [fNIRS]) of the n-back task have been generally based on verbal stimuli and only investigated EEG frequency bands. We simultaneously acquired the EEG and fNIRS in 35 participants (16 males; age = 26.4 ± 4.3 years; educational attainment = 18 ± 2 years) during a visuospatial n-back task. The task encompassed a control condition and a low (requiring to recall one previous stimulus) and a high (requiring to recall two previous stimuli) working memory load experimental conditions. Accuracy decreased and reaction times slowed in the high compared to both low load and control conditions. Regarding EEG, P3a showed higher amplitude in the experimental conditions compared to the control one, and P3b exhibited higher amplitude in the low compared to the high load condition. Regarding fNIRS, the high load condition showed higher deoxygenated hemoglobin compared to the control one. Moreover, the central frontopolar cortex showed higher activation compared with the left frontal cortex. Our study showed that working memory load during a visuospatial n-back task influenced behavioral and electrophysiological indices. Even if the load effect was only observed for deoxygenated hemoglobin on hemodynamic data, this was in line with previous studies and coherent with its electrophysiological correlates. Thus, our study confirms that EEG and fNIRS can be successfully used in multimodal acquisitions, but also highlights that future studies are needed to develop a novel version of the task. (PsycInfo Database Record (c) 2024 APA, all rights reserved).",https://pubmed.ncbi.nlm.nih.gov/39347792/,https://pubmed.ncbi.nlm.nih.gov/39347792/,English,Include,,Electrophysiological and hemodynamic mechanisms underlying load modulations in visuospatial working memory: A functional near-infrared spectroscopy (fNIRS) and electroencephalogram (EEG) study.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39347621,pubmed:39347621,PubMed,pubmed:39347621,A Lightweight Convolutional Neural Network-Reformer Model for Efficient Epileptic Seizure Detection.,Haozhou Cui;Xiangwen Zhong;Haotian Li;Chuanyu Li;Xingchen Dong;Dezan Ji;Landi He;Weidong Zhou,2024,10.1142/s0129065724500655,"A real-time and reliable automatic detection system for epileptic seizures holds significant value in assisting physicians with rapid diagnosis and treatment of epilepsy. Aiming to address this issue, a novel lightweight model called Convolutional Neural Network-Reformer (CNN-Reformer) is proposed for seizure detection on long-term EEG. The CNN-Reformer consists of two main parts: the Data Reshaping (DR) module and the Efficient Attention and Concentration (EAC) module. This framework reduces network parameters while retaining effective feature extraction of multi-channel EEGs, thereby improving model computational efficiency and real-time performance. Initially, the raw EEG signals undergo Discrete Wavelet Transform (DWT) for signal filtering, and then fed into the DR module for data compression and reshaping while preserving local features. Subsequently, these local features are sent to the EAC module to extract global features and perform categorization. Post-processing involving sliding window averaging, thresholding, and collar techniques is further deployed to reduce the false detection rate (FDR) and improve detection performance. On the CHB-MIT scalp EEG dataset, our method achieves an average sensitivity of 97.57%, accuracy of 98.09%, and specificity of 98.11% at segment-based level, and a sensitivity of 96.81%, along with FDR of 0.27/h, and latency of 17.81 s at the event-based level. On the SH-SDU dataset we collected, our method yielded segment-based sensitivity of 94.51%, specificity of 92.83%, and accuracy of 92.81%, along with event-based sensitivity of 94.11%. The average testing time for 1[Formula: see text]h of multi-channel EEG signals is 1.92[Formula: see text]s. The excellent results and fast computational speed of the CNN-Reformer model demonstrate its potential for efficient seizure detection.",https://pubmed.ncbi.nlm.nih.gov/39347621/,https://pubmed.ncbi.nlm.nih.gov/39347621/,English,Include,,A Lightweight Convolutional Neural Network-Reformer Model for Efficient Epileptic Seizure Detection.,Include,,"llar techniques is further deployed to reduce the false detection rate (FDR) and improve detection performance. On the CHB-MIT scalp EEG dataset, our method achieves an average sensitivity of 97.57%, accuracy of 98.09%, and specificity of 98.11% at segment-based level, and a sensitivity of 96.81%, along with FDR of 0.27/h, and latency of 17.81 s at the event-based level. On the SH-SDU dataset we c",,0.95,0.6,
pubmed:39347003,pubmed:39347003,PubMed,pubmed:39347003,Optimizing spatial accuracy in electroencephalography reconstruction through diffuse optical tomography priors in the auditory cortex.,Yutian Qin;Jingyi Wu;Eli Bulger;Jiaming Cao;Hamid Dehghani;Barbara Shinn-Cunningham;Jana M Kainerstorfer,2024,10.1016/j.jneumeth.2007.06.031,"Diffuse optical tomography (DOT) enhances the localization accuracy of neural activity measured with electroencephalography (EEG) while preserving EEG's high temporal resolution. However, the spatial resolution of reconstructed activity diminishes for deeper neural sources. In this study, we analyzed DOT-enhanced EEG localization of neural sources modeled at depths ranging from 11-25 mm in simulations. Our findings reveal systematic biases in reconstructed depth related to DOT channel length. To address this, we developed a data-informed method for selecting DOT channels to improve the spatial accuracy of DOT-enhanced EEG reconstruction. Using our method, the average absolute reconstruction depth errors of DOT reconstruction across all depths are 0.9 ± 0.6 mm, 1.2 ± 0.9 mm, and 1.2 ± 1.1 mm under noiseless, low-level noise, and high-level noise conditions, respectively. In comparison, using fixed channel lengths resulted in errors of 2.6 ± 1.5 mm, 5.0 ± 2.6 mm, and 7.3 ± 4.5 mm under the same conditions. Consequently, our method improved the depth accuracy of DOT reconstructions and facilitated the use of more accurate spatial priors for EEG reconstructions, enhancing the overall precision of the technique.",https://pubmed.ncbi.nlm.nih.gov/39347003/,https://pubmed.ncbi.nlm.nih.gov/39347003/,English,Include,,Optimizing spatial accuracy in electroencephalography reconstruction through diffuse optical tomography priors in the auditory cortex.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39343110,pubmed:39343110,PubMed,pubmed:39343110,Representational dissimilarity component analysis (ReDisCA).,Alexei Ossadtchi;Ilia Semenkov;Anna Zhuravleva;Vladimir Kozunov;Oleg Serikov;Ekaterina Voloshina,2024,10.1016/j.neuroimage.2024.120868,"The principle of Representational Similarity Analysis (RSA) posits that neural representations reflect the structure of encoded information, allowing exploration of spatial and temporal organization of brain information processing. Traditional RSA when applied to EEG or MEG data faces challenges in accessing activation time series at the brain source level due to modeling complexities and insufficient geometric/anatomical data. To overcome this, we introduce Representational Dissimilarity Component Analysis (ReDisCA), a method for estimating spatial-temporal components in EEG or MEG responses aligned with a target representational dissimilarity matrix (RDM). ReDisCA yields informative spatial filters and associated topographies, offering insights into the location of ""representationally relevant"" sources. Applied to evoked response time series, ReDisCA produces temporal source activation profiles with the desired RDM. Importantly, while ReDisCA does not require inverse modeling its output is consistent with EEG and MEG observation equation and can be used as an input to rigorous source localization procedures. Demonstrating ReDisCA's efficacy through simulations and comparison with conventional methods, we show superior source localization accuracy and apply the method to real EEG and MEG datasets, revealing physiologically plausible representational structures without inverse modeling. ReDisCA adds to the family of inverse modeling free methods such as independent component analysis (Makeig, 1995), Spatial spectral decomposition (Nikulin, 2011), and Source power comodulation (Dähne, 2014) designed for extraction sources with desired properties from EEG or MEG data. Extending its utility beyond EEG and MEG analysis, ReDisCA is likely to find application in fMRI data analysis and exploration of representational structures emerging in multilayered artificial neural networks.",https://pubmed.ncbi.nlm.nih.gov/39343110/,https://pubmed.ncbi.nlm.nih.gov/39343110/,English,Include,,Representational dissimilarity component analysis (ReDisCA).,Include,,"can be used as an input to rigorous source localization procedures. Demonstrating ReDisCA's efficacy through simulations and comparison with conventional methods, we show superior source localization accuracy and apply the method to real EEG and MEG datasets, revealing physiologically plausible representational structures without inverse modeling. ReDisCA adds to the family of inverse modeling fre",,0.95,0.6,
pubmed:39342695,pubmed:39342695,PubMed,pubmed:39342695,Multi-source Selective Graph Domain Adaptation Network for cross-subject EEG emotion recognition.,Jing Wang;Xiaojun Ning;Wei Xu;Yunze Li;Ziyu Jia;Youfang Lin,2024,10.1016/j.neunet.2024.106742,"Affective brain-computer interface is an important part of realizing emotional human-computer interaction. However, existing objective individual differences among subjects significantly hinder the application of electroencephalography (EEG) emotion recognition. Existing methods still lack the complete extraction of subject-invariant representations for EEG and the ability to fuse valuable information from multiple subjects to facilitate the emotion recognition of the target subject. To address the above challenges, we propose a Multi-source Selective Graph Domain Adaptation Network (MSGDAN), which can better utilize data from different source subjects and perform more robust emotion recognition on the target subject. The proposed network extracts and selects the individual information specific to each subject, where public information refers to subject-invariant components from multi-source subjects. Moreover, the graph domain adaptation network captures both functional connectivity and regional states of the brain via a dynamic graph network and then integrates graph domain adaptation to ensure the invariance of both functional connectivity and regional states. To evaluate our method, we conduct cross-subject emotion recognition experiments on the SEED, SEED-IV, and DEAP datasets. The results demonstrate that the MSGDAN has superior classification performance.",https://pubmed.ncbi.nlm.nih.gov/39342695/,https://pubmed.ncbi.nlm.nih.gov/39342695/,English,Include,,Multi-source Selective Graph Domain Adaptation Network for cross-subject EEG emotion recognition.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39342443,pubmed:39342443,PubMed,pubmed:39342443,Error monitoring under working memory load: An electrocortical investigation.,Brandon K Watanabe;Elizabeth A Bauer;Annmarie MacNamara,2024,10.1016/s0278-2626(01)80090-7,"Error monitoring is essential for detecting errors and may facilitate behavioral adjustments that can reduce or prevent future errors. At times, error monitoring must occur while individuals are engaged in other, cognitively demanding tasks that might consume processing resources necessary for error monitoring. Here, we set out to determine whether concurrent working memory (WM) load interferes with error monitoring, as measured using event-related potentials, the error-related negativity (Ne/ERN), and error positivity (Pe). Fifty-four participants (n = 33 female) completed an arrowhead flanker task, with trials presented under low (2 letter) or high (6 letter) WM load. Participants were required to hold letter strings in memory and to recall these letters at the end of a set of flanker trials. Results showed that WM load reduced the Pe but did not affect the Ne/ERN. Therefore, WM load appeared to attenuate later, more elaborated stages of error processing, though initial error detection was unaffected. Additionally, high WM load slowed reaction times overall, but did not lead to a significant increase in errors. As such, slower responses may have helped participants maintain comparable accuracy for low-load versus high-load trials. Overall, results indicate that WM load interferes with the evaluation of error significance, which could interfere with behavioral adaptations over time.",,https://pubmed.ncbi.nlm.nih.gov/39342443/,English,Exclude,Not EEG-BCI focused,Error monitoring under working memory load: An electrocortical investigation.,,,,,0.9,0.8,small_sample_mentioned
pubmed:39342058,pubmed:39342058,PubMed,pubmed:39342058,Predictive modeling of evoked intracranial EEG response to medial temporal lobe stimulation in patients with epilepsy.,Gagan Acharya;Kathryn A Davis;Erfan Nozari,2024,10.1038/s42003-024-06859-2,"Despite promising advancements, closed-loop neurostimulation for drug-resistant epilepsy (DRE) still relies on manual tuning and produces variable outcomes, while automated predictable algorithms remain an aspiration. As a fundamental step towards addressing this gap, here we study predictive dynamical models of human intracranial EEG (iEEG) response under parametrically rich neurostimulation. Using data from n = 13 DRE patients, we find that stimulation-triggered switched-linear models with ~300 ms of causal historical dependence best explain evoked iEEG dynamics. These models are highly consistent across different stimulation amplitudes and frequencies, allowing for learning a generalizable model from abundant STIM OFF and limited STIM ON data. Further, evoked iEEG in nearly all subjects exhibited a distance-dependent pattern, whereby stimulation directly impacts the actuation site and nearby regions (≲ 20 mm), affects medium-distance regions (20 ~ 100 mm) through network interactions, and hardly reaches more distal areas (≳ 100 mm). Peak network interaction occurs at 60 ~ 80 mm from the stimulation site. Due to their predictive accuracy and mechanistic interpretability, these models hold significant potential for model-based seizure forecasting and closed-loop neurostimulation design.",https://pubmed.ncbi.nlm.nih.gov/39342058/,https://pubmed.ncbi.nlm.nih.gov/39342058/,English,Include,,Predictive modeling of evoked intracranial EEG response to medial temporal lobe stimulation in patients with epilepsy.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39338869,pubmed:39338869,PubMed,pubmed:39338869,Optimizing Real-Time MI-BCI Performance in Post-Stroke Patients: Impact of Time Window Duration on Classification Accuracy and Responsiveness.,Aleksandar Miladinović;Agostino Accardo;Joanna Jarmolowska;Uros Marusic;Miloš Ajčević,2024,10.1007/s41233-018-0023-z,"Brain-computer interfaces (BCIs) are promising tools for motor neurorehabilitation. Achieving a balance between classification accuracy and system responsiveness is crucial for real-time applications. This study aimed to assess how the duration of time windows affects performance, specifically classification accuracy and the false positive rate, to optimize the temporal parameters of MI-BCI systems. We investigated the impact of time window duration on classification accuracy and false positive rate, employing Linear Discriminant Analysis (LDA), Multilayer Perceptron (MLP), and Support Vector Machine (SVM) on data acquired from six post-stroke patients and on the external BCI IVa dataset. EEG signals were recorded and processed using the Common Spatial Patterns (CSP) algorithm for feature extraction. Our results indicate that longer time windows generally enhance classification accuracy and reduce false positives across all classifiers, with LDA performing the best. However, to maintain the real-time responsiveness, crucial for practical applications, a balance must be struck. The results suggest an optimal time window of 1-2 s, offering a trade-off between classification performance and excessive delay to guarantee the system responsiveness. These findings underscore the importance of temporal optimization in MI-BCI systems to improve usability in real rehabilitation scenarios.",https://pubmed.ncbi.nlm.nih.gov/39338869/,https://pubmed.ncbi.nlm.nih.gov/39338869/,English,Include,,Optimizing Real-Time MI-BCI Performance in Post-Stroke Patients: Impact of Time Window Duration on Classification Accuracy and Responsiveness.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39338854,pubmed:39338854,PubMed,pubmed:39338854,Enhancing EEG-Based MI-BCIs with Class-Specific and Subject-Specific Features Detected by Neural Manifold Analysis.,Mirco Frosolone;Roberto Prevete;Lorenzo Ognibeni;Salvatore Giugliano;Andrea Apicella;Giovanni Pezzulo;Francesco Donnarumma,2024,10.1016/j.csi.2024.103896,"This paper presents an innovative approach leveraging Neuronal Manifold Analysis of EEG data to identify specific time intervals for feature extraction, effectively capturing both class-specific and subject-specific characteristics. Different pipelines were constructed and employed to extract distinctive features within these intervals, specifically for motor imagery (MI) tasks. The methodology was validated using the Graz Competition IV datasets 2A (four-class) and 2B (two-class) motor imagery classification, demonstrating an improvement in classification accuracy that surpasses state-of-the-art algorithms designed for MI tasks. A multi-dimensional feature space, constructed using NMA, was built to detect intervals that capture these critical characteristics, which led to significantly enhanced classification accuracy, especially for individuals with initially poor classification performance. These findings highlight the robustness of this method and its potential to improve classification performance in EEG-based MI-BCI systems.",https://pubmed.ncbi.nlm.nih.gov/39338854/,https://pubmed.ncbi.nlm.nih.gov/39338854/,English,Include,,Enhancing EEG-Based MI-BCIs with Class-Specific and Subject-Specific Features Detected by Neural Manifold Analysis.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39338848,pubmed:39338848,PubMed,pubmed:39338848,Implications of Aperiodic and Periodic EEG Components in Classification of Major Depressive Disorder from Source and Electrode Perspectives.,Ahmad Zandbagleh;Saeid Sanei;Hamed Azami,2024,10.1097/jcp.0000000000001500,"Electroencephalography (EEG) is useful for studying brain activity in major depressive disorder (MDD), particularly focusing on theta and alpha frequency bands via power spectral density (PSD). However, PSD-based analysis has often produced inconsistent results due to difficulties in distinguishing between periodic and aperiodic components of EEG signals. We analyzed EEG data from 114 young adults, including 74 healthy controls (HCs) and 40 MDD patients, assessing periodic and aperiodic components alongside conventional PSD at both source and electrode levels. Machine learning algorithms classified MDD versus HC based on these features. Sensor-level analysis showed stronger Hedge's g effect sizes for parietal theta and frontal alpha activity than source-level analysis. MDD individuals exhibited reduced theta and alpha activity relative to HC. Logistic regression-based classifications showed that periodic components slightly outperformed PSD, with the best results achieved by combining periodic and aperiodic features (AUC = 0.82). Strong negative correlations were found between reduced periodic parietal theta and frontal alpha activities and higher scores on the Beck Depression Inventory, particularly for the anhedonia subscale. This study emphasizes the superiority of sensor-level over source-level analysis for detecting MDD-related changes and highlights the value of incorporating both periodic and aperiodic components for a more refined understanding of depressive disorders.",https://pubmed.ncbi.nlm.nih.gov/39338848/,https://pubmed.ncbi.nlm.nih.gov/39338848/,English,Include,,Implications of Aperiodic and Periodic EEG Components in Classification of Major Depressive Disorder from Source and Electrode Perspectives.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39338748,pubmed:39338748,PubMed,pubmed:39338748,Detection of Movement-Related Brain Activity Associated with Hand and Tongue Movements from Single-Trial Around-Ear EEG.,Dávid Gulyás;Mads Jochumsen,2024,10.3389/fnins.2017.00356,"Movement intentions of motor impaired individuals can be detected in laboratory settings via electroencephalography Brain-Computer Interfaces (EEG-BCIs) and used for motor rehabilitation and external system control. The real-world BCI use is limited by the costly, time-consuming, obtrusive, and uncomfortable setup of scalp EEG. Ear-EEG offers a faster, more convenient, and more aesthetic setup for recording EEG, but previous work using expensive amplifiers detected motor intentions at chance level. This study investigates the feasibility of a low-cost ear-EEG BCI for the detection of tongue and hand movements for rehabilitation and control purposes. In this study, ten able-bodied participants performed 100 right wrist extensions and 100 tongue-palate movements while three channels of EEG were recorded around the left ear. Offline movement vs. idle activity classification of ear-EEG was performed using temporal and spectral features classified with Random Forest, Support Vector Machine, K-Nearest Neighbours, and Linear Discriminant Analysis in three scenarios: Hand (rehabilitation purpose), hand (control purpose), and tongue (control purpose). The classification accuracies reached 70%, 73%, and 83%, respectively, which was significantly higher than chance level. These results suggest that a low-cost ear-EEG BCI can detect movement intentions for rehabilitation and control purposes. Future studies should include online BCI use with the intended user group in real-life settings.",https://pubmed.ncbi.nlm.nih.gov/39338748/,https://pubmed.ncbi.nlm.nih.gov/39338748/,English,Include,,Detection of Movement-Related Brain Activity Associated with Hand and Tongue Movements from Single-Trial Around-Ear EEG.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39338733,pubmed:39338733,PubMed,pubmed:39338733,A Spatio-Temporal Capsule Neural Network with Self-Correlation Routing for EEG Decoding of Semantic Concepts of Imagination and Perception Tasks.,Jianxi Huang;Yinghui Chang;Wenyu Li;Jigang Tong;Shengzhi Du,2024,10.1016/j.neuroimage.2023.120209,"Decoding semantic concepts for imagination and perception tasks (SCIP) is important for rehabilitation medicine as well as cognitive neuroscience. Electroencephalogram (EEG) is commonly used in the relevant fields, because it is a low-cost noninvasive technique with high temporal resolution. However, as EEG signals contain a high noise level resulting in a low signal-to-noise ratio, it makes decoding EEG-based semantic concepts for imagination and perception tasks (SCIP-EEG) challenging. Currently, neural network algorithms such as CNN, RNN, and LSTM have almost reached their limits in EEG signal decoding due to their own short-comings. The emergence of transformer methods has improved the classification performance of neural networks for EEG signals. However, the transformer model has a large parameter set and high complexity, which is not conducive to the application of BCI. EEG signals have high spatial correlation. The relationship between signals from different electrodes is more complex. Capsule neural networks can effectively model the spatial relationship between electrodes through vector representation and a dynamic routing mechanism. Therefore, it achieves more accurate feature extraction and classification. This paper proposes a spatio-temporal capsule network with a self-correlation routing mechaninsm for the classification of semantic conceptual EEG signals. By improving the feature extraction and routing mechanism, the model is able to more effectively capture the highly variable spatio-temporal features from EEG signals and establish connections between capsules, thereby enhancing classification accuracy and model efficiency. The performance of the proposed model was validated using the publicly accessible semantic concept dataset for imagined and perceived tasks from Bath University. Our model achieved average accuracies of 94.9%, 93.3%, and 78.4% in the three sensory modalities (pictorial, orthographic, and audio), respectively. The overall average accuracy across the three sensory modalities is 88.9%. Compared to existing advanced algorithms, the proposed model achieved state-of-the-art performance, significantly improving classification accuracy. Additionally, the proposed model is more stable and efficient, making it a better decoding solution for SCIP-EEG decoding.",https://pubmed.ncbi.nlm.nih.gov/39338733/,https://pubmed.ncbi.nlm.nih.gov/39338733/,English,Include,,A Spatio-Temporal Capsule Neural Network with Self-Correlation Routing for EEG Decoding of Semantic Concepts of Imagination and Perception Tasks.,Include,,"ing mechanism, the model is able to more effectively capture the highly variable spatio-temporal features from EEG signals and establish connections between capsules, thereby enhancing classification accuracy and model efficiency. The performance of the proposed model was validated using the publicly accessible semantic concept dataset for imagined and perceived tasks from Bath University. Our mod",,0.95,0.6,
pubmed:39338628,pubmed:39338628,PubMed,pubmed:39338628,Automatic Recognition of Multiple Emotional Classes from EEG Signals through the Use of Graph Theory and Convolutional Neural Networks.,Fatemeh Mohajelin;Sobhan Sheykhivand;Abbas Shabani;Morad Danishvar;Sebelan Danishvar;Lida Zare Lahijan,2024,10.1142/s0218127497001618,"Emotion is a complex state caused by the functioning of the human brain in relation to various events, for which there is no scientific definition. Emotion recognition is traditionally conducted by psychologists and experts based on facial expressions-the traditional way to recognize something limited and is associated with errors. This study presents a new automatic method using electroencephalogram (EEG) signals based on combining graph theory with convolutional networks for emotion recognition. In the proposed model, firstly, a comprehensive database based on musical stimuli is provided to induce two and three emotional classes, including positive, negative, and neutral emotions. Generative adversarial networks (GANs) are used to supplement the recorded data, which are then input into the suggested deep network for feature extraction and classification. The suggested deep network can extract the dynamic information from the EEG data in an optimal manner and has 4 GConv layers. The accuracy of the categorization for two classes and three classes, respectively, is 99% and 98%, according to the suggested strategy. The suggested model has been compared with recent research and algorithms and has provided promising results. The proposed method can be used to complete the brain-computer-interface (BCI) systems puzzle.",https://pubmed.ncbi.nlm.nih.gov/39338628/,https://pubmed.ncbi.nlm.nih.gov/39338628/,English,Include,,Automatic Recognition of Multiple Emotional Classes from EEG Signals through the Use of Graph Theory and Convolutional Neural Networks.,Include,,"the suggested deep network for feature extraction and classification. The suggested deep network can extract the dynamic information from the EEG data in an optimal manner and has 4 GConv layers. The accuracy of the categorization for two classes and three classes, respectively, is 99% and 98%, according to the suggested strategy. The suggested model has been compared with recent research and algo",,0.95,0.6,
pubmed:39335410,pubmed:39335410,PubMed,pubmed:39335410,Fronto-Central Changes in Multiple Frequency Bands in Active Tactile Width Discrimination Task.,Tiago Ramos;Júlia Ramos;Carla Pais-Vieira;Miguel Pais-Vieira,2024,10.1016/j.neuroimage.2020.116610,"The neural basis of tactile processing in humans has been extensively studied; however, the neurophysiological basis of human width discrimination remains relatively unexplored. In particular, the changes that occur in neural networks underlying active tactile width discrimination learning have yet to be described. Here, it is hypothesized that subjects learning to perform the active version of the width discrimination task would present changes in behavioral data and in the neurophysiological activity, specifically in networks of electrodes relevant for tactile and motor processing. The specific hypotheses tested here were that the performance and response latency of subjects would change between the first and the second blocks; the power of the different frequency bands would change between the first and the second blocks; electrode F4 would encode task performance and response latency through changes in the power of the delta, theta, alpha, beta, and low-gamma frequency bands; the relative power in the alpha and beta frequency bands in electrodes C3 and C4 (Interhemispheric Spectral Difference-ISD) would change because of learning between the first and the second blocks. To test this hypothesis, we recorded and analyzed electroencephalographic (EEG) activity while subjects performed a session where they were tested twice (i.e., two different blocks) in an active tactile width discrimination task using their right index finger. Subjects (n = 18) presented high performances (high discrimination accuracy) already in their first block, and therefore no significant improvements were found in the second block. Meanwhile, a reduction in response latency was observed between the two blocks. EEG recordings revealed an increase in power for the low-gamma frequency band (30-45 Hz) for electrodes F3 and C3 from the first to the second block. This change was correlated with neither performance nor latency. Analysis of the neural activity in electrode F4 revealed that the beta frequency band encoded the subjects' performance. Meanwhile, the delta frequency band in the same electrode revealed a complex pattern where blocks appeared clustered in two different patterns: an Upper Pattern (UP), where power and latency were highly correlated (Rho = 0.950), and a sparser and more uncorrelated Lower Pattern (LP). Blocks belonging to the UP or LP patterns did not differ in performance and were not specific to the first or the second block. However, blocks belonging to the LP presented an increase in response latency, increased variability in performance, and an increased ISD in alpha and beta frequency bands for the pair of electrodes C3-C4, suggesting that the LP may reflect a state related to increased cognitive load or task difficulty. These results suggest that changes in performance and latency in an active tactile width discrimination task are encoded in the delta, alpha, beta, and low-gamma frequency bands in a fronto-central network. The main contribution of this study is therefore related to the description of neural dynamics in frontal and central networks involved in the learning process of active tactile width discrimination.",https://pubmed.ncbi.nlm.nih.gov/39335410/,https://pubmed.ncbi.nlm.nih.gov/39335410/,English,Include,,Fronto-Central Changes in Multiple Frequency Bands in Active Tactile Width Discrimination Task.,Include,,"e they were tested twice (i.e., two different blocks) in an active tactile width discrimination task using their right index finger. Subjects (n = 18) presented high performances (high discrimination accuracy) already in their first block, and therefore no significant improvements were found in the second block. Meanwhile, a reduction in response latency was observed between the two blocks. EEG re",,0.95,0.6,
pubmed:39335391,pubmed:39335391,PubMed,pubmed:39335391,Transcranial Magnetic Stimulation Facilitates Neural Speech Decoding.,Lindy Comstock;Vinícius Rezende Carvalho;Claudia Lainscsek;Aria Fallah;Terrence J Sejnowski,2024,10.1155/2011/879716,"Transcranial magnetic stimulation (TMS) has been widely used to study the mechanisms that underlie motor output. Yet, the extent to which TMS acts upon the cortical neurons implicated in volitional motor commands and the focal limitations of TMS remain subject to debate. Previous research links TMS to improved subject performance in behavioral tasks, including a bias in phoneme discrimination. Our study replicates this result, which implies a causal relationship between electro-magnetic stimulation and psychomotor activity, and tests whether TMS-facilitated psychomotor activity recorded via electroencephalography (EEG) may thus serve as a superior input for neural decoding. First, we illustrate that site-specific TMS elicits a double dissociation in discrimination ability for two phoneme categories. Next, we perform a classification analysis on the EEG signals recorded during TMS and find a dissociation between the stimulation site and decoding accuracy that parallels the behavioral results. We observe weak to moderate evidence for the alternative hypothesis in a Bayesian analysis of group means, with more robust results upon stimulation to a brain region governing multiple phoneme features. Overall, task accuracy was a significant predictor of decoding accuracy for phoneme categories (F(1,135) = 11.51, ",https://pubmed.ncbi.nlm.nih.gov/39335391/,https://pubmed.ncbi.nlm.nih.gov/39335391/,English,Include,,Transcranial Magnetic Stimulation Facilitates Neural Speech Decoding.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39335390,pubmed:39335390,PubMed,pubmed:39335390,A Machine Learning Approach to Classifying EEG Data Collected with or without Haptic Feedback during a Simulated Drilling Task.,Michael S Ramirez Campos;Heather S McCracken;Alvaro Uribe-Quevedo;Brianna L Grant;Paul C Yielder;Bernadette A Murphy,2024,10.1093/geroni/igac059.2821,"Artificial Intelligence (AI), computer simulations, and virtual reality (VR) are increasingly becoming accessible tools that can be leveraged to implement training protocols and educational resources. Typical assessment tools related to sensory and neural processing associated with task performance in virtual environments often rely on self-reported surveys, unlike electroencephalography (EEG), which is often used to compare the effects of different types of sensory feedback (e.g., auditory, visual, and haptic) in simulation environments in an objective manner. However, it can be challenging to know which aspects of the EEG signal represent the impact of different types of sensory feedback on neural processing. Machine learning approaches offer a promising direction for identifying EEG signal features that differentiate the impact of different types of sensory feedback during simulation training. For the current study, machine learning techniques were applied to differentiate neural circuitry associated with haptic and non-haptic feedback in a simulated drilling task. Nine EEG channels were selected and analyzed, extracting different time-domain, frequency-domain, and nonlinear features, where 360 features were tested (40 features per channel). A feature selection stage identified the most relevant features, including the Hurst exponent of 13-21 Hz, kurtosis of 21-30 Hz, power spectral density of 21-30 Hz, variance of 21-30 Hz, and spectral entropy of 13-21 Hz. Using those five features, trials with haptic feedback were correctly identified from those without haptic feedback with an accuracy exceeding 90%, increasing to 99% when using 10 features. These results show promise for the future application of machine learning approaches to predict the impact of haptic feedback on neural processing during VR protocols involving drilling tasks, which can inform future applications of VR and simulation for occupational skill acquisition.",,https://pubmed.ncbi.nlm.nih.gov/39335390/,English,Exclude,Review/survey papers,A Machine Learning Approach to Classifying EEG Data Collected with or without Haptic Feedback during a Simulated Drilling Task.,,,,,0.95,0.6,
pubmed:39335379,pubmed:39335379,PubMed,pubmed:39335379,Ongoing Dynamics of Peak Alpha Frequency Characterize Hypnotic Induction in Highly Hypnotic-Susceptible Individuals.,Mathieu Landry;Jason da Silva Castanheira;Floriane Rousseaux;Pierre Rainville;David Ogez;Karim Jerbi,2024,10.1016/j.neubiorev.2017.02.002,"Hypnotic phenomena exhibit significant inter-individual variability, with some individuals consistently demonstrating efficient responses to hypnotic suggestions, while others show limited susceptibility. Recent neurophysiological studies have added to a growing body of research that shows variability in hypnotic susceptibility is linked to distinct neural characteristics. Building on this foundation, our previous work identified that individuals with high and low hypnotic susceptibility can be differentiated based on the arrhythmic activity observed in resting-state electrophysiology (rs-EEG) outside of hypnosis. However, because previous work has largely focused on mean spectral characteristics, our understanding of the variability over time of these features, and how they relate to hypnotic susceptibility, is still limited. Here we address this gap using a time-resolved assessment of rhythmic alpha peaks and arrhythmic components of the EEG spectrum both prior to and following hypnotic induction. Using multivariate pattern classification, we investigated whether these neural features differ between individuals with high and low susceptibility to hypnosis. Specifically, we used multivariate pattern classification to investigate whether these non-stationary neural features could distinguish between individuals with high and low susceptibility to hypnosis before and after a hypnotic induction. Our analytical approach focused on time-resolved spectral decomposition to capture the intricate dynamics of neural oscillations and their non-oscillatory counterpart, as well as Lempel-Ziv complexity. Our results show that variations in the alpha center frequency are indicative of hypnotic susceptibility, but this discrimination is only evident during hypnosis. Highly hypnotic-susceptible individuals exhibit higher variability in alpha peak center frequency. These findings underscore how dynamic changes in neural states related to alpha peak frequency represent a central neurophysiological feature of hypnosis and hypnotic susceptibility.",https://pubmed.ncbi.nlm.nih.gov/39335379/,https://pubmed.ncbi.nlm.nih.gov/39335379/,English,Include,,Ongoing Dynamics of Peak Alpha Frequency Characterize Hypnotic Induction in Highly Hypnotic-Susceptible Individuals.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39335356,pubmed:39335356,PubMed,pubmed:39335356,Classification of Known and Unknown Study Items in a Memory Task Using Single-Trial Event-Related Potentials and Convolutional Neural Networks.,Jorge Delgado-Munoz;Reiko Matsunaka;Kazuo Hiraki,2024,10.1007/s11063-021-10533-7,This study examines the feasibility of using event-related potentials (ERPs) obtained from electroencephalographic (EEG) recordings as biomarkers for long-term memory item classification. Previous studies have identified old/new effects in memory paradigms associated with explicit long-term memory and familiarity. Recent advancements in convolutional neural networks (CNNs) have enabled the classification of ERP trials under different conditions and the identification of features related to neural processes at the single-trial level. We employed this approach to compare three CNN models with distinct architectures using experimental data. Participants (,https://pubmed.ncbi.nlm.nih.gov/39335356/,https://pubmed.ncbi.nlm.nih.gov/39335356/,English,Include,,Classification of Known and Unknown Study Items in a Memory Task Using Single-Trial Event-Related Potentials and Convolutional Neural Networks.,Include,,familiarity. Recent advancements in convolutional neural networks (CNNs) have enabled the classification of ERP trials under different conditions and the identification of features related to neural processes at the single-trial level. We employed this approach to compare three CNN models with distinct architectures using experimental data. Participants (,,0.95,0.8,small_sample_mentioned
pubmed:39333717,pubmed:39333717,PubMed,pubmed:39333717,Attentional templates for target features versus locations.,Mikel Jimenez;Ziyi Wang;Anna Grubert,2024,10.1038/s41598-024-73656-6,"Visual search is guided by visual working memory representations (i.e., attentional templates) that are activated prior to search and contain target-defining features (e.g., color). In the present study, we tested whether attentional templates can also contain spatial target properties (knowing where to look for) and whether attentional selection guided by such feature-specific templates is equally efficient than selection that is based on feature-specific templates (knowing what to look for). In every trial, search displays were either preceded by semantic color or location cues, indicating the upcoming target color or location, respectively. Qualitative differences between feature- and location-based template guidance were substantiated in terms of selection efficiency in low-load (one target color/location) versus high-load trials (two target colors/locations). Behavioral and electrophysiological (N2pc) measures of target selection speed and accuracy were combined for converging evidence. In line with previous studies, we found that color search was highly efficient, even under high-low conditions, when multiple attentional templates were activated to guide attentional selection in a spatially global fashion. Importantly, results in the location task almost perfectly mirrored the findings of the color task, suggesting that multiple templates for different target locations were activated concurrently when two possible target locations were task relevant. Our findings align with accounts that assume a common neuronal network during preparation for location and color search, but regard spatial and feature-based selection mechanisms as independent.",,https://pubmed.ncbi.nlm.nih.gov/39333717/,English,Exclude,Not EEG-BCI focused,Attentional templates for target features versus locations.,,,,,0.9,0.6,
pubmed:39332212,pubmed:39332212,PubMed,pubmed:39332212,OS-SSVEP: One-shot SSVEP classification.,Yang Deng;Zhiwei Ji;Yijun Wang;S Kevin Zhou,2024,10.1016/j.neunet.2024.106734,"It is extremely challenging to classify steady-state visual evoked potentials (SSVEPs) in scenarios characterized by a huge scarcity of calibration data where only one calibration trial is available for each stimulus target. To address this challenge, we introduce a novel approach named OS-SSVEP, which combines a dual domain cross-subject fusion network (CSDuDoFN) with the task-related and task-discriminant component analysis (TRCA and TDCA) based on data augmentation. The CSDuDoFN framework is designed to comprehensively transfer information from source subjects, while TRCA and TDCA are employed to exploit the information from the single available calibration trial of the target subject. Specifically, CSDuDoFN uses multi-reference least-squares transformation (MLST) to map data from both the source subjects and the target subject into the domain of sine-cosine templates, thereby reducing cross-subject domain gap and benefiting transfer learning. In addition, CSDuDoFN is fed with both transformed and original data, with an adequate fusion of their features occurring at different network layers. To capitalize on the calibration trial of the target subject, OS-SSVEP utilizes source aliasing matrix estimation (SAME)-based data augmentation to incorporate into the training process of the ensemble TRCA (eTRCA) and TDCA models. Ultimately, the outputs of CSDuDoFN, eTRCA, and TDCA are combined for the SSVEP classification. The effectiveness of our proposed approach is comprehensively evaluated on three publicly available SSVEP datasets, achieving the best performance on two datasets and competitive performance on the third. Further, it is worth noting that our method follows a different technical route from the current state-of-the-art (SOTA) method and the two are complementary. The performance is significantly improved when our method is combined with the SOTA method. This study underscores the potential to integrate the SSVEP-based brain-computer interface (BCI) into daily life. The corresponding source code is accessible at https://github.com/Sungden/One-shot-SSVEP-classification.",https://pubmed.ncbi.nlm.nih.gov/39332212/,https://pubmed.ncbi.nlm.nih.gov/39332212/,English,Include,,OS-SSVEP: One-shot SSVEP classification.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39332118,pubmed:39332118,PubMed,pubmed:39332118,Handwritten character classification from EEG through continuous kinematic decoding.,Markus R Crell;Gernot R Müller-Putz,2024,10.1016/j.compbiomed.2024.109132,"The classification of handwritten letters from invasive neural signals has lately been subject of research to restore communication abilities in people with limited movement capacities. This study explores the classification of ten letters (a,d,e,f,j,n,o,s,t,v) from non-invasive neural signals of 20 participants, offering new insights into the neural correlates of handwriting. Letters were classified with two methods: the direct classification from low-frequency and broadband electroencephalogram (EEG) and a two-step approach comprising the continuous decoding of hand kinematics and the application of those in subsequent classification. The two-step approach poses a novel application of continuous movement decoding for the classification of letters from EEG. When using low-frequency EEG, results show moderate accuracies of 23.1% for ten letters and 39.0% for a subset of five letters with highest discriminability of the trajectories. The two-step approach yielded significantly higher performances of 26.2% for ten letters and 46.7% for the subset of five letters. Hand kinematics could be reconstructed with a correlation of 0.10 to 0.57 (average chance level: 0.04) between the decoded and original kinematic. The study shows the general feasibility of extracting handwritten letters from non-invasively recorded neural signals and indicates that the proposed two-step approach can improve performances. As an exploratory investigation of the neural mechanisms of handwriting in EEG, we found significant influence of the written letter on the low-frequency components of neural signals. Differences between letters occurred mostly in central and occipital channels. Further, our results suggest movement speed as the most informative kinematic for the decoding of short hand movements.",https://pubmed.ncbi.nlm.nih.gov/39332118/,https://pubmed.ncbi.nlm.nih.gov/39332118/,English,Include,,Handwritten character classification from EEG through continuous kinematic decoding.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39332081,pubmed:39332081,PubMed,pubmed:39332081,"Using deep learning and pretreatment EEG to predict response to sertraline, bupropion, and placebo.",Marman Ravan;Amin Noroozi;Harshil Gediya;Kennette James Basco;Gary Hasey,2024,10.1016/j.clinph.2024.09.002,"Predicting an individual's response to antidepressant medication remains one of the most challenging tasks in the treatment of major depressive disorder (MDD). Our objective was to use the large EMBARC study database to develop an electroencephalography (EEG)-based method to predict response to antidepressant treatment. Pre-treatment EEG data were collected from study participants treated with either sertraline (N = 105), placebo (N = 119), or bupropion (N = 35). After preprocessing, the robust exact low-resolution electromagnetic tomography (ReLORETA) brain source localization method was used to reconstruct the source signals in 54 brain regions. Connectivity between regions was determined using symbolic transfer entropy (STE). A convolutional neural network (CNN) classified participants as responders or non-responders to each treatment. Classification accuracy was 91.0%, 95.4%, and 86.8% for sertraline, placebo, and bupropion, respectively. The most highly predictive features were connectivity between i) the anterior cingulate cortex and superior parietal lobule (alpha frequency), ii) the anterior cingulate cortex and orbitofrontal area (beta frequency), and iii) the orbitofrontal area and anterior cingulate cortex (gamma frequency). CNN analysis of EEG connectivity may accurately predict response to sertraline, bupropion, and placebo. The suggested method may offer clinicians an accessible and cost-effective tool for speedy treatment and helps pharmaceutical firms to test new antidepressants efficiently.",https://pubmed.ncbi.nlm.nih.gov/39332081/,https://pubmed.ncbi.nlm.nih.gov/39332081/,English,Include,,"Using deep learning and pretreatment EEG to predict response to sertraline, bupropion, and placebo.",Include,,"ty between regions was determined using symbolic transfer entropy (STE). A convolutional neural network (CNN) classified participants as responders or non-responders to each treatment. Classification accuracy was 91.0%, 95.4%, and 86.8% for sertraline, placebo, and bupropion, respectively. The most highly predictive features were connectivity between i) the anterior cingulate cortex and superior p",,0.95,0.8,small_sample_mentioned
pubmed:39330063,pubmed:39330063,PubMed,pubmed:39330063,Multi-Frequency Entropy for Quantifying Complex Dynamics and Its Application on EEG Data.,Yan Niu;Jie Xiang;Kai Gao;Jinglong Wu;Jie Sun;Bin Wang;Runan Ding;Mingliang Dou;Xin Wen;Xiaohong Cui;Mengni Zhou,2024,10.1016/j.physa.2016.06.012,"Multivariate entropy algorithms have proven effective in the complexity dynamic analysis of electroencephalography (EEG) signals, with researchers commonly configuring the variables as multi-channel time series. However, the complex quantification of brain dynamics from a multi-frequency perspective has not been extensively explored, despite existing evidence suggesting interactions among brain rhythms at different frequencies. In this study, we proposed a novel algorithm, termed multi-frequency entropy (mFreEn), enhancing the capabilities of existing multivariate entropy algorithms and facilitating the complexity study of interactions among brain rhythms of different frequency bands. Firstly, utilizing simulated data, we evaluated the mFreEn's sensitivity to various noise signals, frequencies, and amplitudes, investigated the effects of parameters such as the embedding dimension and data length, and analyzed its anti-noise performance. The results indicated that mFreEn demonstrated enhanced sensitivity and reduced parameter dependence compared to traditional multivariate entropy algorithms. Subsequently, the mFreEn algorithm was applied to the analysis of real EEG data. We found that mFreEn exhibited a good diagnostic performance in analyzing resting-state EEG data from various brain disorders. Furthermore, mFreEn showed a good classification performance for EEG activity induced by diverse task stimuli. Consequently, mFreEn provides another important perspective to quantify complex dynamics.",https://pubmed.ncbi.nlm.nih.gov/39330063/,https://pubmed.ncbi.nlm.nih.gov/39330063/,English,Include,,Multi-Frequency Entropy for Quantifying Complex Dynamics and Its Application on EEG Data.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39329668,pubmed:39329668,PubMed,pubmed:39329668,Efficient Multi-View Graph Convolutional Network with Self-Attention for Multi-Class Motor Imagery Decoding.,Xiyue Tan;Dan Wang;Meng Xu;Jiaming Chen;Shuhan Wu,2024,10.1109/tnsre.2022.3230250,"Research on electroencephalogram-based motor imagery (MI-EEG) can identify the limbs of subjects that generate motor imagination by decoding EEG signals, which is an important issue in the field of brain-computer interface (BCI). Existing deep-learning-based classification methods have not been able to entirely employ the topological information among brain regions, and thus, the classification performance needs further improving. In this paper, we propose a multi-view graph convolutional attention network (MGCANet) with residual learning structure for multi-class MI decoding. Specifically, we design a multi-view graph convolution spatial feature extraction method based on the topological relationship of brain regions to achieve more comprehensive information aggregation. During the modeling, we build an adaptive weight fusion (Awf) module to adaptively merge feature from different brain views to improve classification accuracy. In addition, the self-attention mechanism is introduced for feature selection to expand the receptive field of EEG signals to global dependence and enhance the expression of important features. The proposed model is experimentally evaluated on two public MI datasets and achieved a mean accuracy of 78.26% (BCIC IV 2a dataset) and 73.68% (OpenBMI dataset), which significantly outperforms representative comparative methods in classification accuracy. Comprehensive experiment results verify the effectiveness of our proposed method, which can provide novel perspectives for MI decoding.",https://pubmed.ncbi.nlm.nih.gov/39329668/,https://pubmed.ncbi.nlm.nih.gov/39329668/,English,Include,,Efficient Multi-View Graph Convolutional Network with Self-Attention for Multi-Class Motor Imagery Decoding.,Include,,"hieve more comprehensive information aggregation. During the modeling, we build an adaptive weight fusion (Awf) module to adaptively merge feature from different brain views to improve classification accuracy. In addition, the self-attention mechanism is introduced for feature selection to expand the receptive field of EEG signals to global dependence and enhance the expression of important featur",,0.95,0.6,
pubmed:39329639,pubmed:39329639,PubMed,pubmed:39329639,Improved Dipole Source Localization from Simultaneous MEG-EEG Data by Combining a Global Optimization Algorithm with a Local Parameter Search: A Brain Phantom Study.,Subrat Bastola;Saeed Jahromi;Rupesh Chikara;Steven M Stufflebeam;Mark P Ottensmeyer;Gianluca De Novi;Christos Papadelis;George Alexandrakis,2024,10.1016/j.procs.2015.12.114,"Dipole localization, a fundamental challenge in electromagnetic source imaging, inherently constitutes an optimization problem aimed at solving the inverse problem of electric current source estimation within the human brain. The accuracy of dipole localization algorithms is contingent upon the complexity of the forward model, often referred to as the head model, and the signal-to-noise ratio (SNR) of measurements. In scenarios characterized by low SNR, often corresponding to deep-seated sources, existing optimization techniques struggle to converge to global minima, thereby leading to the localization of dipoles at erroneous positions, far from their true locations. This study presents a novel hybrid algorithm that combines simulated annealing with the traditional quasi-Newton optimization method, tailored to address the inherent limitations of dipole localization under low-SNR conditions. Using a realistic head model for both electroencephalography (EEG) and magnetoencephalography (MEG), it is demonstrated that this novel hybrid algorithm enables significant improvements of up to 45% in dipole localization accuracy compared to the often-used dipole scanning and gradient descent techniques. Localization improvements are not only found for single dipoles but also in two-dipole-source scenarios, where sources are proximal to each other. The novel methodology presented in this work could be useful in various applications of clinical neuroimaging, particularly in cases where recordings are noisy or sources are located deep within the brain.",https://pubmed.ncbi.nlm.nih.gov/39329639/,https://pubmed.ncbi.nlm.nih.gov/39329639/,English,Include,,Improved Dipole Source Localization from Simultaneous MEG-EEG Data by Combining a Global Optimization Algorithm with a Local Parameter Search: A Brain Phantom Study.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39329584,pubmed:39329584,PubMed,pubmed:39329584,Emotion Recognition Using EEG Signals through the Design of a Dry Electrode Based on the Combination of Type 2 Fuzzy Sets and Deep Convolutional Graph Networks.,Shokoufeh Mounesi Rad;Sebelan Danishvar,2024,10.1016/j.patcog.2023.109461,"Emotion is an intricate cognitive state that, when identified, can serve as a crucial component of the brain-computer interface. This study examines the identification of two categories of positive and negative emotions through the development and implementation of a dry electrode electroencephalogram (EEG). To achieve this objective, a dry EEG electrode is created using the silver-copper sintering technique, which is assessed through Scanning Electron Microscope (SEM) and Energy Dispersive X-ray Analysis (EDXA) evaluations. Subsequently, a database is generated utilizing the designated electrode, which is based on the musical stimulus. The collected data are fed into an improved deep network for automatic feature selection/extraction and classification. The deep network architecture is structured by combining type 2 fuzzy sets (FT2) and deep convolutional graph networks. The fabricated electrode demonstrated superior performance, efficiency, and affordability compared to other electrodes (both wet and dry) in this study. Furthermore, the dry EEG electrode was examined in noisy environments and demonstrated robust resistance across a diverse range of Signal-To-Noise ratios (SNRs). Furthermore, the proposed model achieved a classification accuracy of 99% for distinguishing between positive and negative emotions, an improvement of approximately 2% over previous studies. The manufactured dry EEG electrode is very economical and cost-effective in terms of manufacturing costs when compared to recent studies. The proposed deep network, combined with the fabricated dry EEG electrode, can be used in real-time applications for long-term recordings that do not require gel.",https://pubmed.ncbi.nlm.nih.gov/39329584/,https://pubmed.ncbi.nlm.nih.gov/39329584/,English,Include,,Emotion Recognition Using EEG Signals through the Design of a Dry Electrode Based on the Combination of Type 2 Fuzzy Sets and Deep Convolutional Graph Networks.,Include,," EEG electrode was examined in noisy environments and demonstrated robust resistance across a diverse range of Signal-To-Noise ratios (SNRs). Furthermore, the proposed model achieved a classification accuracy of 99% for distinguishing between positive and negative emotions, an improvement of approximately 2% over previous studies. The manufactured dry EEG electrode is very economical and cost-effe",,0.95,0.6,
pubmed:39329517,pubmed:39329517,PubMed,pubmed:39329517,A Multivariate Approach to Quantifying Risk Factors Impacting Stereotactic Robotic-Guided Stereoelectroencephalography.,Ryan R Song;Akshay Sharma;Nehaw Sarmey;Stephen Harasimchuk;Juan Bulacio;Richard Rammo;William Bingaman;Demitre Serletis,2025,10.1227/ons.0000000000001383,"Stereoelectroencephalography (SEEG) is an important method for invasive monitoring to establish surgical candidacy in approximately half of refractory epilepsy patients. Identifying factors affecting lead placement can mitigate potential surgical risks. This study applies multivariate analyses to identify perioperative factors affecting stereotactic electrode placement. We collected registration and accuracy data for consecutive patients undergoing SEEG implantation between May 2022 and November 2023. Stereotactic robotic guidance, using intraoperative imaging and a novel frame-based fiducial, was used for planning and SEEG implantation. Entry-point (EE), target-point (TE), and angular errors were measured, and statistical univariate and multivariate linear regression analyses were performed. Twenty-seven refractory epilepsy patients (aged 15-57 years) undergoing SEEG were reviewed. Sixteen patients had unilateral implantation (10 left-sided, 6 right-sided); 11 patients underwent bilateral implantation. The mean number of electrodes per patient was 18 (SD = 3) with an average registration mean error of 0.768 mm (SD = 0.108). Overall, 486 electrodes were reviewed. Univariate analysis showed significant correlations of lead error with skull thickness (EE: P = .003; TE: P = .012); entry angle (EE: P < .001; TE: P < .001; angular error: P = .030); lead length (TE: P = .020); and order of electrode implantation (EE: P = .003; TE: P = .001). Three multiple linear regression models were used. All models featured predictors of implantation region (157 temporal, 241 frontal, 79 parietal, 9 occipital); skull thickness (mean = 5.80 mm, SD = 2.97 mm); order (range: 1-23); and entry angle in degrees (mean = 75.47, SD = 11.66). EE and TE error models additionally incorporated lead length (mean = 44.08 mm, SD = 13.90 mm) as a predictor. Implantation region and entry angle were significant predictors of error ( P ≤ .05). Our study identified 2 primary predictors of SEEG lead error, region of implantation and entry angle, with nonsignificant contributions from lead length or order of electrode placement. Future considerations for SEEG may consider varying regional approaches and angles for more optimal accuracy in lead placement.",,https://pubmed.ncbi.nlm.nih.gov/39329517/,English,Exclude,Outside date range,A Multivariate Approach to Quantifying Risk Factors Impacting Stereotactic Robotic-Guided Stereoelectroencephalography.,,,,,0.95,0.6,
pubmed:39329359,pubmed:39329359,PubMed,pubmed:39329359,The neural signature of an erroneous thought.,Klara Steinhauser;Robert Steinhauser;Benjamin Ernst;Martin E Maier;Marco Steinhauser,2024,10.1093/cercor/bhae390,"The human brain detects errors in overt behavior fast and efficiently. However, little is known about how errors are monitored that emerge on a mental level. We investigate whether neural correlates of error monitoring can be found during inner speech and whether the involved neural processes differ between these non-motor responses and behavioral motor responses. Therefore, electroencephalographic data were collected while participants performed two versions of a decision task that only differed between these response modalities. Erroneous responses were identified based on participants' metacognitive judgments. Correlates of error monitoring in event-related potentials were analyzed by applying residue iteration decomposition on stimulus-locked activity. Non-motor responses elicited the same cascade of early error-related negativity and late error positivity as motor responses. An analysis of oscillatory brain activity showed a similar theta response for both error types. A multivariate pattern classifier trained on theta from the motor condition could decode theta from the non-motor condition, demonstrating the similarity of both neural responses. These results show that errors in inner speech are monitored and detected utilizing the same neural processes as behavioral errors, suggesting that goal-directed cognition and behavior are supported by a generic error-monitoring system.",,https://pubmed.ncbi.nlm.nih.gov/39329359/,English,Exclude,Not EEG-BCI focused,The neural signature of an erroneous thought.,,,,,0.9,0.8,small_sample_mentioned
pubmed:39329303,pubmed:39329303,PubMed,pubmed:39329303,Integration of cognitive-motor dual-task training in physical sessions of highly-skilled basketball players.,Stefania Lucia;Mattia Digno;Iker Madinabeita;Francesco Di Russo,2024,10.1080/02640414.2024.2408191,"We investigated the effects of a cognitive-motor dual-task training (CMDT) integrated into a physical training circuit. Specific tests on sprint, agility, and cognitive processes associated with anticipatory event-related potential (ERP) components and behavioural performance during a cognitive discrimination response task (DRT) were evaluated before and after the intervention. Thirty skilled basketball players were recruited and divided into an experimental group executing the ""physical CMDT"" and a control group performing standard physical training. The CMDT session was performed by four athletes simultaneously who executed different circuits. One circuit was the CMDT, implemented with interactive devices thus engaging strong motor control, preparedness, and quick decision-making during task performance. Results on physical performance showed that only the experimental group improved in completion time on sprint (5.83%) and agility (3.55%) tests. At the brain level, we found that in the DRT the motor anticipation increased by over 50%, and the response time became 10% faster. Instead, regarding cognitive preparation, both protocols were equally effective and response accuracy parallelly increased in the post-test. In conclusion, the proposed ""physical CMDT"" integrated into a group session, can improve sprint and agility and the neural correlate of this effect is the increase of motor preparation in the premotor cortex in only five weeks.",,https://pubmed.ncbi.nlm.nih.gov/39329303/,English,Exclude,Not EEG-BCI focused,Integration of cognitive-motor dual-task training in physical sessions of highly-skilled basketball players.,,,,,0.9,0.6,
pubmed:39328315,pubmed:39328315,PubMed,pubmed:39328315,Explainable feature selection and deep learning based emotion recognition in virtual reality using eye tracker and physiological data.,Hadeel Alharbi,2024,10.1016/j.eswa.2021.115524,"Emotional recognition is a way of detecting, evaluating, interpreting, and responding to others' emotional states and feelings, which might range from delight to fear to disgrace. There is increasing interest in the domains of psychological computing and human-computer interface (HCI), especially Emotion Recognition (ER) in Virtual Reality (VR). Human emotions and mental states are effectively captured using Electroencephalography (EEG), and there has been a growing need for analysis in VR situations. In this study, we investigated emotion recognition in a VR environment using explainable machine learning and deep learning techniques. Specifically, we employed Support Vector Classifiers (SVC), K-Nearest Neighbors (KNN), Logistic Regression (LR), Deep Neural Networks (DNN), DNN with flattened layer, Bi-directional Long-short Term Memory (Bi-LSTM), and Attention LSTM. This research utilized an effective multimodal dataset named VREED (VR Eyes: Emotions Dataset) for emotion recognition. The dataset was first reduced to binary and multi-class categories. We then processed the dataset to handle missing values and applied normalization techniques to enhance data consistency. Subsequently, explainable Machine Learning (ML) and Deep Learning (DL) classifiers were employed to predict emotions in VR. Experimental analysis and results indicate that the Attention LSTM model excelled in binary classification, while both DNN and Attention LSTM achieved outstanding performance in multi-class classification, with up to 99.99% accuracy. These findings underscore the efficacy of integrating VR with advanced, explainable ML and DL methods for emotion recognition.",https://pubmed.ncbi.nlm.nih.gov/39328315/,https://pubmed.ncbi.nlm.nih.gov/39328315/,English,Include,,Explainable feature selection and deep learning based emotion recognition in virtual reality using eye tracker and physiological data.,Include,,"d results indicate that the Attention LSTM model excelled in binary classification, while both DNN and Attention LSTM achieved outstanding performance in multi-class classification, with up to 99.99% accuracy. These findings underscore the efficacy of integrating VR with advanced, explainable ML and DL methods for emotion recognition.",,0.95,0.6,
pubmed:39327599,pubmed:39327599,PubMed,pubmed:39327599,Recovery of consciousness after acute brain injury: a narrative review.,Satoshi Egawa;Jeremy Ader;Jan Claassen,2024,10.1186/s40560-024-00749-9,"Disorders of consciousness (DoC) are frequently encountered in both, acute and chronic brain injuries. In many countries, early withdrawal of life-sustaining treatments is common practice for these patients even though the accuracy of predicting recovery is debated and delayed recovery can be seen. In this review, we will discuss theoretical concepts of consciousness and pathophysiology, explore effective strategies for management, and discuss the accurate prediction of long-term clinical outcomes. We will also address research challenges. DoC are characterized by alterations in arousal and/or content, being classified as coma, unresponsive wakefulness syndrome/vegetative state, minimally conscious state, and confusional state. Patients with willful modulation of brain activity detectable by functional MRI or EEG but not by behavioral examination is a state also known as covert consciousness or cognitive motor dissociation. This state may be as common as every 4th or 5th patient without behavioral evidence of verbal command following and has been identified as an independent predictor of long-term functional recovery. Underlying mechanisms are uncertain but intact arousal and thalamocortical projections maybe be essential. Insights into the mechanisms underlying DoC will be of major importance as these will provide a framework to conceptualize treatment approaches, including medical, mechanical, or electoral brain stimulation. We are beginning to gain insights into the underlying mechanisms of DoC, identifying novel advanced prognostication tools to improve the accuracy of recovery predictions, and are starting to conceptualize targeted treatments to support the recovery of DoC patients. It is essential to determine how these advancements can be implemented and benefit DoC patients across a range of clinical settings and global societal systems. The Curing Coma Campaign has highlighted major gaps knowledge and provides a roadmap to advance the field of coma science with the goal to support the recovery of patients with DoC.",,https://pubmed.ncbi.nlm.nih.gov/39327599/,English,Exclude,Review/survey papers,Recovery of consciousness after acute brain injury: a narrative review.,,,,,0.95,0.6,
pubmed:39322029,pubmed:39322029,PubMed,pubmed:39322029,Detection of sleep arousal from STFT-based instantaneous features of single channel EEG signal.,Md Hussain Ali;Md Bashir Uddin,2024,10.1088/1361-6579/ad7fcb,"Sleep arousal, a frequent interruption in sleep with complete or partial wakefulness from sleep, may indicate a breathing disorder, neurological disorder, or sleep-related disorders. These phenomena necessitate the detection of sleep arousals. Uses of deep learning methods to detect features inhibits the scope to understand the specific distinctive nature of the signals and reduces the interpretability of the model. To evade these inconsistencies and to improve the classification performance of the sleep arousal detection model, a model has been proposed in this study on the prospect of understandable features that are useful in detecting sleep arousals. &#xD;Approach: Time-frequency analysis of the electroencephalogram (EEG) signals was performed using Short-Time Fourier Transform (STFT). From the STFT coefficients, the spectrogram and instantaneous properties (frequency, bandwidth, power spectrum, band energy, local maxima, and band energy ratios) were investigated. From these properties, instantaneous features were generated by statistical analysis. Additive feature sets and reduced feature sets, formed by adding features successively and reducing features using the analysis of variance test respectively, were subjected to a tri-layered neural network classifier to evaluate the capability of the features to detect sleep arousal and normal sleep segments. &#xD;Main results: The reduced feature set (Set 6) has proved to be efficacious in facilitating superior classification performance metrics (accuracy, sensitivity, specificity, and AUC of 89.14%, 83.52%, 89.49%, and 93.84% respectively). &#xD;Significance: This efficient model can be incorporated with an automatic sleep apnea detection system where the estimation of hypopnea requires the detection of sleep arousal.&#xD;&#xD.",https://pubmed.ncbi.nlm.nih.gov/39322029/,https://pubmed.ncbi.nlm.nih.gov/39322029/,English,Include,,Detection of sleep arousal from STFT-based instantaneous features of single channel EEG signal.,Include,,"eatures to detect sleep arousal and normal sleep segments. &#xD;Main results: The reduced feature set (Set 6) has proved to be efficacious in facilitating superior classification performance metrics (accuracy, sensitivity, specificity, and AUC of 89.14%, 83.52%, 89.49%, and 93.84% respectively). &#xD;Significance: This efficient model can be incorporated with an automatic sleep apnea detection sys",,0.95,0.6,
pubmed:39321842,pubmed:39321842,PubMed,pubmed:39321842,A shared robot control system combining augmented reality and motor imagery brain-computer interfaces with eye tracking.,Arnau Dillen;Mohsen Omidi;Fakhreddine Ghaffari;Bram Vanderborght;Bart Roelands;Olivier Romain;Ann Nowé;Kevin De Pauw,2024,10.1088/1741-2552/ad7f8d,,,https://pubmed.ncbi.nlm.nih.gov/39321842/,English,Exclude,Not classification-focused,A shared robot control system combining augmented reality and motor imagery brain-computer interfaces with eye tracking.,,,,,0.85,0.6,
pubmed:39321841,pubmed:39321841,PubMed,pubmed:39321841,Filter banks guided correlational convolutional neural network for SSVEPs based BCI classification.,Xin Wen;Shuting Jia;Dan Han;Yanqing Dong;Chengxin Gao;Ruochen Cao;Yanrong Hao;Yuxiang Guo;Rui Cao,2024,10.1088/1741-2552/ad7f89,,https://pubmed.ncbi.nlm.nih.gov/39321841/,https://pubmed.ncbi.nlm.nih.gov/39321841/,English,Include,,Filter banks guided correlational convolutional neural network for SSVEPs based BCI classification.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39321840,pubmed:39321840,PubMed,pubmed:39321840,A comprehensive survey of evolutionary algorithms and metaheuristics in brain EEG-based applications.,Muhammad Arif;Faizan Ur Rehman;Lukas Sekanina;Aamir Saeed Malik,2024,10.1088/1741-2552/ad7f8e,"Electroencephalography (EEG) has emerged as a primary non-invasive and mobile modality for understanding the complex workings of the human brain, providing invaluable insights into cognitive processes, neurological disorders, and brain-computer interfaces. Nevertheless, the volume of EEG data, the presence of artifacts, the selection of optimal channels, and the need for feature extraction from EEG data present considerable challenges in achieving meaningful and distinguishing outcomes for machine learning algorithms utilized to process EEG data. Consequently, the demand for sophisticated optimization techniques has become imperative to overcome these hurdles effectively. Evolutionary algorithms (EAs) and other nature-inspired metaheuristics have been applied as powerful design and optimization tools in recent years, showcasing their significance in addressing various design and optimization problems relevant to brain EEG-based applications. This paper presents a comprehensive survey highlighting the importance of EAs and other metaheuristics in EEG-based applications. The survey is organized according to the main areas where EAs have been applied, namely artifact mitigation, channel selection, feature extraction, feature selection, and signal classification. Finally, the current challenges and future aspects of EAs in the context of EEG-based applications are discussed.",,https://pubmed.ncbi.nlm.nih.gov/39321840/,English,Exclude,Review/survey papers,A comprehensive survey of evolutionary algorithms and metaheuristics in brain EEG-based applications.,,,,,0.95,0.6,
pubmed:39321611,pubmed:39321611,PubMed,pubmed:39321611,Decoding motor imagery loaded on steady-state somatosensory evoked potential based on complex task-related component analysis.,Xiaoyan Wang;Hongzhi Qi,2024,10.1016/j.cmpb.2024.108425,"Motor Imagery (MI) recognition is one of the most critical decoding problems in brain- computer interface field. Combined with the steady-state somatosensory evoked potential (MI-SSSEP), this new paradigm can achieve higher recognition accuracy than the traditional MI paradigm. Typical algorithms do not fully consider the characteristics of MI-SSSEP signals. Developing an algorithm that fully captures the paradigm's characteristics to reduce false triggering rate is the new step in improving performance. The idea to use complex signal task-related component analysis (cTRCA) algorithm for spatial filtering processing has been proposed in this paper according to the features of SSSEP signal. In this research, it's proved from the analysis of simulation signals that task-related component analysis (TRCA) as typical method is affected when the response between stimuli has reduced correlation and the proposed algorithm can effectively overcome this problem. The experimental data under the MI-SSSEP paradigm have been used to identify right-handed target tasks and three unique interference tasks are used to test the false triggering rate. cTRCA demonstrates superior performance as confirmed by the Wilcoxon signed-rank test. The recognition algorithm of cTRCA combined with mutual information-based best individual feature (MIBIF) and minimum distance to mean (MDM) can obtain AUC value up to 0.89, which is much higher than traditional algorithm common spatial pattern (CSP) combined with support vector machine (SVM) (the average AUC value is 0.77, p < 0.05). Compared to CSP+SVM, this algorithm model reduced the false triggering rate from 38.69 % to 20.74 % (p < 0.001). The research prove that TRCA is influenced by MI-SSSEP signals. The results further prove that the motor imagery task in the new paradigm MI-SSSEP causes the phase change in evoked potential. and the cTRCA algorithm based on such phase change is more suitable for this hybrid paradigm and more conducive to decoding the motor imagery task and reducing false triggering rate.",,https://pubmed.ncbi.nlm.nih.gov/39321611/,English,Exclude,Not EEG-BCI focused,Decoding motor imagery loaded on steady-state somatosensory evoked potential based on complex task-related component analysis.,,,,,0.9,0.6,
pubmed:39321571,pubmed:39321571,PubMed,pubmed:39321571,EEG-based sensorimotor neurofeedback for motor neurorehabilitation in children and adults: A scoping review.,Elena Cioffi;Anna Hutber;Rob Molloy;Sarah Murden;Aaron Yurkewich;Adam Kirton;Jean-Pierre Lin;Hortensia Gimeno;Verity M McClelland,2024,10.1002/mds.25501,"Therapeutic interventions for children and young people with dystonia and dystonic/dyskinetic cerebral palsy are limited. EEG-based neurofeedback is emerging as a neurorehabilitation tool. This scoping review maps research investigating EEG-based sensorimotor neurofeedback in adults and children with neurological motor impairments, including augmentative strategies. MEDLINE, CINAHL and Web of Science databases were searched up to 2023 for relevant studies. Study selection and data extraction were conducted independently by at least two reviewers. Of 4380 identified studies, 133 were included, only three enrolling children. The most common diagnosis was adult-onset stroke (77%). Paradigms mostly involved upper limb motor imagery or motor attempt. Common neurofeedback modes included visual, haptic and/or electrical stimulation. EEG parameters varied widely and were often incompletely described. Two studies applied augmentative strategies. Outcome measures varied widely and included classification accuracy of the Brain-Computer Interface, degree of enhancement of mu rhythm modulation or other neurophysiological parameters, and clinical/motor outcome scores. Few studies investigated whether functional outcomes related specifically to the EEG-based neurofeedback. There is limited evidence exploring EEG-based sensorimotor neurofeedback in individuals with movement disorders, especially in children. Further clarity of neurophysiological parameters is required to develop optimal paradigms for evaluating sensorimotor neurofeedback. The expanding field of sensorimotor neurofeedback offers exciting potential as a non-invasive therapy. However, this needs to be balanced by robust study design and detailed methodological reporting to ensure reproducibility and validation that clinical improvements relate to induced neurophysiological changes.",,https://pubmed.ncbi.nlm.nih.gov/39321571/,English,Exclude,Review/survey papers,EEG-based sensorimotor neurofeedback for motor neurorehabilitation in children and adults: A scoping review.,,,,,0.95,0.6,
pubmed:39321002,pubmed:39321002,PubMed,pubmed:39321002,Cascaded Thinning in Upscale and Downscale Representation for EEG Signal Processing.,Quang Manh Doan;Tran Hiep Dinh;Avinash Kumar Singh;Chin-Teng Lin;Nguyen Linh Trung,2024,10.1109/tnsre.2024.3465515,"Smoothing filters are widely used in EEG signal processing for noise removal while preserving signals' features. Inspired by our recent work on Upscale and Downscale Representation (UDR), this paper proposes a cascade arrangement of some effective image-processing techniques for signal filtering in the image domain. The UDR concept is to visualize EEG signals at an appropriate line width and convert it to a binary image. The smoothing process is then conducted by skeletonizing the signal object to a unit width and projecting it back to the time domain. Two successive UDRs could result in a better-smoothing performance, but their binary image conversion should be restricted. The process is computationally ineffective, especially at higher line width values. Cascaded Thinning UDR (CTUDR) is proposed, exploiting morphological operations to perform a two-stage upscale and downscale within one binary image representation. CTUDR is verified on a signal smoothing and classification task and compared with conventional techniques, such as the Moving Average, the Binomial, the Median, and the Savitzky Golay filters. Simulated EEG data with added white Gaussian noise is employed in the former, while cognitive conflict data obtained from a 3D object selection task is utilized in the latter. CTUDR outperforms its counterparts, scoring the best fitting error and correlation coefficient in signal smoothing while achieving the highest gain in Accuracy (0.7640%) and F-measure (0.7607%) when used as a smoothing filter for training data of EEGNet.",https://pubmed.ncbi.nlm.nih.gov/39321002/,https://pubmed.ncbi.nlm.nih.gov/39321002/,English,Include,,Cascaded Thinning in Upscale and Downscale Representation for EEG Signal Processing.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39317529,pubmed:39317529,PubMed,pubmed:39317529,EEG bispectral index sensor guidance improves accuracy and safety of procedural sedation.,A Oh;N Karim;A Pitt;S Hodgetts;D W Edwards;D Mullan;H-U Laasch,2024,10.1016/j.crad.2024.08.033,"To re-audit compliance with an amended sedation protocol following the latest national guidelines. To confirm the improved safety achieved through EEG guidance for drug administration during procedural sedation. Following the revision of the departmental protocol, 14 standards were set. Sedation data and outcomes in 150 consecutive patients undergoing fluoroscopic and combined endoscopic procedures were evaluated against these. Combination sedo-analgesia was titrated by the interventional radiology nurses guided by bispectral index sensor (BIS) measurements to achieve readings between 80 and 85. Doses were stratified by patient age and ASA status. Nasal oxygen was given and standard monitoring including pulse oximetry and capnography were used alongside to assess for complications, notably hypoxaemia of ≤ 94%. 85% were non-vascular procedures, the bulk made up of oesophageal stent insertion, gastrostomy, oesophageal dilatation of radiation strictures and biliary procedures. Mean procedure time was 32.9 minutes (10-170). Mean doses of midazolam and fentanyl were 3.99mg (±1.9) and 92.3μg (±35.4), respectively. 84% of patients were classified as having received light or moderate sedation (BIS 70-89). Three standards for patient sedation were missed, but no patient required sedation reversal or airway management, and none developed hypoxaemia. BIS guidance of sedation administration allows real-time assessment of the patient's response to sedo-analgesia administered and allows prediction about the safety of further drug administration. It identifies patients waking up, allowing this to be anticipated and reduces interruptions of the procedure. It offers clear clinical advantages to interval assessment of patients' response to clinical stimuli and reduces under-as well as oversedation.",https://pubmed.ncbi.nlm.nih.gov/39317529/,https://pubmed.ncbi.nlm.nih.gov/39317529/,English,Include,,EEG bispectral index sensor guidance improves accuracy and safety of procedural sedation.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39317392,pubmed:39317392,PubMed,pubmed:39317392,Optimizing anesthesia management based on early identification of electroencephalogram burst suppression risk in non-cardiac surgery patients: a visualized dynamic nomogram.,Jian Chen;Wanxia Li;Qianping Chen;Zhou Zhou;Chen Chen;Yuping Hu;Yanna Si;Jianjun Zou,2024,10.1097/wnp.0000000000000806,"Burst suppression (BS) is a specific electroencephalogram (EEG) pattern that may contribute to postoperative delirium and negative outcomes. Few prediction models of BS are available and some factors such as frailty and intraoperative hypotension (IOH) which have been reported to promote the occurrence of BS were not included. Therefore, we look forward to creating a straightforward, precise, and clinically useful prediction model by incorporating new factors, such as frailty and IOH. We retrospectively collected 540 patients and analyzed the data from 418 patients. Univariate analysis and backward stepwise logistic regression were used to select risk factors to develop a dynamic nomogram model, and then we developed a web calculator to visualize the process of prediction. The performance of the nomogram was evaluated in terms of discrimination, calibration, and clinical utility. According to the receiver operating characteristic (ROC) analysis, the nomogram showed good discriminative ability (AUC = 0.933) and the Hosmer-Lemeshow goodness-of-fit test demonstrated the nomogram had good calibration ( Incorporating two distinctive new risk factors, frailty and IOH, we firstly developed a visualized nomogram for accurately predicting BS in non-cardiac surgery patients. The model is expected to guide clinical decision-making and optimize anesthesia management. We firstly developed a dynamic nomogram to accurately predict the risk of burst suppression (BS) in non-cardiac surgery, and provided a Quick Response (QR) code based on a web calculator to visualize it.The accuracy of the model is enhanced by the inclusion of frailty and intraoperative hypotension (IOH).Our model aims to help clinicians effectively identify the risk of BS, thus guiding clinical decision-making and optimizing anesthesia management.",https://pubmed.ncbi.nlm.nih.gov/39317392/,https://pubmed.ncbi.nlm.nih.gov/39317392/,English,Include,,Optimizing anesthesia management based on early identification of electroencephalogram burst suppression risk in non-cardiac surgery patients: a visualized dynamic nomogram.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39315035,pubmed:39315035,PubMed,pubmed:39315035,"Effects of color-flavor association on visual search process for reference pictures on beverage packaging: behavioral, electrophysiological, and causal mechanisms.",Chen Cai;Le Zhang;Zitao Guo;Xin Fang;Zihan Quan,2024,10.1038/s41598-024-54215-5,"The visual search for product packaging involves intricate cognitive processes that are prominently impacted by learned associations derived from extensive long-term experiences. The present research employed EEG technology and manipulated the color display of reference pictures on beverage bottles to explore the underlying neurocognitive pathways. Specifically, we aimed to investigate the influence of color-flavor association strength on the visual processing of such stimuli as well as the in-depth neural mechanisms. The behavioral results revealed that stimuli with strong association strength triggered the fastest response and the highest accuracy, compared with the stimuli with weak association strength and the achromatic ones. The EEG findings further substantiated that the chromatic stimuli evoked a more pronounced N2 component than achromatic ones, and the stimuli with strong association strength elicited larger P3 and smaller N400 amplitudes than the ones with weak association strength. Additionally, the source localization using sLORETA showed significant activations in the inferior temporal gyrus. In conclusion, our research suggests that (1) color expectations would guide visual search process and trigger faster responses to congruent visual stimuli, (2) both the initial perceptual representation and subsequent semantic representation play pivotal roles in effective visual search for the targets, and (3) the color-flavor association strength potentially exerts an impact on visual processing by modulating memory accessibility.",https://pubmed.ncbi.nlm.nih.gov/39315035/,https://pubmed.ncbi.nlm.nih.gov/39315035/,English,Include,,"Effects of color-flavor association on visual search process for reference pictures on beverage packaging: behavioral, electrophysiological, and causal mechanisms.",Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39314693,pubmed:39314693,PubMed,pubmed:39314693,Schizophrenia diagnosis based on diverse epoch size resting-state EEG using machine learning.,Athar Alazzawı;Saif Aljumaili;Adil Deniz Duru;Osman Nuri Uçan;Oğuz Bayat;Paulo Jorge Coelho;Ivan Miguel Pires,2024,10.1111/eip.13063,"Schizophrenia is a severe mental disorder that impairs a person's mental, social, and emotional faculties gradually. Detection in the early stages with an accurate diagnosis is crucial to remedying the patients. This study proposed a new method to classify schizophrenia disease in the rest state based on neurologic signals achieved from the brain by electroencephalography (EEG). The datasets used consisted of 28 subjects, 14 for each group, which are schizophrenia and healthy control. The data was collected from the scalps with 19 EEG channels using a 250 Hz frequency. Due to the brain signal variation, we have decomposed the EEG signals into five sub-bands using a band-pass filter, ensuring the best signal clarity and eliminating artifacts. This work was performed with several scenarios: First, traditional techniques were applied. Secondly, augmented data (additive white Gaussian noise and stretched signals) were utilized. Additionally, we assessed Minimum Redundancy Maximum Relevance (MRMR) as the features reduction method. All these data scenarios are applied with three different window sizes (epochs): 1, 2, and 5 s, utilizing six algorithms to extract features: Fast Fourier Transform (FFT), Approximate Entropy (ApEn), Log Energy entropy (LogEn), Shannon Entropy (ShnEn), and kurtosis. The L2-normalization method was applied to the derived features, positively affecting the results. In terms of classification, we applied four algorithms: K-nearest neighbor (KNN), support vector machine (SVM), quadratic discriminant analysis (QDA), and ensemble classifier (EC). From all the scenarios, our evaluation showed that SVM had remarkable results in all evaluation metrics with LogEn features utilizing a 1-s window size, impacting the diagnosis of Schizophrenia disease. This indicates that an accurate diagnosis of schizophrenia can be achieved through the right features and classification model selection. Finally, we contrasted our results to recently published works using the same and a different dataset, where our method showed a notable improvement.",https://pubmed.ncbi.nlm.nih.gov/39314693/,https://pubmed.ncbi.nlm.nih.gov/39314693/,English,Include,,Schizophrenia diagnosis based on diverse epoch size resting-state EEG using machine learning.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39314082,pubmed:39314082,PubMed,pubmed:39314082,Substantiating the Short Burst Duration in Cortical Myoclonus.,Sterre van der Veen;Amber Maliepaard;Madelein van der Stouwe;Jelle Dalenberg;Inge Tuitert;Jan Willem J Elting;Marina A J Tijssen,2024,10.1038/s41572-018-0023-6,"Myoclonus is characterized by involuntary, shock-like movements, of which cortical (CM) and non-cortical myoclonus (NCM) are most common. Electrophysiology can help differentiate between these subtypes; however, the diagnostic value of several features is largely unknown. This study aims to determine the diagnostic value of the burst duration in distinguishing CM and NCM. We manually identified the burst duration of 8 patients with CM, confirmed by electromyography-electroencephalography registration or somatosensory-evoked potentials, and 19 patients with NCM, suspected due to a myoclonus-dystonia phenotype (MYC/DYT-SGCE positive and negative). The sensitivity and specificity were calculated to assess the diagnostic value. The burst duration of CM (31.1 ms) was significantly shorter than that of NCM (56.7 ms), with a sensitivity of 100% and a specificity of 89.5% at a threshold of 45.0 ms. A minimum of 10 randomly selected bursts were sufficient for reliable diagnostic accuracy. The burst duration seems a valuable supportive diagnostic criterion for distinguishing CM and NCM.",https://pubmed.ncbi.nlm.nih.gov/39314082/,https://pubmed.ncbi.nlm.nih.gov/39314082/,English,Include,,Substantiating the Short Burst Duration in Cortical Myoclonus.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39313166,pubmed:39313166,PubMed,pubmed:39313166,Darts fast-learning reduces theta power but is not affected by Hf-tRNS: A behavioral and electrophysiological investigation.,Giorgia Francesca Scaramuzzi;Anna Concetta Spina;Valerio Manippa;Francesca Amico;Ester Cornacchia;Annalisa Palmisano;Gaetano Scianatico;Richard Buscombe;Richard Avery;Volker Thoma;Davide Rivolta,2025,10.1016/j.brainres.2024.149249,"Sports trainers have recently shown increasing interest in innovative methods, including transcranial electric stimulation, to enhance motor performance and boost the acquisition of new skills during training. However, studies on the effectiveness of these tools on fast visuomotor learning and brain activity are still limited. In this randomized single-blind, sham-controlled, between-subjects study, we investigated whether a single training session, either coupled or not with 2 mA online high-frequency transcranial random noise stimulation (hf-tRNS) over the bilateral primary motor cortex (M1), would affect dart-throwing performance (i.e., radial error, arm range of motion, and movement variability) in 37 healthy volunteers. In addition, potential neurophysiological correlates were monitored before and after the training through a 32-electrode portable electroencephalogram (EEG). Results revealed that a single training session improved radial error and arm range of motion during the dart-throwing task, but not movement variability. Furthermore, after the training, resting state-EEG data showed a decrease in theta power. Radial error, arm movement, and EEG were not further modulated by hf-tRNS. This indicates that a single training session, regardless of hf-tRNS administration, improves dart-throwing precision and movement accuracy. However, it does not improve movement variability, which might require multiple training sessions (expertise resulting in slow learning). Theta power decrease could describe a more efficient use of cognitive resources (i.e., attention and visuomotor skills) due to the fast dart-throwing learning. Further research could explore different sports by applying longer stimulation protocols and evaluating other EEG variables to enhance our understanding of the lasting impacts of multi-session hf-tRNS on the sensorimotor cortex within the framework of slow learning and training assistance.",,https://pubmed.ncbi.nlm.nih.gov/39313166/,English,Exclude,Outside date range,Darts fast-learning reduces theta power but is not affected by Hf-tRNS: A behavioral and electrophysiological investigation.,,,,,0.95,0.6,
pubmed:39308401,pubmed:39308401,PubMed,pubmed:39308401,Age-Related Effects on Facial Emotion Recognition in Schoolchildren: An ERP Study.,Julieta Ramos-Loyo;Sara E Espinosa-Denenea;Araceli Sanz-Martin;Luis A Llamas-Alonso,2024,10.1080/87565641.2024.2403986,"The ability to recognize emotions in others is crucial for social interaction and develops during childhood. We studied the effects of age on emotional facial recognition in schoolchildren using ERP components. Children aged 6, 8, and 10 completed identity, sex, and emotion recognition (happiness, anger, sadness) tasks. The oldest group had the highest accuracy and fastest reaction times. Only the LPP component showed age-related differences, with lower amplitudes in older children. LPP showed higher amplitude during emotion recognition, which may be associated with motivational evaluation. ERP accounted for the temporal dynamics of facial processing, which involve cognitive and emotional processes.",,https://pubmed.ncbi.nlm.nih.gov/39308401/,English,Exclude,Not EEG-BCI focused,Age-Related Effects on Facial Emotion Recognition in Schoolchildren: An ERP Study.,,,,,0.9,0.6,
pubmed:39307327,pubmed:39307327,PubMed,pubmed:39307327,"Cardiorespiratory fitness, independent of APOE genotype, is associated with better neurocognitive function in older adults: An ERP study.",Yu-Kai Chang;Jennifer L Etnier;Ruei-Hong Li;Ying-Chu Chen;Chen-Sin Hung;Feng-Tzu Chen;Chung-Yu Chen;Chien-Heng Chu,2025,10.1016/j.psychsport.2024.102748,"This study assessed the association between cardiorespiratory fitness and carriage of the apolipoprotein-E ε4 (APOE ε4) alleles and cognitive function using behavioral and neuroelectric measures obtained from cognitively normal older adults. A total of 159 adults aged 50-70 years were categorized into four groups based on cardiorespiratory fitness (i.e., higher vs. lower fitness) and the APOE genotype status (i.e., APOE ε4 carrier vs. non-carrier). Neurocognitive functions were indexed using response time and accuracy measures from the Stroop task and averaged mean P3 amplitudes of event-related potentials obtained during task performance. A significant main effect of cardiorespiratory fitness (p = .01) and the Stroop congruency (p < .001), but not the APOE genotype status, with shorter response times for the higher fitness group than for the lower fitness group and for the congruent condition relative to the incongruent condition, were observed. Similar findings were also revealed, with larger averaged mean P3 amplitudes for the higher fitness group than those in the lower fitness group, and in the congruent condition than in the incongruent condition. These findings suggest that higher cardiorespiratory fitness is linked to better neurocognitive function, and the positive association is evident regardless of the APOE ε4 status and the cognitive domain assessed in cognitively normal older adults.",,https://pubmed.ncbi.nlm.nih.gov/39307327/,English,Exclude,Outside date range,"Cardiorespiratory fitness, independent of APOE genotype, is associated with better neurocognitive function in older adults: An ERP study.",,,,,0.95,0.6,
pubmed:39307285,pubmed:39307285,PubMed,pubmed:39307285,Comparison of short- and long-term effects of neurofeedback and transcranial electrical stimulation on the motor learning in healthy adults.,Sara Rezaei;Roya Khanmohammadi,2025,10.1016/j.bbr.2024.115263,"Researchers are exploring non-invasive neuromodulation techniques like transcranial direct current stimulation (tDCS) and neurofeedback (NFB) for enhancing motor learning. While tDCS modulates brain excitability using exogenous electric fields, NFB is an endogenous brain stimulation technique that enables individuals to regulate brain excitability in a closed-loop system. Despite their differing mechanisms, a direct comparison of their effects on motor learning is lacking. This study aimed to compare tDCS and NFB on online learning, short-term offline learning, and long-term offline learning in healthy participants, seeking to identify the most effective method for motor learning enhancement. In this parallel, randomized, single-blinded, controlled trial, 100 healthy participants were randomly assigned to one of five groups: real tDCS, sham tDCS, real NFB, sham NFB, and passive control. Primary outcomes included normalized reaction time (NRT), normalized response accuracy (NRA), and normalized skill index (NSI), measured through a serial reaction time task. Secondary outcomes involved physical and mental fatigue, assessed using a visual analog scale. The study involved 14 blocks of 80 trials each. Online learning was assessed by changes in NRT, NRA, and NSI between Block 3 and Block 9. Short-term and long-term offline learning were evaluated by changes in these measures between Block 9 and Block 11, and between Block 9 and Block 13, respectively. RESULTS: showed a significant decrease in NRA in the sham tDCS and passive control groups from block 3-9, with no changes in other groups. NRT significantly decreased in all intervention groups from block 9-11, with no change in the control group. The NSI significantly increased across all intervention groups between blocks 9 and 11, with large to very large effect sizes, while the passive control group saw a medium effect size increase. Furthermore, NRA significantly increased in the real NFB and real tDCS groups from block 9 to block 13. NRT also significantly decreased in all intervention groups when comparing block 13 to block 9, while the passive control group showed no significant changes. Notably, the reduction in NRT from block 9 to block 13 was significantly greater in the real tDCS group than in the control group, with a mean difference of 0.087 (95 % CI: 0.004-0.169, p = 0.031). Additionally, NSI significantly increased in all intervention groups except the control group from block 9 to block 13. In conclusion, neither NFB nor tDCS had a significant positive impact on online learning. However, both real and sham versions of tDCS and NFB resulted in notable improvements in short-term offline learning. The difference in improvement between NFB and tDCS, as well as between real and sham interventions, was not statistically significant, suggesting that the placebo effect may play a significant role in enhancing short-term offline learning. For long-term offline learning, both brain stimulation methods, particularly tDCS, showed positive effects, although the placebo effect also appeared to contribute.",,https://pubmed.ncbi.nlm.nih.gov/39307285/,English,Exclude,Outside date range,Comparison of short- and long-term effects of neurofeedback and transcranial electrical stimulation on the motor learning in healthy adults.,,,,,0.95,0.8,small_sample_mentioned
pubmed:39306981,pubmed:39306981,PubMed,pubmed:39306981,Progression to refractory status epilepticus: A machine learning analysis by means of classification and regression tree analysis.,Stefano Meletti;Giada Giovannini;Simona Lattanzi;Arian Zaboli;Niccolò Orlandi;Gianni Turcato;Francesco Brigo,2024,10.1016/j.yebeh.2024.110005,"to identify predictors of progression to refractory status epilepticus (RSE) using a machine learning technique. Consecutive patients aged ≥ 14 years with SE registered in a 9-years period at Modena Academic Hospital were included in the analysis. We evaluated the risk of progression to RSE using logistic regression and a machine learning analysis by means of classification and regression tree analysis (CART) to develop a predictive model of progression to RSE. 705 patients with SE were included in the study; of those, 33 % (233/705) evolved to RSE. The progression to RSE was an independent risk factor for 30-day mortality, with an OR adjusted for previously identified possible univariate confounders of 4.086 (CI 95 % 2.390-6.985; p < 0.001). According to CART the most important variable predicting evolution to RSE was the impaired consciousness before treatment, followed by acute symptomatic hypoxic etiology and periodic EEG patterns. The decision tree identified 14 nodes with a risk of evolution to RSE ranging from 1.5 % to 90.8 %. The overall percentage of success in classifying patients of the decision tree was 79.4 %; the percentage of accurate prediction was high, 94.1 %, for those patients not progressing to RSE and moderate, 49.8 %, for patients evolving to RSE. Decision-tree analysis provided a meaningful risk stratification based on few variables that are easily obtained at SE first evaluation: consciousness before treatment, etiology, and severe EEG patterns. CART models must be viewed as potential new method for the stratification RSE at single subject level deserving further exploration and validation.",https://pubmed.ncbi.nlm.nih.gov/39306981/,https://pubmed.ncbi.nlm.nih.gov/39306981/,English,Include,,Progression to refractory status epilepticus: A machine learning analysis by means of classification and regression tree analysis.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39305732,pubmed:39305732,PubMed,pubmed:39305732,An enzyme-inspired specificity in deep learning model for sleep stage classification using multi-channel PSG signals input: Separating training approach and its performance on cross-dataset validation for generalizability.,Nantawachara Jirakittayakorn;Yodchanan Wongsawat;Somsak Mitrirattanakul,2024,10.1016/j.compbiomed.2024.109138,"Numerous automatic sleep stage classification systems have been developed, but none have become effective assistive tools for sleep technicians due to issues with generalization. Four key factors hinder the generalization of these models are instruments, montage of recording, subject type, and scoring manual factors. This study aimed to develop a deep learning model that addresses generalization problems by integrating enzyme-inspired specificity and employing separating training approaches. Subject type and scoring manual factors were controlled, while the focus was on instruments and montage of recording factors. The proposed model consists of three sets of signal-specific models including EEG-, EOG-, and EMG-specific model. The EEG-specific models further include three sets of channel-specific models. All signal-specific and channel-specific models were established with data manipulation and weighted loss strategies, resulting in three sets of data manipulation models and class-specific models, respectively. These models were CNNs. Additionally, BiLSTM models were applied to EEG- and EOG-specific models to obtain temporal information. Finally, classification task for sleep stage was handled by 'the-last-dense' layer. The optimal sampling frequency for each physiological signal was identified and used during the training process. The proposed model was trained on MGH dataset and evaluated using both within dataset and cross-dataset. For MGH dataset, overall accuracy of 81.05 %, MF1 of 79.05 %, Kappa of 0.7408, and per-class F1-scores: W (84.98 %), N1 (58.06 %), N2 (84.82 %), N3 (79.20 %), and REM (88.17 %) can be achieved. Performances on cross-datasets are as follows: SHHS1 200 records reached 79.54 %, 70.56 %, and 0.7078; SHHS2 200 records achieved 76.77 %, 66.30 %, and 0.6632; Sleep-EDF 153 records gained 78.52 %, 72.13 %, and 0.7031; and BCI-MU (local dataset) 94 records achieved 83.57 %, 82.17 %, and 0.7769 for overall accuracy, MF1, and Kappa respectively. Additionally, the proposed model has approximately 9.3 M trainable parameters and takes around 26 s to process one PSG record. The results indicate that the proposed model demonstrates generalizability in sleep stage classification and shows potential as a feasibility tool for real-world applications. Additionally, enzyme-inspired specificity effectively addresses the challenges posed by varying montage of recording, while the identified optimal frequencies mitigate instrument-related issues.",https://pubmed.ncbi.nlm.nih.gov/39305732/,https://pubmed.ncbi.nlm.nih.gov/39305732/,English,Include,,An enzyme-inspired specificity in deep learning model for sleep stage classification using multi-channel PSG signals input: Separating training approach and its performance on cross-dataset validation for generalizability.,Include,,"iological signal was identified and used during the training process. The proposed model was trained on MGH dataset and evaluated using both within dataset and cross-dataset. For MGH dataset, overall accuracy of 81.05 %, MF1 of 79.05 %, Kappa of 0.7408, and per-class F1-scores: W (84.98 %), N1 (58.06 %), N2 (84.82 %), N3 (79.20 %), and REM (88.17 %) can be achieved. Performances on cross-datasets ",,0.95,0.6,
pubmed:39297584,pubmed:39297584,PubMed,pubmed:39297584,Total posterior quadrant disconnection for drug-resistant epilepsy in children.,Hao Yu;Chang Liu;Yu Sun;Yao Wang;Qingzhu Liu;Taoyun Ji;Shuang Wang;Xiaoyan Liu;Yuwu Jiang;Ye Wu;Lixin Cai,2024,10.1002/epi4.13044,"To assess seizure outcomes, prognostic factors, and developmental changes in children undergoing total posterior quadrant disconnection (PQD) for drug-resistant epilepsy (DRE). We conducted a retrospective analysis of the clinical data of children with DRE who underwent total PQD surgery. The study focused on Engel's classification for seizure outcomes, exploring correlation of preoperative data and surgical effectiveness, and predictors of seizure prognosis. It involved a comparative analysis of developmental levels pre- and 3 months postoperatively using Griffiths Mental Development Scales-China (GMDS-C), and the correlation between clinical characteristics and GMDS-C results. Out of 61 pediatric patients, 70.5% showed no seizure recurrence postoperatively. In the univariate analysis, interictal electroencephalogram (EEG), magnetic resonance imaging (MRI), fluorodeoxyglucose positron emission tomography (FDG-PET), and acute postoperative seizure (APOS) were significantly related to surgical prognosis. In multivariate analysis, interictal EEG and APOS were identified as predictors of seizure prognosis. Survival analysis indicated significant associations between MRI, interictal EEG, FDG-PET, APOS and postoperative seizure occurrence. Preoperative GMDS-C levels were significantly correlated with epilepsy duration, seizure frequency, interictal EEG, and FDG-PET. GMDS-C scores improved postoperatively, while developmental quotients remained stable. For patients with structural abnormalities in the entire posterior quadrant, thorough preoperative assessment and timely total PQD surgery can effectively control seizures without causing neurological development deterioration. APOS and interictal EEG abnormalities beyond the posterior quadrant are predictors for seizure prognosis but should not be deemed contraindications for surgery. Due to lack of analysis on pediatric total PQD cases, 61 pediatric patients who underwent total PQD surgery were retrospectively enrolled. Seizure and development results were collected and analyzed as dependent variables. The study found that 70.5% of patients were seizure-free and showed development improvement, with no deaths or severe complications reported. Prognosis predictors included APOS and interictal EEG abnormalities beyond the posterior quadrant.",https://pubmed.ncbi.nlm.nih.gov/39297584/,https://pubmed.ncbi.nlm.nih.gov/39297584/,English,Include,,Total posterior quadrant disconnection for drug-resistant epilepsy in children.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39301184,pubmed:39301184,PubMed,pubmed:39301184,What stakeholders with neurodegenerative conditions value about speech and accuracy in development of BCI systems for communication.,Melanie Fried-Oken;Michelle Kinsella;Ian Stevens;Eran Klein,2024,10.1080/07434610902739876,"This research examined values of individuals with neurodegenerative conditions about features of speed and accuracy as they consider potential use of augmentative and alternative communication brain-computer interface systems (AAC-BCI). Sixty-six individuals with neurodegenerative disease responded to prompts about six hypothetical ethical vignettes. Data were analyzed with qualitative content analysis. The following themes emerged. (1) Disease progression may contribute to the trade-off between speed and accuracy with AAC-BCI systems. (2) Individual experiences with technology use inform their views about the speed-accuracy trade-off. (3) There is a range of views about how slow or inaccurate communication may impact relationships, the integrity of a message, and quality of life. (4) Design solutions are proposed to address trade-offs in AAC-BCI systems. With the rapid development of AAC-BCI systems, user-centered design must integrate values of potential end-users illustrating that context, partner, message, and environment impact the prioritization of speed or accuracy in any communication exchange.",https://pubmed.ncbi.nlm.nih.gov/39301184/,https://pubmed.ncbi.nlm.nih.gov/39301184/,English,Include,,What stakeholders with neurodegenerative conditions value about speech and accuracy in development of BCI systems for communication.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39300855,pubmed:39300855,PubMed,pubmed:39300855,Attention deficit hyperactivity disorder (ADHD) detection for IoT based EEG signal.,J Aarthy Suganthi Kani;S Immanuel Alex Pandian;Anitha J;R Harry John Asir,2024,10.1080/10255842.2024.2399025,"ADHD is a prevalent childhood behavioral problem. Early ADHD identification is essential towards addressing the disorder and minimizing its negative impact on school, career, relationships, as well as general well-being. The present ADHD diagnosis relies primarily on an emotional assessment which can be readily influenced by clinical expertise and lacks a basis of objective markers. In this paper, an innovative IoT based ADHD detection is proposed using an EEG signal. To the input EEG signal, the min-max normalization technique is processed. Features are extracted as the subsequent step, where improved fuzzy feature, in which the entropy is estimated to increase the effectiveness of recognizing the vector along with, fractal dimension, wavelet transform and non-linear features are extracted. Also, proposes the new hybrid PUDMO algorithm to select the optimal features from the extracted feature set. Subsequently, the selected features are fed to the proposed hybrid detection system that including IDBN and LSTM classifier to detect whether it is ADHD or not. Further, the weights of both classifiers are tuned optimally as per the hybrid PUDMO algorithm to enhance the detection performance. The PUDMO achieved an accuracy of 0.9649 in the best statistical metric, compared to the SLO's 0.8266, SOA's 0.8201, SMA's 0.8060, BRO's 0.8563, DE's 0.8083, POA's 0.8537, and DMOA's 0.8647, respectively. Thus, the assessments and detection help the clinicians to take appropriate decision.",https://pubmed.ncbi.nlm.nih.gov/39300855/,https://pubmed.ncbi.nlm.nih.gov/39300855/,English,Include,,Attention deficit hyperactivity disorder (ADHD) detection for IoT based EEG signal.,Include,,"ssifier to detect whether it is ADHD or not. Further, the weights of both classifiers are tuned optimally as per the hybrid PUDMO algorithm to enhance the detection performance. The PUDMO achieved an accuracy of 0.9649 in the best statistical metric, compared to the SLO's 0.8266, SOA's 0.8201, SMA's 0.8060, BRO's 0.8563, DE's 0.8083, POA's 0.8537, and DMOA's 0.8647, respectively. Thus, the assessm",,0.95,0.6,
pubmed:39302782,pubmed:39302782,PubMed,pubmed:39302782,Detection of Low Resilience Using Data-Driven Effective Connectivity Measures.,Ayman Siddiqui;Rumaisa Abu Hasan;Syed Saad Azhar Ali;Irraivan Elamvazuthi;Cheng-Kai Lu;Tong Boon Tang,2024,10.1109/tnsre.2024.3465269,"Conventional thresholding techniques for graph theory analysis, such as absolute, proportional and mean degree, have often been used in characterizing human brain networks under different mental disorders, such as mental stress. However, these approaches may not always be reliable as conventional thresholding approaches are subjected to human biases. Using a mental resilience study, we investigate if data-driven thresholding techniques such as Global Cost Efficiency (GCE-abs) and Orthogonal Minimum Spanning Trees (OMSTs) could provide equivalent results, whilst eliminating human biases. We implemented Phase Slope Index (PSI) to compute effective brain connectivity, and applied data-driven thresholding approaches to filter the brain networks in order to identify key features of low resilience within a cohort of healthy individuals. Our dataset encompassed resting-state EEG recordings gathered from a total of 36 participants (31 females and 5 males). Relevant features were extracted to train and validate a classifier model (Support Vector Machine, SVM). The detection of low stress resilience among healthy individuals using the SVM model scores an accuracy of 80.6% with GCE-abs, and 75% with OMSTs, respectively.",https://pubmed.ncbi.nlm.nih.gov/39302782/,https://pubmed.ncbi.nlm.nih.gov/39302782/,English,Include,,Detection of Low Resilience Using Data-Driven Effective Connectivity Measures.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39302776,pubmed:39302776,PubMed,pubmed:39302776,"RoBoSS: A Robust, Bounded, Sparse, and Smooth Loss Function for Supervised Learning.",Mushir Akhtar;M Tanveer;Mohd Arshad,2025,10.1109/tpami.2024.3465535,"In the domain of machine learning, the significance of the loss function is paramount, especially in supervised learning tasks. It serves as a fundamental pillar that profoundly influences the behavior and efficacy of supervised learning algorithms. Traditional loss functions, though widely used, often struggle to handle outlier-prone and high-dimensional data, resulting in suboptimal outcomes and slow convergence during training. In this paper, we address the aforementioned constraints by proposing a novel robust, bounded, sparse, and smooth (RoBoSS) loss function for supervised learning. Further, we incorporate the RoBoSS loss within the framework of support vector machine (SVM) and introduce a new robust algorithm named -SVM. For the theoretical analysis, the classification-calibrated property and generalization ability are also presented. These investigations are crucial for gaining deeper insights into the robustness of the RoBoSS loss function in classification problems and its potential to generalize well to unseen data. To validate the potency of the proposed -SVM, we assess it on 88 benchmark datasets from KEEL and UCI repositories. Further, to rigorously evaluate its performance in challenging scenarios, we conducted an assessment using datasets intentionally infused with outliers and label noise. Additionally, to exemplify the effectiveness of -SVM within the biomedical domain, we evaluated it on two medical datasets: the electroencephalogram (EEG) signal dataset and the breast cancer (BreaKHis) dataset. The numerical results substantiate the superiority of the proposed -SVM model, both in terms of its remarkable generalization performance and its efficiency in training time.",,https://pubmed.ncbi.nlm.nih.gov/39302776/,English,Exclude,Outside date range,"RoBoSS: A Robust, Bounded, Sparse, and Smooth Loss Function for Supervised Learning.",,,,,0.95,0.6,
pubmed:39302394,pubmed:39302394,PubMed,pubmed:39302394,An automated ECG-based deep learning for the early-stage identification and classification of cardiovascular disease.,Anand Pandey;Ajeet Singh;Prasanthi Boyapati;Abhay Chaturvedi;N Purushotham;Sangeetha M,2024,10.3233/thc-240543,"Heart disease represents the leading cause of death globally. Timely diagnosis and treatment can prevent cardiovascular issues. An Electrocardiograms (ECG) serves as a diagnostic tool for identifying heart difficulties. Cardiovascular Disease (CVD) often gets identified through ECGs. Deep learning (DL) garners attention in healthcare due to its potential in swiftly diagnosing ECG anomalies, crucial for patient monitoring. Conversely, automatic CVD detection from ECGs poses a challenging task, wherein rule-based diagnostic models usually achieve top-notch performance. These models encounter complications in supervision vast volumes of diverse data, demanding widespread analysis and medical capability to ensure precise CVD diagnosis. This study aims to enhance cardiovascular disease diagnosis by combining symptom-based detection and ECG analysis. To enhance these experiments, we built a novel automated prediction method based on a Feed Forward Neural Network (FFNN) model. The fundamental objective of our method is to develop the accuracy of ECG diagnosis. Our strategy employs chaos theory and destruction analysis to combine optimum deep learning features with a well-organized set of ECG properties. In addition, we use the constant-Q non-stationary Gabor transform (CQNGT) to convert one-dimensional ECG data into a two-dimensional picture. A pre-trained FFNN processes this image. To identify significant features from the FFNN output that correspond with the ECG data, we employ pairwise feature proximity. According to experimental findings, the suggested system, FFNN-CQNGT, surpasses other state-of-the-art systems in terms of precision of 94.89%, computational efficiency of 2.114 ms, accuracy of 95.55%, specificity of 93.77%, and sensitivity of 93.99% and MSE 40.32%. Contributing an automated ECG-based DL system based on FFNN-CQNGT for early-stage cardiovascular disease identification and classification holds great potential for both patient care and public health.",,https://pubmed.ncbi.nlm.nih.gov/39302394/,English,Exclude,Not EEG-BCI focused,An automated ECG-based deep learning for the early-stage identification and classification of cardiovascular disease.,,,,,0.9,0.6,
pubmed:39300181,pubmed:39300181,PubMed,pubmed:39300181,An ensemble method for improving robustness against the electrode contact problems in automated sleep stage scoring.,Kazumasa Horie;Ryusuke Miyamoto;Leo Ota;Takashi Abe;Yoko Suzuki;Fusae Kawana;Toshio Kokubo;Masashi Yanagisawa;Hiroyuki Kitagawa,2024,10.1038/s41598-024-72612-8,"In-home automated scoring systems are in high demand; however, the current systems are not widely adopted in clinical settings. Problems with electrode contact and restriction on measurable signals often result in unstable and inaccurate scoring for clinical use. To address these issues, we propose a method based on ensemble of small sleep stage scoring models with different input signal sets. By excluding models that employ problematic signals from the voting process, our method can mitigate the effects of electrode contact failure. Comparative experiments demonstrated that our method could reduce the impact of contact problems and improve scoring accuracy for epochs with problematic signals by 8.3 points, while also decreasing the deterioration in scoring accuracy from 7.9 to 0.3 points compared to typical methods. Additionally, we confirmed that assigning different input sets to small models did not diminish the advantages of the ensemble but instead increased its efficacy. The proposed model can improve overall scoring accuracy and minimize the effect of problematic signals simultaneously, making in-home sleep stage scoring systems more suitable for clinical practice.",,https://pubmed.ncbi.nlm.nih.gov/39300181/,English,Exclude,Not EEG-BCI focused,An ensemble method for improving robustness against the electrode contact problems in automated sleep stage scoring.,,,,,0.9,0.6,
pubmed:39296709,pubmed:39296709,PubMed,pubmed:39296709,A review of artificial intelligence methods enabled music-evoked EEG emotion recognition and their applications.,Yan Su;Yong Liu;Yan Xiao;Jiaqi Ma;Dezhao Li,2024,10.3390/ijerph20010378,"Music is an archaic form of emotional expression and arousal that can induce strong emotional experiences in listeners, which has important research and practical value in related fields such as emotion regulation. Among the various emotion recognition methods, the music-evoked emotion recognition method utilizing EEG signals provides real-time and direct brain response data, playing a crucial role in elucidating the neural mechanisms underlying music-induced emotions. Artificial intelligence technology has greatly facilitated the research on the recognition of music-evoked EEG emotions. AI algorithms have ushered in a new era for the extraction of characteristic frequency signals and the identification of novel feature signals. The robust computational capabilities of AI have provided fresh perspectives for the development of innovative quantitative models of emotions, tailored to various emotion recognition paradigms. The discourse surrounding AI algorithms in the context of emotional classification models is gaining momentum, with their applications in music therapy, neuroscience, and social activities increasingly coming under the spotlight. Through an in-depth analysis of the complete process of emotion recognition induced by music through electroencephalography (EEG) signals, we have systematically elucidated the influence of AI on pertinent research issues. This analysis offers a trove of innovative approaches that could pave the way for future research endeavors.",,https://pubmed.ncbi.nlm.nih.gov/39296709/,English,Exclude,Review/survey papers,A review of artificial intelligence methods enabled music-evoked EEG emotion recognition and their applications.,,,,,0.95,0.6,
pubmed:39296126,pubmed:39296126,PubMed,pubmed:39296126,Advanced neurological activity status of athletes based on big data technology.,Wenhui Ma;Bin Guo,2024,10.1016/j.heliyon.2024.e37294,"Currently, the application scope of big data (BD for short here) technology is relatively narrow, mostly used in the medical field, and the degree of application is relatively superficial, mostly for data statistical record analysis. Therefore, By combining the literature review, this article has decided to construct a system based on BD technology for analyzing the advanced neural activity status of athletes. The system is mainly divided into two parts, one is the biological information collection part. As an important source of system data, it is necessary to use professional equipment to collect ECG and EEG data and ensure the accuracy of the data through signal filtering, Gaussian noise elimination, salt and pepper noise, and exponential noise de-noising technology. The other is the algorithm problem of BD systems. Considering that the traditional algorithm can not deal with a large amount of data effectively, this paper chooses the BD spectral clustering algorithm based on core points as the main algorithm to cluster the data. By evaluating the efficiency of system learning, data collection and classification, system scheme construction, and error rate, this article ultimately determined the practical feasibility and effectiveness of the system. After completing the construction of the system, considering the gap between the system's performance and traditional data, this article analyzed the improvement data of various aspects of sports training. This paper compares the performance differences between the system based on BD technology and the traditional data analysis method under different indicators. In terms of data collection and classification, the accuracy of the system based on BD technology in the collection and classification of ECG and EEG data reached 100 % and 90 %, respectively, which was significantly higher than 60 % and 30 % of the traditional methods. By comparing the data from five training courses, it is found that the training efficiency of the conventional method has increased by 60 % in the first course, while the efficiency of the training method based on the BD system has increased by 85 % in the fifth course. For the activation efficiency of nerve function, the activation efficiency of brain nerve function reached 60 % and 90 % respectively in the two nerve function activation training based on the BD system, which was much higher than 30 % and 45 % of the traditional methods. Through a series of tests and comparative analysis of data, the effectiveness of the BD system is finally determined, which can achieve the goal of improving athletes' training efficiency.",,https://pubmed.ncbi.nlm.nih.gov/39296126/,English,Exclude,Review/survey papers,Advanced neurological activity status of athletes based on big data technology.,,,,,0.95,0.6,
pubmed:39296025,pubmed:39296025,PubMed,pubmed:39296025,Improving inter-session performance via relevant session-transfer for multi-session motor imagery classification.,Dong-Jin Sung;Keun-Tae Kim;Ji-Hyeok Jeong;Laehyun Kim;Song Joo Lee;Hyungmin Kim;Seung-Jong Kim,2024,10.1016/j.heliyon.2024.e37343,"Motor imagery (MI)-based brain-computer interfaces (BCIs) using electroencephalography (EEG) have found practical applications in external device control. However, the non-stationary nature of EEG signals remains to obstruct BCI performance across multiple sessions, even for the same user. In this study, we aim to address the impact of non-stationarity, also known as inter-session variability, on multi-session MI classification performance by introducing a novel approach, the relevant session-transfer (RST) method. Leveraging the cosine similarity as a benchmark, the RST method transfers relevant EEG data from the previous session to the current one. The effectiveness of the proposed RST method was investigated through performance comparisons with the self-calibrating method, which uses only the data from the current session, and the whole-session transfer method, which utilizes data from all prior sessions. We validated the effectiveness of these methods using two datasets: a large MI public dataset (Shu Dataset) and our own dataset of gait-related MI, which includes both healthy participants and individuals with spinal cord injuries. Our experimental results revealed that the proposed RST method leads to a 2.29 % improvement (p < 0.001) in the Shu Dataset and up to a 6.37 % improvement in our dataset when compared to the self-calibrating method. Moreover, our method surpassed the performance of the recent highest-performing method that utilized the Shu Dataset, providing further support for the efficacy of the RST method in improving multi-session MI classification performance. Consequently, our findings confirm that the proposed RST method can improve classification performance across multiple sessions in practical MI-BCIs.",https://pubmed.ncbi.nlm.nih.gov/39296025/,https://pubmed.ncbi.nlm.nih.gov/39296025/,English,Include,,Improving inter-session performance via relevant session-transfer for multi-session motor imagery classification.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39294238,pubmed:39294238,PubMed,pubmed:39294238,Machine learning algorithm for predicting seizure control after temporal lobe resection using peri-ictal electroencephalography.,Shehryar R Sheikh;Zachary A McKee;Samer Ghosn;Ki-Soo Jeong;Michael Kattan;Richard C Burgess;Lara Jehi;Carl Y Saab,2024,10.1038/s41598-024-72249-7,"Brain resection is curative for a subset of patients with drug resistant epilepsy but up to half will fail to achieve sustained seizure freedom in the long term. There is a critical need for accurate prediction tools to identify patients likely to have recurrent postoperative seizures. Results from preclinical models and intracranial EEG in humans suggest that the window of time immediately before and after a seizure (""peri-ictal"") represents a unique brain state with implications for clinical outcome prediction. Using a dataset of 294 patients who underwent temporal lobe resection for seizures, we show that machine learning classifiers can make accurate predictions of postoperative seizure outcome using 5 min of peri-ictal scalp EEG data that is part of universal presurgical evaluation (AUC 0.98, out-of-group testing accuracy > 90%). This is the first approach to seizure outcome prediction that employs a routine non-invasive preoperative study (scalp EEG) with accuracy range likely to translate into a clinical tool. Decision curve analysis (DCA) shows that compared to the prevalent clinical-variable based nomogram, use of the EEG-augmented approach could decrease the rate of unsuccessful brain resections by 20%.",https://pubmed.ncbi.nlm.nih.gov/39294238/,https://pubmed.ncbi.nlm.nih.gov/39294238/,English,Include,,Machine learning algorithm for predicting seizure control after temporal lobe resection using peri-ictal electroencephalography.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39294177,pubmed:39294177,PubMed,pubmed:39294177,Internet of things based smart framework for the safe driving experience of two wheelers.,Gunjan Chhabra;Keshav Kaushik;Pardeep Singh;Gourav Bathla;Ahmad Almogren;Salil Bharany;Ayman Altameem;Ateeq Ur Rehman,2024,10.1038/s41598-024-72357-4,"Several parameters affect our brain's neuronal system and can be identified by analyzing electroencephalogram (EEG) signals. One of the parameters is alcoholism, which affects the pattern of our EEG signals. By analyzing these EEG signals, one can derive information regarding the alcoholic or normal stage of an individual. Many road accident cases around the world, including drinking and driving scenarios, which result in loss of life, have been reported. Another reason for such incidents is that riders avoid wearing helmets while driving two-wheelers. Many road accident cases involving two-wheelers, including drinking, driving, overspeeding, and nonwearing helmets, have been reported. Therefore, to solve such issues, the present work highlights the features of an intelligent model that can predict the alcoholism level of the subject, wearing of a helmet, vehicle speed, location, etc. The system is designed with the latest technologies and is smart enough to make decisions. The system is based on multilayer perceptron, histogram of oriented gradients (HoG) feature extraction, and random forest to make decisions in real time. The accuracy of the proposed method is approximately 95%, which will reduce the fatality rate due to road accidents. The system is tested under different working environments, i.e., indoor and outdoor, and satisfactory outcomes are observed.",https://pubmed.ncbi.nlm.nih.gov/39294177/,https://pubmed.ncbi.nlm.nih.gov/39294177/,English,Include,,Internet of things based smart framework for the safe driving experience of two wheelers.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39293638,pubmed:39293638,PubMed,pubmed:39293638,Neural responses to camouflage targets with different exposure signs based on EEG.,Zhou Yu;Li Xue;Weidong Xu;Jun Liu;Qi Jia;Yawen Liu;Lu Zhou;Jianghua Hu;Hao Li;Jidong Wu,2024,10.1016/j.neuropsychologia.2024.109002,"This study investigates the relationship between various target exposure signs and brain activation patterns by analyzing the EEG signals of 35 subjects observing four types of targets: well-camouflaged, with large color differences, with shadows, and of large size. Through ERP analysis and source localization, we have established that different exposure signs elicit distinct brain activation patterns. The ERP analysis revealed a strong correlation between the latency of the P300 component and the visibility of the exposure signs. Furthermore, our source localization findings indicate that exposure signs alter the current density distribution within the cortex, with shadows causing significantly higher activation in the frontal lobe compared to other conditions. The study also uncovered a pronounced right-brain laterality in subjects during target identification. By employing an LSTM neural network, we successfully differentiated EEG signals triggered by various exposure signs, achieving a classification accuracy of up to 96.4%. These results not only suggest that analyzing the P300 latency and cortical current distribution can differentiate the degree of visibility of target exposure signs, but also demonstrate the potential of using EEG characteristics to identify key exposure signs in camouflaged targets. This provides crucial insights for developing auxiliary camouflage strategies.",https://pubmed.ncbi.nlm.nih.gov/39293638/,https://pubmed.ncbi.nlm.nih.gov/39293638/,English,Include,,Neural responses to camouflage targets with different exposure signs based on EEG.,Include,,"in laterality in subjects during target identification. By employing an LSTM neural network, we successfully differentiated EEG signals triggered by various exposure signs, achieving a classification accuracy of up to 96.4%. These results not only suggest that analyzing the P300 latency and cortical current distribution can differentiate the degree of visibility of target exposure signs, but also ",,0.95,0.6,
pubmed:39293596,pubmed:39293596,PubMed,pubmed:39293596,Enhanced network synchronization connectivity following transcranial direct current stimulation (tDCS) in bipolar depression: Effects on EEG oscillations and deep learning-based predictors of clinical remission.,Wenyi Xiao;Jijomon C Moncy;Ali-Reza Ghazi-Noori;Rachel D Woodham;Hakimeh Rezaei;Elvira Bramon;Philipp Ritter;Michael Bauer;Allan H Young;Cynthia H Y Fu,2025,10.1016/j.jad.2024.09.054,"To investigate oscillatory networks in bipolar depression, effects of a home-based tDCS treatment protocol, and potential predictors of clinical response. 20 participants (14 women) with bipolar disorder, mean age 50.75 ± 10.46 years, in a depressive episode of severe severity (mean Montgomery-Åsberg Rating Scale (MADRS) score 24.60 ± 2.87) received home-based transcranial direct current stimulation (tDCS) treatment for 6 weeks. Clinical remission defined as MADRS score < 10. Resting-state EEG data were acquired at baseline, prior to the start of treatment, and at the end of treatment, using a portable 4-channel EEG device (electrode positions: AF7, AF8, TP9, TP10). EEG band power was extracted for each electrode and phase locking value (PLV) was computed as a functional connectivity measure of phase synchronization. Deep learning was applied to pre-treatment PLV features to examine potential predictors of clinical remission. Following treatment, 11 participants (9 women) attained clinical remission. A significant positive correlation was observed with improvements in depressive symptoms and delta band PLV in frontal and temporoparietal regional channel pairs. An interaction effect in network synchronization was observed in beta band PLV in temporoparietal regions, in which participants who attained clinical remission showed increased synchronization following tDCS treatment, which was decreased in participants who did not achieve clinical remission. Main effects of clinical remission status were observed in several PLV bands: clinical remission following tDCS treatment was associated with increased PLV in frontal and temporal regions and in several frequency bands, including delta, theta, alpha and beta, as compared to participants who did not achieve clinical remission. The highest deep learning prediction accuracy 69.45 % (sensitivity 71.68 %, specificity 66.72 %) was obtained from PLV features combined from theta, beta, and gamma bands. tDCS treatment enhances network synchronization, potentially increasing inhibitory control, which underscores improvement in depressive symptoms. Baseline EEG-based measures might aid predicting clinical response.",,https://pubmed.ncbi.nlm.nih.gov/39293596/,English,Exclude,Outside date range,Enhanced network synchronization connectivity following transcranial direct current stimulation (tDCS) in bipolar depression: Effects on EEG oscillations and deep learning-based predictors of clinical remission.,,,,,0.95,0.8,small_sample_mentioned
pubmed:39293479,pubmed:39293479,PubMed,pubmed:39293479,EEG electrodes and where to find them: automated localization from 3D scans.,Mats Tveter;Thomas Tveitstøl;Tønnes Nygaard;Ana S Pérez T;Shrikanth Kulashekhar;Ricardo Bruña;Hugo L Hammer;Christoffer Hatlestad-Hall;Ira R J Hebold Haraldsen,2024,10.1088/1741-2552/ad7c7e,,,https://pubmed.ncbi.nlm.nih.gov/39293479/,English,Exclude,Not classification-focused,EEG electrodes and where to find them: automated localization from 3D scans.,,,,,0.85,0.6,
pubmed:39292714,pubmed:39292714,PubMed,pubmed:39292714,Effects of acute stress on biological motion perception.,Jifu Wang;Fang Shi;Lin Yu,2024,10.1002/cne.920180503,"Biological motion perception is an essential part of the cognitive process. Stress can affect the cognitive process. The present study explored the intrinsic ERP features of the effects of acute psychological stress on biological motion perception. The results contributed scientific evidence for the adaptive behavior changes under acute stress. After a mental arithmetic task was used to induce stress, the paradigm of point-light displays was used to evaluate biological motion perception. Longer reaction time and lower accuracy were found in the inverted walking condition than in the upright walking condition, which was called the ""inversion effect"". The P2 peak amplitude and the LPP mean amplitude were significantly higher in the local inverted perception than in the local upright walking condition. Compared to the control condition, the stress condition induced lower RT, shorter P1 peak latency of biological motion perception, lower P2 peak amplitude and LPP mean amplitude, and higher N330 peak amplitude. There was an ""inversion effect"" in biological motion perception. This effect was related to the structural characteristics of biological motion perception but unrelated to the state of acute psychological stress. Acute psychological stress accelerated the reaction time and enhanced attention control of biological motion perception. Attention resources were used earlier, and less attentional investment was made in the early stage of biological motion perception processing. In the late stage, a continuous weakening of inhibition was shown in the parieto-occipital area.",,https://pubmed.ncbi.nlm.nih.gov/39292714/,English,Exclude,Not EEG-BCI focused,Effects of acute stress on biological motion perception.,,,,,0.9,0.6,
pubmed:39289475,pubmed:39289475,PubMed,pubmed:39289475,Machine learning based classification of presence utilizing psychophysiological signals in immersive virtual environments.,Shuvodeep Saha;Chelsea Dobbins;Anubha Gupta;Arindam Dey,2024,10.1038/s41598-024-72376-1,"In Virtual Reality (VR), a higher level of presence positively influences the experience and engagement of a user. There are several parameters that are responsible for generating different levels of presence in VR, including but not limited to, graphical fidelity, multi-sensory stimuli, and embodiment. However, standard methods of measuring presence, including self-reported questionnaires, are biased. This research focuses on developing a robust model, via machine learning, to detect different levels of presence in VR using multimodal neurological and physiological signals, including electroencephalography and electrodermal activity. An experiment has been undertaken whereby participants (N = 22) were each exposed to three different levels of presence (high, medium, and low) in a random order in VR. Four parameters within each level, including graphics fidelity, audio cues, latency, and embodiment with haptic feedback, were systematically manipulated to differentiate the levels. A number of multi-class classifiers were evaluated within a three-class classification problem, using a One-vs-Rest approach, including Support Vector Machine, k-Nearest Neighbour, Extra Gradient Boosting, Random Forest, Logistic Regression, and Multiple Layer Perceptron. Results demonstrated that the Multiple Layer Perceptron model obtained the highest macro average accuracy of ",https://pubmed.ncbi.nlm.nih.gov/39289475/,https://pubmed.ncbi.nlm.nih.gov/39289475/,English,Include,,Machine learning based classification of presence utilizing psychophysiological signals in immersive virtual environments.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39289330,pubmed:39289330,PubMed,pubmed:39289330,Accurate Machine Learning-based Monitoring of Anesthesia Depth with EEG Recording.,Zhiyi Tu;Yuehan Zhang;Xueyang Lv;Yanyan Wang;Tingting Zhang;Juan Wang;Xinren Yu;Pei Chen;Suocheng Pang;Shengtian Li;Xiongjie Yu;Xuan Zhao,2025,10.1007/s12264-024-01297-w,"General anesthesia, pivotal for surgical procedures, requires precise depth monitoring to mitigate risks ranging from intraoperative awareness to postoperative cognitive impairments. Traditional assessment methods, relying on physiological indicators or behavioral responses, fall short of accurately capturing the nuanced states of unconsciousness. This study introduces a machine learning-based approach to decode anesthesia depth, leveraging EEG data across different anesthesia states induced by propofol and esketamine in rats. Our findings demonstrate the model's robust predictive accuracy, underscored by a novel intra-subject dataset partitioning and a 5-fold cross-validation method. The research diverges from conventional monitoring by utilizing anesthetic infusion rates as objective indicators of anesthesia states, highlighting distinct EEG patterns and enhancing prediction accuracy. Moreover, the model's ability to generalize across individuals suggests its potential for broad clinical application, distinguishing between anesthetic agents and their depths. Despite relying on rat EEG data, which poses questions about real-world applicability, our approach marks a significant advance in anesthesia monitoring.",,https://pubmed.ncbi.nlm.nih.gov/39289330/,English,Exclude,Outside date range,Accurate Machine Learning-based Monitoring of Anesthesia Depth with EEG Recording.,,,,,0.95,0.25,cv_reported
pubmed:39287615,pubmed:39287615,PubMed,pubmed:39287615,Statistical characteristics of large-scale objective tonic-clonic seizure records from medical smartwatches used in daily life.,Boyu Zhang;Weixuan V Chen;Giulia Regalia;Daniel M Goldenholz;Rosalind W Picard,2024,10.1016/j.pcad.2008.10.003,"This study aimed to assess whether population-level patterns in seizure occurrence previously observed in self-reported diaries, medical records, and electroencephalographic recordings were also present in tonic-clonic seizure (TCS) diaries produced via the combined input of a US Food and Drug Administration-cleared wristband with an artificial intelligence detection algorithm and patient self-reports. We also investigated the characteristics of patient interactions with wearable seizure alerts. We analyzed wristband data from patients with TCSs who had at least three reported TCSs over a minimum of 90 days. We quantified TCS frequency and cycles, and the relationship between the mean and variability of monthly TCS counts. We also assessed interaction metrics such as false alarm dismissal and seizure confirmation rates. Applying strict criteria for usable data, we reviewed 137 490 TCSs from 3012 patients, with a median length of TCS alert records of 445 days (range = 90-1806). Analyses showed consistency between prior diary studies and the present data concerning (1) the distribution of monthly TCS frequency (median = 3.1, range = .08-26); (2) the linear relationship (slope = .79, R Key population-level patterns in seizure occurrence are recapitulated in wrist-worn device recordings, supporting their validity for tracking TCS burden. Compared to other approaches, wearables can provide noninvasive, objective, long-term data, revealing cycles in seizure risk. However, improved patient engagement with wristband alerts and further validation of detection accuracy in ambulatory settings are needed. Together, these findings suggest that data from smart wristbands may be used to derive features of TCS records and, ultimately, facilitate remote monitoring and the development of personalized forecasting tools for TCS management. Our findings may not generalize to other types of seizures.",,https://pubmed.ncbi.nlm.nih.gov/39287615/,English,Exclude,Review/survey papers,Statistical characteristics of large-scale objective tonic-clonic seizure records from medical smartwatches used in daily life.,,,,,0.95,0.6,
pubmed:39286921,pubmed:39286921,PubMed,pubmed:39286921,Joint multi-feature extraction and transfer learning in motor imagery brain computer interface.,Miao Cai;Jie Hong,2024,10.1080/10255842.2024.2404541,"Motor imagery brain computer interface (BCI) systems are considered one of the most crucial paradigms and have received extensive attention from researchers worldwide. However, the non-stationary from subject-to-subject transfer is a substantial challenge for robust BCI operations. To address this issue, this paper proposes a novel approach that integrates joint multi-feature extraction, specifically combining common spatial patterns (CSP) and wavelet packet transforms (WPT), along with transfer learning (TL) in motor imagery BCI systems. This approach leverages the time-frequency characteristics of WPT and the spatial characteristics of CSP while utilizing transfer learning to facilitate EEG identification for target subjects based on knowledge acquired from non-target subjects. Using dataset IVa from BCI Competition III, our proposed approach achieves an impressive average classification accuracy of 93.4%, outperforming five kinds of state-of-the-art approaches. Furthermore, it offers the advantage of enabling the design of various auxiliary problems to learn different aspects of the target problem from unlabeled data through transfer learning, thereby facilitating the implementation of innovative ideas within our proposed approach. Simultaneously, it demonstrates that integrating CSP and WPT while transferring knowledge from other subjects is highly effective in enhancing the average classification accuracy of EEG signals and it provides a novel solution to address subject-to-subject transfer challenges in motor imagery BCI systems.",https://pubmed.ncbi.nlm.nih.gov/39286921/,https://pubmed.ncbi.nlm.nih.gov/39286921/,English,Include,,Joint multi-feature extraction and transfer learning in motor imagery brain computer interface.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39285215,pubmed:39285215,PubMed,pubmed:39285215,Neural signatures of motor imagery for a supernumerary thumb in VR: an EEG analysis.,Haneen Alsuradi;Joseph Hong;Alireza Sarmadi;Robert Volcic;Hanan Salam;S Farokh Atashzar;Farshad Khorrami;Mohamad Eid,2024,10.1038/s41598-024-72358-3,"Human movement augmentation is a rising field of research. A promising control strategy for augmented effectors involves utilizing electroencephalography through motor imagery (MI) functions. However, performing MI of a supernumerary effector is challenging, to which MI training is one potential solution. In this study, we investigate the validity of a virtual reality (VR) environment as a medium for eliciting MI neural activations for a supernumerary thumb. Specifically, we assess whether it is possible to induce a distinct neural signature for MI of a supernumerary thumb in VR. Twenty participants underwent a two-fold experiment in which they observed movements of natural and supernumerary thumbs, then engaged in MI of the observed movements. Spectral power and event related desynchronization (ERD) analyses at the group level showed that the MI signature associated with the supernumerary thumb was indeed distinct, significantly different from both the baseline and the MI signature associated with the natural thumb, while single-trial classification showed that it is distinguishable with a 78% and 69% classification accuracy, respectively. Furthermore, spectral power and ERD analyses at the group level showed that the MI signatures associated with directional movement of the supernumerary thumb, flexion and extension, were also significantly different, and single-trial classification demonstrated that these movements could be distinguished with 60% accuracy. Fine-tuning the models further increased the respective classification accuracies, indicating the potential presence of personalized features across subjects.",https://pubmed.ncbi.nlm.nih.gov/39285215/,https://pubmed.ncbi.nlm.nih.gov/39285215/,English,Include,,Neural signatures of motor imagery for a supernumerary thumb in VR: an EEG analysis.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39284648,pubmed:39284648,PubMed,pubmed:39284648,A novel universal deep learning approach for accurate detection of epilepsy.,Ola Marwan Assim;Ahlam Fadhil Mahmood,2024,10.1016/j.medengphy.2024.104219,"Epilepsy claims the lives of many people, so researchers strive to build highly accurate diagnostic models. One of the limitations of obtaining high accuracy is the scarcity of Electroencephalography (EEG) data and the fact that they are from different devices in terms of the channels number and sampling frequency. The paper proposes universal epilepsy diagnoses with high accuracy from electroencephalography signals taken from any device. The novelty of the proposal is to convert VEEG video into images, separating some parts and unifying images taken from different devices. The images were tested by dividing the video into labeled frames of different periods. By adding the spatial attention layer to the deep learning in the new model, classification accuracy increased to 99.95 %, taking five seconds/frame. The proposed has high accuracy in detecting epilepsy from any EEG without being restricted to a specific number of channels or sampling frequencies.",https://pubmed.ncbi.nlm.nih.gov/39284648/,https://pubmed.ncbi.nlm.nih.gov/39284648/,English,Include,,A novel universal deep learning approach for accurate detection of epilepsy.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39282426,pubmed:39282426,PubMed,pubmed:39282426,Predictive Modeling of Sleep Slow Oscillation Emergence on the electrode manifold: Toward Personalized Closed-Loop Brain Stimulation.,Mahmoud Alipour;Sara C Mednick;Paola Malerba,2024,10.1101/2024.09.03.611113,"Sleep slow oscillations (SOs), characteristic of NREM sleep, are causally tied to cognitive outcomes and the health-promoting homeostatic functions of sleep. Due to these known benefits, brain stimulation techniques aiming to enhance SOs are being developed, with great potential to contribute to clinical interventions, as they hold promise for improving sleep functions in populations with identified SO deficits (e.g., mild cognitive impairment). SO-targeting closed-loop stimulation protocols currently strive to identify SO occurrences in real time, a computationally intensive step that can lead to reduced precision (compared to post-hoc detection). These approaches are also often limited to focusing on only one electrode location, thus inherently precluding targeting of SOs that is informed by the overall organization of SOs in space-time. Prediction of SO emergence across the electrode manifold would establish an alternative to online detection, thus greatly advancing the development of personalized and flexible brain stimulation paradigms. This study presents a computational model that predicts SO occurrences at multiple locations across a night of sleep. In combination with our previous study on optimizing brain stimulation protocols using the spatiotemporal properties of SOs, this model contributes to increasing the accuracy of SO targeting in brain stimulation applications. SOs were detected in a dataset of nighttime sleep of 22 subjects (9 females), acquired with polysomnography including 64 EEG channels. Modeling of SO occurrence was achieved for SOs in stage N3, or in a combination of stages N2 and N3 (N2&N3). We study SO emergence at progressively more refined time scales. First, the cumulative SO occurrences in successive sleep cycles were successfully fit with exponentials. Secondly, the SO timing in each individual was modeled with a renewal point process. Using an inverse Gaussian model, we estimated the probability density function of SO timing and its parameters μ (mean) and λ (shape, representing skewness) in successive cycles. We observed a declining trend in the SO count across sleep cycles, which we modeled using a power law relationship. The decay rate per cycle was 1.473 for N3 and 1.139 for N2&N3, with variances of the decay rates across participants being 1 and 0.53, respectively. This pattern mirrors the declining trend of slow wave activity (SWA) across sleep cycles, likely due to the inherent relationship between SWA and SO. Additionally, the SO timing model for N3 showed an increasing trend in the model parameters (μ, λ) across cycles. The increase rate per cycle followed a power law relationship with a rate of 0.83 and an exponential relationship with a rate of 4.59, respectively. The variances of the increase rates were 0.02 for μ and 0.44 for λ across participants. This study establishes a predictive model for SO occurrence during NREM sleep, providing insights into its organization in successive cycles and at different EEG channels, which is relevant to development of personalized stimulation paradigms. These findings imply that personalized model parameters can be estimated by incorporating SO information in the first sleep cycle, and hence SO timing can be predicted before its occurrence with a probability distribution, enabling more precise targeting of SOs.",https://pubmed.ncbi.nlm.nih.gov/39282426/,https://pubmed.ncbi.nlm.nih.gov/39282426/,English,Include,,Predictive Modeling of Sleep Slow Oscillation Emergence on the electrode manifold: Toward Personalized Closed-Loop Brain Stimulation.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39281864,pubmed:39281864,PubMed,pubmed:39281864,Noninvasive brain stimulation during EEG improves machine learning classi,Rishishankar E Suresh;M S Zobaer;Matthew J Triano;Brian F Saway;Nathan C Rowland,2024,10.3390/s19071631,"In individuals with chronic stroke and hemiparesis, noninvasive brain stimulation (NIBS) may be used as an adjunct to therapy for improving motor recovery. Specific states of movement during motor recovery are more responsive to brain stimulation than others, thus a system that could auto-detect movement state would be useful in correctly identifying the most effective stimulation periods. The aim of this study was to compare the performance of different machine learning models in classifying movement periods during EEG recordings of hemiparetic individuals receiving noninvasive brain stimulation. We hypothesized that transcranial direct current stimulation, a form of NIBS, would modulate brain recordings correlating with movement state and improve classification accuracies above those receiving sham stimulation. Electroencephalogram data were obtained from 10 participants with chronic stroke and 11 healthy individuals performing a motor task while undergoing transcranial direct current stimulation. Eight traditional machine learning algorithms and five ensemble methods were used to classify two movement states (a hold posture and an arm reaching movement) before, during and after stimulation. To minimize compute times, preprocessing and feature extraction were limited to z-score normalization and power binning into five frequency bands (delta through gamma). Classification of disease state produced significantly higher accuracies in the stimulation (versus sham) group at 78.9% (versus 55.6%, p < 0.000002). We observed significantly higher accuracies when classifying stimulation state in the chronic stroke group (77.6%) relative to healthy controls (64.1%, p < 0.0095). In the chronic stroke cohort, classification of hold versus reach was highest during the stimulation period (75.2%) as opposed to the pre- and post-stimulation periods. Linear discriminant analysis, logistic regression, and decision tree algorithms classified movement state most accurately in participants with chronic stroke during the stimulation period (76.1%). For the ensemble methods, the highest classification accuracy for hold versus reach was achieved using low gamma frequency (30-50 Hz) as a feature (74.5%), although this result did not achieve statistical significance. Machine learning algorithms demonstrated sufficiently high movement state classification accuracy in participants with chronic stroke performing functional tasks during noninvasive brain stimulation. tDCS improved disease state and movement state classification in participants with chronic stroke.",https://pubmed.ncbi.nlm.nih.gov/39281864/,https://pubmed.ncbi.nlm.nih.gov/39281864/,English,Include,,Noninvasive brain stimulation during EEG improves machine learning classi,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39278086,pubmed:39278086,PubMed,pubmed:39278086,Infant sleep spindle measures from EEG improve prediction of cerebral palsy.,Erin D Berja;Hunki Kwon;Katherine G Walsh;Sara V Bates;Mark A Kramer;Catherine J Chu,2024,10.1016/j.clinph.2024.08.017,"Early identification of infants at risk of cerebral palsy (CP) enables interventions to optimize outcomes. Central sleep spindles reflect thalamocortical sensorimotor circuit function. We hypothesized that abnormal infant central spindle activity would predict later contralateral CP. We trained and validated an automated detector to measure spindle rate, duration, and percentage from central electroencephalogram (EEG) channels in high-risk infants (n = 35) and age-matched controls (n = 42). Neonatal magnetic resonance imaging (MRI) findings, infant motor exam, and CP outcomes were obtained from chart review. Using univariable and multivariable logistic regression models, we examined whether spindle activity, MRI abnormalities, and/or motor exam predicted future contralateral CP. The detector had excellent performance (F1 = 0.50). Spindle rate (p = 0.005, p = 0.0004), duration (p < 0.001, p < 0.001), and percentage (p < 0.001, p < 0.001) were decreased in hemispheres corresponding to future CP compared to those without. In this cohort, PLIC abnormality (p = 0.004) and any MRI abnormality (p = 0.004) also predicted subsequent CP. After controlling for MRI findings, spindle features remained significant predictors and improved model fit (p < 0.001, all tests). Using both spindle duration and MRI findings had highest accuracy to classify hemispheres corresponding to future CP (F1 = 0.98, AUC 0.999). Decreased central spindle activity improves the prediction of future CP in high-risk infants beyond early MRI or clinical exam alone. Decreased central spindle activity provides an early biomarker for CP.",,https://pubmed.ncbi.nlm.nih.gov/39278086/,English,Exclude,Review/survey papers,Infant sleep spindle measures from EEG improve prediction of cerebral palsy.,,,,,0.95,0.6,
pubmed:39275725,pubmed:39275725,PubMed,pubmed:39275725,A Comprehensive Review of Hardware Acceleration Techniques and Convolutional Neural Networks for EEG Signals.,Yu Xie;Stefan Oniga,2024,10.1016/j.neuroimage.2021.118403,"This paper comprehensively reviews hardware acceleration techniques and the deployment of convolutional neural networks (CNNs) for analyzing electroencephalogram (EEG) signals across various application areas, including emotion classification, motor imagery, epilepsy detection, and sleep monitoring. Previous reviews on EEG have mainly focused on software solutions. However, these reviews often overlook key challenges associated with hardware implementation, such as scenarios that require a small size, low power, high security, and high accuracy. This paper discusses the challenges and opportunities of hardware acceleration for wearable EEG devices by focusing on these aspects. Specifically, this review classifies EEG signal features into five groups and discusses hardware implementation solutions for each category in detail, providing insights into the most suitable hardware acceleration strategies for various application scenarios. In addition, it explores the complexity of efficient CNN architectures for EEG signals, including techniques such as pruning, quantization, tensor decomposition, knowledge distillation, and neural architecture search. To the best of our knowledge, this is the first systematic review that combines CNN hardware solutions with EEG signal processing. By providing a comprehensive analysis of current challenges and a roadmap for future research, this paper provides a new perspective on the ongoing development of hardware-accelerated EEG systems.",,https://pubmed.ncbi.nlm.nih.gov/39275725/,English,Exclude,Review/survey papers,A Comprehensive Review of Hardware Acceleration Techniques and Convolutional Neural Networks for EEG Signals.,,,,,0.95,0.6,
pubmed:39275712,pubmed:39275712,PubMed,pubmed:39275712,Low-Cost Dynamometer for Measuring and Regulating Wrist Extension and Flexion Motor Tasks in Electroencephalography Experiments.,Abdul-Khaaliq Mohamed;Muhammed Aswat;Vered Aharonson,2024,10.3389/fnhum.2021.656975,"A brain-computer interface could control a bionic hand by interpreting electroencephalographic (EEG) signals associated with wrist extension (WE) and wrist flexion (WF) movements. Misinterpretations of the EEG may stem from variations in the force, speed and range of these movements. To address this, we designed, constructed and tested a novel dynamometer, the IsoReg, which regulates WE and WF movements during EEG recording experiments. The IsoReg restricts hand movements to isometric WE and WF, controlling their speed and range of motion. It measures movement force using a dual-load cell system that calculates the percentage of maximum voluntary contraction and displays it to help users control movement force. Linearity and measurement accuracy were tested, and the IsoReg's performance was evaluated under typical EEG experimental conditions with 14 participants. The IsoReg demonstrated consistent linearity between applied and measured forces across the required force range, with a mean accuracy of 97% across all participants. The visual force gauge provided normalised force measurements with a mean accuracy exceeding 98.66% across all participants. All participants successfully controlled the motor tasks at the correct relative forces (with a mean accuracy of 89.90%) using the IsoReg, eliminating the impact of inherent force differences between typical WE and WF movements on the EEG analysis. The IsoReg offers a low-cost method for measuring and regulating movements in future neuromuscular studies, potentially leading to improved neural signal interpretation.",https://pubmed.ncbi.nlm.nih.gov/39275712/,https://pubmed.ncbi.nlm.nih.gov/39275712/,English,Include,,Low-Cost Dynamometer for Measuring and Regulating Wrist Extension and Flexion Motor Tasks in Electroencephalography Experiments.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39274138,pubmed:39274138,PubMed,pubmed:39274138,Enhancing Brain-Computer Interfaces through Kriging-Based Fusion of Sparse Regression Partial Differential Equations to Counter Injection Molding View of Node Displacement Effects.,Hanjui Chang;Yue Sun;Shuzhou Lu;Yuntao Lan,2024,10.1016/j.eswa.2009.02.017,"Injection molding is an efficient and precise manufacturing technology that is widely used in the production of plastic products. In recent years, injection molding technology has made significant progress, especially with the combination of in-mold electronics (IME) technology, which makes it possible to embed electronic components directly into the surface of a product. IME technology improves the integration and performance of a product by embedding conductive materials and functional components in the mold. Brain-computer interfaces (BCIs) are a rapidly growing field of research that aims to capture, analyze, and feedback brain signals by directly connecting the brain to external devices. The Utah array, a high-density microelectrode array, has been widely used for the recording and transmission of brain signals. However, the traditional fabrication method of the Utah array suffers from high cost and low integration, which limits its promotion in practical applications. The lines that receive EEG signals are one of the key parts of a brain-computer interface system. The optimization of injection molding parameters is particularly important in order to effectively embed these lines into thin films and to ensure the precise displacement of the line nodes and the stability of signal transmission during the injection molding process. In this study, a method based on the Kriging prediction model and sparse regression partial differential equations (PDEs) is proposed to optimize the key parameters in the injection molding process. This method can effectively predict and control the displacement of nodes in the film, ensure the stability and reliability of the line during the injection process, and improve the accuracy of EEG signal transmission and system performance. The optimal injection parameters were finally obtained: a holding pressure of 525 MPa, a holding time of 50 s, and a melting temperature of 285 °C. Under this condition, the average node displacement of UA was reduced from the initial 0.19 mm to 0.89 µm, with an optimization rate of 95.32%.",https://pubmed.ncbi.nlm.nih.gov/39274138/,https://pubmed.ncbi.nlm.nih.gov/39274138/,English,Include,,Enhancing Brain-Computer Interfaces through Kriging-Based Fusion of Sparse Regression Partial Differential Equations to Counter Injection Molding View of Node Displacement Effects.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39272771,pubmed:39272771,PubMed,pubmed:39272771,Lobish: Symbolic Language for Interpreting Electroencephalogram Signals in Language Detection Using Channel-Based Transformation and Pattern.,Turker Tuncer;Sengul Dogan;Irem Tasci;Mehmet Baygin;Prabal Datta Barua;U Rajendra Acharya,2024,10.1016/j.knosys.2022.110190,"Electroencephalogram (EEG) signals contain information about the brain's state as they reflect the brain's functioning. However, the manual interpretation of EEG signals is tedious and time-consuming. Therefore, automatic EEG translation models need to be proposed using machine learning methods. In this study, we proposed an innovative method to achieve high classification performance with explainable results. We introduce channel-based transformation, a channel pattern (ChannelPat), the t algorithm, and Lobish (a symbolic language). By using channel-based transformation, EEG signals were encoded using the index of the channels. The proposed ChannelPat feature extractor encoded the transition between two channels and served as a histogram-based feature extractor. An iterative neighborhood component analysis (INCA) feature selector was employed to select the most informative features, and the selected features were fed into a new ensemble k-nearest neighbor (tkNN) classifier. To evaluate the classification capability of the proposed channel-based EEG language detection model, a new EEG language dataset comprising Arabic and Turkish was collected. Additionally, Lobish was introduced to obtain explainable outcomes from the proposed EEG language detection model. The proposed channel-based feature engineering model was applied to the collected EEG language dataset, achieving a classification accuracy of 98.59%. Lobish extracted meaningful information from the cortex of the brain for language detection.",https://pubmed.ncbi.nlm.nih.gov/39272771/,https://pubmed.ncbi.nlm.nih.gov/39272771/,English,Include,,Lobish: Symbolic Language for Interpreting Electroencephalogram Signals in Language Detection Using Channel-Based Transformation and Pattern.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39271921,pubmed:39271921,PubMed,pubmed:39271921,Detection of Alcoholic EEG signal using LASSO regression with metaheuristics algorithms based LSTM and enhanced artificial neural network classification algorithms.,Gowri Shankar Manivannan;Kalaiyarasi Mani;Harikumar Rajaguru;Satish V Talawar,2024,10.1080/03772063.2022.2088627,"The world has a higher count of death rates as a result of Alcohol consumption. Identification is possible because Alcoholic EEG waves have a certain behavior that is totally different compared to the non-alcoholic individual. The available approaches take longer to provide the feedback because they analyze the data manually. For this reason, in the present paper we propose a novel approach applied to detect alcoholic EEG signals automatically by using deep learning methods. Our strategy has advantages as far as fast detection is concerned; hence people can help immediately when there is a need. The potential for a significant decrease in deaths from alcohol poisoning and improvement to public health is presented by this advancement. In order to create clusters and classify the alcoholic EEG signals, this research uses a cascaded process. To begin with, an initial clustering and feature extraction is done by LASSO regression. After that, a variety of meta-heuristics algorithms like Particle Swarm Optimization (PSO), Binary Coding Harmony Search (BCHS) as well as Binary Dragonfly Algorithm (BDA) are employed for feature minimization. When this method is used, normal and alcoholic EEG signals may be differentiated using non-linear features. PSO, BCHS, and BDA features allow for estimation of statistical parameters through t-test, Friedman statistic test, Mann-Whitney U test, and Z-Score with corresponding p-values for alcoholic EEG signals. Lastly, classification is done by the use of support vector machines (SVM) (including linear, polynomial, and Gaussian kernels), random forests, artificial neural networks (ANN), enhanced artificial neural networks (EANN), and LSTM models. Results showed that LASSO regression with BDA-based EANN proposed classifier have a classification accuracy of 99.59%, indicating that our method is highly accurate at classifying alcoholic EEG signals.",https://pubmed.ncbi.nlm.nih.gov/39271921/,https://pubmed.ncbi.nlm.nih.gov/39271921/,English,Include,,Detection of Alcoholic EEG signal using LASSO regression with metaheuristics algorithms based LSTM and enhanced artificial neural network classification algorithms.,Include,,"ests, artificial neural networks (ANN), enhanced artificial neural networks (EANN), and LSTM models. Results showed that LASSO regression with BDA-based EANN proposed classifier have a classification accuracy of 99.59%, indicating that our method is highly accurate at classifying alcoholic EEG signals.",,0.95,0.6,
pubmed:39271023,pubmed:39271023,PubMed,pubmed:39271023,Research on shared control of robots based on hybrid brain-computer interface.,Ziqi Zhang;Mengfan Li;Ran Wei;Wenzhe Liao;Fuyong Wang;Guizhi Xu,2024,10.1016/j.jneumeth.2024.110280,"With the arrival of the new generation of artificial intelligence wave, new human-robot interaction technologies continue to emerge. Brain-computer interface (BCI) offers a pathway for state monitoring and interaction control between human and robot. However, the unstable mental state reduce the accuracy of human brain intent decoding, and consequently affects the precision of BCI control. This paper proposes a hybrid BCI-based shared control (HB-SC) method for brain-controlled robot navigation. Hybrid BCI fuses electroencephalogram (EEG) and electromyography (EMG) for mental state monitoring and interactive control to output human perception and decision. The shared control based on multi-sensory fusion integrates the special obstacle information perceived by humans with the regular environmental information perceived by the robot. In this process, valid BCI commands are screened by mental state assessment and output to a layered costmap for fusion. Eight subjects participated in the navigation experiment with dynamically changing mental state levels to validate the effects of a hybrid brain-computer interface through two shared control modes. The results show that the proposed HB-SC reduces collisions by 37.50 %, improves the success rate of traversing obstacles by 25.00 %, and the navigation trajectory is more consistent with expectations. The HB-SC method can dynamically and intelligently adjust command output according to different brain states, helping to reduce errors made by subjects in a unstable mental state, thereby greatly enhancing the system's safety.",https://pubmed.ncbi.nlm.nih.gov/39271023/,https://pubmed.ncbi.nlm.nih.gov/39271023/,English,Include,,Research on shared control of robots based on hybrid brain-computer interface.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39269793,pubmed:39269793,PubMed,pubmed:39269793,A Compact Graph Convolutional Network With Adaptive Functional Connectivity for Seizure Prediction.,Boxuan Wei;Lu Xu;Jicong Zhang,2024,10.1109/tnsre.2024.3460348,"Seizure prediction using EEG has significant implications for the daily monitoring and treatment of epilepsy patients. However, the task is challenging due to the underlying spatiotemporal correlations and patient heterogeneity. Traditional methods often use large-scale models with independent components to capture the spatial and temporal features of EEG separately or explore shared patterns among patients with the help of pre-defined functional connectivity. In this paper, we propose a compact model, called the graph convolutional network based on adaptive functional connectivity (AFC-GCN), for seizure prediction. The model can adaptively infer evolution of functional connectivity in epilepsy patients during seizures through data-driven methods and synchronously analyze spatiotemporal response of functional connectivity in multiple topologies. On CHB-MIT datasets, the experimental results demonstrate that AFC-GCN achieves accurate and robust performance with low complexity. (AUC: 0.9820, accuracy: 0.9815, sensitivity: 0.9802, FPR: 0.0172). The proposed method has the potential to predict seizure during daily monitoring.",https://pubmed.ncbi.nlm.nih.gov/39269793/,https://pubmed.ncbi.nlm.nih.gov/39269793/,English,Include,,A Compact Graph Convolutional Network With Adaptive Functional Connectivity for Seizure Prediction.,Include,,"e of functional connectivity in multiple topologies. On CHB-MIT datasets, the experimental results demonstrate that AFC-GCN achieves accurate and robust performance with low complexity. (AUC: 0.9820, accuracy: 0.9815, sensitivity: 0.9802, FPR: 0.0172). The proposed method has the potential to predict seizure during daily monitoring.",,0.95,0.6,
pubmed:39268345,pubmed:39268345,PubMed,pubmed:39268345,Two Cases of Sleep-related Dissociative Disorder with Episodes of Nocturnal Eating.,Carlos H Schenck,2024,10.1093/sleep/zsy233,"Sleep-related dissociative disorder (SRDD) is a female-predominant psychiatric parasomnia that was first identified as a condition that mimics sleepwalking in 1989, and was included in the International Classification of Sleep Disorders, 2nd edition, in 2005, with a subsequent expanding literature of case series and case reports. The objective hallmark of SRDD, found in about half of the reported cases, is sustained electroencephalogram (EEG) wakefulness during dissociative episodes emerging during wake-sleep transitions or after awakenings from light non-rapid eye movement (NREM) sleep or rapid eye movement (REM) sleep. Herein are reported two additional cases of SRDD in two female patients aged 53 and 40 years with prominent histories of multimodal abuse (typical of SRDD), with childhood emotional and food deprivation abuse in Case 1, and childhood emotional, sexual, and physical abuse in Case 2. Both patients were affected by ""sleep phobia"" and had recurrent nocturnal eating episodes. Major findings from the cumulative literature on SRDD are reinforced by these cases, with additional findings being described, particularly nocturnal eating behaviors and priming/triggering factors.",https://pubmed.ncbi.nlm.nih.gov/39268345/,https://pubmed.ncbi.nlm.nih.gov/39268345/,English,Include,,Two Cases of Sleep-related Dissociative Disorder with Episodes of Nocturnal Eating.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39265862,pubmed:39265862,PubMed,pubmed:39265862,Common and differential EEG microstate of major depressive disorder patients with and without response to rTMS treatment.,Zongya Zhao;Xiangying Ran;Junming Wang;Shiyang Lv;Mengyue Qiu;Yanxiang Niu;Chang Wang;Yongtao Xu;Zhixian Gao;Wu Ren;Xuezhi Zhou;Xiaofeng Fan;Jinggui Song;Yi Yu,2024,10.1016/j.jad.2024.09.040,"Repetitive transcranial magnetic stimulation (rTMS) has recently emerged as a novel treatment option for patients with major depressive disorder (MDD), but clinical observations reveal variability in patient's responses to rTMS. Therefore, it is clinically significant to investigate the baseline neuroimaging differences between patients with (Responder) and without (NonResponder) response to rTMS treatment and predict rTMS treatment outcomes based on baseline neuroimaging data. Baseline resting-state EEG data and Beck Depression Inventory (BDI) were collected from 74 rTMS Responder, 43 NonResponder, and 47 matched healthy controls (HC). EEG microstate analysis was applied to analyze common and differential microstate characteristics of Responder and NonResponder. In addition, the microstate temporal parameters were sent to four machine learning models to classify Responder from NonResponder. There exists some common and differential EEG microstate characteristics for Responder and NonResponder. Specifically, compared to the HC group, both Responder and NonResponder exhibited a significant increase in the occurrence of microstate A. Only Responder showed an increase in the coverage of microstate A, occurrence of microstate D, transition probability (TP) from A to D, D to A, and C to A, and a decrease in the duration of microstates B and E, TP from A to B and C to B compared to HC. Only NonResponder exhibited a significant decrease in the duration of microstate D, TP from C to D, and an increase in the occurrence of microstate E, TP from C to E compared to HC. The primary differences between the Responder and NonResponder are that Responder had higher parameters for microstate D, TP from other microstates to D, and lower parameters for microstate E, TP from other microstates to E compared to NonResponder. Baseline parameters of microstate D showed significant correlation with Beck Depression Inventory (BDI) reduction rate. Additionally, these microstate features were sent to four machine learning models to predict rTMS treatment response and classification results indicate that an excellent predicting performance (accuracy = 97.35 %, precision = 96.31 %, recall = 100 %, F1 score = 98.06 %) was obtained when using AdaBoost model. These results suggest that baseline resting-state EEG microstate parameters could serve as robust indicators for predicting the effectiveness of rTMS treatment. This study reveals significant baseline EEG microstate differences between rTMS Responder, NonResponder, and healthy controls. Microstates D and E in baseline EEG can serve as potential biomarkers for predicting rTMS treatment outcomes in MDD patients. These findings may aid in identifying patients likely to respond to rTMS, optimizing treatment plans and reducing trial-and-error approaches in therapy selection.",https://pubmed.ncbi.nlm.nih.gov/39265862/,https://pubmed.ncbi.nlm.nih.gov/39265862/,English,Include,,Common and differential EEG microstate of major depressive disorder patients with and without response to rTMS treatment.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39265802,pubmed:39265802,PubMed,pubmed:39265802,Brain connectivity and time-frequency fusion-based auditory spatial attention detection.,Yixiang Niu;Ning Chen;Hongqing Zhu;Guangqiang Li;Yibo Chen,2024,10.1016/j.neuroscience.2024.09.017,"Auditory spatial attention detection (ASAD) aims to decipher the spatial locus of a listener's selective auditory attention from electroencephalogram (EEG) signals. However, current models may exhibit deficiencies in EEG feature extraction, leading to overfitting on small datasets or a decline in EEG discriminability. Furthermore, they often neglect topological relationships between EEG channels and, consequently, brain connectivities. Although graph-based EEG modeling has been employed in ASAD, effectively incorporating both local and global connectivities remains a great challenge. To address these limitations, we propose a new ASAD model. First, time-frequency feature fusion provides a more precise and discriminative EEG representation. Second, EEG segments are treated as graphs, and the graph convolution and global attention mechanism are leveraged to capture local and global brain connections, respectively. A series of experiments are conducted in a leave-trials-out cross-validation manner. On the MAD-EEG and KUL datasets, the accuracies of the proposed model are more than 9% and 3% higher than those of the corresponding state-of-the-art models, respectively, while the accuracy of the proposed model on the SNHL dataset is roughly comparable to that of the state-of-the-art model. EEG time-frequency feature fusion proves to be indispensable in the proposed model. EEG electrodes over the frontal cortex are most important for ASAD tasks, followed by those over the temporal lobe. Additionally, the proposed model performs well even on small datasets. This study contributes to a deeper understanding of the neural encoding related to human hearing and attention, with potential applications in neuro-steered hearing devices.",https://pubmed.ncbi.nlm.nih.gov/39265802/,https://pubmed.ncbi.nlm.nih.gov/39265802/,English,Include,,Brain connectivity and time-frequency fusion-based auditory spatial attention detection.,Include,,"alidation manner. On the MAD-EEG and KUL datasets, the accuracies of the proposed model are more than 9% and 3% higher than those of the corresponding state-of-the-art models, respectively, while the accuracy of the proposed model on the SNHL dataset is roughly comparable to that of the state-of-the-art model. EEG time-frequency feature fusion proves to be indispensable in the proposed model. EEG ",,0.95,0.45,cv_reported;overfit_terms_found
pubmed:39265481,pubmed:39265481,PubMed,pubmed:39265481,SpeechBrain-MOABB: An open-source Python library for benchmarking deep neural networks applied to EEG signals.,Davide Borra;Francesco Paissan;Mirco Ravanelli,2024,10.1016/j.compbiomed.2024.109097,"Deep learning has revolutionized EEG decoding, showcasing its ability to outperform traditional machine learning models. However, unlike other fields, EEG decoding lacks comprehensive open-source libraries dedicated to neural networks. Existing tools (MOABB and braindecode) prevent the creation of robust and complete decoding pipelines, as they lack support for hyperparameter search across the entire pipeline, and are sensitive to fluctuations in results due to network random initialization. Furthermore, the absence of a standardized experimental protocol exacerbates the reproducibility crisis in the field. To address these limitations, we introduce SpeechBrain-MOABB, a novel open-source toolkit carefully designed to facilitate the development of a comprehensive EEG decoding pipeline based on deep learning. SpeechBrain-MOABB incorporates a complete experimental protocol that standardizes critical phases, such as hyperparameter search and model evaluation. It natively supports multi-step hyperparameter search for finding the optimal hyperparameters in a high-dimensional space defined by the entire pipeline, and multi-seed training and evaluation for obtaining performance estimates robust to the variability caused by random initialization. SpeechBrain-MOABB outperforms other libraries, including MOABB and braindecode, with accuracy improvements of 14.9% and 25.2% (on average), respectively. By enabling easy-to-use and easy-to-share decoding pipelines, our toolkit can be exploited by neuroscientists for decoding EEG with neural networks in a replicable and trustworthy way.",https://pubmed.ncbi.nlm.nih.gov/39265481/,https://pubmed.ncbi.nlm.nih.gov/39265481/,English,Include,,SpeechBrain-MOABB: An open-source Python library for benchmarking deep neural networks applied to EEG signals.,Include,,"ning and evaluation for obtaining performance estimates robust to the variability caused by random initialization. SpeechBrain-MOABB outperforms other libraries, including MOABB and braindecode, with accuracy improvements of 14.9% and 25.2% (on average), respectively. By enabling easy-to-use and easy-to-share decoding pipelines, our toolkit can be exploited by neuroscientists for decoding EEG with",,0.95,0.6,
pubmed:39265288,pubmed:39265288,PubMed,pubmed:39265288,Machine learning for (non-)epileptic tissue detection from the intraoperative electrocorticogram.,Sem Hoogteijling;Eline V Schaft;Evi H M Dirks;Sven Straumann;Matteo Demuru;Pieter van Eijsden;Tineke Gebbink;Willem M Otte;Geertjan M Huiskamp;Maryse A van 't Klooster;Maeike Zijlmans,2024,10.1016/j.clinph.2024.08.012,"Clinical visual intraoperative electrocorticography (ioECoG) reading intends to localize epileptic tissue and improve epilepsy surgery outcome. We aimed to understand whether machine learning (ML) could complement ioECoG reading, how subgroups affected performance, and which ioECoG features were most important. We included 91 ioECoG-guided epilepsy surgery patients with Engel 1A outcome. We allocated 71 training and 20 test set patients. We trained an extra trees classifier (ETC) with 14 spectral features to classify ioECoG channels as covering resected or non-resected tissue. We compared the ETC's performance with clinical ioECoG reading and assessed whether patient subgroups affected performance. Explainable artificial intelligence (xAI) unveiled the most important ioECoG features learnt by the ETC. The ETC outperformed clinical reading in five test set patients, was inferior in six, and both were inconclusive in nine. The ETC performed best in the tumor subgroup (area under ROC curve: 0.84 [95%CI 0.79-0.89]). xAI revealed predictors of resected (relative theta, alpha, and fast ripple power) and non-resected tissue (relative beta and gamma power). Combinations of subtle spectral ioECoG changes, imperceptible by the human eye, can aid healthy and pathological tissue discrimination. ML with spectral ioECoG features can support, rather than replace, clinical ioECoG reading, particularly in tumors.",,https://pubmed.ncbi.nlm.nih.gov/39265288/,English,Exclude,Not EEG-BCI focused,Machine learning for (non-)epileptic tissue detection from the intraoperative electrocorticogram.,,,,,0.9,0.6,
pubmed:39263228,pubmed:39263228,PubMed,pubmed:39263228,Acquisition and processing of Motor Imagery and Motor Execution Dataset (MIMED) for six movement activities.,I Made Agus Wirawan;Dechrit Maneetham;I Gede Mahendra Darmawiguna;Arnon Niyomphol;Pakornkiat Sawetmethikul;Padma Nyoman Crisnapati;Yamin Thwe;Ni Nyoman Mestri Agustini,2024,10.1016/j.compbiomed.2020.103927,"The MIMED dataset is a dataset that provides raw electroencephalogram signal data for activities: raising the right-hand, lowering the right-hand, raising the left-hand, lowering the left-hand, standing, and sitting. In addition to raw data, this dataset provides feature data that undergoes a baseline reduction process. The baseline reduction process is a process to increase the value of EEG signal features. The feature values ​​of the enhanced EEG signal can be easily recognized in the classification process. The device used is Emotiv Epoc X, which consists of 14 channels. Participants involved in this experiment were 30 students from the Bali region in Indonesia. Four recording scenarios were carried out on the first day and four further scenarios on the second day. Two datasets were obtained based on the recording scenario: the motor movement and image datasets. The duration of motor execution is 40 minutes, while motor imagery is 8 minutes for each scenario.",https://pubmed.ncbi.nlm.nih.gov/39263228/,https://pubmed.ncbi.nlm.nih.gov/39263228/,English,Include,,Acquisition and processing of Motor Imagery and Motor Execution Dataset (MIMED) for six movement activities.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39261550,pubmed:39261550,PubMed,pubmed:39261550,Cognitive benefits of higher cardiorespiratory fitness in preadolescent children are associated with increased connectivity within the cingulo-opercular network.,Tomasz S Ligeza;Lauren B Raine;Matthew B Pontifex;Miroslaw Wyczesany;Arthur F Kramer;Charles H Hillman,2024,10.1016/j.yebeh.2017.06.021,"Higher cardiorespiratory fitness has been associated with improved cognitive control in preadolescent children, with various studies highlighting related brain health benefits. This cross-sectional study aimed to provide novel insights into the fitness-cognition relationship by investigating task-related changes in effective connectivity within two brain networks involved in cognitive control: the cingulo-opercular and fronto-parietal networks. Twenty-four higher-fit and twenty-four lower-fit preadolescent children completed a modified flanker task that modulated inhibitory control demand while their EEG and task performance were concurrently recorded. Effective connectivity for correct trials in the theta band was estimated using directed transfer function. The results indicate that children with higher fitness levels demonstrated greater connectivity in specific directions within the cingulo-opercular network (average effect size, d = 0.72). Brain-behavior correlations demonstrated a positive association between the majority of these connections and general task accuracy, which was also higher in higher fit children (average correlation coefficient, ρ = 0.34). The findings further support a positive relationship between fitness and cognitive performance in children. EEG findings offer novel insights into the potential brain mechanisms underlying the fitness-cognition relationship. The study suggests that increased task-related connectivity within the cingulo-opercular network may mediate the cognitive benefits associated with higher fitness levels in preadolescent children.",https://pubmed.ncbi.nlm.nih.gov/39261550/,https://pubmed.ncbi.nlm.nih.gov/39261550/,English,Include,,Cognitive benefits of higher cardiorespiratory fitness in preadolescent children are associated with increased connectivity within the cingulo-opercular network.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39261275,pubmed:39261275,PubMed,pubmed:39261275,EEG Functional Connectivity Differences Predict Future Conversion to Dementia in Mild Cognitive Impairment With Lewy Body or Alzheimer Disease.,Jahfer Hasoon;Calum A Hamilton;Julia Schumacher;Sean Colloby;Paul C Donaghy;Alan J Thomas;John-Paul Taylor,2024,10.1002/gps.6138,"Predicting which individuals may convert to dementia from mild cognitive impairment (MCI) remains difficult in clinical practice. Electroencephalography (EEG) is a widely available investigation but there is limited research exploring EEG connectivity differences in patients with MCI who convert to dementia. Participants with a diagnosis of MCI due to Alzheimer's disease (MCI-AD) or Lewy body disease (MCI-LB) underwent resting state EEG recording. They were followed up annually with a review of the clinical diagnosis (n = 66). Participants with a diagnosis of dementia at year 1 or year 2 follow up were classed as converters (n = 23) and those with a diagnosis of MCI at year 2 were classed as stable (n = 43). We used phase lag index (PLI) to estimate functional connectivity as well as analysing dominant frequency (DF) and relative band power. The Network-based statistic (NBS) toolbox was used to assess differences in network topology. The converting group had reduced DF (U = 285.5, p = 0.005) and increased relative pre-alpha power (U = 702, p = 0.005) consistent with previous findings. PLI showed reduced average beta band synchrony in the converting group (U = 311, p = 0.014) as well as significant differences in alpha and beta network topology. Logistic regression models using regional beta PLI values revealed that right central to right lateral (Sens = 56.5%, Spec = 86.0%, -2LL = 72.48, p = 0.017) and left central to right lateral (Sens = 47.8%, Spec = 81.4%, -2LL = 71.37, p = 0.012) had the best classification accuracy and fit when adjusted for age and MMSE score. Patients with MCI who convert to dementia have significant differences in EEG frequency, average connectivity and network topology prior to the onset of dementia. The MCI group is clinically heterogeneous and have underlying physiological differences that may be driving the progression of cognitive symptoms. EEG connectivity could be useful to predict which patients with MCI-AD and MCI-LB convert to dementia, regardless of the neurodegenerative aetiology.",,https://pubmed.ncbi.nlm.nih.gov/39261275/,English,Exclude,Review/survey papers,EEG Functional Connectivity Differences Predict Future Conversion to Dementia in Mild Cognitive Impairment With Lewy Body or Alzheimer Disease.,,,,,0.95,0.8,small_sample_mentioned
pubmed:39258825,pubmed:39258825,PubMed,pubmed:39258825,Depression of cortical neuronal activity after a low-dose fentanyl in preterm infants.,Sofie Nilsson;Anton Tokariev;Timo Vehviläinen;Vineta Fellman;Sampsa Vanhatalo;Elisabeth Norman,2025,10.1111/apa.17411,"Opioids might be harmful to the developing brain and dosing accuracy is important. We aimed at investigating fentanyl effects on cortical activity in infants using computational re-analysis of bedside recorded EEG signals. Fifteen infants born at median 26.4 gestational weeks (range 23.3-34.1), with a birth weight 740 grams (530-1420) and postnatal age 7 days (5-11) received fentanyl 0.5 or 2 μg/kg intravenously before a skin-breaking procedure or tracheal intubation, respectively. Cortical activity was continuously recorded using amplitude-integrated electroencephalography (aEEG).  Analyses using three computational EEG features representing cortical synchrony and signal power, were conducted five minutes pre- and 10 minutes post the drug administration. Visual assessment of trends displayed from the EEG metrics did not indicate systematic changes. However, the magnitude of the changes in the parietal and right hemisphere signals after the dose was significantly correlated (ρ < -0.5, p < 0.05) to the EEG amplitude and frequency power level before drug administration. This effect started after 3-4 min. Fentanyl, even in small doses, may affect cortical activity in the preterm brain. The effect is robustly related to the state of cortical activity prior to drug treatment, which must be taken into account when analysing the effects of sedative drugs.",,https://pubmed.ncbi.nlm.nih.gov/39258825/,English,Exclude,Outside date range,Depression of cortical neuronal activity after a low-dose fentanyl in preterm infants.,,,,,0.95,0.6,
pubmed:39255823,pubmed:39255823,PubMed,pubmed:39255823,DOCTer: a novel EEG-based diagnosis framework for disorders of consciousness.,Sha Zhao;Yue Cao;Wei Yang;Jie Yu;Chuan Xu;Wei Dai;Shijian Li;Gang Pan;Benyan Luo,2024,10.1088/1741-2552/ad7904,,,https://pubmed.ncbi.nlm.nih.gov/39255823/,English,Exclude,Not classification-focused,DOCTer: a novel EEG-based diagnosis framework for disorders of consciousness.,,,,,0.85,0.6,
pubmed:39255658,pubmed:39255658,PubMed,pubmed:39255658,Siamese based deep neural network for ADHD detection using EEG signal.,Behnam Latifi;Ali Amini;Ali Motie Nasrabadi,2024,10.1016/j.compbiomed.2024.109092,"Detecting Attention-Deficit/Hyperactivity Disorder (ADHD) in children is crucial for timely intervention and personalized treatment. This study aims to utilize deep learning techniques to analyze brain maps derived from Power Spectral Density (PSD) of Electroencephalography (EEG) signals in pediatric subjects for ADHD detection. We employed a Siamese-based Convolutional Neural Network (CNN) to analyze EEG-based brain maps. Gradient-weighted class activation mapping (Grad-CAM) was used as an explainable AI (XAI) visualization method to identify significant features. The CNN model achieved a high classification accuracy of 99.17 %. Grad-CAM analysis revealed that PSD features from the theta band of the frontal and occipital lobes are effective discriminators for distinguishing children with ADHD from healthy controls. This study demonstrates the effectiveness of deep learning in ADHD detection and highlights the importance of regional PSD metrics in accurate classification. By utilizing Grad-CAM, we elucidate the discriminative power of specific brain regions and frequency bands, thereby enhancing the understanding of ADHD neurobiology for improved diagnostic precision in pediatric populations.",https://pubmed.ncbi.nlm.nih.gov/39255658/,https://pubmed.ncbi.nlm.nih.gov/39255658/,English,Include,,Siamese based deep neural network for ADHD detection using EEG signal.,Include,,ain maps. Gradient-weighted class activation mapping (Grad-CAM) was used as an explainable AI (XAI) visualization method to identify significant features. The CNN model achieved a high classification accuracy of 99.17 %. Grad-CAM analysis revealed that PSD features from the theta band of the frontal and occipital lobes are effective discriminators for distinguishing children with ADHD from healthy,,0.95,0.6,
pubmed:39255190,pubmed:39255190,PubMed,pubmed:39255190,Multimodal Emotion Recognition Based on EEG and EOG Signals Evoked by the Video-Odor Stimuli.,Minchao Wu;Wei Teng;Cunhang Fan;Shengbing Pei;Ping Li;Guanxiong Pei;Taihao Li;Wen Liang;Zhao Lv,2024,10.1109/tnsre.2024.3457580,"Affective data is the basis of emotion recognition, which is mainly acquired through extrinsic elicitation. To investigate the enhancing effects of multi-sensory stimuli on emotion elicitation and emotion recognition, we designed an experimental paradigm involving visual, auditory, and olfactory senses. A multimodal emotional dataset (OVPD-II) that employed the video-only or video-odor patterns as the stimuli materials, and recorded the electroencephalogram (EEG) and electrooculogram (EOG) signals, was created. The feedback results reported by subjects after each trial demonstrated that the video-odor pattern outperformed the video-only pattern in evoking individuals' emotions. To further validate the efficiency of the video-odor pattern, the transformer was employed to perform the emotion recognition task, where the highest accuracy reached 86.65% (66.12%) for EEG (EOG) modality with the video-odor pattern, which improved by 1.42% (3.43%) compared with the video-only pattern. What's more, the hybrid fusion (HF) method combined with the transformer and joint training was developed to improve the performance of the emotion recognition task, which achieved classify accuracies of 89.50% and 88.47% for the video-odor and video-only patterns, respectively.",https://pubmed.ncbi.nlm.nih.gov/39255190/,https://pubmed.ncbi.nlm.nih.gov/39255190/,English,Include,,Multimodal Emotion Recognition Based on EEG and EOG Signals Evoked by the Video-Odor Stimuli.,Include,,"eo-only pattern in evoking individuals' emotions. To further validate the efficiency of the video-odor pattern, the transformer was employed to perform the emotion recognition task, where the highest accuracy reached 86.65% (66.12%) for EEG (EOG) modality with the video-odor pattern, which improved by 1.42% (3.43%) compared with the video-only pattern. What's more, the hybrid fusion (HF) method co",,0.95,0.6,
pubmed:39255189,pubmed:39255189,PubMed,pubmed:39255189,Federated Motor Imagery Classification for Privacy-Preserving Brain-Computer Interfaces.,Tianwang Jia;Lubin Meng;Siyang Li;Jiajing Liu;Dongrui Wu,2024,10.1109/tnsre.2024.3457504,"Training an accurate classifier for EEG-based brain-computer interface (BCI) requires EEG data from a large number of users, whereas protecting their data privacy is a critical consideration. Federated learning (FL) is a promising solution to this challenge. This paper proposes Federated classification with local Batch-specific batch normalization and Sharpness-aware minimization (FedBS) for privacy protection in EEG-based motor imagery (MI) classification. FedBS utilizes local batch-specific batch normalization to reduce data discrepancies among different clients, and sharpness-aware minimization optimizer in local training to improve model generalization. Experiments on three public MI datasets using three popular deep learning models demonstrated that FedBS outperformed six state-of-the-art FL approaches. Remarkably, it also outperformed centralized training, which does not consider privacy protection at all. In summary, FedBS protects user EEG data privacy, enabling multiple BCI users to participate in large-scale machine learning model training, which in turn improves the BCI decoding accuracy.",https://pubmed.ncbi.nlm.nih.gov/39255189/,https://pubmed.ncbi.nlm.nih.gov/39255189/,English,Include,,Federated Motor Imagery Classification for Privacy-Preserving Brain-Computer Interfaces.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39255188,pubmed:39255188,PubMed,pubmed:39255188,Subject-Independent Wearable P300 Brain-Computer Interface Based on Convolutional Neural Network and Metric Learning.,Li Hu;Wei Gao;Zilin Lu;Chun Shan;Haiwei Ma;Wenyu Zhang;Yuanqing Li,2024,10.1109/tnsre.2024.3457502,"The calibration procedure for a wearable P300 brain-computer interface (BCI) greatly impact the user experience of the system. Each user needs to spend additional time establishing a decoder adapted to their own brainwaves. Therefore, achieving subject independent is an urgent issue for wearable P300 BCI needs to be addressed. A dataset of electroencephalogram (EEG) signals was constructed from 100 individuals by conducting a P300 speller task with a wearable EEG amplifier. A framework is proposed that initially improves cross- subject consistency of EEG features through a common feature extractor. Subsequently, a simple and compact convolutional neural network (CNN) architecture is employed to learn an embedding sub-space, where the mapped EEG features are maximally separated, while pursuing the minimum distance within the same class and the maximum distance between different classes. Finally, the model's generalization capability was further optimized through fine-tuning. Results: The proposed method significantly boosts the average accuracy of wearable P300 BCI to 73.23±7.62 % without calibration and 78.75±6.37 % with fine-tuning. The results demonstrate the feasibility and excellent performance of our dataset and framework. A calibration-free wearable P300 BCI system is feasible, suggesting significant potential for practical applications of the wearable P300 BCI system.",https://pubmed.ncbi.nlm.nih.gov/39255188/,https://pubmed.ncbi.nlm.nih.gov/39255188/,English,Include,,Subject-Independent Wearable P300 Brain-Computer Interface Based on Convolutional Neural Network and Metric Learning.,Include,,"the maximum distance between different classes. Finally, the model's generalization capability was further optimized through fine-tuning. Results: The proposed method significantly boosts the average accuracy of wearable P300 BCI to 73.23±7.62 % without calibration and 78.75±6.37 % with fine-tuning. The results demonstrate the feasibility and excellent performance of our dataset and framework. A c",,0.95,0.6,
pubmed:39255187,pubmed:39255187,PubMed,pubmed:39255187,Effective Phoneme Decoding With Hyperbolic Neural Networks for High-Performance Speech BCIs.,Xianhan Tan;Qi Lian;Junming Zhu;Jianmin Zhang;Yueming Wang;Yu Qi,2024,10.1109/tnsre.2024.3457313,"Speech brain-computer interfaces (speech BCIs), which convert brain signals into spoken words or sentences, have demonstrated great potential for high-performance BCI communication. Phonemes are the basic pronunciation units. For monosyllabic languages such as Chinese Mandarin, where a word usually contains less than three phonemes, accurate decoding of phonemes plays a vital role. We found that in the neural representation space, phonemes with similar pronunciations are often inseparable, leading to confusion in phoneme classification. We mapped the neural signals of phoneme pronunciation into a hyperbolic space for a more distinct phoneme representation. Critically, we proposed a hyperbolic hierarchical clustering approach to specifically learn a phoneme-level structure to guide the representation. We found such representation facilitated greater distance between similar phonemes, effectively reducing confusion. In the phoneme decoding task, our approach demonstrated an average accuracy of 75.21% for 21 phonemes and outperformed existing methods across different experimental days. Our approach showed high accuracy in phoneme classification. By learning the phoneme-level neural structure, the representations of neural signals were more discriminative and interpretable. Our approach can potentially facilitate high-performance speech BCIs for Chinese and other monosyllabic languages.",https://pubmed.ncbi.nlm.nih.gov/39255187/,https://pubmed.ncbi.nlm.nih.gov/39255187/,English,Include,,Effective Phoneme Decoding With Hyperbolic Neural Networks for High-Performance Speech BCIs.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39255100,pubmed:39255100,PubMed,pubmed:39255100,Classification of Internal and External Distractions in an Educational VR Environment Using Multimodal Features.,Sarker M Asish;Arun K Kulshreshth;Christoph W Borst;Shaon Sutradhar,2024,10.1109/tvcg.2024.3456207,"Virtual reality (VR) can potentially enhance student engagement and memory retention in the classroom. However, distraction among participants in a VR-based classroom is a significant concern. Several factors, including mind wandering, external noise, stress, etc., can cause students to become internally and/or externally distracted while learning. To detect distractions, single or multi-modal features can be used. A single modality is found to be insufficient to detect both internal and external distractions, mainly because of individual variability. In this work, we investigated multi-modal features: eye tracking and EEG data, to classify the internal and external distractions in an educational VR environment. We set up our educational VR environment and equipped it for multi-modal data collection. We implemented different machine learning (ML) methods, including k-nearest-neighbors (kNN), Random Forest (RF), one-dimensional convolutional neural network - long short-term memory (1 D-CNN-LSTM), and two-dimensional convolutional neural networks (2D-CNN) to classify participants' internal and external distraction states using the multi-modal features. We performed cross-subject, cross-session, and gender-based grouping tests to evaluate our models. We found that the RF classifier achieves the highest accuracy over 83% in the cross-subject test, around 68% to 78% in the cross-session test, and around 90% in the gender-based grouping test compared to other models. SHAP analysis of the extracted features illustrated greater contributions from the occipital and prefrontal regions of the brain, as well as gaze angle, gaze origin, and head rotation features from the eye tracking data.",https://pubmed.ncbi.nlm.nih.gov/39255100/,https://pubmed.ncbi.nlm.nih.gov/39255100/,English,Include,,Classification of Internal and External Distractions in an Educational VR Environment Using Multimodal Features.,Include,,"traction states using the multi-modal features. We performed cross-subject, cross-session, and gender-based grouping tests to evaluate our models. We found that the RF classifier achieves the highest accuracy over 83% in the cross-subject test, around 68% to 78% in the cross-session test, and around 90% in the gender-based grouping test compared to other models. SHAP analysis of the extracted feat",,0.95,0.8,small_sample_mentioned
pubmed:39254794,pubmed:39254794,PubMed,pubmed:39254794,Understanding Learning from EEG Data: Combining Machine Learning and Feature Engineering Based on Hidden Markov Models and Mixed Models.,Gabriel R Palma;Conor Thornberry;Seán Commins;Rafael A Moral,2024,10.1007/s12021-024-09690-6,"Theta oscillations, ranging from 4-8 Hz, play a significant role in spatial learning and memory functions during navigation tasks. Frontal theta oscillations are thought to play an important role in spatial navigation and memory. Electroencephalography (EEG) datasets are very complex, making any changes in the neural signal related to behaviour difficult to interpret. However, multiple analytical methods are available to examine complex data structures, especially machine learning-based techniques. These methods have shown high classification performance, and their combination with feature engineering enhances their capability. This paper proposes using hidden Markov and linear mixed effects models to extract features from EEG data. Based on the engineered features obtained from frontal theta EEG data during a spatial navigation task in two key trials (first, last) and between two conditions (learner and non-learner), we analysed the performance of six machine learning methods on classifying learner and non-learner participants. We also analysed how different standardisation methods used to pre-process the EEG data contribute to classification performance. We compared the classification performance of each trial with data gathered from the same subjects, including solely coordinate-based features, such as idle time and average speed. We found that more machine learning methods perform better classification using coordinate-based data. However, only deep neural networks achieved an area under the ROC curve higher than 80% using the theta EEG data alone. Our findings suggest that standardising the theta EEG data and using deep neural networks enhances the classification of learner and non-learner subjects in a spatial learning task.",https://pubmed.ncbi.nlm.nih.gov/39254794/,https://pubmed.ncbi.nlm.nih.gov/39254794/,English,Include,,Understanding Learning from EEG Data: Combining Machine Learning and Feature Engineering Based on Hidden Markov Models and Mixed Models.,Include,," and non-learner), we analysed the performance of six machine learning methods on classifying learner and non-learner participants. We also analysed how different standardisation methods used to pre-process the EEG data contribute to classification performance. We compared the classification performance of each trial with data gathered from the same subjects, including solely coordinate-based feat",,0.95,0.8,small_sample_mentioned
pubmed:39253981,pubmed:39253981,PubMed,pubmed:39253981,Nonictal electroencephalographic measures for the diagnosis of functional seizures.,Chloe H L Hinchliffe;Mahinda Yogarajah;Samia Elkommos;Hongying Tang;Daniel Abasolo,2024,10.1111/epi.18110,"Functional seizures (FS) look like epileptic seizures but are characterized by a lack of epileptic activity in the brain. Approximately one in five referrals to epilepsy clinics are diagnosed with this condition. FS are diagnosed by recording a seizure using video-electroencephalography (EEG), from which an expert inspects the semiology and the EEG. However, this method can be expensive and inaccessible and can present significant patient burden. No single biomarker has been found to diagnose FS. However, the current limitations in FS diagnosis could be improved with machine learning to classify signal features extracted from EEG, thus providing a potentially very useful aid to clinicians. The current study has investigated the use of seizure-free EEG signals with machine learning to identify subjects with FS from those with epilepsy. The dataset included interictal and preictal EEG recordings from 48 subjects with FS (mean age = 34.76 ± 10.55 years, 14 males) and 29 subjects with epilepsy (mean age = 38.95 ± 13.93 years, 18 males) from which various statistical, temporal, and spectral features from the five EEG frequency bands were extracted then analyzed with threshold accuracy, five machine learning classifiers, and two feature importance approaches. The highest classification accuracy reported from thresholding was 60.67%. However, the temporal features were the best performing, with the highest balanced accuracy reported by the machine learning models: 95.71% with all frequency bands combined and a support vector machine classifier. Machine learning was much more effective than using individual features and could be a powerful aid in FS diagnosis. Furthermore, combining the frequency bands improved the accuracy of the classifiers in most cases, and the lowest performing EEG bands were consistently delta and gamma.",https://pubmed.ncbi.nlm.nih.gov/39253981/,https://pubmed.ncbi.nlm.nih.gov/39253981/,English,Include,,Nonictal electroencephalographic measures for the diagnosis of functional seizures.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39253213,pubmed:39253213,PubMed,pubmed:39253213,Multimodal insights into granger causality connectivity: Integrating physiological signals and gated eye-tracking data for emotion recognition using convolutional neural network.,Javid Farhadi Sedehi;Nader Jafarnia Dabanloo;Keivan Maghooli;Ali Sheikhani,2024,10.1016/j.heliyon.2024.e36411,"This study introduces a groundbreaking method to enhance the accuracy and reliability of emotion recognition systems by combining electrocardiogram (ECG) with electroencephalogram (EEG) data, using an eye-tracking gated strategy. Initially, we propose a technique to filter out irrelevant portions of emotional data by employing pupil diameter metrics from eye-tracking data. Subsequently, we introduce an innovative approach for estimating effective connectivity to capture the dynamic interaction between the brain and the heart during emotional states of happiness and sadness. Granger causality (GC) is estimated and utilized to optimize input for a highly effective pre-trained convolutional neural network (CNN), specifically ResNet-18. To assess this methodology, we employed EEG and ECG data from the publicly available MAHNOB-HCI database, using a 5-fold cross-validation approach. Our method achieved an impressive average accuracy and area under the curve (AUC) of 91.00 % and 0.97, respectively, for GC-EEG-ECG images processed with ResNet-18. Comparative analysis with state-of-the-art studies clearly shows that augmenting ECG with EEG and refining data with an eye-tracking strategy significantly enhances emotion recognition performance across various emotions.",https://pubmed.ncbi.nlm.nih.gov/39253213/,https://pubmed.ncbi.nlm.nih.gov/39253213/,English,Include,,Multimodal insights into granger causality connectivity: Integrating physiological signals and gated eye-tracking data for emotion recognition using convolutional neural network.,Include,,"This study introduces a groundbreaking method to enhance the accuracy and reliability of emotion recognition systems by combining electrocardiogram (ECG) with electroencephalogram (EEG) data, using an eye-tracking gated strategy. Initially, we propose a techniq",,0.95,0.25,cv_reported
pubmed:39253067,pubmed:39253067,PubMed,pubmed:39253067,Improved motor imagery training for subject's self-modulation in EEG-based brain-computer interface.,Yilu Xu;Lilin Jie;Wenjuan Jian;Wenlong Yi;Hua Yin;Yingqiong Peng,2024,10.1109/access.2019.2913154,"For the electroencephalogram- (EEG-) based motor imagery (MI) brain-computer interface (BCI) system, more attention has been paid to the advanced machine learning algorithms rather than the effective MI training protocols over past two decades. However, it is crucial to assist the subjects in modulating their active brains to fulfill the endogenous MI tasks during the calibration process, which will facilitate signal processing using various machine learning algorithms. Therefore, we propose a trial-feedback paradigm to improve MI training and introduce a non-feedback paradigm for comparison. Each paradigm corresponds to one session. Two paradigms are applied to the calibration runs of corresponding sessions. And their effectiveness is verified in the subsequent testing runs of respective sessions. Different from the non-feedback paradigm, the trial-feedback paradigm presents a topographic map and its qualitative evaluation in real time after each MI training trial, so the subjects can timely realize whether the current trial successfully induces the event-related desynchronization/event-related synchronization (ERD/ERS) phenomenon, and then they can adjust their brain rhythm in the next MI trial. Moreover, after each calibration run of the trial-feedback session, a feature distribution is visualized and quantified to show the subjects' abilities to distinguish different MI tasks and promote their self-modulation in the next calibration run. Additionally, if the subjects feel distracted during the training processes of the non-feedback and trial-feedback sessions, they can execute the blinking movement which will be captured by the electrooculogram (EOG) signals, and the corresponding MI training trial will be abandoned. Ten healthy participants sequentially performed the non-feedback and trial-feedback sessions on the different days. The experiment results showed that the trial-feedback session had better spatial filter visualization, more beneficiaries, higher average off-line and on-line classification accuracies than the non-feedback session, suggesting the trial-feedback paradigm's usefulness in subject's self-modulation and good ability to perform MI tasks.",https://pubmed.ncbi.nlm.nih.gov/39253067/,https://pubmed.ncbi.nlm.nih.gov/39253067/,English,Include,,Improved motor imagery training for subject's self-modulation in EEG-based brain-computer interface.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39252923,pubmed:39252923,PubMed,pubmed:39252923,Deep Brain Stimulation restores information processing in parkinsonian cortical networks.,Charlotte Piette;Sophie Ng Wing Tin;Astrid De Liège;Coralie Bloch-Queyrat;Bertrand Degos;Laurent Venance;Jonathan Touboul,2024,10.1101/2024.08.25.24310748,"Parkinson's disease (PD) is a neurodegenerative disorder associated with alterations of neural activity and information processing primarily in the basal ganglia and cerebral cortex. Deep brain stimulation (DBS) of the subthalamic nucleus (STN-DBS) is the most effective therapy when patients experience levodopa-induced motor complications. A growing body of evidence points towards a cortical effect of STN-DBS, restoring key electrophysiological markers, such as excessive beta band oscillations, commonly observed in PD. However, the mechanisms of STN-DBS remain elusive. Here, we aim to better characterize the cortical substrates underlying STN-DBS-induced improvement in motor symptoms. We recorded electroencephalograms (EEG) from PD patients and found that, although apparent EEG features were not different with or without therapy, EEG signals could more accurately predict limb movements under STN-DBS. To understand the origins of this enhanced information transmission under STN-DBS in the human EEG data, we investigated the information capacity and dynamics of a variety of computational models of cortical networks. The extent of improvement in decoding accuracy of complex naturalistic inputs under STN-DBS depended on the synaptic parameters of the network as well as its excitability and synchronization levels. Additionally, decoding accuracy could be optimized by adjusting STN-DBS parameters. Altogether, this work draws a comprehensive link between known alterations in cortical activity and the degradation of information processing capacity, as well as its restoration under DBS. These results also offer new perspectives for optimizing STN-DBS parameters based on clinically accessible measures of cortical information processing capacity.",https://pubmed.ncbi.nlm.nih.gov/39252923/,https://pubmed.ncbi.nlm.nih.gov/39252923/,English,Include,,Deep Brain Stimulation restores information processing in parkinsonian cortical networks.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39252680,pubmed:39252680,PubMed,pubmed:39252680,Efficient EEG Feature Learning Model Combining Random Convolutional Kernel with Wavelet Scattering for Seizure Detection.,Yasheng Liu;Yonghui Jiang;Jie Liu;Jie Li;Mingze Liu;Weiwei Nie;Qi Yuan,2024,10.1142/s0129065724500606,"Automatic seizure detection has significant value in epilepsy diagnosis and treatment. Although a variety of deep learning models have been proposed to automatically learn electroencephalography (EEG) features for seizure detection, the generalization performance and computational burden of such deep models remain the bottleneck of practical application. In this study, a novel lightweight model based on random convolutional kernel transform (ROCKET) is developed for EEG feature learning for seizure detection. Specifically, random convolutional kernels are embedded into the structure of a wavelet scattering network instead of original wavelet transform convolutions. Then the significant EEG features are selected from the scattering coefficients and convolutional outputs by analysis of variance (ANOVA) and minimum redundancy-maximum relevance (MRMR) methods. This model not only preserves the merits of the fast-training process from ROCKET, but also provides insight into seizure detection by retaining only the helpful channels. The extreme gradient boosting (XGboost) classifier was combined with this EEG feature learning model to build a comprehensive seizure detection system that achieved promising epoch-based results, with over 90% of both sensitivity and specificity on the scalp and intracranial EEG databases. The experimental comparisons showed that the proposed method outperformed other state-of-the-art methods for cross-patient and patient-specific seizure detection.",https://pubmed.ncbi.nlm.nih.gov/39252680/,https://pubmed.ncbi.nlm.nih.gov/39252680/,English,Include,,Efficient EEG Feature Learning Model Combining Random Convolutional Kernel with Wavelet Scattering for Seizure Detection.,Include,,"ation performance and computational burden of such deep models remain the bottleneck of practical application. In this study, a novel lightweight model based on random convolutional kernel transform (ROCKET) is developed for EEG feature learning for seizure detection. Specifically, random convolutional kernels are embedded into the structure of a wavelet scattering network instead of original wave",,0.95,0.6,
pubmed:39251722,pubmed:39251722,PubMed,pubmed:39251722,The neural basis of attentional selection in goal-directed memory retrieval.,Melinda Sabo;Edmund Wascher;Daniel Schneider,2024,10.3389/fpsyg.2013.00863,"Goal-directed memory reactivation involves retrieving the most relevant information for the current behavioral goal. Previous research has linked this process to activations in the fronto-parietal network, but the underlying neurocognitive mechanism remains poorly understood. The current electroencephalogram (EEG) study explores attentional selection as a possible mechanism supporting goal-directed retrieval. We designed a long-term memory experiment containing three phases. First, participants learned associations between objects and two screen locations. In a following phase, we changed the relevance of some locations (selective cue condition) to simulate goal-directed retrieval. We also introduced a control condition, in which the original associations remained unchanged (neutral cue condition). Behavior performance measured during the final retrieval phase revealed faster and more confident responses in the selective vs. neutral condition. At the EEG level, we found significant differences in decoding accuracy, with above-chance effects in the selective cue condition but not in the neutral cue condition. Additionally, we observed a stronger posterior contralateral negativity and lateralized alpha power in the selective cue condition. Overall, these results suggest that attentional selection enhances task-relevant information accessibility, emphasizing its role in goal-directed memory retrieval.",https://pubmed.ncbi.nlm.nih.gov/39251722/,https://pubmed.ncbi.nlm.nih.gov/39251722/,English,Include,,The neural basis of attentional selection in goal-directed memory retrieval.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39251633,pubmed:39251633,PubMed,pubmed:39251633,Electroencephalography-based endogenous phenotype of diagnostic transition from major depressive disorder to bipolar disorder.,Kuk-In Jang;Euijin Kim;Ho Sung Lee;Hyeon-Ah Lee;Jae Hyun Han;Sungkean Kim;Ji Sun Kim,2024,10.1016/j.jns.2020.117077,"The neuropathology of mood disorders, including the diagnostic transition from major depressive disorder (MDD) to bipolar disorder (BD), is poorly understood. This study investigated resting-state electroencephalography (EEG) activity in patients with MDD and those whose diagnosis changed from MDD to BD. Among sixty-eight enrolled patients with MDD, the diagnosis of 17 patients converted to BD during the study period. We applied machine learning techniques to differentiate the two groups using sensor- and source-level EEG features. At the sensor level, patients with BD showed higher theta band power at the AF3 channel and low-alpha band power at the FC5 channel compared to patients with MDD. At the source level, patients with BD showed higher theta band activity in the right anterior cingulate and low-alpha band activity in the left parahippocampal gyrus. These four EEG features were selected for discriminating between BD and MDD with the best classification performance showing an accuracy of 80.88%, a sensitivity of 76.47%, and a specificity of 82.35%. Our findings revealed distinct theta and low-alpha band activities in patients with BD and MDD. These differences could potentially serve as candidate neuromarkers for the diagnosis and diagnostic transition between the two distinct mood disorders.",https://pubmed.ncbi.nlm.nih.gov/39251633/,https://pubmed.ncbi.nlm.nih.gov/39251633/,English,Include,,Electroencephalography-based endogenous phenotype of diagnostic transition from major depressive disorder to bipolar disorder.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39251228,pubmed:39251228,PubMed,pubmed:39251228,Deep Learning-Based Artificial Intelligence Can Differentiate Treatment-Resistant and Responsive Depression Cases with High Accuracy.,Sinem Zeynep Metin;Çağlar Uyulan;Shams Farhad;Türker Tekin Ergüzel;Ömer Türk;Barış Metin;Önder Çerezci;Nevzat Tarhan,2025,10.1177/15500594241273181,,,https://pubmed.ncbi.nlm.nih.gov/39251228/,English,Exclude,Outside date range,Deep Learning-Based Artificial Intelligence Can Differentiate Treatment-Resistant and Responsive Depression Cases with High Accuracy.,,,,,0.95,0.6,
pubmed:39250958,pubmed:39250958,PubMed,pubmed:39250958,I see artifacts: ICA-based EEG artifact removal does not improve deep network decoding across three BCI tasks.,Taeho Kang;Yiyu Chen;Christian Wallraven,2024,10.1088/1741-2552/ad788e,,,https://pubmed.ncbi.nlm.nih.gov/39250958/,English,Exclude,Not classification-focused,I see artifacts: ICA-based EEG artifact removal does not improve deep network decoding across three BCI tasks.,,,,,0.85,0.6,
pubmed:39250956,pubmed:39250956,PubMed,pubmed:39250956,Integrating spatial and temporal features for enhanced artifact removal in multi-channel EEG recordings.,Jin Yin;Aiping Liu;Lanlan Wang;Ruobing Qian;Xun Chen,2024,10.1088/1741-2552/ad788d,,,https://pubmed.ncbi.nlm.nih.gov/39250956/,English,Exclude,Not classification-focused,Integrating spatial and temporal features for enhanced artifact removal in multi-channel EEG recordings.,,,,,0.85,0.6,
pubmed:39250934,pubmed:39250934,PubMed,pubmed:39250934,OxcarNet: sinc convolutional network with temporal and channel attention for prediction of oxcarbazepine monotherapy responses in patients with newly diagnosed epilepsy.,Runkai Zhang;Rong Rong;Yun Xu;Haixian Wang;Xiaoyun Wang,2024,10.1088/1741-2552/ad788c,,,https://pubmed.ncbi.nlm.nih.gov/39250934/,English,Exclude,Not EEG-BCI focused,OxcarNet: sinc convolutional network with temporal and channel attention for prediction of oxcarbazepine monotherapy responses in patients with newly diagnosed epilepsy.,,,,,0.9,0.6,
pubmed:39250352,pubmed:39250352,PubMed,pubmed:39250352,Automatic Feature Selection for Sensorimotor Rhythms Brain-Computer Interface Fusing Expert and Data-Driven Knowledge.,Mushfika Sultana;Serafeim Perdikis,2024,10.1109/tnsre.2024.3456591,"Early brain-computer interface (BCI) systems were mainly based on prior neurophysiological knowledge coupled with feedback training, while state-of-the-art interfaces rely on data-driven, machine learning (ML)-oriented methods. Despite the advances in BCI that ML can be credited with, the performance of BCI solutions is still not up to the mark, posing a major barrier to the widespread use of this technology. This paper proposes a novel, automatic feature selection method for BCI able to leverage both data-dependent and expert knowledge to suppress noisy features and highlight the most relevant ones thanks to a fuzzy logic (FL) system. Our approach exploits the capability of FL to increase the reliability of decision-making by fusing heterogeneous information channels while maintaining transparency and simplicity. We show that our method leads to significant improvement in classification accuracy, feature stability and class bias when applied to large motor imagery or attempt datasets including end-users with motor disabilities. We postulate that combining data-driven methods with knowledge derived from neuroscience literature through FL can enhance the performance, explainability, and learnability of BCIs.",https://pubmed.ncbi.nlm.nih.gov/39250352/,https://pubmed.ncbi.nlm.nih.gov/39250352/,English,Include,,Automatic Feature Selection for Sensorimotor Rhythms Brain-Computer Interface Fusing Expert and Data-Driven Knowledge.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39248654,pubmed:39248654,PubMed,pubmed:39248654,Brain-Controlled Augmented Hearing for Spatially Moving Conversations in Multi-Talker Environments.,Vishal Choudhari;Cong Han;Stephan Bickel;Ashesh D Mehta;Catherine Schevon;Guy M McKhann;Nima Mesgarani,2024,10.1002/advs.202401379,"Focusing on a specific conversation amidst multiple interfering talkers is challenging, especially for those with hearing loss. Brain-controlled assistive hearing devices aim to alleviate this problem by enhancing the attended speech based on the listener's neural signals using auditory attention decoding (AAD). Departing from conventional AAD studies that relied on oversimplified scenarios with stationary talkers, a realistic AAD task that involves multiple talkers taking turns as they continuously move in space in background noise is presented. Invasive electroencephalography (iEEG) data are collected from three neurosurgical patients as they focused on one of the two moving conversations. An enhanced brain-controlled assistive hearing system that combines AAD and a binaural speaker-independent speech separation model is presented. The separation model unmixes talkers while preserving their spatial location and provides talker trajectories to the neural decoder to improve AAD accuracy. Subjective and objective evaluations show that the proposed system enhances speech intelligibility and facilitates conversation tracking while maintaining spatial cues and voice quality in challenging acoustic environments. This research demonstrates the potential of this approach in real-world scenarios and marks a significant step toward developing assistive hearing technologies that adapt to the intricate dynamics of everyday auditory experiences.",https://pubmed.ncbi.nlm.nih.gov/39248654/,https://pubmed.ncbi.nlm.nih.gov/39248654/,English,Include,,Brain-Controlled Augmented Hearing for Spatially Moving Conversations in Multi-Talker Environments.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39248624,pubmed:39248624,PubMed,pubmed:39248624,Design and application of pneumatic rehabilitation glove system based on brain-computer interface.,Cheng Chen;Yize Song;Duoyou Chen;Jiahua Zhu;Huansheng Ning;Ruoxiu Xiao,2024,10.1063/5.0225972,"Stroke has been the second leading cause of death and disability worldwide. With the innovation of therapeutic schedules, its death rate has decreased significantly but still guides chronic movement disorders. Due to the lack of independent activities and minimum exercise standards, the traditional rehabilitation means of occupational therapy and constraint-induced movement therapy pose challenges in stroke patients with severe impairments. Therefore, specific and effective rehabilitation methods seek innovation. To address the overlooked limitation, we design a pneumatic rehabilitation glove system. Specially, we developed a pneumatic glove, which utilizes ElectroEncephaloGram (EEG) acquisition to gain the EEG signals. A proposed EEGTran model is inserted into the system to distinguish the specific motor imagination behavior, thus, the glove can perform specific activities according to the patient's imagination, facilitating the patients with severe movement disorders and promoting the rehabilitation technology. The experimental results show that the proposed EEGTrans reached an accuracy of 87.3% and outperformed that of competitors. It demonstrates that our pneumatic rehabilitation glove system contributes to the rehabilitation training of stroke patients.",https://pubmed.ncbi.nlm.nih.gov/39248624/,https://pubmed.ncbi.nlm.nih.gov/39248624/,English,Include,,Design and application of pneumatic rehabilitation glove system based on brain-computer interface.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39247844,pubmed:39247844,PubMed,pubmed:39247844,Simultaneous EEG-fNIRS Data Classification Through Selective Channel Representation and Spectrogram Imaging.,Chayut Bunterngchit;Jiaxing Wang;Zeng-Guang Hou,2024,10.1109/jtehm.2024.3448457,"The integration of electroencephalography (EEG) and functional near-infrared spectroscopy (fNIRS) can facilitate the advancement of brain-computer interfaces (BCIs). However, existing research in this domain has grappled with the challenge of the efficient selection of features, resulting in the underutilization of the temporal richness of EEG and the spatial specificity of fNIRS data.To effectively address this challenge, this study proposed a deep learning architecture called the multimodal DenseNet fusion (MDNF) model that was trained on two-dimensional (2D) EEG data images, leveraging advanced feature extraction techniques. The model transformed EEG data into 2D images using a short-time Fourier transform, applied transfer learning to extract discriminative features, and consequently integrated them with fNIRS-derived spectral entropy features. This approach aimed to bridge existing gaps in EEG-fNIRS-based BCI research by enhancing classification accuracy and versatility across various cognitive and motor imagery tasks.Experimental results on two public datasets demonstrated the superiority of our model over existing state-of-the-art methods.Thus, the high accuracy and precise feature utilization of the MDNF model demonstrates the potential in clinical applications for neurodiagnostics and rehabilitation, thereby paving the method for patient-specific therapeutic strategies.",https://pubmed.ncbi.nlm.nih.gov/39247844/,https://pubmed.ncbi.nlm.nih.gov/39247844/,English,Include,,Simultaneous EEG-fNIRS Data Classification Through Selective Channel Representation and Spectrogram Imaging.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39246298,pubmed:39246298,PubMed,pubmed:39246298,Cross-domain prediction approach of human lower limb voluntary movement intention for exoskeleton robot based on EEG signals.,Runlin Dong;Xiaodong Zhang;Hanzhe Li;Zhufeng Lu;Cunxin Li;Aibin Zhu,2024,10.3389/fnbot.2021.642607,"Exoskeleton robot control should ideally be based on human voluntary movement intention. The readiness potential (RP) component of the motion-related cortical potential is observed before movement in the electroencephalogram and can be used for intention prediction. However, its single-trial features are weak and highly variable, and existing methods cannot achieve high cross-temporal and cross-subject accuracies in practical online applications. Therefore, this work aimed to combine a deep convolutional neural network (CNN) framework with a transfer learning (TL) strategy to predict the lower limb voluntary movement intention, thereby improving the accuracy while enhancing the model generalization capability; this would also provide sufficient processing time for the response of the exoskeleton robotic system and help realize robot control based on the intention of the human body. The signal characteristics of the RP for lower limb movement were analyzed, and a parameter TL strategy based on CNN was proposed to predict the intention of voluntary lower limb movements. We recruited 10 subjects for offline and online experiments. Multivariate empirical-mode decomposition was used to remove the artifacts, and the moment of onset of voluntary movement was labeled using lower limb electromyography signals during network training. The RP features can be observed from multiple data overlays before the onset of voluntary lower limb movements, and these features have long latency periods. The offline experimental results showed that the average movement intention prediction accuracy was 95.23% ± 1.25% for the right leg and 91.21% ± 1.48% for the left leg, which showed good cross-temporal and cross-subject generalization while greatly reducing the training time. Online movement intention prediction can predict results about 483.9 ± 11.9 ms before movement onset with an average accuracy of 82.75%. The proposed method has a higher prediction accuracy with a lower training time, has good generalization performance for cross-temporal and cross-subject aspects, and is well-prioritized in terms of the temporal responses; these features are expected to lay the foundation for further investigations on exoskeleton robot control.",https://pubmed.ncbi.nlm.nih.gov/39246298/,https://pubmed.ncbi.nlm.nih.gov/39246298/,English,Include,,Cross-domain prediction approach of human lower limb voluntary movement intention for exoskeleton robot based on EEG signals.,Include,,"re, this work aimed to combine a deep convolutional neural network (CNN) framework with a transfer learning (TL) strategy to predict the lower limb voluntary movement intention, thereby improving the accuracy while enhancing the model generalization capability; this would also provide sufficient processing time for the response of the exoskeleton robotic system and help realize robot control based",,0.95,0.6,
pubmed:39245330,pubmed:39245330,PubMed,pubmed:39245330,Validating a novel paradigm for simultaneously assessing mismatch response and frequency-following response to speech sounds.,Tzu-Han Zoe Cheng;Tian Christina Zhao,2024,10.1016/j.neuroimage.2022.119242,"Speech sounds are processed in the human brain through intricate and interconnected cortical and subcortical structures. Two neural signatures, one largely from cortical sources (mismatch response, MMR) and one largely from subcortical sources (frequency-following response, FFR) are critical for assessing speech processing as they both show sensitivity to high-level linguistic information. However, there are distinct prerequisites for recording MMR and FFR, making them difficult to acquire simultaneously NEW METHOD: Using a new paradigm, our study aims to concurrently capture both signals and test them against the following criteria: (1) replicating the effect that the MMR to a native speech contrast significantly differs from the MMR to a nonnative speech contrast, and (2) demonstrating that FFRs to three speech sounds can be reliably differentiated. Using EEG from 18 adults, we observed a decoding accuracy of 72.2 % between the MMR to native vs. nonnative speech contrasts. A significantly larger native MMR was shown in the expected time window. Similarly, a significant decoding accuracy of 79.6 % was found for FFR. A high stimulus-to-response cross-correlation with a 9 ms lag suggested that FFR closely tracks speech sounds. These findings demonstrate that our paradigm reliably captures both MMR and FFR concurrently, replicating and extending past research with much fewer trials (MMR: 50 trials; FFR: 200 trials) and shorter experiment time (12 minutes). This study paves the way to understanding cortical-subcortical interactions for speech and language processing, with the ultimate goal of developing an assessment tool specific to early development.",https://pubmed.ncbi.nlm.nih.gov/39245330/,https://pubmed.ncbi.nlm.nih.gov/39245330/,English,Include,,Validating a novel paradigm for simultaneously assessing mismatch response and frequency-following response to speech sounds.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39244950,pubmed:39244950,PubMed,pubmed:39244950,Seizure outcome in drug-resistant epilepsy in the setting of polymicrogyria.,Thandar Aung;Jin Bo;William Bingaman;Imad Najm;Andreas Alexopoulos;Juan C Bulacio,2024,10.1016/j.seizure.2024.08.016,"We aimed to analyze seizure outcomes and define ictal onset with intracranial electroencephalography (ICEEG) in patients with polymicrogyria (PMG)-related drug-resistant epilepsy (DRE), considering surrounding cortex and extent of surgical resection. Retrospective study of PMG-diagnosed patients (2001 to June 2018) at a single epilepsy center was performed. Primary outcome was complete seizure freedom (SF), based on Engel classification with follow-up of ≥ 1 year. Univariate analyses identified predictive clinical variables, later integrated into multivariate Cox proportional hazards models. Thirty-five patients with PMG-related DRE (19 adults/16 pediatric: 20 unilateral/15 bilateral) were studied. In surgical group (n = 23), 52 % achieved SF (mean follow-up:47 months), whereas none in non-resective treatment group (n = 12) attained SF (mean follow-up:39.3 months) (p = 0.002). In surgical group, there were no significant differences in SF, based on the laterality of the PMG [uni or bilateral,p = 0.35], involvement of perisylvian region(p = 0.714), and extent of the PMG resection [total vs. partial,p = 0.159]. Patients with ictal ICEEG onset in both PMG and non-PMG cortices, and those limited to non- PMG cortices had a greater chance of achieving SF compared to those limited to the PMG cortices. Resective surgery guided by ICEEG for defining the epileptogenic zone (EZ), in DRE patients with PMG, leads to favorable seizure outcomes. ICEEG-guided focal surgical resection(s) may lead to SF in patients with bilateral or extensive unilateral PMG. ICEEG aids in EZ localization within and/or outside the MRI-identified PMG. Complete removal of PMG identified on MRI does not guarantee SF. Hence, developing preimplantation hypotheses based on epileptogenic networks evaluation during presurgical assessment is crucial in this patient population.",https://pubmed.ncbi.nlm.nih.gov/39244950/,https://pubmed.ncbi.nlm.nih.gov/39244950/,English,Include,,Seizure outcome in drug-resistant epilepsy in the setting of polymicrogyria.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39244827,pubmed:39244827,PubMed,pubmed:39244827,"A novel nomogram for predicting the prognosis of critically ill patients with EEG patterns exhibiting stimulus-induced rhythmic, periodic, or ictal discharges.",Yan Wang;Jiajia Yang;Wei Wang;Xin Zhou;Xuefeng Wang;Jing Luo;Feng Li,2024,10.1016/j.neucli.2024.103010,"To explore the factors associated with poor prognosis in critically ill patients with Electroencephalogram (EEG) patterns exhibiting stimulus-induced rhythmic, periodic, or ictal discharges (SIRPIDs), and to construct a prognostic prediction model. This study included a total of 53 critically ill patients with EEG patterns exhibiting SIRPIDs who were admitted to the First Affiliated Hospital of Chongqing Medical University from May 2023 to March 2024. Patients were divided into two groups based on their Modified Rankin Scale (mRS) scores at discharge: good prognosis group (0-3 points) and poor prognosis group (4-6 points). Retrospective analyses were performed on the clinical and EEG parameters of patients in both groups. Logistic regression analysis was applied to identify the risk factors related to poor prognosis in critically ill patients with EEG patterns exhibiting SIRPIDs; a risk prediction model for poor prognosis was constructed, along with an individualized predictive nomogram model, and the predictive performance and consistency of the model were evaluated. Multivariate logistic regression analysis revealed that APACHE II score (OR=1.217, 95 %CI=1.030∼1.438), slow frequency bands or no obvious brain electrical activity (OR=8.720, 95 %CI=1.220∼62.313), and no sleep waveforms (OR=9.813, 95 %CI=1.371∼70.223) were independent risk factors for poor prognosis in patients. A regression model established based on multivariate logistic regression analysis had an area under the curve of 0.902. The model's accuracy was 90.60 %, with a sensitivity of 92.86 % and a specificity of 89.70 %. The nomogram model, after internal validation, showed a concordance index of 0.904. A high APACHE II score, EEG patterns with slow frequency bands or no obvious brain electrical activity, and no sleep waveforms were independent risk factors for poor prognosis in patients with SIRPIDs. The nomogram model constructed based on these factors had a favorably high level of accuracy in predicting the risk of poor prognosis and held certain reference and application value for clinical neurofunctional assessment and prognostic determination.",https://pubmed.ncbi.nlm.nih.gov/39244827/,https://pubmed.ncbi.nlm.nih.gov/39244827/,English,Include,,"A novel nomogram for predicting the prognosis of critically ill patients with EEG patterns exhibiting stimulus-induced rhythmic, periodic, or ictal discharges.",Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39243591,pubmed:39243591,PubMed,pubmed:39243591,SleepGCN: A transition rule learning model based on Graph Convolutional Network for sleep staging.,Xuhui Wang;Yuanyuan Zhu,2024,10.1016/j.cmpb.2024.108405,"Automatic sleep staging is essential for assessing and diagnosing sleep disorders, serving millions of people who suffer from them. Numerous sleep staging models have been proposed recently, but most of them have not fully explored the sleep transition rules that are essential for sleep experts to identify sleep stages. Therefore, one objective of this paper is to develop an automatic sleep staging model to capture the transition rules between sleep stages. In this paper, we propose a novel sleep staging model named SleepGCN. It utilizes the deep features of electroencephalogram (EEG) and electrooculogram (EOG) signals extracted by the sleep representation learning (SRL) module, in conjunction with the transition rules learned by the sleep transition rule learning (STRL) module to identify sleep stages. Specifically, the SRL module utilizes the residual network (ResNet) and Long Short Term Memory (LSTM) structure to capture the deep time-invariant features and temporal information of each sleep stage from the two-channel EEG-EOG, and then applies a feature enhancement block to obtain the refined features. The STRL module employs a Graph Convolutional Network (GCN) and a transition rule matrix to capture transition rules between sleep stages based on the sequence labels of the input signals. We evaluate SleepGCN on five public datasets: SleepEDF-20, SleepEDF-78, SHHS, DOD-H and DOD-O. Overall, SleepGCN achieves an accuracy of 89.70%, 87.70%, 86.16%, 82.07%, and 81.20%, alongside a macro-average F1-score of 85.20%, 82.70%, 77.69%, 72.44%, and 72.93% across these datasets, respectively. The results achieved by our proposed model are much better than those of all other compared models. The ablation study validates the contributions of the SRL and STRL modules proposed in SleepGCN to the sleep staging tasks. Additionally, it shows that the sleep staging model using two-channel EEG-EOG outperforms the model using single-channel EEG or EOG. Overall, SleepGCN is an effective solution for sleep staging using two-channel EEG-EOG.",https://pubmed.ncbi.nlm.nih.gov/39243591/,https://pubmed.ncbi.nlm.nih.gov/39243591/,English,Include,,SleepGCN: A transition rule learning model based on Graph Convolutional Network for sleep staging.,Include,,"es between sleep stages based on the sequence labels of the input signals. We evaluate SleepGCN on five public datasets: SleepEDF-20, SleepEDF-78, SHHS, DOD-H and DOD-O. Overall, SleepGCN achieves an accuracy of 89.70%, 87.70%, 86.16%, 82.07%, and 81.20%, alongside a macro-average F1-score of 85.20%, 82.70%, 77.69%, 72.44%, and 72.93% across these datasets, respectively. The results achieved by ou",,0.95,0.6,
pubmed:39241437,pubmed:39241437,PubMed,pubmed:39241437,Improving classification performance of motor imagery BCI through EEG data augmentation with conditional generative adversarial networks.,Sanghyun Choo;Hoonseok Park;Jae-Yoon Jung;Kevin Flores;Chang S Nam,2024,10.1016/j.neunet.2024.106665,"In brain-computer interface (BCI), building accurate electroencephalogram (EEG) classifiers for specific mental tasks is critical for BCI performance. The classifiers are developed by machine learning (ML) and deep learning (DL) techniques, requiring a large dataset for training to build reliable and accurate models. However, collecting large enough EEG datasets is difficult due to intra-/inter-subject variabilities and experimental costs. This leads to the data scarcity problem, which causes overfitting issues to training samples, resulting in reducing generalization performance. To solve the EEG data scarcity problem and improve the performance of the EEG classifiers, we propose a novel EEG data augmentation (DA) framework using conditional generative adversarial networks (cGANs). An experimental study is implemented with two public EEG datasets, including motor imagery (MI) tasks (BCI competition IV IIa and III IVa), to validate the effectiveness of the proposed EEG DA method for the EEG classifiers. To evaluate the proposed cGAN-based DA method, we tested eight EEG classifiers for the experiment, including traditional MLs and state-of-the-art DLs with three existing EEG DA methods. Experimental results showed that most DA methods with proper DA proportion in the training dataset had higher classification performances than without DA. Moreover, applying the proposed DA method showed superior classification performance improvement than the other DA methods. This shows that the proposed method is a promising EEG DA method for enhancing the performances of the EEG classifiers in MI-based BCIs.",https://pubmed.ncbi.nlm.nih.gov/39241437/,https://pubmed.ncbi.nlm.nih.gov/39241437/,English,Include,,Improving classification performance of motor imagery BCI through EEG data augmentation with conditional generative adversarial networks.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,overfit_terms_found
pubmed:39240267,pubmed:39240267,PubMed,pubmed:39240267,Novel cyclic homogeneous oscillation detection method for high accuracy and specific characterization of neural dynamics.,Hohyun Cho;Markus Adamek;Jon T Willie;Peter Brunner,2024,10.1016/j.cub.2018.07.009,Determining the presence and frequency of neural oscillations is essential to understanding dynamic brain function. Traditional methods that detect peaks over 1/,,https://pubmed.ncbi.nlm.nih.gov/39240267/,English,Exclude,Not EEG-BCI focused,Novel cyclic homogeneous oscillation detection method for high accuracy and specific characterization of neural dynamics.,,,,,0.9,0.6,
pubmed:39239460,pubmed:39239460,PubMed,pubmed:39239460,"Design of an injectable, self-adhesive, and highly stable hydrogel electrode for sleep recording.",Ju-Chun Hsieh;Weilong He;Dhivya Venkatraghavan;Victoria B Koptelova;Zoya J Ahmad;Ilya Pyatnitskiy;Wenliang Wang;Jinmo Jeong;Kevin Kai Wing Tang;Cody Harmeier;Conrad Li;Manini Rana;Sruti Iyer;Eesha Nayak;Hong Ding;Pradeep Modur;Vincent Mysliwiec;David M Schnyer;Benjamin Baird;Huiliang Wang,2024,10.1016/j.device.2023.100182,"High-quality and continuous electroencephalogram (EEG) monitoring is desirable for sleep research, sleep monitoring, and the evaluation and treatment of sleep disorders. Existing continuous EEG monitoring technologies suffer from fragile connections, long-term stability, and complex preparation for electrodes under real-life conditions. Here, we report an injectable and spontaneously cross-linked hydrogel electrode for long-term EEG applications. Specifically, our electrodes have a long-term low impedance on hairy scalp regions of 17.53 kΩ for more than 8 h of recording, high adhesiveness on the skin of 0.92 N cm",,https://pubmed.ncbi.nlm.nih.gov/39239460/,English,Exclude,Not classification-focused,"Design of an injectable, self-adhesive, and highly stable hydrogel electrode for sleep recording.",,,,,0.85,0.6,
pubmed:39237764,pubmed:39237764,PubMed,pubmed:39237764,Robot-assisted insular stereoelectroencephalography in pediatric drug-resistant epilepsy: accuracy and diagnostic value.,A González-Crespo;F Brugada-Bellsolà;S Candela-Cantó;J Aparicio Calvo;J Rumià Arboix;J Hinojosa Bernal,2024,10.3171/2016.4.peds15636,"Insular epilepsy is a well-known cause of drug-resistant epilepsy (DRE) in the pediatric population. It can be a source of surgical epilepsy treatment failures when not ruled out pre-operatively. Non-invasive methods often provide limited information about its existence, being the invasive methods necessary to diagnose it in the vast majority of cases. The most used is stereoelectroencephalography (SEEG). We report a series of DRE pediatric patients in which insular SEEG was performed to rule out insular epilepsy. We performed a retrospective review of pediatric DRE patients operated on SEEG including insular electrodes between April 2016 and September 2022. We described the different trajectories used (orthogonal or oblique) and surgical techniques. After implantation, we assessed electrodes' precision using three measures: entry point location error (EPLE), target point location error (TPLE), and target deviation (TD). We also reported complications that occurred with this technique as well as the diagnostic information provided. Overall, 32 DRE patients were operated on SEEG including insular electrodes. Four hundred one electrodes were implanted, 148 (39.91%) of whom were directed to the insula. One hundred twelve followed an orthogonal trajectory, and 36 were oblique. The mean EPLE was 1.45 mm, TPLE was 1.88 mm and TD was 0.71 mm. Three patients suffered from frontal hematoma, two of them diagnosed on post-operative MRI and one who required surgery, with no sequelae. One patient suffered from meningitis treated with antibiotics with no permanent sequelae. Nine patients (28.13%) had the insula included in the epileptogenic zone. Insular epilepsy has to be ruled out in DRE patients when little suspicion is obtained after non-invasive testing. This is especially important in the pediatric population, in which seizure semiology is more difficult to characterize and failures to control epilepsy have devastating consequences in neurocognitive development and scholarship. Given its relative low rate of relevant complications and potential benefits, we should consider widening the inclusion criteria for insular SEEG monitoring.",,https://pubmed.ncbi.nlm.nih.gov/39237764/,English,Exclude,Review/survey papers,Robot-assisted insular stereoelectroencephalography in pediatric drug-resistant epilepsy: accuracy and diagnostic value.,,,,,0.95,0.6,
pubmed:39237038,pubmed:39237038,PubMed,pubmed:39237038,Cross-subject emotion recognition in brain-computer interface based on frequency band attention graph convolutional adversarial neural networks.,Shinan Chen;Yuchen Wang;Xuefen Lin;Xiaoyong Sun;Weihua Li;Weifeng Ma,2024,10.1016/j.jneumeth.2024.110276,"Emotion is an important area in neuroscience. Cross-subject emotion recognition based on electroencephalogram (EEG) data is challenging due to physiological differences between subjects. Domain gap, which refers to the different distributions of EEG data at different subjects, has attracted great attention for cross-subject emotion recognition. This study focuses on narrowing the domain gap between subjects through the emotional frequency bands and the relationship information between EEG channels. Emotional frequency band features represent the energy distribution of EEG data in different frequency ranges, while relationship information between EEG channels provides spatial distribution information about EEG data. To achieve this, this paper proposes a model called the Frequency Band Attention Graph convolutional Adversarial neural Network (FBAGAN). This model includes three components: a feature extractor, a classifier, and a discriminator. The feature extractor consists of a layer with a frequency band attention mechanism and a graph convolutional neural network. The mechanism effectively extracts frequency band information by assigning weights and Graph Convolutional Networks can extract relationship information between EEG channels by modeling the graph structure. The discriminator then helps minimize the gap in the frequency information and relationship information between the source and target domains, improving the model's ability to generalize. The FBAGAN model is extensively tested on the SEED, SEED-IV, and DEAP datasets. The accuracy and standard deviation scores are 88.17% and 4.88, respectively, on the SEED dataset, and 77.35% and 3.72 on the SEED-IV dataset. On the DEAP dataset, the model achieves 69.64% for Arousal and 65.18% for Valence. These results outperform most existing models. The experiments indicate that FBAGAN effectively addresses the challenges of transferring EEG channel domain and frequency band domain, leading to improved performance.",https://pubmed.ncbi.nlm.nih.gov/39237038/,https://pubmed.ncbi.nlm.nih.gov/39237038/,English,Include,,Cross-subject emotion recognition in brain-computer interface based on frequency band attention graph convolutional adversarial neural networks.,Include,,"on and relationship information between the source and target domains, improving the model's ability to generalize. The FBAGAN model is extensively tested on the SEED, SEED-IV, and DEAP datasets. The accuracy and standard deviation scores are 88.17% and 4.88, respectively, on the SEED dataset, and 77.35% and 3.72 on the SEED-IV dataset. On the DEAP dataset, the model achieves 69.64% for Arousal an",,0.95,0.6,
pubmed:39236887,pubmed:39236887,PubMed,pubmed:39236887,Social anxiety prediction based on ERP features: A deep learning approach.,Xiaodong Tian;Lingkai Zhu;Mingxian Zhang;Songling Wang;Yi Lu;Xiaolei Xu;Weikuan Jia;Yuanjie Zheng;Sutao Song,2024,10.1016/j.jad.2024.09.006,"Social Anxiety Disorder is traditionally diagnosed using subjective scales that may lack accuracy. Recently, EEG technology has gained importance for anxiety detection due to its ability to capture stable and objective neurophysiological activities. However, existing methods mainly focus on extracting EEG features during resting states, with limited use of psychologically features like Event-Related Potential (ERP) in task-related states for anxiety detection in deep learning frameworks. We collected EEG data from 63 participants exposed to four facial expressions and extracted task-relevant features. Using the EEGNet model, we predicted social anxiety and evaluated its performance using metrics such as accuracy, F1 score, sensitivity, and specificity. We compared EEGNet's performance with Deep Convolutional Neural Network (DeepConvNet), ShallowConvNet, Bi-directional Long Short-Term Memory (BiLSTM), and SVM. To assess the generalizability of the results, we carried out the same procedure on our prior dataset. EEGNet outperformed other models, achieving 99.16 % accuracy with Late Positive Potential (LPP). ERP components yielded higher accuracy than time-domain and frequency-domain features for social anxiety recognition. Accuracy was better for neutral and negative facial stimuli. Consistency across two datasets indicates stability of findings. Due to limited publicly available task-state datasets, only our own were used. Future studies could assess generalizability on larger datasets from different sources. We conducted the first test of ERP features in anxiety recognition tasks. Results show ERP features have greater potential in social anxiety recognition, with LPP exhibiting high stability and accuracy. Outcomes indicate recognizing social anxiety with negative or neutral facial stimuli is more useful.",https://pubmed.ncbi.nlm.nih.gov/39236887/,https://pubmed.ncbi.nlm.nih.gov/39236887/,English,Include,,Social anxiety prediction based on ERP features: A deep learning approach.,Include,,"Social Anxiety Disorder is traditionally diagnosed using subjective scales that may lack accuracy. Recently, EEG technology has gained importance for anxiety detection due to its ability to capture stable and objective neurophysiological activities. However, existing methods mainly focus ",,0.95,0.8,small_sample_mentioned
pubmed:39236511,pubmed:39236511,PubMed,pubmed:39236511,Resting-state EEG predicts cognitive decline in a neuropathologically diagnosed longitudinal community autopsied cohort.,Alexander Choi;Nan Zhang;Charles H Adler;Thomas G Beach;Holly A Shill;Erika Driver-Dunckley;Shyamal Mehta;Christine Belden;Alireza Atri;Marwan N Sabbagh;John N Caviness,2024,10.1038/s41598-018-22984-5,"To assess correlative strengths of quantitative electroencephalography (qEEG) and visual rating scale EEG features on cognitive outcomes in only autopsied cases from the Arizona Study of Neurodegenerative Disorders (AZSAND). We hypothesized that autopsy proven Parkinson Disease will show distinct EEG features from Alzheimer's Disease prior to dementia (mild cognitive impairment). Cognitive decline is debilitating across neurodegenerative diseases. Resting-state EEG analysis, including spectral power across frequency bins (qEEG), has shown significant associations with neurodegenerative disease classification and cognitive status, with autopsy confirmed diagnosis relatively lacking. Biannual EEG was analyzed from autopsied cases in AZSAND who had at least one rsEEG (>1 min eyes closed±eyes open). Analysis included global relative spectral power and a previously described visual rating scale (VRS). Linear mixed regression was performed for neuropsychological assessment and testing within 2 years of death (n = 236, 594 EEG exams) in a mixed linear regression model. The cohort included cases with final clinicopathologic diagnoses of Parkinson's disease (n = 73), Alzheimer disease (n = 65), and tauopathy not otherwise specified (n = 56). A VRS score of 3 diffuse or frequent generalized slowing) over the study duration was associated with an increase in consensus diagnosis cognitive worsening at 4.9 (3.1) years (HR 2.02, CI 1.05-3.87). Increases in global theta power% and VRS were the most consistently associated with large regression coefficients inversely with cognitive performance measures. Resting-state EEG analysis was meaningfully related to cognitive performance measures in a community-based autopsy cohort. EEG deserves further study and use as a cognitive biomarker.",https://pubmed.ncbi.nlm.nih.gov/39236511/,https://pubmed.ncbi.nlm.nih.gov/39236511/,English,Include,,Resting-state EEG predicts cognitive decline in a neuropathologically diagnosed longitudinal community autopsied cohort.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39236133,pubmed:39236133,PubMed,pubmed:39236133,Decoding Multi-Class Motor Imagery From Unilateral Limbs Using EEG Signals.,Fenqi Rong;Banghua Yang;Cuntai Guan,2024,10.1109/tnsre.2024.3454088,"The EEG is a widely utilized neural signal source, particularly in motor imagery-based brain-computer interface (MI-BCI), offering distinct advantages in applications like stroke rehabilitation. Current research predominantly concentrates on the bilateral limbs paradigm and decoding, but the use scenarios for stroke rehabilitation are typically for unilateral upper limbs. There is a significant challenge to decoding unilateral MI of multitasks due to the overlapped spatial neural activities of the tasks. This study aims to formulate a novel MI-BCI experimental paradigm for unilateral limbs with multitasks. The paradigm encompasses four imagined movement directions: top-bottom, left-right, top right-bottom left, and top left-bottom right. Forty-six healthy subjects participated in this experiment. Commonly used machine learning techniques, such as FBCSP, EEGNet, deepConvNet, and FBCNet, were employed for evaluation. To improve decoding accuracy, we propose an MVCA method that introduces temporal convolution and attention mechanism to effectively capture temporal features from multiple perspectives. With the MVCA model, we have achieved 40.6% and 64.89% classification accuracies for the four-class and two-class scenarios (top right-bottom left and top left-bottom right), respectively. Conclusion: This is the first study demonstrating that motor imagery of multiple directions in unilateral limbs can be decoded. In particular, decoding two directions, right top to left bottom and left top to right bottom, provides the best accuracy, which sheds light on future studies. This study advances the development of the MI-BCI paradigm, offering preliminary evidence for the feasibility of decoding multiple directional information from EEG. This, in turn, enhances the dimensions of MI control commands.",https://pubmed.ncbi.nlm.nih.gov/39236133/,https://pubmed.ncbi.nlm.nih.gov/39236133/,English,Include,,Decoding Multi-Class Motor Imagery From Unilateral Limbs Using EEG Signals.,Include,,"orty-six healthy subjects participated in this experiment. Commonly used machine learning techniques, such as FBCSP, EEGNet, deepConvNet, and FBCNet, were employed for evaluation. To improve decoding accuracy, we propose an MVCA method that introduces temporal convolution and attention mechanism to effectively capture temporal features from multiple perspectives. With the MVCA model, we have achie",,0.95,0.6,
pubmed:39234591,pubmed:39234591,PubMed,pubmed:39234591,Enhancing Arousal Level Detection in EEG Signals through Genetic Algorithm-based Feature Selection and Fast Bit Hopping.,Elnaz Sheikhian;Majid Ghoshuni;Mahdi Azarnoosh;Mohammad Mahdi Khalilzadeh,2024,10.4103/jmss.jmss_65_23,"This study explores a novel approach to detecting arousal levels through the analysis of electroencephalography (EEG) signals. Leveraging the Faller database with data from 18 healthy participants, we employ a 64-channel EEG system. The approach we employ entails the extraction of ten frequency characteristics from every channel, culminating in a feature vector of 640 dimensions for each signal instance. To enhance classification accuracy, we employ a genetic algorithm for feature selection, treating it as a multiobjective optimization task. The approach utilizes fast bit hopping for efficiency, overcoming traditional bit-string limitations. A hybrid operator expedites algorithm convergence, and a solution selection strategy identifies the most suitable feature subset. Experimental results demonstrate the method's effectiveness in detecting arousal levels across diverse states, with improvements in accuracy, sensitivity, and specificity. In scenario one, the proposed method achieves an average accuracy, sensitivity, and specificity of 93.11%, 98.37%, and 99.14%, respectively. In scenario two, the averages stand at 81.35%, 88.65%, and 84.64%. The obtained results indicate that the proposed method has a high capability of detecting arousal levels in different scenarios. In addition, the advantage of employing the proposed feature reduction method has been demonstrated.",https://pubmed.ncbi.nlm.nih.gov/39234591/,https://pubmed.ncbi.nlm.nih.gov/39234591/,English,Include,,Enhancing Arousal Level Detection in EEG Signals through Genetic Algorithm-based Feature Selection and Fast Bit Hopping.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39234182,pubmed:39234182,PubMed,pubmed:39234182,Group-member selection for RSVP-based collaborative brain-computer interfaces.,Yuan Si;Zhenyu Wang;Guiying Xu;Zikai Wang;Tianheng Xu;Ting Zhou;Honglin Hu,2024,10.3389/fnins.2020.579469,"The brain-computer interface (BCI) systems based on rapid serial visual presentation (RSVP) have been widely utilized for the detection of target and non-target images. Collaborative brain-computer interface (cBCI) effectively fuses electroencephalogram (EEG) data from multiple users to overcome the limitations of low single-user performance in single-trial event-related potential (ERP) detection in RSVP-based BCI systems. In a multi-user cBCI system, a superior group mode may lead to better collaborative performance and lower system cost. However, the key factors that enhance the collaboration capabilities of multiple users and how to further use these factors to optimize group mode remain unclear. This study proposed a group-member selection strategy to optimize the group mode and improve the system performance for RSVP-based cBCI. In contrast to the conventional grouping of collaborators at random, the group-member selection strategy enabled pairing each user with a better collaborator and allowed tasks to be done with fewer collaborators. Initially, we introduced the maximum individual capability and maximum collaborative capability (MIMC) to select optimal pairs, improving the system classification performance. The sequential forward floating selection (SFFS) combined with MIMC then selected a sub-group, aiming to reduce the hardware and labor expenses in the cBCI system. Moreover, the hierarchical discriminant component analysis (HDCA) was used as a classifier for within-session conditions, and the Euclidean space data alignment (EA) was used to overcome the problem of inter-trial variability for cross-session analysis. In this paper, we verified the effectiveness of the proposed group-member selection strategy on a public RSVP-based cBCI dataset. For the two-user matching task, the proposed MIMC had a significantly higher AUC and TPR and lower FPR than the common random grouping mode and the potential group-member selection method. Moreover, the SFFS with MIMC enabled a trade-off between maintaining performance and reducing the number of system users. The results showed that our proposed MIMC effectively optimized the group mode, enhanced the classification performance in the two-user matching task, and could reduce the redundant information by selecting the sub-group in the RSVP-based multi-user cBCI systems.",https://pubmed.ncbi.nlm.nih.gov/39234182/,https://pubmed.ncbi.nlm.nih.gov/39234182/,English,Include,,Group-member selection for RSVP-based collaborative brain-computer interfaces.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39233126,pubmed:39233126,PubMed,pubmed:39233126,"Reward-modulated attention deployment is driven by suppression, not attentional capture.",Emily D Taylor;Tobias Feldmann-Wüstefeld,2024,10.1016/j.neuroimage.2024.120831,"One driving factor for attention deployment towards a stimulus is its associated value due to previous experience and learning history. Previous visual search studies found that when looking for a target, distractors associated with higher reward produce more interference (e.g., longer response times). The present study investigated the neural mechanism of such value-driven attention deployment. Specifically, we were interested in which of the three attention sub-processes are responsible for the interference that was repeatedly observed behaviorally: enhancement of relevant information, attentional capture by irrelevant information, or suppression of irrelevant information. We replicated earlier findings showing longer response times and lower accuracy when a target competed with a high-reward compared to a low-reward distractor. We also found a spatial gradient of interference: behavioral performance dropped with increasing proximity to the target. This gradient was steeper for high- than low-reward distractors. Event-related potentials of the EEG signal showed the reason for the reward-induced attentional bias: High-reward distractors required more suppression than low-reward distractors as evident in larger Pd components. This effect was only found for distractors near targets, showing the additional filtering needs required for competing stimuli in close proximity. As a result, fewer attentional resources can be distributed to the target when it competes with a high-reward distractor, as evident in a smaller target-N2pc amplitude. The distractor-N2pc, indicative of attentional capture, was neither affected by distance nor reward, showing that attentional capture alone cannot explain interference by stimuli of high value. In sum our results show that the higher need for suppression of high-value stimuli contributes to reward-modulated attention deployment and increased suppression can prevent attentional capture of high-value stimuli.",https://pubmed.ncbi.nlm.nih.gov/39233126/,https://pubmed.ncbi.nlm.nih.gov/39233126/,English,Include,,"Reward-modulated attention deployment is driven by suppression, not attentional capture.",Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39231469,pubmed:39231469,PubMed,pubmed:39231469,"Motor imagery with cues in virtual reality, audio and screen.",Sonal Santosh Baberwal;Luz Alejandra Magre;K R Sanjaya D Gunawardhana;Michael Parkinson;Tomas Ward;Shirley Coyle,2024,10.1088/1741-2552/ad775e,"Training plays a significant role in motor imagery (MI), particularly in applications such as Motor Imagery-based Brain-Computer Interface (MIBCI) systems and rehabilitation systems. Previous studies have investigated the intricate relationship between cues and MI signals. However, the medium of presentation still remains an emerging area to be explored, as possible factors to enhance Motor Imagery signals..&#xD;Approach: We hypothesise that the medium used for cue presentation can significantly influence both performance and training outcomes in MI tasks. To test this hypothesis, we designed and executed an experiment implementing no- feedback MI. Our investigation focused on three distinct cue presentation mediums -audio, screen, and virtual reality(VR) headsets-all of which have potential implications for BCI use in the Activities of Daily Lives.&#xD;Main Results: The results of our study uncovered notable variations in MI signals depending on the medium of cue presentation, where the analysis is based on 3 EEG channels. To substantiate our findings, we employed a comprehensive approach, utilizing various evaluation metrics including Event- Related Synchronisation(ERS)/Desynchronisation(ERD), Feature Extraction (using Recursive Feature Elimination (RFE)), Machine Learning methodologies (using Ensemble Learning), and participant Questionnaires. All the approaches signify that Motor Imagery signals are enhanced when presented in VR, followed by audio, and lastly screen. Applying a Machine Learning approach across all subjects, the mean cross-validation accuracy (Mean ± Std. Error) was 69.24 ± 3.12, 68.69 ± 3.3 and 66.1±2.59 when for the VR, audio-based, and screen-based instructions respectively.&#xD;Significance: This multi-faceted exploration provides evidence to inform MI- based BCI design and advocates the incorporation of different mediums into the design of MIBCI systems, experimental setups, and user studies. The influence of the medium used for cue presentation may be applied to develop more effective and inclusive MI applications in the realm of human-computer interaction and rehabilitation.",https://pubmed.ncbi.nlm.nih.gov/39231469/,https://pubmed.ncbi.nlm.nih.gov/39231469/,English,Include,,"Motor imagery with cues in virtual reality, audio and screen.",Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.25,cv_reported
pubmed:39231465,pubmed:39231465,PubMed,pubmed:39231465,Improving non-invasive trajectory decoding via neural correlates of continuous erroneous feedback processing.,Hannah S Pulferer;Kyriaki Kostoglou;Gernot R Müller-Putz,2024,10.1088/1741-2552/ad7762,,,https://pubmed.ncbi.nlm.nih.gov/39231465/,English,Exclude,Not EEG-BCI focused,Improving non-invasive trajectory decoding via neural correlates of continuous erroneous feedback processing.,,,,,0.9,0.6,
pubmed:39229346,pubmed:39229346,PubMed,pubmed:39229346,Virtual stimulation of the interictal EEG network localizes the EZ as a measure of cortical excitability.,Sophia R Zhai;Sridevi V Sarma;Kristin Gunnarsdottir;Nathan E Crone;Adam G Rouse;Jennifer J Cheng;Michael J Kinsman;Patrick Landazuri;Utku Uysal;Carol M Ulloa;Nathaniel Cameron;Sara Inati;Kareem A Zaghloul;Varina L Boerwinkle;Sarah Wyckoff;Niravkumar Barot;Jorge A González-Martínez;Joon Y Kang;Rachel June Smith,2024,10.1093/brain/awac214,,,https://pubmed.ncbi.nlm.nih.gov/39229346/,English,Exclude,Not classification-focused,Virtual stimulation of the interictal EEG network localizes the EZ as a measure of cortical excitability.,,,,,0.85,0.6,
pubmed:39229238,pubmed:39229238,PubMed,pubmed:39229238,Personalized whole-brain activity patterns predict human corticospinal tract activation in real-time.,Uttara U Khatri;Kristen Pulliam;Muskan Manesiya;Melanie Vieyra Cortez;José Del R Millán;Sara J Hussain,2024,10.1016/j.brs.2017.11.016,"Transcranial magnetic stimulation (TMS) interventions could feasibly treat stroke-related motor impairments, but their effects are highly variable. Brain state-dependent TMS approaches are a promising solution to this problem, but inter-individual variation in lesion location and oscillatory dynamics can make translating them to the poststroke brain challenging. Personalized brain state-dependent approaches specifically designed to address these challenges are therefore needed. As a first step towards this goal, we tested a novel machine learning-based EEG-TMS system that identifies personalized brain activity patterns reflecting strong and weak corticospinal tract (CST) output (strong and weak CST states) in healthy adults in real-time. Participants completed a single-session study that included the acquisition of a TMS-EEG-EMG training dataset, personalized classifier training, and real-time EEG-informed single pulse TMS during classifier-predicted personalized CST states. MEP amplitudes elicited in real-time during personalized strong CST states were significantly larger than those elicited during personalized weak and random CST states. MEP amplitudes elicited in real-time during personalized strong CST states were also significantly less variable than those elicited during personalized weak CST states. Personalized CST states lasted for ~1-2 seconds at a time and ~1 second elapsed between consecutive similar states. Individual participants exhibited unique differences in spectro-spatial EEG patterns between personalized strong and weak CST states. Our results show for the first time that personalized whole-brain EEG activity patterns predict CST activation in real-time in healthy humans. These findings represent a pivotal step towards using personalized brain state-dependent TMS interventions to promote poststroke CST function.",https://pubmed.ncbi.nlm.nih.gov/39229238/,https://pubmed.ncbi.nlm.nih.gov/39229238/,English,Include,,Personalized whole-brain activity patterns predict human corticospinal tract activation in real-time.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39229190,pubmed:39229190,PubMed,pubmed:39229190,Gesture encoding in human left precentral gyrus neuronal ensembles.,Carlos E Vargas-Irwin;Tommy Hosman;Jacob T Gusman;Tsam Kiu Pun;John D Simeral;Tyler Singer-Clark;Anastasia Kapitonava;Claire Nicolas;Nishal P Shah;Donald Avansino;Foram Kamdar;Ziv Williams;Jaimie M Henderson;Leigh R Hochberg,2024,10.1101/2024.08.23.608325,"Understanding the cortical activity patterns driving dexterous upper limb motion has the potential to benefit a broad clinical population living with limited mobility through the development of novel brain-computer interface (BCI) technology. The present study examines the activity of ensembles of motor cortical neurons recorded using microelectrode arrays in the dominant hemisphere of two BrainGate clinical trial participants with cervical spinal cord injury as they attempted to perform a set of 48 different hand gestures. Although each participant displayed a unique organization of their respective neural latent spaces, it was possible to achieve classification accuracies of ~70% for all 48 gestures (and ~90% for sets of 10). Our results show that single unit ensemble activity recorded in a single hemisphere of human precentral gyrus has the potential to generate a wide range of gesture-related signals across both hands, providing an intuitive and diverse set of potential command signals for intracortical BCI use.",https://pubmed.ncbi.nlm.nih.gov/39229190/,https://pubmed.ncbi.nlm.nih.gov/39229190/,English,Include,,Gesture encoding in human left precentral gyrus neuronal ensembles.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39227730,pubmed:39227730,PubMed,pubmed:39227730,Increased coherence predicts medical refractoriness in patients with temporal lobe epilepsy on monotherapy.,Sungeun Hwang;Youmin Shin;Jun-Sang Sunwoo;Hyoshin Son;Seung-Bo Lee;Kon Chu;Ki-Young Jung;Sang Kun Lee;Young-Gon Kim;Kyung-Il Park,2024,10.3389/fninf.2014.00014,"Among patients with epilepsy, 30-40% experience recurrent seizures even after adequate antiseizure medications therapies, making them refractory. The early identification of refractory epilepsy is important to provide timely surgical treatment for these patients. In this study, we analyze interictal electroencephalography (EEG) data to predict drug refractoriness in patients with temporal lobe epilepsy (TLE) who were treated with monotherapy at the time of the first EEG acquisition. Various EEG features were extracted, including statistical measurements and interchannel coherence. Feature selection was performed to identify the optimal features, and classification was conducted using different classifiers. Functional connectivity and graph theory measurements were calculated to identify characteristics of refractory TLE. Among the 48 participants, 34 (70.8%) were responsive, while 14 (29.2%) were refractory over a mean follow-up duration of 38.5 months. Coherence feature within the gamma frequency band exhibited the most favorable performance. The light gradient boosting model, employing the mutual information filter-based feature selection method, demonstrated the highest performance (AUROC = 0.821). Compared to the responsive group, interchannel coherence displayed higher values in the refractory group. Interestingly, graph theory measurements using EEG coherence exhibited higher values in the refractory group than in the responsive group. Our study has demonstrated a promising method for the early identification of refractory TLE utilizing machine learning algorithms.",https://pubmed.ncbi.nlm.nih.gov/39227730/,https://pubmed.ncbi.nlm.nih.gov/39227730/,English,Include,,Increased coherence predicts medical refractoriness in patients with temporal lobe epilepsy on monotherapy.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39226850,pubmed:39226850,PubMed,pubmed:39226850,Inter-participant transfer learning with attention based domain adversarial training for P300 detection.,Shurui Li;Ian Daly;Cuntai Guan;Andrzej Cichocki;Jing Jin,2024,10.1016/j.neunet.2024.106655,"A Brain-computer interface (BCI) system establishes a novel communication channel between the human brain and a computer. Most event related potential-based BCI applications make use of decoding models, which requires training. This training process is often time-consuming and inconvenient for new users. In recent years, deep learning models, especially participant-independent models, have garnered significant attention in the domain of ERP classification. However, individual differences in EEG signals hamper model generalization, as the ERP component and other aspects of the EEG signal vary across participants, even when they are exposed to the same stimuli. This paper proposes a novel One-source domain transfer learning method based Attention Domain Adversarial Neural Network (OADANN) to mitigate data distribution discrepancies for cross-participant classification tasks. We train and validate our proposed model on both a publicly available OpenBMI dataset and a Self-collected dataset, employing a leave one participant out cross validation scheme. Experimental results demonstrate that the proposed OADANN method achieves the highest and most robust classification performance and exhibits significant improvements when compared to baseline methods (CNN, EEGNet, ShallowNet, DeepCovNet) and domain generalization methods (ERM, Mixup, and Groupdro). These findings underscore the efficacy of our proposed method.",https://pubmed.ncbi.nlm.nih.gov/39226850/,https://pubmed.ncbi.nlm.nih.gov/39226850/,English,Include,,Inter-participant transfer learning with attention based domain adversarial training for P300 detection.,Include,,"ablishes a novel communication channel between the human brain and a computer. Most event related potential-based BCI applications make use of decoding models, which requires training. This training process is often time-consuming and inconvenient for new users. In recent years, deep learning models, especially participant-independent models, have garnered significant attention in the domain of ER",,0.95,0.8,small_sample_mentioned
pubmed:39226758,pubmed:39226758,PubMed,pubmed:39226758,Hybrid similarity based feature selection and cascade deep maxout fuzzy network for Autism Spectrum Disorder detection using EEG signal.,Joy Karan Singh;Deepti Kakkar,2024,10.1016/j.compbiolchem.2024.108177,"Autism Spectrum Disorder (ASD) is a neurological disorder that influences a person's comprehension and way of behaving. It is a lifetime disability that cannot be completely treated using any therapy up to date. Nevertheless, in time identification and continuous therapies have a huge effect on autism patients. The existing models took a long time to confirm the diagnosis process and also, it is highly complex to differentiate autism from various developmental disorders. To facilitate early diagnosis by providing timely intervention, saving healthcare costs and reducing stress for the family in the long run, this research introduces an affordable and straightforward diagnostic model to detect ASD using EEG and deep learning models. Here, a hybrid deep learning model called Cascade deep maxout fuzzy network (Cascade DMFN) is proposed to identify ASD and it is achieved by the integration of Deep Maxout Network (DMN) and hybrid cascade neuro-fuzzy. Moreover, hybrid similarity measures like Canberra distance and Kumar-hassebrook is employed to conduct the feature selection technique. Also, the EEG dataset and BCIAUT_P300 dataset are used for analyzing the designed Cascade DMFN for detecting Autism Spectrum Disorder. The designed Cascade DMFN has outperformed other classical models by yielding a high accuracy of 0.930, Negative Predictive Value (NPV) of 0.919, Positive Predictive Value (PPV) of 0.923, True Negative Rate (TNR) of 0.926, and True Positive Rate (TPR) of 0.934.",https://pubmed.ncbi.nlm.nih.gov/39226758/,https://pubmed.ncbi.nlm.nih.gov/39226758/,English,Include,,Hybrid similarity based feature selection and cascade deep maxout fuzzy network for Autism Spectrum Disorder detection using EEG signal.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39226201,pubmed:39226201,PubMed,pubmed:39226201,Convolutional Transformer-Based Cross Subject Model for SSVEP-Based BCI Classification.,Jiawei Liu;Ruimin Wang;Yuankui Yang;Yuan Zong;Yue Leng;Wenming Zheng;Sheng Ge,2024,10.1109/jbhi.2024.3454158,"Steady-state visual evoked potential (SSVEP) is a commonly used brain-computer interface (BCI) paradigm. The performance of cross-subject SSVEP classification has a strong impact on SSVEP-BCI. This study designed a cross subject generalization SSVEP classification model based on an improved transformer structure that uses domain generalization (DG). The global receptive field of multi-head self-attention is used to learn the global generalized SSVEP temporal information across subjects. This is combined with a parallel local convolution module, designed to avoid oversmoothing the oscillation characteristics of temporal SSVEP data and better fit the feature. Moreover, to improve the cross-subject calibration-free SSVEP classification performance, an DG method named StableNet is combined with the proposed convolutional transformer structure to form the DG-Conformer method, which can eliminate spurious correlations between SSVEP discriminative information and background noise to improve cross-subject generalization. Experiments on two public datasets, Benchmark and BETA, demonstrated the outstanding performance of the proposed DG-Conformer compared with other calibration-free methods, FBCCA, tt-CCA, Compact-CNN, FB-tCNN, and SSVEPNet. Additionally, DG-Conformer outperforms the classic calibration-required algorithms eCCA, eTRCA and eSSCOR when calibration is used. An incomplete partial stimulus calibration scheme was also explored on the Benchmark dataset, and it was demonstrated to be a potential solution for further high-performance personalized SSVEP-BCI with quick calibration.",https://pubmed.ncbi.nlm.nih.gov/39226201/,https://pubmed.ncbi.nlm.nih.gov/39226201/,English,Include,,Convolutional Transformer-Based Cross Subject Model for SSVEP-Based BCI Classification.,Exclude,No performance metrics reported,No metrics found in full text,,0.9,0.6,
pubmed:39224441,pubmed:39224441,PubMed,pubmed:39224441,Convolutional neural network framework for EEG-based ADHD diagnosis in children.,Umaisa Hassan;Amit Singhal,2024,10.1007/s13755-024-00305-7,"Attention-deficit hyperactivity disorder (ADHD) stands as a significant psychiatric and neuro-developmental disorder with global prevalence. The prevalence of ADHD among school children in India is estimated to range from 5% to 8%. However, certain studies have reported higher prevalence rates, reaching as high as 11%. Utilizing electroencephalography (EEG) signals for the early detection and classification of ADHD in children is crucial. In this study, we introduce a CNN architecture characterized by its simplicity, comprising solely two convolutional layers. Our approach involves pre-processing EEG signals through a band-pass filter and segmenting them into 5-s frames. Following this, the frames undergo normalization and canonical correlation analysis. Subsequently, the proposed CNN architecture is employed for training and testing purposes. Our methodology yields remarkable results, with 100% accuracy, sensitivity, and specificity when utilizing the complete 19-channel EEG signals for diagnosing ADHD in children. However, employing the entire set of EEG channels presents challenges related to the computational complexity. Therefore, we investigate the feasibility of using only frontal brain EEG channels for ADHD detection, which yields an accuracy of 99.08%. The proposed method yields high accuracy and is easy to implement, hence, it has the potential for widespread practical deployment to diagnose ADHD.",https://pubmed.ncbi.nlm.nih.gov/39224441/,https://pubmed.ncbi.nlm.nih.gov/39224441/,English,Include,,Convolutional neural network framework for EEG-based ADHD diagnosis in children.,Include,,"dergo normalization and canonical correlation analysis. Subsequently, the proposed CNN architecture is employed for training and testing purposes. Our methodology yields remarkable results, with 100% accuracy, sensitivity, and specificity when utilizing the complete 19-channel EEG signals for diagnosing ADHD in children. However, employing the entire set of EEG channels presents challenges related",,0.95,0.6,
pubmed:39224246,pubmed:39224246,PubMed,pubmed:39224246,Leveraging electrocardiography signals for deep learning-driven cardiovascular disease classification model.,Hamed Alqahtani;Ghadah Aldehim;Nuha Alruwais;Mohammed Assiri;Amani A Alneil;Abdullah Mohamed,2024,10.1007/s12652-021-03324-4,"Electrocardiography (ECG) is the most non-invasive diagnostic tool for cardiovascular diseases (CVDs). Automatic analysis of ECG signals assists in accurately and rapidly detecting life-threatening arrhythmias like atrioventricular blockage, atrial fibrillation, ventricular tachycardia, etc. The ECG recognition models need to utilize algorithms to detect various kinds of waveforms in the ECG and identify complicated relationships over time. However, the high variability of wave morphology among patients and noise are challenging issues. Physicians frequently utilize automated ECG abnormality recognition models to classify long-term ECG signals. Recently, deep learning (DL) models can be used to achieve enhanced ECG recognition accuracy in the healthcare decision making system. In this aspect, this study introduces an automated DL enabled ECG signal recognition (ADL-ECGSR) technique for CVD detection and classification. The ADL-ECGSR technique employs three most important subprocesses: pre-processed, feature extraction, parameter tuning, and classification. Besides, the ADL-ECGSR technique involves the design of a bidirectional long short-term memory (BiLSTM) based feature extractor, and the Adamax optimizer is utilized to optimize the trained method of the BiLSTM model. Finally, the dragonfly algorithm (DFA) with a stacked sparse autoencoder (SSAE) module is applied to recognize and classify EEG signals. An extensive range of simulations occur on benchmark PTB-XL datasets to validate the enhanced ECG recognition efficiency. The comparative analysis of the ADL-ECGSR methodology showed a remarkable performance of 91.24 % on the existing methods.",https://pubmed.ncbi.nlm.nih.gov/39224246/,https://pubmed.ncbi.nlm.nih.gov/39224246/,English,Include,,Leveraging electrocardiography signals for deep learning-driven cardiovascular disease classification model.,Include,,"sues. Physicians frequently utilize automated ECG abnormality recognition models to classify long-term ECG signals. Recently, deep learning (DL) models can be used to achieve enhanced ECG recognition accuracy in the healthcare decision making system. In this aspect, this study introduces an automated DL enabled ECG signal recognition (ADL-ECGSR) technique for CVD detection and classification. The ",,0.95,0.6,
pubmed:39222613,pubmed:39222613,PubMed,pubmed:39222613,Artificial intelligence and telemedicine in epilepsy and EEG: A narrative review.,Mohammad Alkhaldi;Layla Abu Joudeh;Yaman B Ahmed;Khalil S Husari,2024,10.1016/j.seizure.2024.08.024,"The emergence of telemedicine and artificial intelligence (AI) has set the stage for a possible revolution in the future of medicine and neurology including the diagnosis and management of epilepsy. Telemedicine, with its proven efficacy during the COVID-19 pandemic, offers the advantage of bridging the gap between patients in resource-limited areas and specialized care, where in one study telemedicine reduced the epilepsy treatment gap from 43 % to 9 %. AI innovations promise a transformation in epilepsy care by possibly enhancing the accuracy of electroencephalogram (EEG) interpretation and seizure prediction through machine and deep learning. In one study, abnormal EEG recordings were classified into different categories using a convolutional neural networks (CNN) model showing a specificity of 90 % and an accuracy of 88.3 %. Other models constructed to predict seizures have also achieved a sensitivity of 96.8 % and specificity of 95.5 %. Various machine learning (ML) models highlight the potential AI holds in identifying interictal biomarkers and localizing seizure onset zones aiding in epilepsy treatment decision and outcome prediction. An ML model highlighted in this review localized seizure onset zone with an accuracy reaching 73 % and predicted surgical outcomes with an accuracy reaching 79 % compared to the 43 % accuracy of clinicians. However, limitations and challenges hinder the application of such technologies to reach their full potential in epilepsy care. Limitations include access to compatible devices, integration into clinical workflows, data bias, and availability of sufficient data. Extensive validated research is needed to guide future clinical practice with the implementation of technology-enhanced epilepsy care. This narrative review article will explore the use of AI and telemedicine in EEG and epilepsy care, examining their individual and combined impacts in shaping the future of epilepsy care and discussing the challenges and limitations faced in their usage.",,https://pubmed.ncbi.nlm.nih.gov/39222613/,English,Exclude,Review/survey papers,Artificial intelligence and telemedicine in epilepsy and EEG: A narrative review.,,,,,0.95,0.6,
pubmed:39222461,pubmed:39222461,PubMed,pubmed:39222461,EEG Characteristic Comparison of Motor Imagery Between Supernumerary and Inherent Limb: Sixth-Finger MI Enhances the ERD Pattern and Classification Performance.,Zhuang Wang;Yuan Liu;Shuaifei Huang;Shiyin Qiu;Yujian Zhang;Huimin Huang;Xingwei An;Dong Ming,2024,10.1109/jbhi.2024.3452701,"Adding supernumerary robotic limbs (SRLs) to humans and controlling them directly through the brain are main goals for movement augmentation. However, it remains uncertain whether neural patterns different from the traditional inherent limbs motor imagery (MI) can be extracted, which is essential for high-dimensional control of external devices. In this work, we established a MI neo-framework consisting of novel supernumerary robotic sixth-finger MI (SRF-MI) and traditional right-hand MI (RH-MI) paradigms and validated the distinctness of EEG response patterns between two MI tasks for the first time. Twenty-four subjects were recruited for this experiment involving three mental tasks. Event-related spectral perturbation was adopted to supply details about event-related desynchronization (ERD). Activation region, intensity and response time (RT) of ERD were compared between SRF-MI and RH-MI tasks. Three classical classification algorithms were utilized to verify the separability between different mental tasks. And genetic algorithm aims to select optimal combination of channels for neo-framework. A bilateral sensorimotor and prefrontal modulation was found during the SRF-MI task, whereas in RH-MI only contralateral sensorimotor modulation was exhibited. The novel SRF-MI paradigm enhanced ERD intensity by a maximum of 117% in prefrontal area and 188% in the ipsilateral somatosensory-association cortex. And, a global decrease of RT was exhibited during SRF-MI tasks compared to RH-MI. Classification results indicate well separable performance among different mental tasks (88.1% maximum for 2-class and 88.2% maximum for 3-class). This work demonstrated the difference between the SRF-MI and RH-MI paradigms, widening the control bandwidth of the BCI system.",https://pubmed.ncbi.nlm.nih.gov/39222461/,https://pubmed.ncbi.nlm.nih.gov/39222461/,English,Include,,EEG Characteristic Comparison of Motor Imagery Between Supernumerary and Inherent Limb: Sixth-Finger MI Enhances the ERD Pattern and Classification Performance.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39221950,pubmed:39221950,PubMed,pubmed:39221950,Frontal Disconnection for Treating Mild Malformation of Cortical Development with Oligodendroglial Hyperplasia in Epilepsy (MOGHE) in the Frontal Lobe.,Yao Wang;Qingzhu Liu;Hao Yu;Chang Liu;Yu Sun;Yi Wang;Xiaoyan Liu;Lixin Cai,2024,10.3791/66970,"Malformation of cortical development is an important cause of drug-resistant epilepsy in young children. Mild malformation of cortical development with oligodendroglial hyperplasia in epilepsy (MOGHE) has been added to the last focal cortical dysplasia (FCD) classification and commonly involves the frontal lobe. The semiology at the onset of epilepsy is dominated by non-lateralizing infantile spasm; the boundaries of the malformation are usually difficult to determine by magnetic resonance imaging (MRI) and positron emission tomography (PET), and electroencephalography (EEG) findings are often widespread. Therefore, the traditional concept and strategy of preoperative evaluation to determine the extent of the epileptogenic zone by comprehensive anatomo-electro-clinical methods are difficult to implement. Frontal disconnection is an effective surgical method for the treatment of epilepsy, but there are few related reports. A total of 8 children with histo-pathologically confirmed MOGHE were retrospectively studied. MOGHE was located in the frontal lobe in all patients, and frontal disconnection was performed. The periinsular approach was used in the disconnective procedures, divided into several surgical steps: the partial inferior frontal gyrus resection, the frontobasal and intrafrontal disconnection, and the anterior corpus callosotomy. One patient presented with a short-term postoperative speech disorder, while another patient exhibited transient postoperative limb weakness. No long-term postoperative complications were observed. At 2 years after surgery, 75% of patients were seizure-free, with cognitive improvement in half of them. This finding suggested that frontal disconnection is an effective and safe surgical procedure for the treatment of MOGHE instead of extensive resection in the frontal lobe.",https://pubmed.ncbi.nlm.nih.gov/39221950/,https://pubmed.ncbi.nlm.nih.gov/39221950/,English,Include,,Frontal Disconnection for Treating Mild Malformation of Cortical Development with Oligodendroglial Hyperplasia in Epilepsy (MOGHE) in the Frontal Lobe.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.25,cv_reported
pubmed:39221693,pubmed:39221693,PubMed,pubmed:39221693,The role of animacy in language production: evidence from bare noun naming.,Yufang Wang;Jurriaan Witteman;Niels O Schiller,2025,10.1016/j.cortex.2018.05.014,"According to Levelt's language production model, to name an object, speakers must first conceptualise and lexicalise the object before its name can be articulated. Conceptualisation is conducted through the semantic network that exists at the conceptual level, with the highly activated concept(s) activating lexical items at the lemma level, that is, lexicalisation. So far, research focused mostly on semantic categories (i.e., semantic interference) but less so on animacy-a concept that is correlated with semantic categories. To investigate the role of this semantic feature in language production, we conducted a picture-word interference study in Mandarin Chinese, varying animacy congruency and controlling for classifier congruency while recording behavioural and electrophysiological responses. We observed an animacy interference effect together with a larger N400 component for animacy-incongruent versus congruent picture-word pairs, suggesting animacy-congruent concepts may be in closer proximity and hence lead to a stronger spreading of activation relative to animacy-incongruent concepts. Furthermore, a larger P600 component was observed for classifier-incongruent versus classifier-congruent picture-word pairs, suggesting syntactically driven processing of classifiers at the lemma level.",,https://pubmed.ncbi.nlm.nih.gov/39221693/,English,Exclude,Outside date range,The role of animacy in language production: evidence from bare noun naming.,,,,,0.95,0.6,
pubmed:39220036,pubmed:39220036,PubMed,pubmed:39220036,"Exploring the potential of spiking neural networks in biomedical applications: advantages, limitations, and future perspectives.",Eunsu Kim;Youngmin Kim,2024,10.1109/lra.2023.3264836,"In this paper, a comprehensive exploration is undertaken to elucidate the utilization of Spiking Neural Networks (SNNs) within the biomedical domain. The investigation delves into the experimentally validated advantages of SNNs in comparison to alternative models like LSTM, while also critically examining the inherent limitations of SNN classifiers or algorithms. SNNs exhibit distinctive advantages that render them particularly apt for targeted applications within the biomedical field. Over time, SNNs have undergone extensive scrutiny in realms such as neuromorphic processing, Brain-Computer Interfaces (BCIs), and Disease Diagnosis. Notably, SNNs demonstrate a remarkable affinity for the processing and analysis of biomedical signals, including but not limited to electroencephalogram (EEG), electromyography (EMG), and electrocardiogram (ECG) data. This paper initiates its exploration by introducing some of the biomedical applications of EMG, such as the classification of hand gestures and motion decoding. Subsequently, the focus extends to the applications of SNNs in the analysis of EEG and ECG signals. Moreover, the paper delves into the diverse applications of SNNs in specific anatomical regions, such as the eyes and noses. In the final sections, the paper culminates with a comprehensive analysis of the field, offering insights into the advantages, disadvantages, challenges, and opportunities introduced by various SNN models in the realm of healthcare and biomedical domains. This holistic examination provides a nuanced perspective on the potential transformative impact of SNN across a spectrum of applications within the biomedical landscape.",https://pubmed.ncbi.nlm.nih.gov/39220036/,https://pubmed.ncbi.nlm.nih.gov/39220036/,English,Include,,"Exploring the potential of spiking neural networks in biomedical applications: advantages, limitations, and future perspectives.",Include,,"hibit distinctive advantages that render them particularly apt for targeted applications within the biomedical field. Over time, SNNs have undergone extensive scrutiny in realms such as neuromorphic processing, Brain-Computer Interfaces (BCIs), and Disease Diagnosis. Notably, SNNs demonstrate a remarkable affinity for the processing and analysis of biomedical signals, including but not limited to ",,0.95,0.6,
pubmed:39218599,pubmed:39218599,PubMed,pubmed:39218599,[Fatigue feature extraction and classification algorithm of forehead single-channel electroencephalography signals].,Huizhou Yang;Yunfei Liu;Lijuan Xia,2024,10.1088/1741-2552/ab909f,"Aiming at the problem that the feature extraction ability of forehead single-channel electroencephalography (EEG) signals is insufficient, which leads to decreased fatigue detection accuracy, a fatigue feature extraction and classification algorithm based on supervised contrastive learning is proposed. Firstly, the raw signals are filtered by empirical modal decomposition to improve the signal-to-noise ratio. Secondly, considering the limitation of the one-dimensional signal in information expression, overlapping sampling is used to transform the signal into a two-dimensional structure, and simultaneously express the short-term and long-term changes of the signal. The feature extraction network is constructed by depthwise separable convolution to accelerate model operation. Finally, the model is globally optimized by combining the supervised contrastive loss and the mean square error loss. Experiments show that the average accuracy of the algorithm for classifying three fatigue states can reach 75.80%, which is greatly improved compared with other advanced algorithms, and the accuracy and feasibility of fatigue detection by single-channel EEG signals are significantly improved. The results provide strong support for the application of single-channel EEG signals, and also provide a new idea for fatigue detection research. 针对前额单通道脑电信号特征提取能力不足，导致疲劳检测精度降低的问题，本文提出一种基于有监督对比学习的疲劳特征提取及分类算法。首先，通过经典模态分解对原始信号进行滤波，提高信噪比；其次，考虑到一维信号在信息表达上的局限性，利用有重叠采样将信号转换为二维结构，同时表达信号短期内和长期间变化；由深度可分离卷积构建特征提取网络，加速模型运算；最后，通过联合有监督对比损失与均方误差损失对模型进行全局优化。实验表明，该算法对三种疲劳状态分类的平均准确度可达75.80%，相较于其它先进算法均有较大幅度提高，显著提高了单通道脑电信号进行疲劳检测的准确性与可行性。本文研究为单通道脑电信号应用提供了有力支持，也为疲劳检测研究提供了新思路。.",https://pubmed.ncbi.nlm.nih.gov/39218599/,https://pubmed.ncbi.nlm.nih.gov/39218599/,English,Include,,[Fatigue feature extraction and classification algorithm of forehead single-channel electroencephalography signals].,Include,,"Aiming at the problem that the feature extraction ability of forehead single-channel electroencephalography (EEG) signals is insufficient, which leads to decreased fatigue detection accuracy, a fatigue feature extraction and classification algorithm based on supervised contrastive learning is proposed. Firstly, the raw signals are filtered by empirical modal decomposition to impr",,0.95,0.6,
pubmed:39218593,pubmed:39218593,PubMed,pubmed:39218593,[Visual object detection system based on augmented reality and steady-state visual evoked potential].,Meng'ao Guo;Banghua Yang;Yiting Geng;Rongxin Jie;Yonghuai Zhang;Yanyan Zheng,2024,10.7652/xjtuxb202110010,"This study investigates a brain-computer interface (BCI) system based on an augmented reality (AR) environment and steady-state visual evoked potentials (SSVEP). The system is designed to facilitate the selection of real-world objects through visual gaze in real-life scenarios. By integrating object detection technology and AR technology, the system augmented real objects with visual enhancements, providing users with visual stimuli that induced corresponding brain signals. SSVEP technology was then utilized to interpret these brain signals and identify the objects that users focused on. Additionally, an adaptive dynamic time-window-based filter bank canonical correlation analysis was employed to rapidly parse the subjects' brain signals. Experimental results indicated that the system could effectively recognize SSVEP signals, achieving an average accuracy rate of 90.6% in visual target identification. This system extends the application of SSVEP signals to real-life scenarios, demonstrating feasibility and efficacy in assisting individuals with mobility impairments and physical disabilities in object selection tasks. 本研究探讨了一种基于增强现实（AR）环境和稳态视觉诱发电位（SSVEP）的脑机接口（BCI）系统，用于在真实场景下通过视觉注视完成对现实物品的选取任务。该系统结合了目标检测技术和AR技术，在真实物体上附加视觉增强效果，从而给予用户视觉刺激诱发相关脑电信号，再利用SSVEP技术解析脑电信号，完成对用户关注物体的识别。此外，本文采用了基于自适应动态时间窗的滤波器组典型相关分析算法实现对受试者脑电信号的快速解析。实验结果表明，该系统可以有效地识别解析SSVEP信号，对用户视觉目标的识别平均准确率达到了90.6%。该系统拓展了SSVEP信号在现实生活场景中的应用，在帮助行动不便和肢体功能受损患者进行物品选取任务上具备可行性和有效性。.",https://pubmed.ncbi.nlm.nih.gov/39218593/,https://pubmed.ncbi.nlm.nih.gov/39218593/,English,Include,,[Visual object detection system based on augmented reality and steady-state visual evoked potential].,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39218591,pubmed:39218591,PubMed,pubmed:39218591,[The supernumerary robotic limbs of brain-computer interface based on asynchronous steady-state visual evoked potential].,Ping Xie;Yandi Men;Jiale Zhen;Xiening Shao;Jing Zhao;Xiaoling Chen,2024,10.3390/mi14050976,"Brain-computer interface (BCI) based on steady-state visual evoked potential (SSVEP) have attracted much attention in the field of intelligent robotics. Traditional SSVEP-based BCI systems mostly use synchronized triggers without identifying whether the user is in the control or non-control state, resulting in a system that lacks autonomous control capability. Therefore, this paper proposed a SSVEP asynchronous state recognition method, which constructs an asynchronous state recognition model by fusing multiple time-frequency domain features of electroencephalographic (EEG) signals and combining with a linear discriminant analysis (LDA) to improve the accuracy of SSVEP asynchronous state recognition. Furthermore, addressing the control needs of disabled individuals in multitasking scenarios, a brain-machine fusion system based on SSVEP-BCI asynchronous cooperative control was developed. This system enabled the collaborative control of wearable manipulator and robotic arm, where the robotic arm acts as a ""third hand"", offering significant advantages in complex environments. The experimental results showed that using the SSVEP asynchronous control algorithm and brain-computer fusion system proposed in this paper could assist users to complete multitasking cooperative operations. The average accuracy of user intent recognition in online control experiments was 93.0%, which provides a theoretical and practical basis for the practical application of the asynchronous SSVEP-BCI system. 基于稳态视觉诱发电位（SSVEP）的脑机接口（BCI）在智能机器人领域的应用备受关注。传统基于SSVEP的BCI系统多采用同步触发方式，没有识别用户是处于控制态还是非控制态，导致系统缺乏自主控制能力。为此，本文提出了一种SSVEP异步状态识别方法，通过融合脑电信号（EEG）的多种时频域特征，结合线性判别分类器构建了异步状态识别模型，提高SSVEP异步状态识别准确率。进一步，针对残障人群在多任务场景下的控制需求，搭建了一种基于SSVEP-BCI异步协同控制的脑机融合系统，实现在复杂场景下可穿戴机械手与机械臂即“第三只手”的协同控制。实验结果表明，运用本文所提出的SSVEP异步控制算法和脑机融合系统，可以辅助用户完成多任务协同操作，在线控制实验中用户意图识别的平均准确率为93.0%，为SSVEP异步脑机接口系统的实际应用提供了理论和实践依据。.",https://pubmed.ncbi.nlm.nih.gov/39218591/,https://pubmed.ncbi.nlm.nih.gov/39218591/,English,Include,,[The supernumerary robotic limbs of brain-computer interface based on asynchronous steady-state visual evoked potential].,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39217668,pubmed:39217668,PubMed,pubmed:39217668,Schizophrenia diagnosis using the GRU-layer's alpha-EEG rhythm's dependability.,Pankaj Kumar Sahu;Karan Jain,2024,10.1016/j.pscychresns.2024.111886,"Verifying schizophrenia (SZ) can be assisted by deep learning techniques and patterns in brain activity observed in alpha-EEG recordings. The suggested research provides evidence of the reliability of alpha-EEG rhythm in a Gated-Recurrent-Unit-based deep-learning model for investigating SZ. This study suggests Rudiment Densely-Coupled Convolutional Gated Recurrent Unit (RDCGRU) for the various EEG-rhythm-based (gamma, beta, alpha, theta, and delta) diagnoses of SZ. The model includes multiple 1-D-Convolution (Con-1-D) folds with steps greater than 1, which enables the model to programmatically and effectively learn how to reduce the incoming signal. The Con-1-D layers and numerous Gated Recurrent Unit (GRU) layers comprise the Exponential-Linear-Unit activation function. This powerful activation function facilitates in-deep-network training and improves classification performance. The Densely-Coupled Convolutional Gated Recurrent Unit (DCGRU) layers enable RDCGRU to address the training accuracy loss brought on by vanishing or exploding gradients, and this might make it possible to develop intense, deep versions of RDCGRU for more complex problems. The sigmoid activation function is implemented in the digital (binary) classifier's output nodes. The RDCGRU deep learning model attained the most excellent accuracy, 88.88 %, with alpha-EEG rhythm. The research achievements: The RDCGRU deep learning model's GRU cells responded superiorly to the alpha-EEG rhythm in EEG-based verification of SZ.",https://pubmed.ncbi.nlm.nih.gov/39217668/,https://pubmed.ncbi.nlm.nih.gov/39217668/,English,Include,,Schizophrenia diagnosis using the GRU-layer's alpha-EEG rhythm's dependability.,Include,,"tion function facilitates in-deep-network training and improves classification performance. The Densely-Coupled Convolutional Gated Recurrent Unit (DCGRU) layers enable RDCGRU to address the training accuracy loss brought on by vanishing or exploding gradients, and this might make it possible to develop intense, deep versions of RDCGRU for more complex problems. The sigmoid activation function is ",,0.95,0.6,
pubmed:39216077,pubmed:39216077,PubMed,pubmed:39216077,Conjunctive processing of spatial border and locomotion in retrosplenial cortex during spatial navigation.,Hao Sun;Ruolan Cai;Rui Li;Mingxuan Li;Lixia Gao;Xinjian Li,2024,10.1113/jp286434,"Spatial information and dynamic locomotor behaviours are equally important for achieving locomotor goals during spatial navigation. However, it remains unclear how spatial and locomotor information is integrated during the processing of self-initiated spatial navigation. Anatomically, the retrosplenial cortex (RSC) has reciprocal connections with brain regions related to spatial processing, including the hippocampus and para-hippocampus, and also receives inputs from the secondary motor cortex. In addition, RSC is functionally associated with allocentric and egocentric spatial targets and head-turning. So, RSC may be a critical region for integrating spatial and locomotor information. In this study, we first examined the role of RSC in spatial navigation using the Morris water maze and found that mice with inactivated RSC took a longer time and distance to reach their destination. Then, by imaging neuronal activity in freely behaving mice within two open fields of different sizes, we identified a large proportion of border cells, head-turning cells and locomotor speed cells in the superficial layer of RSC. Interestingly, some RSC neurons exhibited conjunctive coding for both spatial and locomotor signals. Furthermore, these conjunctive neurons showed higher prediction accuracy compared with simple spatial or locomotor neurons in special navigator scenes using the border, turning and positive-speed conjunctive cells. Our study reveals that the RSC is an important conjunctive brain region that processes spatial and locomotor information during spatial navigation. KEY POINTS: Retrosplenial cortex (RSC) is indispensable during spatial navigation, which was displayed by the longer time and distance of mice to reach their destination after the inactivation of RSC in a water maze. The superficial layer of RSC has a larger population of spatial-related border cells, and locomotion-related head orientation and speed cells; however, it has few place cells in two-dimensional spatial arenas. Some RSC neurons exhibited conjunctive coding for both spatial and locomotor signals, and the conjunctive neurons showed higher prediction accuracy compared with simple spatial or locomotor neurons in special navigation scenes. Our study reveals that the RSC is an important conjunctive brain region that processes both spatial and locomotor information during spatial navigation.",,https://pubmed.ncbi.nlm.nih.gov/39216077/,English,Exclude,Not EEG-BCI focused,Conjunctive processing of spatial border and locomotion in retrosplenial cortex during spatial navigation.,,,,,0.9,0.6,
pubmed:39215886,pubmed:39215886,PubMed,pubmed:39215886,Rhythm Facilitates Auditory Working Memory via Beta-Band Encoding and Theta-Band Maintenance.,Suizi Tian;Yu-Ang Cheng;Huan Luo,2025,10.1007/s12264-024-01289-w,"Rhythm, as a prominent characteristic of auditory experiences such as speech and music, is known to facilitate attention, yet its contribution to working memory (WM) remains unclear. Here, human participants temporarily retained a 12-tone sequence presented rhythmically or arrhythmically in WM and performed a pitch change-detection task. Behaviorally, while having comparable accuracy, rhythmic tone sequences showed a faster response time and lower response boundaries in decision-making. Electroencephalographic recordings revealed that rhythmic sequences elicited enhanced non-phase-locked beta-band (16 Hz-33 Hz) and theta-band (3 Hz-5 Hz) neural oscillations during sensory encoding and WM retention periods, respectively. Importantly, the two-stage neural signatures were correlated with each other and contributed to behavior. As beta-band and theta-band oscillations denote the engagement of motor systems and WM maintenance, respectively, our findings imply that rhythm facilitates auditory WM through intricate oscillation-based interactions between the motor and auditory systems that facilitate predictive attention to auditory sequences.",,https://pubmed.ncbi.nlm.nih.gov/39215886/,English,Exclude,Outside date range,Rhythm Facilitates Auditory Working Memory via Beta-Band Encoding and Theta-Band Maintenance.,,,,,0.95,0.8,small_sample_mentioned
pubmed:39208388,pubmed:39208388,PubMed,pubmed:39208388,Digital assessment of cognitive-affective biases related to mental health.,Sang-Eon Park;Jisu Chung;Jeonghyun Lee;Minwoo Jb Kim;Jinhee Kim;Hong Jin Jeon;Hyungsook Kim;Choongwan Woo;Hackjin Kim;Sang Ah Lee,2024,10.31887/dcns.2020.22.2/gsmall,"With an increasing societal need for digital therapy solutions for poor mental health, we face a corresponding rise in demand for scientifically validated digital contents. In this study we aimed to lay a sound scientific foundation for the development of brain-based digital therapeutics to assess and monitor cognitive effects of social and emotional bias across diverse populations and age-ranges. First, we developed three computerized cognitive tasks using animated graphics: 1) an emotional flanker task designed to test attentional bias, 2) an emotional go-no-go task to measure bias in memory and executive function, and 3) an emotional social evaluation task to measure sensitivity to social judgments. Then, we confirmed the generalizability of our results in a wide range of samples (children (N = 50), young adults (N = 172), older adults (N = 39), online young adults (N=93), and depression patients (N = 41)) using touchscreen and online computer-based tasks, and devised a spontaneous thought generation task that was strongly associated with, and therefore could potentially serve as an alternative to, self-report scales. Using PCA, we extracted five components that represented different aspects of cognitive-affective function (emotional bias, emotional sensitivity, general accuracy, and general/social attention). Next, a gamified version of the above tasks was developed to test the feasibility of digital cognitive training over a 2-week period. A pilot training study utilizing this application showed decreases in emotional bias in the training group (that were not observed in the control group), which was correlated with a reduction in anxiety symptoms. Using a 2-channel wearable EEG system, we found that frontal alpha and gamma power were associated with both emotional bias and its reduction across the 2-week training period.",https://pubmed.ncbi.nlm.nih.gov/39208388/,https://pubmed.ncbi.nlm.nih.gov/39208388/,English,Include,,Digital assessment of cognitive-affective biases related to mental health.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39215400,pubmed:39215400,PubMed,pubmed:39215400,Adiposity influences intraindividual variability in behavioral and neuroelectric indices of attentional inhibition.,Jeongwoon Kim;Anne M Walk;Shelby A Keye;Christopher J Kinder;Corinne N Cannavale;Nicholas A Burd;Naiman A Khan,2024,10.1016/j.appet.2021.105908,"While overweight or obesity are thought to affect over 70% of the US population, the effects of adiposity on neurocognitive efficiency and stability remain unclear. Intra-individual variability or trial-to-trial variability (IIV) could provide insights into the influence of adiposity on neurophysiological stability. However, previous work examining the association between adiposity and IIV of cognitive outcomes is limited. Thus, this study examined the association between whole-body fat (%BF) and central tendency and IIV metrics of behavioral performance and event-related potentials. Adults (n = 320; 19-64 yrs) completed the Flanker task to assess attentional inhibition with concurrent electroencephalogram recordings to examine the N2 and P3b components. In addition to central tendency outcomes typically reported (i.e., mean accuracy and reaction time [RT]), dispersion outcomes (e.g., standard deviation [SD] of RT, P3b latency, N2 latency, etc.) were also extracted. Upon controlling for age and sex, %BF was inversely associated with (congruent: β = -.18, p = .016; incongruent: β = -.23, p < .001) accuracy. Increasing %BF was related to greater RT SD (congruent: β = .13, p = .032; incongruent: β = .23, p < .001). Furthermore, increased %BF was associated with slower P3b latencies (congruent: β = .21, p = .003; incongruent: β = .18, p = .010), and greater incongruent N2 (β = .16, p = .017) and P3b (β = .16, p = .025) latency SD. These findings suggest adiposity exerts a generalized negative influence on attentional inhibition for both measures of central tendency and dispersion across behavioral and neuroelectric indices.",,https://pubmed.ncbi.nlm.nih.gov/39215400/,English,Exclude,Not EEG-BCI focused,Adiposity influences intraindividual variability in behavioral and neuroelectric indices of attentional inhibition.,,,,,0.9,0.6,
pubmed:39215126,pubmed:39215126,PubMed,pubmed:39215126,CTNet: a convolutional transformer network for EEG-based motor imagery classification.,Wei Zhao;Xiaolu Jiang;Baocan Zhang;Shixiao Xiao;Sujun Weng,2024,10.1109/jproc.2015.2404941,"Brain-computer interface (BCI) technology bridges the direct communication between the brain and machines, unlocking new possibilities for human interaction and rehabilitation. EEG-based motor imagery (MI) plays a pivotal role in BCI, enabling the translation of thought into actionable commands for interactive and assistive technologies. However, the constrained decoding performance of brain signals poses a limitation to the broader application and development of BCI systems. In this study, we introduce a convolutional Transformer network (CTNet) designed for EEG-based MI classification. Firstly, CTNet employs a convolutional module analogous to EEGNet, dedicated to extracting local and spatial features from EEG time series. Subsequently, it incorporates a Transformer encoder module, leveraging a multi-head attention mechanism to discern the global dependencies of EEG's high-level features. Finally, a straightforward classifier module comprising fully connected layers is followed to categorize EEG signals. In subject-specific evaluations, CTNet achieved remarkable decoding accuracies of 82.52% and 88.49% on the BCI IV-2a and IV-2b datasets, respectively. Furthermore, in the challenging cross-subject assessments, CTNet achieved recognition accuracies of 58.64% on the BCI IV-2a dataset and 76.27% on the BCI IV-2b dataset. In both subject-specific and cross-subject evaluations, CTNet holds a leading position when compared to some of the state-of-the-art methods. This underscores the exceptional efficacy of our approach and its potential to set a new benchmark in EEG decoding.",https://pubmed.ncbi.nlm.nih.gov/39215126/,https://pubmed.ncbi.nlm.nih.gov/39215126/,English,Include,,CTNet: a convolutional transformer network for EEG-based motor imagery classification.,Exclude,No performance metrics reported,No metrics found in full text,,0.9,0.6,
pubmed:39215011,pubmed:39215011,PubMed,pubmed:39215011,Chrono-EEG dynamics influencing hand gesture decoding: a 10-hour study.,Johanna Egger;Kyriaki Kostoglou;Gernot R Müller-Putz,2024,10.1364/fio.2014.fth3c.5,"Long-term electroencephalography (EEG) recordings have primarily been used to study resting-state fluctuations. These recordings provide valuable insights into various phenomena such as sleep stages, cognitive processes, and neurological disorders. However, this study explores a new angle, focusing for the first time on the evolving nature of EEG dynamics over time within the context of movement. Twenty-two healthy individuals were measured six times from 2 p.m. to 12 a.m. with intervals of 2 h while performing four right-hand gestures. Analysis of movement-related cortical potentials (MRCPs) revealed a reduction in amplitude for the motor and post-motor potential during later hours of the day. Evaluation in source space displayed an increase in the activity of M1 of the contralateral hemisphere and the SMA of both hemispheres until 8 p.m. followed by a decline until midnight. Furthermore, we investigated how changes over time in MRCP dynamics affect the ability to decode motor information. This was achieved by developing classification schemes to assess performance across different scenarios. The observed variations in classification accuracies over time strongly indicate the need for adaptive decoders. Such adaptive decoders would be instrumental in delivering robust results, essential for the practical application of BCIs during day and nighttime usage.",https://pubmed.ncbi.nlm.nih.gov/39215011/,https://pubmed.ncbi.nlm.nih.gov/39215011/,English,Include,,Chrono-EEG dynamics influencing hand gesture decoding: a 10-hour study.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39213709,pubmed:39213709,PubMed,pubmed:39213709,Temporal aware Mixed Attention-based Convolution and Transformer Network for cross-subject EEG emotion recognition.,Xiaopeng Si;Dong Huang;Zhen Liang;Yulin Sun;He Huang;Qile Liu;Zhuobin Yang;Dong Ming,2024,10.1016/j.compbiomed.2024.108973,"Emotion recognition is crucial for human-computer interaction, and electroencephalography (EEG) stands out as a valuable tool for capturing and reflecting human emotions. In this study, we propose a hierarchical hybrid model called Mixed Attention-based Convolution and Transformer Network (MACTN). This model is designed to collectively capture both local and global temporal information and is inspired by insights from neuroscientific research on the temporal dynamics of emotions. First, we introduce depth-wise temporal convolution and separable convolution to extract local temporal features. Then, a self-attention-based transformer is used to integrate the sparse global emotional features. Besides, channel attention mechanism is designed to identify the most task-relevant channels, facilitating the capture of relationships between different channels and emotional states. Extensive experiments are conducted on three public datasets under both offline and online evaluation modes. In the multi-class cross-subject online evaluation using the THU-EP dataset, MACTN demonstrates an approximate 8% enhancement in 9-class emotion recognition accuracy in comparison to state-of-the-art methods. In the multi-class cross-subject offline evaluation using the DEAP and SEED datasets, a comparable performance is achieved solely based on the raw EEG signals, without the need for prior knowledge or transfer learning during the feature extraction and learning process. Furthermore, ablation studies have shown that integrating self-attention and channel-attention mechanisms improves classification performance. This method won the Emotional BCI Competition's final championship in the World Robot Contest. The source code is available at https://github.com/ThreePoundUniverse/MACTN.",https://pubmed.ncbi.nlm.nih.gov/39213709/,https://pubmed.ncbi.nlm.nih.gov/39213709/,English,Include,,Temporal aware Mixed Attention-based Convolution and Transformer Network for cross-subject EEG emotion recognition.,Include,," both offline and online evaluation modes. In the multi-class cross-subject online evaluation using the THU-EP dataset, MACTN demonstrates an approximate 8% enhancement in 9-class emotion recognition accuracy in comparison to state-of-the-art methods. In the multi-class cross-subject offline evaluation using the DEAP and SEED datasets, a comparable performance is achieved solely based on the raw E",,0.95,0.6,
pubmed:39213275,pubmed:39213275,PubMed,pubmed:39213275,A Learnable and Explainable Wavelet Neural Network for EEG Artifacts Detection and Classification.,Yifei Yu;Yuanxiang Li;Yunqing Zhou;Yingyan Wang;Jiwen Wang,2024,10.1109/tnsre.2024.3452315,"Electroencephalography (EEG) artifacts are very common in clinical diagnosis and can heavily impact diagnosis. Manual screening of artifact events is labor-intensive with little benefit. Therefore, exploring algorithms for automatic detection and classification of EEG artifacts can significantly assist clinical diagnosis. In this paper, we propose a learnable and explainable wavelet neural network (WaveNet) for EEG artifact detection and classification. The model is powered by the wavelet decomposition block based on invertible neural network, which can extract signal features without information loss, and a tree generator for building wavelet tree structure automatically. They provide the model with good feature extraction capabilities and explainability. To evaluate the model's performance more fairly, we introduce the base point level matching score (BASE) and the Event-Aligned Compensation Scoring (EACS) at the event level as two metrics for model performance evaluation. On the challenging Temple University EEG Artifact (TUAR) dataset, our model outperforms other baselines in terms of F1-score for both artifact detection and classification tasks. The case study also validates the model's ability to offer explainability for predictions based on frequency band energy, suggesting potential applications in clinical diagnosis.",https://pubmed.ncbi.nlm.nih.gov/39213275/,https://pubmed.ncbi.nlm.nih.gov/39213275/,English,Include,,A Learnable and Explainable Wavelet Neural Network for EEG Artifacts Detection and Classification.,Include,," Scoring (EACS) at the event level as two metrics for model performance evaluation. On the challenging Temple University EEG Artifact (TUAR) dataset, our model outperforms other baselines in terms of F1-score for both artifact detection and classification tasks. The case study also validates the model's ability to offer explainability for predictions based on frequency band energy, suggesting pote",,0.95,0.6,
pubmed:39213268,pubmed:39213268,PubMed,pubmed:39213268,Using Semi-Supervised Domain Adaptation to Enhance EEG-Based Cross-Task Mental Workload Classification Performance.,Tao Wang;Yufeng Ke;Yichao Huang;Feng He;Wenxiao Zhong;Shuang Liu;Dong Ming,2024,10.1109/jbhi.2024.3452410,"Mental workload (MWL) assessment is critical for accident prevention and operator safety. However, achieving cross-task generalization of MWL classification models is a significant challenge for real-world applications. Classifiers trained on labeled samples from one task often experience a notable performance drop when directly applied to samples from other tasks, limiting its use cases. To address this issue, we propose a semi-supervised cross-task domain adaptation (SCDA) method using power spectral density (PSD) features for MWL recognition across tasks (MATB-II and n-back). Our results demonstrated that the SCDA method achieved the best cross-task classification performance on our data and COG-BCI public dataset, with accuracies of 90.98% ± 9.36% and 96.61% ± 4.35%, respectively. Furthermore, in the cross-task classification of cross-subject scenarios, SCDA showed the highest average accuracy (75.39% ± 9.56% on our data, 90.98% ± 9.36% on the COG-BCI public dataset). The findings indicate that the semi-supervised transfer learning approach using PSD features is feasible and effective for cross-task MWL assessment.",https://pubmed.ncbi.nlm.nih.gov/39213268/,https://pubmed.ncbi.nlm.nih.gov/39213268/,English,Include,,Using Semi-Supervised Domain Adaptation to Enhance EEG-Based Cross-Task Mental Workload Classification Performance.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39209118,pubmed:39209118,PubMed,pubmed:39209118,Bio-inspired EEG signal computing using machine learning and fuzzy theory for decision making in future-oriented brain-controlled vehicles.,Haewon Byeon;Aadam Quraishi;Mohammed I Khalaf;Sunil Mp;Ihtiram Raza Khan;Ashit Kumar Dutta;Rakeshnag Dasari;Ramswaroop Reddy Yellu;Faheem Ahmad Reegu;Mohammed Wasim Bhatt,2024,10.1016/j.slast.2024.100187,"One kind of autonomous vehicle that can take instructions from the driver by reading their electroencephalogram (EEG) signals using a Brain-Computer Interface (BCI) is called a Brain-Controlled Vehicle (BCV). The operation of such a vehicle is greatly affected by how well the BCI works. At present, there are limitations on the accuracy of BCI recognition, the number of distinguishable command categories, and the execution duration of command recognition. Consequently, vehicles that are exclusively controlled by EEG signals demonstrate suboptimal control performance. To address the difficulty of improving the control capabilities of brain-controlled cars while maintaining BCI performance, a fuzzy logic-based technique called as Fuzzy Brain-Control Fusion Control is introduced. This approach uses Fuzzy Discrete Event System (FDES) supervisory theory to verify the accuracy of the driver's brain-controlled directives. Concurrently, a fuzzy logic-based automatic controller is developed to generate decisions automatically in accordance with the present state of the vehicle via fuzzy reasoning. The final decision is then reached through the application of secondary fuzzy reasoning to the accuracy of the driver's instructions and the automated decisions to make adjustments that are more consistent with human intent. A clever BCI gadget known as the Consistent State Visual Evoked Potential (SSVEP) is utilized to show the viability of the proposed technique. We recommend that additional research should be conducted at this time to confirm that our recommended system may further improve the control execution of BCI-fueled cars, regardless of whether BCIs have special limitations.",https://pubmed.ncbi.nlm.nih.gov/39209118/,https://pubmed.ncbi.nlm.nih.gov/39209118/,English,Include,,Bio-inspired EEG signal computing using machine learning and fuzzy theory for decision making in future-oriented brain-controlled vehicles.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39208441,pubmed:39208441,PubMed,pubmed:39208441,Closed-loop auditory stimulation targeting alpha and theta oscillations during rapid eye movement sleep induces phase-dependent power and frequency changes.,Valeria Jaramillo;Henry Hebron;Sara Wong;Giuseppe Atzori;Ullrich Bartsch;Derk-Jan Dijk;Ines R Violante,2024,10.1093/sleep/zsae193,"Alpha and theta oscillations characterize the waking human electroencephalogram (EEG) and can be modulated by closed-loop auditory stimulation (CLAS). These oscillations also occur during rapid eye movement (REM) sleep, but their function here remains elusive. CLAS represents a promising tool to pinpoint how these brain oscillations contribute to brain function in humans. Here we investigate whether CLAS can modulate alpha and theta oscillations during REM sleep in a phase-dependent manner. We recorded high-density EEG during an extended overnight sleep period in 18 healthy young adults. Auditory stimulation was delivered during both phasic and tonic REM sleep in alternating 6-second ON and 6-second OFF windows. During the ON windows, stimuli were phase-locked to four orthogonal phases of ongoing alpha or theta oscillations detected in a frontal electrode. The phases of ongoing alpha and theta oscillations were targeted with high accuracy during REM sleep. Alpha and theta CLAS induced phase-dependent changes in power and frequency at the target location. Frequency-specific effects were observed for alpha trough (speeding up) and rising (slowing down) and theta trough (speeding up) conditions. CLAS-induced phase-dependent changes were observed during both REM sleep substages, even though auditory evoked potentials were very much reduced in phasic compared to tonic REM sleep. This study provides evidence that faster REM sleep rhythms can be modulated by CLAS in a phase-dependent manner. This offers a new approach to investigating how modulation of REM sleep oscillations affects the contribution of this vigilance state to brain function.",https://pubmed.ncbi.nlm.nih.gov/39208441/,https://pubmed.ncbi.nlm.nih.gov/39208441/,English,Include,,Closed-loop auditory stimulation targeting alpha and theta oscillations during rapid eye movement sleep induces phase-dependent power and frequency changes.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39208242,pubmed:39208242,PubMed,pubmed:39208242,Wavelet phase coherence of ictal scalp EEG-extracted muscle activity (SMA) as a biomarker for sudden unexpected death in epilepsy (SUDEP).,Adam C Gravitis;Krishram Sivendiran;Uilki Tufa;Katherine Zukotynski;Yotin Chinvarun;Orrin Devinsky;Richard Wennberg;Peter L Carlen;Berj L Bardakjian,2024,10.1002/epi4.12831,"Approximately 50 million people worldwide have epilepsy and 8-17% of the deaths in patients with epilepsy are attributed to sudden unexpected death in epilepsy (SUDEP). The goal of the present work was to establish a biomarker for SUDEP so that preventive treatment can be instituted. Seizure activity in patients with SUDEP and non-SUDEP was analyzed, specifically, the scalp EEG extracted muscle activity (SMA) and the average wavelet phase coherence (WPC) during seizures was computed for two frequency ranges (1-12 Hz, 13-30 Hz) to identify differences between the two groups. Ictal SMA in SUDEP patients showed a statistically higher average WPC value when compared to non-SUDEP patients for both frequency ranges. Area under curve for a cross-validated logistic classifier was 81%. Average WPC of ictal SMA is a candidate biomarker for early detection of SUDEP.",https://pubmed.ncbi.nlm.nih.gov/39208242/,https://pubmed.ncbi.nlm.nih.gov/39208242/,English,Include,,Wavelet phase coherence of ictal scalp EEG-extracted muscle activity (SMA) as a biomarker for sudden unexpected death in epilepsy (SUDEP).,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39208037,pubmed:39208037,PubMed,pubmed:39208037,Motor Imagery Recognition Based on GMM-JCSFE Model.,Chuncheng Liao;Shiyu Zhao;Jiacai Zhang,2024,10.1109/tnsre.2024.3451716,"Features from EEG microstate models, such as time-domain statistical features and state transition probabilities, are typically manually selected based on experience. However, traditional microstate models assume abrupt transitions between states, and the classification features can vary among individuals due to personal differences. To date, both empirical and theoretical classification results of EEG microstate features have not been entirely satisfactory. Here, we introduce an enhanced feature extraction method that combines Joint label-Common and label-Specific Feature Exploration (JCSFE) with Gaussian Mixture Models (GMM) to explore microstate features. First, GMMs are employed to represent the smooth transitions of EEG spatiotemporal features within microstate models. Second, category-common and category-specific features are identified by applying regularization constraints to linear classifiers. Third, a graph regularizer is used to extract subject-invariant microstate features. Experimental results on publicly available datasets demonstrate that the proposed model effectively encodes microstate features and improves the accuracy of motor imagery recognition across subjects. The primary code is accessible for download from the website: https://github.com/liaoliao3450/GMM-JCSFE.",https://pubmed.ncbi.nlm.nih.gov/39208037/,https://pubmed.ncbi.nlm.nih.gov/39208037/,English,Include,,Motor Imagery Recognition Based on GMM-JCSFE Model.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39207081,pubmed:39207081,PubMed,pubmed:39207081,Diagnostic Accuracy of the Persyst Automated Seizure Detector in the Neonatal Population.,Eleanor Duckworth;Daniyal Motan;Kitty Howse;Stewart Boyd;Ronit Pressler;Maria Chalia,2024,10.31083/j.jin2308150,"Neonatal seizures are diagnostically challenging and predominantly electrographic-only. Multichannel video continuous electroencephalography (cEEG) is the gold standard investigation, however, out-of-hours access to neurophysiology support can be limited. Automated seizure detection algorithms (SDAs) are designed to detect changes in EEG data, translated into user-friendly seizure probability trends. The aim of this study was to evaluate the diagnostic accuracy of the Persyst neonatal SDA in an intensive care setting. Single-centre retrospective service evaluation study in neonates undergoing cEEG during intensive care admission to Great Ormond Street Hospital (GOSH) between May 2019 and December 2022. Neonates with <44 weeks corrected gestational age, who had a cEEG recording duration >60 minutes, whilst inpatient in intensive care, were included in the study. One-hour cEEG clips were created for all cases (seizures detected) and controls (seizure-free) and analysed by the Persyst neonatal SDA. Expert neurophysiology reports of the cEEG recordings were used as the gold standard for diagnostic comparison. A receiver operating characteristic (ROC) curve was created using the highest seizure probability in each recording. Optimal seizure probability thresholds for sensitivity and specificity were identified. Eligibility screening produced 49 cases, and 49 seizure-free controls. Seizure prevalence within those patients eligible for the study, was approximately 19% with 35% mortality. The most common case seizure aetiology was hypoxic ischaemic injury (35%) followed by inborn errors of metabolism (18%). The ROC area under the curve was 0.94 with optimal probability thresholds 0.4 and 0.6. Applying a threshold of 0.6, produced 80% sensitivity and 98% specificity. The Persyst neonatal SDA demonstrates high diagnostic accuracy in identifying neonatal seizures; comparable to the accuracy of the standard Persyst SDA in adult populations, other neonatal SDAs, and amplitude integrated EEG (aEEG). Overdiagnosis of seizures is a risk, particularly from cEEG recording artefact. To fully examine its clinical utility, further investigation of the Persyst neonatal SDA's accuracy is required, as well as confirming the optimal seizure probability thresholds in a larger patient cohort.",https://pubmed.ncbi.nlm.nih.gov/39207081/,https://pubmed.ncbi.nlm.nih.gov/39207081/,English,Include,,Diagnostic Accuracy of the Persyst Automated Seizure Detector in the Neonatal Population.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39207066,pubmed:39207066,PubMed,pubmed:39207066,EEG-Based Feature Classification Combining 3D-Convolutional Neural Networks with Generative Adversarial Networks for Motor Imagery.,Chengcheng Fan;Banghua Yang;Xiaoou Li;Shouwei Gao;Peng Zan,2024,10.31083/j.jin2308153,"The adoption of convolutional neural networks (CNNs) for decoding electroencephalogram (EEG)-based motor imagery (MI) in brain-computer interfaces has significantly increased recently. The effective extraction of motor imagery features is vital due to the variability among individuals and temporal states. This study introduces a novel network architecture, 3D-convolutional neural network-generative adversarial network (3D-CNN-GAN), for decoding both within-session and cross-session motor imagery. Initially, EEG signals were extracted over various time intervals using a sliding window technique, capturing temporal, frequency, and phase features to construct a temporal-frequency-phase feature (TFPF) three-dimensional feature map. Generative adversarial networks (GANs) were then employed to synthesize artificial data, which, when combined with the original datasets, expanded the data capacity and enhanced functional connectivity. Moreover, GANs proved capable of learning and amplifying the brain connectivity patterns present in the existing data, generating more distinctive brain network features. A compact, two-layer 3D-CNN model was subsequently developed to efficiently decode these TFPF features. Taking into account session and individual differences in EEG data, tests were conducted on both the public GigaDB dataset and the SHU laboratory dataset. On the GigaDB dataset, our 3D-CNN and 3D-CNN-GAN models achieved two-class within-session motor imagery accuracies of 76.49% and 77.03%, respectively, demonstrating the algorithm's effectiveness and the improvement provided by data augmentation. Furthermore, on the SHU dataset, the 3D-CNN and 3D-CNN-GAN models yielded two-class within-session motor imagery accuracies of 67.64% and 71.63%, and cross-session motor imagery accuracies of 58.06% and 63.04%, respectively. The 3D-CNN-GAN algorithm significantly enhances the generalizability of EEG-based motor imagery brain-computer interfaces (BCIs). Additionally, this research offers valuable insights into the potential applications of motor imagery BCIs.",https://pubmed.ncbi.nlm.nih.gov/39207066/,https://pubmed.ncbi.nlm.nih.gov/39207066/,English,Include,,EEG-Based Feature Classification Combining 3D-Convolutional Neural Networks with Generative Adversarial Networks for Motor Imagery.,Exclude,No performance metrics reported,No metrics found in full text,,0.9,0.6,
pubmed:39206447,pubmed:39206447,PubMed,pubmed:39206447,Abnormal theta-band rhythm: EEG abnormality as potential biomarkers for disease severity in pediatric anti-NMDAR encephalitis.,Yumie Tamura;Mitsumasa Fukuda;Akihiko Ishiyama;Hiroya Nishida;Hirofumi Kashii;Hideaki Mashimo;Kenji Inoue;Hiroshi Sakuma;Satoko Kumada,2024,10.3389/fneur.2021.711376,"Anti-N-methyl-D-aspartate receptor (NMDAR) encephalitis in children often requires early immunosuppressive therapy before antibody detection. While various electroencephalogram (EEG) patterns, including extreme delta brushes (EDBs), have been reported in adults, pediatric EEG characteristics remain understudied. This study aims to assist clinicians in identifying severe cases early, potentially improving treatment outcomes through prompt intervention. This retrospective case series examined EEG features influenced by disease severity in children with anti-NMDAR encephalitis. We evaluated six children (1-13 years old; four females, two males) treated at Tokyo Metropolitan Neurological Hospital from January 2007 to January 2023. The severity of autoimmune encephalitis in our patients was assessed using the Clinical Assessment Scale in Autoimmune Encephalitis (CASE). The literature proposes a severity classification for the CASE score, wherein scores of 0-8 points are categorized as mild, 9-18 points as moderate, and 19-27 points as severe. In our patients, CASE scores ranged from 4 to 25 (median:19). We reviewed acute-phase EEG recordings, including 13 long-term videos and 58 conventional recordings. None of the patients maintained a normal posterior-dominant rhythm, and only one exhibited EDBs. Notably, three patients with higher CASE scores (≥15) displayed abnormal theta-band rhythm during non-REM sleep and prolonged EEG recovery times. Our findings suggest that abnormal theta-band rhythms may serve as a potential acute-phase EEG biomarker for severe anti-NMDAR encephalitis in children.",,https://pubmed.ncbi.nlm.nih.gov/39206447/,English,Exclude,Review/survey papers,Abnormal theta-band rhythm: EEG abnormality as potential biomarkers for disease severity in pediatric anti-NMDAR encephalitis.,,,,,0.95,0.6,
pubmed:39205122,pubmed:39205122,PubMed,pubmed:39205122,Independent Vector Analysis for Feature Extraction in Motor Imagery Classification.,Caroline Pires Alavez Moraes;Lucas Heck Dos Santos;Denis Gustavo Fantinato;Aline Neves;Tülay Adali,2024,10.1109/tbme.2024.3364704,"Independent vector analysis (IVA) can be viewed as an extension of independent component analysis (ICA) to multiple datasets. It exploits the statistical dependency between different datasets through mutual information. In the context of motor imagery classification based on electroencephalogram (EEG) signals for the brain-computer interface (BCI), several methods have been proposed to extract features efficiently, mainly based on common spatial patterns, filter banks, and deep learning. However, most methods use only one dataset at a time, which may not be sufficient for dealing with a multi-source retrieving problem in certain scenarios. From this perspective, this paper proposes an original approach for feature extraction through multiple datasets based on IVA to improve the classification of EEG-based motor imagery movements. The IVA components were used as features to classify imagined movements using consolidated classifiers (support vector machines and K-nearest neighbors) and deep classifiers (EEGNet and EEGInception). The results show an interesting performance concerning the clustering of MI-based BCI patients, and the proposed method reached an average accuracy of 86.7%.",https://pubmed.ncbi.nlm.nih.gov/39205122/,https://pubmed.ncbi.nlm.nih.gov/39205122/,English,Include,,Independent Vector Analysis for Feature Extraction in Motor Imagery Classification.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39205120,pubmed:39205120,PubMed,pubmed:39205120,Advanced Sensing System for Sleep Bruxism across Multiple Postures via EMG and Machine Learning.,Jahan Zeb Gul;Noor Fatima;Zia Mohy Ud Din;Maryam Khan;Woo Young Kim;Muhammad Muqeet Rehman,2024,10.14704/nq.2022.20.5.nq22771,"Diagnosis of bruxism is challenging because not all contractions of the masticatory muscles can be classified as bruxism. Conventional methods for sleep bruxism detection vary in effectiveness. Some provide objective data through EMG, ECG, or EEG; others, such as dental implants, are less accessible for daily practice. These methods have targeted the masseter as the key muscle for bruxism detection. However, it is important to consider that the temporalis muscle is also active during bruxism among masticatory muscles. Moreover, studies have predominantly examined sleep bruxism in the supine position, but other anatomical positions are also associated with sleep. In this research, we have collected EMG data to detect the maximum voluntary contraction of the temporalis and masseter muscles in three primary anatomical positions associated with sleep, i.e., supine and left and right lateral recumbent positions. A total of 10 time domain features were extracted, and six machine learning classifiers were compared, with random forest outperforming others. The models achieved better accuracies in the detection of sleep bruxism with the temporalis muscle. An accuracy of 93.33% was specifically found for the left lateral recumbent position among the specified anatomical positions. These results indicate a promising direction of machine learning in clinical applications, facilitating enhanced diagnosis and management of sleep bruxism.",https://pubmed.ncbi.nlm.nih.gov/39205120/,https://pubmed.ncbi.nlm.nih.gov/39205120/,English,Include,,Advanced Sensing System for Sleep Bruxism across Multiple Postures via EMG and Machine Learning.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39205067,pubmed:39205067,PubMed,pubmed:39205067,One-Channel Wearable Mental Stress State Monitoring System.,Lamis Abdul Kader;Fares Al-Shargie;Usman Tariq;Hasan Al-Nashash,2024,10.1109/i2mtc.2013.6555658,"Assessments of stress can be performed using physiological signals, such as electroencephalograms (EEGs) and galvanic skin response (GSR). Commercialized systems that are used to detect stress with EEGs require a controlled environment with many channels, which prohibits their daily use. Fortunately, there is a rise in the utilization of wearable devices for stress monitoring, offering more flexibility. In this paper, we developed a wearable monitoring system that integrates both EEGs and GSR. The novelty of our proposed device is that it only requires one channel to acquire both physiological signals. Through sensor fusion, we achieved an improved accuracy, lower cost, and improved ease of use. We tested the proposed system experimentally on twenty human subjects. We estimated the power spectrum of the EEG signals and utilized five machine learning classifiers to differentiate between two levels of mental stress. Furthermore, we investigated the optimum electrode location on the scalp when using only one channel. Our results demonstrate the system's capability to classify two levels of mental stress with a maximum accuracy of 70.3% when using EEGs alone and 84.6% when using fused EEG and GSR data. This paper shows that stress detection is reliable using only one channel on the prefrontal and ventrolateral prefrontal regions of the brain.",https://pubmed.ncbi.nlm.nih.gov/39205067/,https://pubmed.ncbi.nlm.nih.gov/39205067/,English,Include,,One-Channel Wearable Mental Stress State Monitoring System.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39205057,pubmed:39205057,PubMed,pubmed:39205057,An Approach of Query Audience's Attention in Virtual Speech.,Hongbo Kang;Rui Yang;Ruoyang Song;Chunjie Yang;Wenqing Wang,2024,10.1016/j.actpsy.2014.04.001,"Virtual speeches are a very popular way for remote multi-user communication, but it has the disadvantage of the lack of eye contact. This paper proposes the evaluation of an online audience attention based on gaze tracking. Our research only uses webcams to capture the audience's head posture, gaze time, and other features, providing a low-cost method for attention monitoring with reference values across multiple domains. Meantime, we also propose a set of indexes which can be used to evaluate the audience's degree of attention, making up for the fact that the speaker cannot gauge the audience's concentration through eye contact during online speeches. We selected 96 students for a 20 min group simulation session and used Spearman's correlation coefficient to analyze the correlation between our evaluation indicators and concentration. The result showed that each evaluation index has a significant correlation with the degree of attention (",,https://pubmed.ncbi.nlm.nih.gov/39205057/,English,Exclude,Not EEG-BCI focused,An Approach of Query Audience's Attention in Virtual Speech.,,,,,0.9,0.6,
pubmed:39204995,pubmed:39204995,PubMed,pubmed:39204995,Air Traffic Controller Workload Detection Based on EEG Signals.,Quan Shao;Hui Li;Zhe Sun,2024,10.1109/tpami.2005.159,"The assessment of the cognitive workload experienced by air traffic controllers is a complex and prominent issue in the research community. This study introduces new indicators related to gamma waves to detect controllers' workload and develops experimental protocols to capture their EEG data and NASA-TXL data. Then, statistical tests, including the Shapiro-Wilk test and ANOVA, were used to verify whether there was a significant difference between the workload data of the controllers in different scenarios. Furthermore, the Support Vector Machine (SVM) classifier was employed to assess the detection accuracy of these indicators across four categorizations. According to the outcomes, hypotheses suggesting a strong correlation between gamma waves and an air traffic controller's workload were put forward and subsequently verified; meanwhile, compared with traditional indicators, the indicators associated with gamma waves proposed in this paper have higher accuracy. In addition, to explore the applicability of the indicator, sensitive channels were selected based on the mRMR algorithm for the indicator with the highest accuracy, β + θ + α + γ, showcasing a recognition rate of a single channel exceeding 95% of the full channel, which meets the requirements of convenience and accuracy in practical applications. In conclusion, this study demonstrates that utilizing EEG gamma wave-associated indicators can offer valuable insights into analyzing workload levels among air traffic controllers.",https://pubmed.ncbi.nlm.nih.gov/39204995/,https://pubmed.ncbi.nlm.nih.gov/39204995/,English,Include,,Air Traffic Controller Workload Detection Based on EEG Signals.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39204960,pubmed:39204960,PubMed,pubmed:39204960,Efficient Sleep Stage Identification Using Piecewise Linear EEG Signal Reduction: A Novel Algorithm for Sleep Disorder Diagnosis.,Yash Paul;Rajesh Singh;Surbhi Sharma;Saurabh Singh;In-Ho Ra,2024,10.1016/j.eswa.2011.12.043,"Sleep is a vital physiological process for human health, and accurately detecting various sleep states is crucial for diagnosing sleep disorders. This study presents a novel algorithm for identifying sleep stages using EEG signals, which is more efficient and accurate than the state-of-the-art methods. The key innovation lies in employing a piecewise linear data reduction technique called the Halfwave method in the time domain. This method simplifies EEG signals into a piecewise linear form with reduced complexity while preserving sleep stage characteristics. Then, a features vector with six statistical features is built using parameters obtained from the reduced piecewise linear function. We used the MIT-BIH Polysomnographic Database to test our proposed method, which includes more than 80 h of long data from different biomedical signals with six main sleep classes. We used different classifiers and found that the K-Nearest Neighbor classifier performs better in our proposed method. According to experimental findings, the average sensitivity, specificity, and accuracy of the proposed algorithm on the Polysomnographic Database considering eight records is estimated as 94.82%, 96.65%, and 95.73%, respectively. Furthermore, the algorithm shows promise in its computational efficiency, making it suitable for real-time applications such as sleep monitoring devices. Its robust performance across various sleep classes suggests its potential for widespread clinical adoption, making significant advances in the knowledge, detection, and management of sleep problems.",https://pubmed.ncbi.nlm.nih.gov/39204960/,https://pubmed.ncbi.nlm.nih.gov/39204960/,English,Include,,Efficient Sleep Stage Identification Using Piecewise Linear EEG Signal Reduction: A Novel Algorithm for Sleep Disorder Diagnosis.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39204910,pubmed:39204910,PubMed,pubmed:39204910,A Method for the Spatial Interpolation of EEG Signals Based on the Bidirectional Long Short-Term Memory Network.,Wenlong Hu;Bowen Ji;Kunpeng Gao,2024,10.1109/tkde.2020.3025580,"The precision of electroencephalograms (EEGs) significantly impacts the performance of brain-computer interfaces (BCI). Currently, the majority of research into BCI technology gives priority to lightweight design and a reduced electrode count to make it more suitable for application in wearable environments. This paper introduces a deep learning-based time series bidirectional (BiLSTM) network that is designed to capture the inherent characteristics of EEG channels obtained from neighboring electrodes. It aims to predict the EEG data time series and facilitate the conversion process from low-density EEG signals to high-density EEG signals. BiLSTM pays more attention to the dependencies in time series data rather than mathematical maps, and the root mean square error can be effectively restricted to below 0.4μV, which is less than half the error in traditional methods. After expanding the BCI Competition III 3a dataset from 18 channels to 60 channels, we conducted classification experiments on four types of motor imagery tasks. Compared to the original low-density EEG signals (18 channels), the classification accuracy was around 82%, an increase of about 20%. When juxtaposed with real high-density signals, the increment in the error rate remained below 5%. The expansion of the EEG channels showed a substantial and notable improvement compared with the original low-density signals.",https://pubmed.ncbi.nlm.nih.gov/39204910/,https://pubmed.ncbi.nlm.nih.gov/39204910/,English,Include,,A Method for the Spatial Interpolation of EEG Signals Based on the Bidirectional Long Short-Term Memory Network.,Include,,"taset from 18 channels to 60 channels, we conducted classification experiments on four types of motor imagery tasks. Compared to the original low-density EEG signals (18 channels), the classification accuracy was around 82%, an increase of about 20%. When juxtaposed with real high-density signals, the increment in the error rate remained below 5%. The expansion of the EEG channels showed a substan",,0.95,0.6,
pubmed:39204903,pubmed:39204903,PubMed,pubmed:39204903,MOVING: A Multi-Modal Dataset of EEG Signals and Virtual Glove Hand Tracking.,Enrico Mattei;Daniele Lozzi;Alessandro Di Matteo;Alessia Cipriani;Costanzo Manes;Giuseppe Placidi,2024,10.3390/s21144626,"Brain-computer interfaces (BCIs) are pivotal in translating neural activities into control commands for external assistive devices. Non-invasive techniques like electroencephalography (EEG) offer a balance of sensitivity and spatial-temporal resolution for capturing brain signals associated with motor activities. This work introduces MOVING, a Multi-Modal dataset of EEG signals and Virtual Glove Hand Tracking. This dataset comprises neural EEG signals and kinematic data associated with three hand movements-open/close, finger tapping, and wrist rotation-along with a rest period. The dataset, obtained from 11 subjects using a 32-channel dry wireless EEG system, also includes synchronized kinematic data captured by a Virtual Glove (VG) system equipped with two orthogonal Leap Motion Controllers. The use of these two devices allows for fast assembly (∼1 min), although introducing more noise than the gold standard devices for data acquisition. The study investigates which frequency bands in EEG signals are the most informative for motor task classification and the impact of baseline reduction on gesture recognition. Deep learning techniques, particularly EEGnetV4, are applied to analyze and classify movements based on the EEG data. This dataset aims to facilitate advances in BCI research and in the development of assistive devices for people with impaired hand mobility. This study contributes to the repository of EEG datasets, which is continuously increasing with data from other subjects, which is hoped to serve as benchmarks for new BCI approaches and applications.",https://pubmed.ncbi.nlm.nih.gov/39204903/,https://pubmed.ncbi.nlm.nih.gov/39204903/,English,Include,,MOVING: A Multi-Modal Dataset of EEG Signals and Virtual Glove Hand Tracking.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39204873,pubmed:39204873,PubMed,pubmed:39204873,Detection of Pilots' Psychological Workload during Turning Phases Using EEG Characteristics.,Li Ji;Leiye Yi;Haiwei Li;Wenjie Han;Ningning Zhang,2024,10.1016/j.tust.2018.08.032,"Pilot behavior is crucial for aviation safety. This study aims to investigate the EEG characteristics of pilots, refine training assessment methodologies, and bolster flight safety measures. The collected EEG signals underwent initial preprocessing. The EEG characteristic analysis was performed during left and right turns, involving the calculation of the energy ratio of beta waves and Shannon entropy. The psychological workload of pilots during different flight phases was quantified as well. Based on the EEG characteristics, the pilots' psychological workload was classified through the use of a support vector machine (SVM). The study results showed significant changes in the energy ratio of beta waves and Shannon entropy during left and right turns compared to the cruising phase. Additionally, the pilots' psychological workload was found to have increased during these turning phases. Using support vector machines to detect the pilots' psychological workload, the classification accuracy for the training set was 98.92%, while for the test set, it was 93.67%. This research holds significant importance in understanding pilots' psychological workload.",https://pubmed.ncbi.nlm.nih.gov/39204873/,https://pubmed.ncbi.nlm.nih.gov/39204873/,English,Include,,Detection of Pilots' Psychological Workload during Turning Phases Using EEG Characteristics.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39204804,pubmed:39204804,PubMed,pubmed:39204804,Driving Attention State Detection Based on GRU-EEGNet.,Xiaoli Wu;Changcheng Shi;Lirong Yan,2024,10.1109/tits.2022.3159602,"The present study utilizes the significant differences in θ, α, and β band power spectra observed in electroencephalograms (EEGs) during distracted versus focused driving. Three subtasks, visual distraction, auditory distraction, and cognitive distraction, were designed to appear randomly during driving simulations. The θ, α, and β band power spectra of the EEG signals of the four driving attention states were extracted, and SVM, EEGNet, and GRU-EEGNet models were employed for the detection of the driving attention states, respectively. Online experiments were conducted. The extraction of the θ, α, and β band power spectrum features of the EEG signals was found to be a more effective method than the extraction of the power spectrum features of the whole EEG signals for the detection of driving attention states. The driving attention state detection accuracy of the proposed GRU-EEGNet model is improved by 6.3% and 12.8% over the EEGNet model and PSD_SVM method, respectively. The EEG decoding method combining EEG features and an improved deep learning algorithm, which effectively improves the driving attention state detection accuracy, was manually and preliminarily selected based on the results of existing studies.",https://pubmed.ncbi.nlm.nih.gov/39204804/,https://pubmed.ncbi.nlm.nih.gov/39204804/,English,Include,,Driving Attention State Detection Based on GRU-EEGNet.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39199779,pubmed:39199779,PubMed,pubmed:39199779,Optogenetic Brain-Computer Interfaces.,Feifang Tang;Feiyang Yan;Yushan Zhong;Jinqian Li;Hui Gong;Xiangning Li,2024,10.1038/505612a,"The brain-computer interface (BCI) is one of the most powerful tools in neuroscience and generally includes a recording system, a processor system, and a stimulation system. Optogenetics has the advantages of bidirectional regulation, high spatiotemporal resolution, and cell-specific regulation, which expands the application scenarios of BCIs. In recent years, optogenetic BCIs have become widely used in the lab with the development of materials and software. The systems were designed to be more integrated, lightweight, biocompatible, and power efficient, as were the wireless transmission and chip-level embedded BCIs. The software is also constantly improving, with better real-time performance and accuracy and lower power consumption. On the other hand, as a cutting-edge technology spanning multidisciplinary fields including molecular biology, neuroscience, material engineering, and information processing, optogenetic BCIs have great application potential in neural decoding, enhancing brain function, and treating neural diseases. Here, we review the development and application of optogenetic BCIs. In the future, combined with other functional imaging techniques such as near-infrared spectroscopy (fNIRS) and functional magnetic resonance imaging (fMRI), optogenetic BCIs can modulate the function of specific circuits, facilitate neurological rehabilitation, assist perception, establish a brain-to-brain interface, and be applied in wider application scenarios.",,https://pubmed.ncbi.nlm.nih.gov/39199779/,English,Exclude,Review/survey papers,Optogenetic Brain-Computer Interfaces.,,,,,0.95,0.6,
pubmed:39199740,pubmed:39199740,PubMed,pubmed:39199740,Emotion Detection from EEG Signals Using Machine Deep Learning Models.,João Vitor Marques Rabelo Fernandes;Auzuir Ripardo de Alexandria;João Alexandre Lobo Marques;Débora Ferreira de Assis;Pedro Crosara Motta;Bruno Riccelli Dos Santos Silva,2024,10.1109/taffc.2018.2817622,"Detecting emotions is a growing field aiming to comprehend and interpret human emotions from various data sources, including text, voice, and physiological signals. Electroencephalogram (EEG) is a unique and promising approach among these sources. EEG is a non-invasive monitoring technique that records the brain's electrical activity through electrodes placed on the scalp's surface. It is used in clinical and research contexts to explore how the human brain responds to emotions and cognitive stimuli. Recently, its use has gained interest in real-time emotion detection, offering a direct approach independent of facial expressions or voice. This is particularly useful in resource-limited scenarios, such as brain-computer interfaces supporting mental health. The objective of this work is to evaluate the classification of emotions (positive, negative, and neutral) in EEG signals using machine learning and deep learning, focusing on Graph Convolutional Neural Networks (GCNN), based on the analysis of critical attributes of the EEG signal (Differential Entropy (DE), Power Spectral Density (PSD), Differential Asymmetry (DASM), Rational Asymmetry (RASM), Asymmetry (ASM), Differential Causality (DCAU)). The electroencephalography dataset used in the research was the public SEED dataset (SJTU Emotion EEG Dataset), obtained through auditory and visual stimuli in segments from Chinese emotional movies. The experiment employed to evaluate the model results was ""subject-dependent"". In this method, the Deep Neural Network (DNN) achieved an accuracy of 86.08%, surpassing SVM, albeit with significant processing time due to the optimization characteristics inherent to the algorithm. The GCNN algorithm achieved an average accuracy of 89.97% in the subject-dependent experiment. This work contributes to emotion detection in EEG, emphasizing the effectiveness of different models and underscoring the importance of selecting appropriate features and the ethical use of these technologies in practical applications. The GCNN emerges as the most promising methodology for future research.",https://pubmed.ncbi.nlm.nih.gov/39199740/,https://pubmed.ncbi.nlm.nih.gov/39199740/,English,Include,,Emotion Detection from EEG Signals Using Machine Deep Learning Models.,Include,," and visual stimuli in segments from Chinese emotional movies. The experiment employed to evaluate the model results was ""subject-dependent"". In this method, the Deep Neural Network (DNN) achieved an accuracy of 86.08%, surpassing SVM, albeit with significant processing time due to the optimization characteristics inherent to the algorithm. The GCNN algorithm achieved an average accuracy of 89.97%",,0.95,0.6,
pubmed:39199739,pubmed:39199739,PubMed,pubmed:39199739,Single-Trial Detection and Classification of Event-Related Optical Signals for a Brain-Computer Interface Application.,Nicole Chiou;Mehmet Günal;Sanmi Koyejo;David Perpetuini;Antonio Maria Chiarelli;Kathy A Low;Monica Fabiani;Gabriele Gratton,2024,10.1111/1469-8986.00058,"Event-related optical signals (EROS) measure fast modulations in the brain's optical properties related to neuronal activity. EROS offer a high spatial and temporal resolution and can be used for brain-computer interface (BCI) applications. However, the ability to classify single-trial EROS remains unexplored. This study evaluates the performance of neural network methods for single-trial classification of motor response-related EROS. EROS activity was obtained from a high-density recording montage covering the motor cortex during a two-choice reaction time task involving responses with the left or right hand. This study utilized a convolutional neural network (CNN) approach to extract spatiotemporal features from EROS data and perform classification of left and right motor responses. Subject-specific classifiers trained on EROS phase data outperformed those trained on intensity data, reaching an average single-trial classification accuracy of around 63%. Removing low-frequency noise from intensity data is critical for achieving discriminative classification results with this measure. Our results indicate that deep learning with high-spatial-resolution signals, such as EROS, can be successfully applied to single-trial classifications.",https://pubmed.ncbi.nlm.nih.gov/39199739/,https://pubmed.ncbi.nlm.nih.gov/39199739/,English,Include,,Single-Trial Detection and Classification of Event-Related Optical Signals for a Brain-Computer Interface Application.,Include,,"classification of left and right motor responses. Subject-specific classifiers trained on EROS phase data outperformed those trained on intensity data, reaching an average single-trial classification accuracy of around 63%. Removing low-frequency noise from intensity data is critical for achieving discriminative classification results with this measure. Our results indicate that deep learning with",,0.95,0.6,
pubmed:39199539,pubmed:39199539,PubMed,pubmed:39199539,Detection of Anxiety-Based Epileptic Seizures in EEG Signals Using Fuzzy Features and Parrot Optimization-Tuned LSTM.,Kamini Kamakshi Palanisamy;Arthi Rengaraj,2024,10.3390/s24113360,"In humans, epilepsy is diagnosed through electroencephalography (EEG) signals. Epileptic seizures (ESs) arise due to anxiety. The detection of anxiety-based seizures is challenging for radiologists, and there is a limited availability of anxiety-based EEG signals. Data augmentation methods are required to increase the number of novel samples. An epileptic seizure arises due to anxiety, which manifests as variations in EEG signal patterns consisting of changes in the size and shape of the signal. In this study, anxiety EEG signals were synthesized by applying data augmentation methods such as random data augmentation (RDA) to existing epileptic seizure signals from the Bonn EEG dataset. The data-augmented anxiety seizure signals were processed using three algorithms-(i) fuzzy C-means-particle swarm optimization-long short-term memory (FCM-PS-LSTM), (ii) particle swarm optimization-long short-term memory (PS-LSTM), and (iii) parrot optimization LSTM (PO-LSTM)-for the detection of anxiety ESs via EEG signals. The predicted accuracies of detecting ESs through EEG signals using the proposed algorithms-namely, (i) FCM-PS-LSTM, (ii) PS-LSTM, and (iii) PO-LSTM-were about 98%, 98.5%, and 96%, respectively.",https://pubmed.ncbi.nlm.nih.gov/39199539/,https://pubmed.ncbi.nlm.nih.gov/39199539/,English,Include,,Detection of Anxiety-Based Epileptic Seizures in EEG Signals Using Fuzzy Features and Parrot Optimization-Tuned LSTM.,Include,,"thesized by applying data augmentation methods such as random data augmentation (RDA) to existing epileptic seizure signals from the Bonn EEG dataset. The data-augmented anxiety seizure signals were processed using three algorithms-(i) fuzzy C-means-particle swarm optimization-long short-term memory (FCM-PS-LSTM), (ii) particle swarm optimization-long short-term memory (PS-LSTM), and (iii) parrot ",,0.95,0.6,
pubmed:39199537,pubmed:39199537,PubMed,pubmed:39199537,Evaluation of Different Visual Feedback Methods for Brain-Computer Interfaces (BCI) Based on Code-Modulated Visual Evoked Potentials (cVEP).,Milán András Fodor;Hannah Herschel;Atilla Cantürk;Gernot Heisenberg;Ivan Volosyak,2024,10.1109/smc53992.2023.10394503,"Brain-computer interfaces (BCIs) enable direct communication between the brain and external devices using electroencephalography (EEG) signals. BCIs based on code-modulated visual evoked potentials (cVEPs) are based on visual stimuli, thus appropriate visual feedback on the interface is crucial for an effective BCI system. Many previous studies have demonstrated that implementing visual feedback can improve information transfer rate (ITR) and reduce fatigue. This research compares a dynamic interface, where target boxes change their sizes based on detection certainty, with a threshold bar interface in a three-step cVEP speller. In this study, we found that both interfaces perform well, with slight variations in accuracy, ITR, and output characters per minute (OCM). Notably, some participants showed significant performance improvements with the dynamic interface and found it less distracting compared to the threshold bars. These results suggest that while average performance metrics are similar, the dynamic interface can provide significant benefits for certain users. This study underscores the potential for personalized interface choices to enhance BCI user experience and performance. By improving user friendliness, performance, and reducing distraction, dynamic visual feedback could optimize BCI technology for a broader range of users.",https://pubmed.ncbi.nlm.nih.gov/39199537/,https://pubmed.ncbi.nlm.nih.gov/39199537/,English,Include,,Evaluation of Different Visual Feedback Methods for Brain-Computer Interfaces (BCI) Based on Code-Modulated Visual Evoked Potentials (cVEP).,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39199530,pubmed:39199530,PubMed,pubmed:39199530,EEG-Based Seizure Prediction Using Hybrid DenseNet-ViT Network with Attention Fusion.,Shasha Yuan;Kuiting Yan;Shihan Wang;Jin-Xing Liu;Juan Wang,2024,10.3390/app11167661,"Epilepsy seizure prediction is vital for enhancing the quality of life for individuals with epilepsy. In this study, we introduce a novel hybrid deep learning architecture, merging DenseNet and Vision Transformer (ViT) with an attention fusion layer for seizure prediction. DenseNet captures hierarchical features and ensures efficient parameter usage, while ViT offers self-attention mechanisms and global feature representation. The attention fusion layer effectively amalgamates features from both networks, guaranteeing the most relevant information is harnessed for seizure prediction. The raw EEG signals were preprocessed using the short-time Fourier transform (STFT) to implement time-frequency analysis and convert EEG signals into time-frequency matrices. Then, they were fed into the proposed hybrid DenseNet-ViT network model to achieve end-to-end seizure prediction. The CHB-MIT dataset, including data from 24 patients, was used for evaluation and the leave-one-out cross-validation method was utilized to evaluate the performance of the proposed model. Our results demonstrate superior performance in seizure prediction, exhibiting high accuracy and low redundancy, which suggests that combining DenseNet, ViT, and the attention mechanism can significantly enhance prediction capabilities and facilitate more precise therapeutic interventions.",https://pubmed.ncbi.nlm.nih.gov/39199530/,https://pubmed.ncbi.nlm.nih.gov/39199530/,English,Include,,EEG-Based Seizure Prediction Using Hybrid DenseNet-ViT Network with Attention Fusion.,Include,,"ation and the leave-one-out cross-validation method was utilized to evaluate the performance of the proposed model. Our results demonstrate superior performance in seizure prediction, exhibiting high accuracy and low redundancy, which suggests that combining DenseNet, ViT, and the attention mechanism can significantly enhance prediction capabilities and facilitate more precise therapeutic interven",,0.95,0.25,cv_reported
pubmed:39199511,pubmed:39199511,PubMed,pubmed:39199511,EEG-fNIRS-Based Emotion Recognition Using Graph Convolution and Capsule Attention Network.,Guijun Chen;Yue Liu;Xueying Zhang,2024,10.1111/j.1751-9004.2010.00324.x,"Electroencephalogram (EEG) and functional near-infrared spectroscopy (fNIRS) can objectively reflect a person's emotional state and have been widely studied in emotion recognition. However, the effective feature fusion and discriminative feature learning from EEG-fNIRS data is challenging. In order to improve the accuracy of emotion recognition, a graph convolution and capsule attention network model (GCN-CA-CapsNet) is proposed. Firstly, EEG-fNIRS signals are collected from 50 subjects induced by emotional video clips. And then, the features of the EEG and fNIRS are extracted; the EEG-fNIRS features are fused to generate higher-quality primary capsules by graph convolution with the Pearson correlation adjacency matrix. Finally, the capsule attention module is introduced to assign different weights to the primary capsules, and higher-quality primary capsules are selected to generate better classification capsules in the dynamic routing mechanism. We validate the efficacy of the proposed method on our emotional EEG-fNIRS dataset with an ablation study. Extensive experiments demonstrate that the proposed GCN-CA-CapsNet method achieves a more satisfactory performance against the state-of-the-art methods, and the average accuracy can increase by 3-11%.",https://pubmed.ncbi.nlm.nih.gov/39199511/,https://pubmed.ncbi.nlm.nih.gov/39199511/,English,Include,,EEG-fNIRS-Based Emotion Recognition Using Graph Convolution and Capsule Attention Network.,Include,,"tional state and have been widely studied in emotion recognition. However, the effective feature fusion and discriminative feature learning from EEG-fNIRS data is challenging. In order to improve the accuracy of emotion recognition, a graph convolution and capsule attention network model (GCN-CA-CapsNet) is proposed. Firstly, EEG-fNIRS signals are collected from 50 subjects induced by emotional vi",,0.95,0.6,
pubmed:39199509,pubmed:39199509,PubMed,pubmed:39199509,CSA-SA-CRTNN: A Dual-Stream Adaptive Convolutional Cyclic Hybrid Network Combining Attention Mechanisms for EEG Emotion Recognition.,Ren Qian;Xin Xiong;Jianhua Zhou;Hongde Yu;Kaiwen Sha,2024,10.1007/s42486-021-00078-y,"In recent years, EEG-based emotion recognition technology has made progress, but there are still problems of low model efficiency and loss of emotional information, and there is still room for improvement in recognition accuracy. To fully utilize EEG's emotional information and improve recognition accuracy while reducing computational costs, this paper proposes a Convolutional-Recurrent Hybrid Network with a dual-stream adaptive approach and an attention mechanism (CSA-SA-CRTNN). Firstly, the model utilizes a CSAM module to assign corresponding weights to EEG channels. Then, an adaptive dual-stream convolutional-recurrent network (SA-CRNN and MHSA-CRNN) is applied to extract local spatial-temporal features. After that, the extracted local features are concatenated and fed into a temporal convolutional network with a multi-head self-attention mechanism (MHSA-TCN) to capture global information. Finally, the extracted EEG information is used for emotion classification. We conducted binary and ternary classification experiments on the DEAP dataset, achieving 99.26% and 99.15% accuracy for arousal and valence in binary classification and 97.69% and 98.05% in ternary classification, and on the SEED dataset, we achieved an accuracy of 98.63%, surpassing relevant algorithms. Additionally, the model's efficiency is significantly higher than other models, achieving better accuracy with lower resource consumption.",https://pubmed.ncbi.nlm.nih.gov/39199509/,https://pubmed.ncbi.nlm.nih.gov/39199509/,English,Include,,CSA-SA-CRTNN: A Dual-Stream Adaptive Convolutional Cyclic Hybrid Network Combining Attention Mechanisms for EEG Emotion Recognition.,Include,,"-based emotion recognition technology has made progress, but there are still problems of low model efficiency and loss of emotional information, and there is still room for improvement in recognition accuracy. To fully utilize EEG's emotional information and improve recognition accuracy while reducing computational costs, this paper proposes a Convolutional-Recurrent Hybrid Network with a dual-str",,0.95,0.6,
pubmed:39199502,pubmed:39199502,PubMed,pubmed:39199502,Cognitive Workload Detection of Air Traffic Controllers Based on mRMR and Fewer EEG Channels.,Li Hui;Zhu Pei;Shao Quan;Xue Ke;Sun Zhe,2024,10.14257/ijca.2016.9.3.30,"For air traffic controllers, the extent of their cognitive workload can significantly impact their cognitive function and response time, consequently influencing their operational efficiency or even resulting in safety incidents. In order to enhance the accuracy and efficiency in determining the cognitive workload of air traffic controllers, a cognitive workload detection method for air traffic controllers based on mRMR and fewer EEG channels was proposed in this study. First of all, a set of features related to gamma waves was initially proposed; subsequently, an EEG feature evaluation method based on the mRMR algorithm was employed to pinpoint the most relevant indicators for the detection of the cognitive workload. Consequently, a model for the detection of the cognitive workload of controllers was developed, and it was optimized by filtering out channel combinations that exhibited higher sensitivity to the workload using the mRMR algorithm. The results demonstrate that the enhanced model achieves the accuracy and stability required for practical applications. Notably, in this study, only three EEG channels were employed to achieve the highly precise detection of the cognitive workload of controllers. This approach markedly increases the practicality of employing EEG equipment for the detection of the cognitive workload and streamlines the detection process.",https://pubmed.ncbi.nlm.nih.gov/39199502/,https://pubmed.ncbi.nlm.nih.gov/39199502/,English,Include,,Cognitive Workload Detection of Air Traffic Controllers Based on mRMR and Fewer EEG Channels.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39199495,pubmed:39199495,PubMed,pubmed:39199495,Overt and Covert Effects of Mental Fatigue on Attention Networks: Evidence from Event-Related Potentials during the Attention Network Test.,Caterina Pauletti;Daniela Mannarelli;Francesco Fattapposta,2024,10.3390/brainsci10100715,"Mental fatigue is a variation in the psychophysiological state that subjects encounter during or after prolonged cognitive activity periods, affecting top-down attention and cognitive control. The present study aimed to investigate the effects of mental fatigue on attention in the context of the three attention networks according to the Posnerian model (alerting, orienting, and executive networks) by combining the Attentional Network Test (ANT) and event-related potentials technique. Thirty healthy subjects were enrolled in the study. A continuous arithmetic task lasting one hour induced mental fatigue, and EEG recordings were conducted before and after the task while subjects were performing the ANT. The efficiencies of three networks were comparable between groups, while RTs shortened only in the control group and the accuracy related to the alerting and conflict networks declined only after mental effort. Mental fatigue reduced N1 amplitude during alerting network engagement and p3 amplitude during orienting. It also reduced N2 and P3 amplitude during the conflict, particularly the incongruent target-locked response. These findings underscore the covert effects of mental fatigue on attention, suggesting that even in healthy young subjects, compensatory mechanisms may maintain adequate overt performances, but fatigue still has a detrimental effect on top-down attentional mechanisms.",https://pubmed.ncbi.nlm.nih.gov/39199495/,https://pubmed.ncbi.nlm.nih.gov/39199495/,English,Include,,Overt and Covert Effects of Mental Fatigue on Attention Networks: Evidence from Event-Related Potentials during the Attention Network Test.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39199073,pubmed:39199073,PubMed,pubmed:39199073,Predicting Behaviour Patterns in Online and PDF Magazines with AI Eye-Tracking.,Hedda Martina Šola;Fayyaz Hussain Qureshi;Sarwar Khawaja,2024,10.47604/ijsmp.2749,"This study aims to improve college magazines, making them more engaging and user-friendly. We combined eye-tracking technology with artificial intelligence to accurately predict consumer behaviours and preferences. Our analysis included three college magazines, both online and in PDF format. We evaluated user experience using neuromarketing eye-tracking AI prediction software, trained on a large consumer neuroscience dataset of eye-tracking recordings from 180,000 participants, using Tobii X2 30 equipment, encompassing over 100 billion data points and 15 consumer contexts. An analysis was conducted with R programming v. 2023.06.0+421 and advanced SPSS statistics v. 27, IBM. (ANOVA, Welch's Two-Sample ",,https://pubmed.ncbi.nlm.nih.gov/39199073/,English,Exclude,Not EEG-BCI focused,Predicting Behaviour Patterns in Online and PDF Magazines with AI Eye-Tracking.,,,,,0.9,0.8,small_sample_mentioned
pubmed:39196847,pubmed:39196847,PubMed,pubmed:39196847,Vigilant Attention During Cognitive and Language Processing in Aphasia.,Dannielle Hibshman;Ellyn A Riley,2024,10.1016/j.neuropsychologia.2017.12.005,"Persons with aphasia (PWA) experience differences in attention after stroke, potentially impacting cognitive/language performance. This secondary analysis investigated physiologically measured vigilant attention during linguistic and nonlinguistic processing in PWA and control participants. To evaluate performance and attention in a language task, seven PWA read sentences aloud (linguistic task) and were compared to a previous data set of 10 controls and 10 PWA. To evaluate performance and attention in a language-independent task, 11 controls and nine PWA completed the Bivalent Shape Task (nonlinguistic task). Continuous electroencephalogram (EEG) data were collected during each session. A previously validated EEG algorithm classified vigilant-attention state for each experiment trial into high, moderate, distracted, or no attention. Dependent measures were task accuracy and amount of time spent in each attention state (measured by the number of trials). PWA produced significantly more errors than controls on the linguistic task, but groups performed similarly on the nonlinguistic task. During the linguistic task, controls spent significantly more time than PWA in a moderate-attention state, but no statistically significant differences were found between groups for other attention states. For the nonlinguistic task, amount of time controls and PWA spent in each attention state was more evenly distributed. When directly comparing attention patterns between linguistic and nonlinguistic tasks, PWA showed significantly more time in a high-attention state during the linguistic task as compared to the nonlinguistic task; however, controls showed no significant differences between linguistic and nonlinguistic tasks. This study provides new evidence that PWA experience a heightened state of vigilant attention when language processing demands are higher (during a linguistic task) than when language demands are lower (during a nonlinguistic task). Collectively, results of this study suggest that when processing language, PWA may allocate more attentional resources than when completing other kinds of cognitive tasks.",https://pubmed.ncbi.nlm.nih.gov/39196847/,https://pubmed.ncbi.nlm.nih.gov/39196847/,English,Include,,Vigilant Attention During Cognitive and Language Processing in Aphasia.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39196743,pubmed:39196743,PubMed,pubmed:39196743,A Strong and Simple Deep Learning Baseline for BCI Motor Imagery Decoding.,Yassine El Ouahidi;Vincent Gripon;Bastien Pasdeloup;Ghaith Bouallegue;Nicolas Farrugia;Giulia Lioi,2024,10.1109/tnsre.2024.3451010,"We propose EEG-SimpleConv, a straightforward 1D convolutional neural network for Motor Imagery decoding in BCI. Our main motivation is to propose a simple and performing baseline that achieves high classification accuracy, using only standard ingredients from the literature, to serve as a standard for comparison. The proposed architecture is composed of standard layers, including 1D convolutions, batch normalisations, ReLU activation functions and pooling functions. EEG-SimpleConv architecture is accompanied by a straightforward and tailored training routine, which is subjected to an extensive ablation study to quantify the influence of its components. We evaluate its performance on four EEG Motor Imagery datasets, including simulated online setups, and compare it to recent Deep Learning and Machine Learning approaches. EEG-SimpleConv is at least as good or far more efficient than other approaches, showing strong knowledge-transfer capabilities across subjects, at the cost of a low inference time. We believe that using standard components and ingredients can significantly help the adoption of Deep Learning approaches for BCI. We make the code of the models and the experiments accessible.",https://pubmed.ncbi.nlm.nih.gov/39196743/,https://pubmed.ncbi.nlm.nih.gov/39196743/,English,Include,,A Strong and Simple Deep Learning Baseline for BCI Motor Imagery Decoding.,Include,,"G-SimpleConv, a straightforward 1D convolutional neural network for Motor Imagery decoding in BCI. Our main motivation is to propose a simple and performing baseline that achieves high classification accuracy, using only standard ingredients from the literature, to serve as a standard for comparison. The proposed architecture is composed of standard layers, including 1D convolutions, batch normali",,0.95,0.6,
pubmed:39196738,pubmed:39196738,PubMed,pubmed:39196738,Enhancement of Hybrid BCI System Performance Based on Motor Imagery and SSVEP by Transcranial Alternating Current Stimulation.,Zhaohui Li;Ruoqing Zhang;Wenjing Li;Meng Li;Xiaogang Chen;Hongyan Cui,2024,10.1109/tnsre.2024.3451015,"The hybrid brain-computer interface (BCI) is verified to reduce disadvantages of conventional BCI systems. Transcranial electrical stimulation (tES) can also improve the performance and applicability of BCI. However, enhancement in BCI performance attained solely from the perspective of users or solely from the angle of BCI system design is limited. In this study, a hybrid BCI system combining MI and SSVEP was proposed. Furthermore, transcranial alternating current stimulation (tACS) was utilized to enhance the performance of the proposed hybrid BCI system. The stimulation interface presented a depiction of grabbing a ball with both of hands, with left-hand and right-hand flickering at frequencies of 34 Hz and 35 Hz. Subjects watched the interface and imagined grabbing a ball with either left hand or right hand to perform SSVEP and MI task. The MI and SSVEP signals were processed separately using filter bank common spatial patterns (FBCSP) and filter bank canonical correlation analysis (FBCCA) algorithms, respectively. A fusion method was proposed to fuse the features extracted from MI and SSVEP. Twenty healthy subjects took part in the online experiment and underwent tACS sequentially. The fusion accuracy post-tACS reached 90.25% ± 11.40%, which was significantly different from pre-tACS. The fusion accuracy also surpassed MI accuracy and SSVEP accuracy respectively. These results indicated the superior performance of the hybrid BCI system and tACS would improve the performance of the hybrid BCI system.",https://pubmed.ncbi.nlm.nih.gov/39196738/,https://pubmed.ncbi.nlm.nih.gov/39196738/,English,Include,,Enhancement of Hybrid BCI System Performance Based on Motor Imagery and SSVEP by Transcranial Alternating Current Stimulation.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39195074,pubmed:39195074,PubMed,pubmed:39195074,Frontal Activity of Recent Suicide Attempters: EEG spectrum Power Performing Raven Task.,Nafee Rasouli;Seyed Kazem Malakouti;Masoumeh Bayat;Firouzeh Mahjoubnavaz;Niloofar Fallahinia;Reza Khosrowabadi,2025,10.1177/15500594241273125,,,https://pubmed.ncbi.nlm.nih.gov/39195074/,English,Exclude,Outside date range,Frontal Activity of Recent Suicide Attempters: EEG spectrum Power Performing Raven Task.,,,,,0.95,0.6,
pubmed:39194635,pubmed:39194635,PubMed,pubmed:39194635,MLS-Net: An Automatic Sleep Stage Classifier Utilizing Multimodal Physiological Signals in Mice.,Chengyong Jiang;Wenbin Xie;Jiadong Zheng;Biao Yan;Junwen Luo;Jiayi Zhang,2024,10.3390/bios13030395,"Over the past decades, feature-based statistical machine learning and deep neural networks have been extensively utilized for automatic sleep stage classification (ASSC). Feature-based approaches offer clear insights into sleep characteristics and require low computational power but often fail to capture the spatial-temporal context of the data. In contrast, deep neural networks can process raw sleep signals directly and deliver superior performance. However, their overfitting, inconsistent accuracy, and computational cost were the primary drawbacks that limited their end-user acceptance. To address these challenges, we developed a novel neural network model, MLS-Net, which integrates the strengths of neural networks and feature extraction for automated sleep staging in mice. MLS-Net leverages temporal and spectral features from multimodal signals, such as EEG, EMG, and eye movements (EMs), as inputs and incorporates a bidirectional Long Short-Term Memory (bi-LSTM) to effectively capture the spatial-temporal nonlinear characteristics inherent in sleep signals. Our studies demonstrate that MLS-Net achieves an overall classification accuracy of 90.4% and REM state precision of 91.1%, sensitivity of 84.7%, and an F1-Score of 87.5% in mice, outperforming other neural network and feature-based algorithms in our multimodal dataset.",https://pubmed.ncbi.nlm.nih.gov/39194635/,https://pubmed.ncbi.nlm.nih.gov/39194635/,English,Include,,MLS-Net: An Automatic Sleep Stage Classifier Utilizing Multimodal Physiological Signals in Mice.,Include,,"o capture the spatial-temporal context of the data. In contrast, deep neural networks can process raw sleep signals directly and deliver superior performance. However, their overfitting, inconsistent accuracy, and computational cost were the primary drawbacks that limited their end-user acceptance. To address these challenges, we developed a novel neural network model, MLS-Net, which integrates th",,0.95,0.8,overfit_terms_found
pubmed:39194625,pubmed:39194625,PubMed,pubmed:39194625,Surface Electromyography-Based Recognition of Electronic Taste Sensations.,Asif Ullah;Fengqi Zhang;Zhendong Song;You Wang;Shuo Zhao;Waqar Riaz;Guang Li,2024,10.1109/10.204774,"Taste sensation recognition is a core for taste-related queries. Most prior research has been devoted to recognizing the basic taste sensations using the Brain-Computer Interface (BCI), which includes EEG, MEG, EMG, and fMRI. This research aims to recognize electronic taste (E-Taste) sensations based on surface electromyography (sEMG). Silver electrodes with platinum plating of the E-Taste device were placed on the tongue's tip to stimulate various tastes and flavors. In contrast, the electrodes of the sEMG were placed on facial muscles to collect the data. The dataset was organized and preprocessed, and a random forest classifier was applied, giving a five-fold accuracy of 70.43%. The random forest classifier was used on each participant dataset individually and in groups, providing the highest accuracy of 84.79% for a single participant. Moreover, various feature combinations were extracted and acquired 72.56% accuracy after extracting eight features. For a future perspective, this research offers guidance for electronic taste recognition based on sEMG.",https://pubmed.ncbi.nlm.nih.gov/39194625/,https://pubmed.ncbi.nlm.nih.gov/39194625/,English,Include,,Surface Electromyography-Based Recognition of Electronic Taste Sensations.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39194597,pubmed:39194597,PubMed,pubmed:39194597,Electrotactile BCI for Top-Down Somatosensory Training: Clinical Feasibility Trial of Online BCI Control in Subacute Stroke Patients.,Andrej M Savić;Marija Novičić;Vera Miler-Jerković;Olivera Djordjević;Ljubica Konstantinović,2024,10.1109/thms.2016.2608931,"This study investigates the feasibility of a novel brain-computer interface (BCI) device designed for sensory training following stroke. The BCI system administers electrotactile stimuli to the user's forearm, mirroring classical sensory training interventions. Concurrently, selective attention tasks are employed to modulate electrophysiological brain responses (somatosensory event-related potentials-sERPs), reflecting cortical excitability in related sensorimotor areas. The BCI identifies attention-induced changes in the brain's reactions to stimulation in an online manner. The study protocol assesses the feasibility of online binary classification of selective attention focus in ten subacute stroke patients. Each experimental session includes a BCI training phase for data collection and classifier training, followed by a BCI test phase to evaluate online classification of selective tactile attention based on sERP. During online classification tests, patients complete 20 repetitions of selective attention tasks with feedback on attention focus recognition. Using a single electroencephalographic channel, attention classification accuracy ranges from 70% to 100% across all patients. The significance of this novel BCI paradigm lies in its ability to quantitatively measure selective tactile attention resources throughout the therapy session, introducing a top-down approach to classical sensory training interventions based on repeated neuromuscular electrical stimulation.",https://pubmed.ncbi.nlm.nih.gov/39194597/,https://pubmed.ncbi.nlm.nih.gov/39194597/,English,Include,,Electrotactile BCI for Top-Down Somatosensory Training: Clinical Feasibility Trial of Online BCI Control in Subacute Stroke Patients.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39194438,pubmed:39194438,PubMed,pubmed:39194438,EEG Motor Imagery Classification: Tangent Space with Gate-Generated Weight Classifier.,Sara Omari;Adil Omari;Fares Abu-Dakka;Mohamed Abderrahim,2024,10.5281/zenodo.5565057,"Individuals grappling with severe central nervous system injuries often face significant challenges related to sensorimotor function and communication abilities. In response, brain-computer interface (BCI) technology has emerged as a promising solution by offering innovative interaction methods and intelligent rehabilitation training. By leveraging electroencephalographic (EEG) signals, BCIs unlock intriguing possibilities in patient care and neurological rehabilitation. Recent research has utilized covariance matrices as signal descriptors. In this study, we introduce two methodologies for covariance matrix analysis: multiple tangent space projections (M-TSPs) and Cholesky decomposition. Both approaches incorporate a classifier that integrates linear and nonlinear features, resulting in a significant enhancement in classification accuracy, as evidenced by meticulous experimental evaluations. The M-TSP method demonstrates superior performance with an average accuracy improvement of 6.79% over Cholesky decomposition. Additionally, a gender-based analysis reveals a preference for men in the obtained results, with an average improvement of 9.16% over women. These findings underscore the potential of our methodologies to improve BCI performance and highlight gender-specific performance differences to be examined further in our future studies.",https://pubmed.ncbi.nlm.nih.gov/39194438/,https://pubmed.ncbi.nlm.nih.gov/39194438/,English,Include,,EEG Motor Imagery Classification: Tangent Space with Gate-Generated Weight Classifier.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39194182,pubmed:39194182,PubMed,pubmed:39194182,Iterative alignment discovery of speech-associated neural activity.,Qinwan Rabbani;Samyak Shah;Griffin Milsap;Matthew Fifer;Hynek Hermansky;Nathan Crone,2024,10.1016/j.neuron.2011.01.019,,,https://pubmed.ncbi.nlm.nih.gov/39194182/,English,Exclude,Not EEG-BCI focused,Iterative alignment discovery of speech-associated neural activity.,,,,,0.9,0.6,
pubmed:39193445,pubmed:39193445,PubMed,pubmed:39193445,ninjaCap: a fully customizable and 3D printable headgear for functional near-infrared spectroscopy and electroencephalography brain imaging.,Alexander von Lühmann;Sreekanth Kura;Walker Joseph O'Brien;Bernhard B Zimmermann;Sudan Duwadi;De'Ja Rogers;Jessica E Anderson;Parya Farzam;Cameron Snow;Anderson Chen;Meryem A Yücel;Nathan Perkins;David A Boas,2024,10.1117/1.jbo.28.6.065003,"Accurate sensor placement is vital for non-invasive brain imaging, particularly for functional near-infrared spectroscopy (fNIRS) and diffuse optical tomography (DOT), which lack standardized layouts such as those in electroencephalography (EEG). Custom, manually prepared probe layouts on textile caps are often imprecise and labor intensive. We introduce a method for creating personalized, 3D-printed headgear, enabling the accurate translation of 3D brain coordinates to 2D printable panels for custom fNIRS and EEG sensor layouts while reducing costs and manual labor. Our approach uses atlas-based or subject-specific head models and a spring-relaxation algorithm for flattening 3D coordinates onto 2D panels, using 10-5 EEG coordinates for reference. This process ensures geometrical fidelity, crucial for accurate probe placement. Probe geometries and holder types are customizable and printed directly on the cap, making the approach agnostic to instrument manufacturers and probe types. Our ninjaCap method offers ",https://pubmed.ncbi.nlm.nih.gov/39193445/,https://pubmed.ncbi.nlm.nih.gov/39193445/,English,Include,,ninjaCap: a fully customizable and 3D printable headgear for functional near-infrared spectroscopy and electroencephalography brain imaging.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39190518,pubmed:39190518,PubMed,pubmed:39190518,Sleep Stage Classification Via Multi-View Based Self-Supervised Contrastive Learning of EEG.,Chen Zhao;Wei Wu;Haoyi Zhang;Ruiyan Zhang;Xinyue Zheng;Xiangzeng Kong,2024,10.1109/jbhi.2024.3432633,"Self-supervised learning (SSL) is a challenging task in sleep stage classification (SSC) that is capable of mining valuable representations from unlabeled data. However, traditional SSL methods typically focus on single-view learning and do not fully exploit the interactions among information across multiple views. In this study, we focused on a multi-domain view of the same EEG signal and developed a self-supervised multi-view representation learning framework via time series and time-frequency contrasting (MV-TTFC). In the MV-TTFC framework, we built-in a cross-domain view contrastive learning prediction task to establish connections between the temporal view and time-frequency (TF) view, thereby enhancing the information exchange between multiple views. In addition, to improve the quality of the TF view inputs, we introduced an enhanced multisynchrosqueezing transform, which can create high energy concentration TF image views to compensate for the inaccurate representations in traditional TF processing techniques. Finally, integrating temporal, TF, and fusion space contrastive learning effectively captured the latent features in EEG signals. We evaluated MV-TTFC based on two real-world SSC datasets (SleepEDF-78 and SHHS) and compared it with baseline methods in downstream tasks. Our method exhibited state-of-the-art performance, achieving accuracies of 78.64% and 81.45% with SleepEDF-78 and SHHS, respectively, and macro F1-scores of 70.39% with SleepEDF-78 and 70.47% with SHHS.",https://pubmed.ncbi.nlm.nih.gov/39190518/,https://pubmed.ncbi.nlm.nih.gov/39190518/,English,Include,,Sleep Stage Classification Via Multi-View Based Self-Supervised Contrastive Learning of EEG.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39190517,pubmed:39190517,PubMed,pubmed:39190517,MSVTNet: Multi-Scale Vision Transformer Neural Network for EEG-Based Motor Imagery Decoding.,Ke Liu;Tao Yang;Zhuliang Yu;Weibo Yi;Hong Yu;Guoyin Wang;Wei Wu,2024,10.1109/jbhi.2024.3450753,"Transformer-based neural networks have been applied to the electroencephalography (EEG) decoding for motor imagery (MI). However, most networks focus on applying the self-attention mechanism to extract global temporal information, while the cross-frequency coupling features between different frequencies have been neglected. Additionally, effectively integrating different neural networks poses challenges for the advanced design of decoding algorithms. This study proposes a novel end-to-end Multi-Scale Vision Transformer Neural Network (MSVTNet) for MI-EEG classification. MSVTNet first extracts local spatio-temporal features at different filtered scales through convolutional neural networks (CNNs). Then, these features are concatenated along the feature dimension to form local multi-scale spatio-temporal feature tokens. Finally, Transformers are utilized to capture cross-scale interaction information and global temporal correlations, providing more distinguishable feature embeddings for classification. Moreover, auxiliary branch loss is leveraged for intermediate supervision to ensure the effective integration of CNNs and Transformers. The performance of MSVTNet was assessed through subject-dependent (session-dependent and session-independent) and subject-independent experiments on three MI datasets, i.e., the BCI competition IV 2a, 2b and OpenBMI datasets. The experimental results demonstrate that MSVTNet achieves state-of-the-art performance in all analyses. MSVTNet shows superiority and robustness in enhancing MI decoding performance.",https://pubmed.ncbi.nlm.nih.gov/39190517/,https://pubmed.ncbi.nlm.nih.gov/39190517/,English,Include,,MSVTNet: Multi-Scale Vision Transformer Neural Network for EEG-Based Motor Imagery Decoding.,Exclude,No performance metrics reported,No metrics found in full text,,0.9,0.6,
pubmed:39190511,pubmed:39190511,PubMed,pubmed:39190511,BELT: Bootstrapped EEG-to-Language Training by Natural Language Supervision.,Jinzhao Zhou;Yiqun Duan;Yu-Cheng Chang;Yu-Kai Wang;Chin-Teng Lin,2024,10.1109/tnsre.2024.3450795,"Decoding natural language from noninvasive brain signals has been an exciting topic with the potential to expand the applications of brain-computer interface (BCI) systems. However, current methods face limitations in decoding sentences from electroencephalography (EEG) signals. Improving decoding performance requires the development of a more effective encoder for the EEG modality. Nonetheless, learning generalizable EEG representations remains a challenge due to the relatively small scale of existing EEG datasets. In this paper, we propose enhancing the EEG encoder to improve subsequent decoding performance. Specifically, we introduce the discrete Conformer encoder (D-Conformer) to transform EEG signals into discrete representations and bootstrap the learning process by imposing EEG-language alignment from the early training stage. The D-Conformer captures both local and global patterns from EEG signals and discretizes the EEG representation, making the representation more resilient to variations, while early-stage EEG-language alignment mitigates the limitations of small EEG datasets and facilitates the learning of the semantic representations from EEG signals. These enhancements result in improved EEG representations and decoding performance. We conducted extensive experiments and ablation studies to thoroughly evaluate the proposed method. Utilizing the D-Conformer encoder and bootstrapping training strategy, our approach demonstrates superior decoding performance across various tasks, including word-level, sentence-level, and sentiment-level decoding from EEG signals. Specifically, in word-level classification, we show that our encoding method produces more distinctive representations and higher classification performance compared to the EEG encoders from existing methods. At the sentence level, our model outperformed the baseline by 5.45%, achieving a BLEU-1 score of 42.31%. Furthermore, in sentiment classification, our model exceeded the baseline by 14%, achieving a sentiment classification accuracy of 69.3%.",https://pubmed.ncbi.nlm.nih.gov/39190511/,https://pubmed.ncbi.nlm.nih.gov/39190511/,English,Include,,BELT: Bootstrapped EEG-to-Language Training by Natural Language Supervision.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39188869,pubmed:39188869,PubMed,pubmed:39188869,Corrigendum: Music-evoked emotions classification using vision transformer in EEG signals.,Dong Wang;Jian Lian;Hebin Cheng;Yanan Zhou,2024,10.3389/fpsyg.2024.1466709,[This corrects the article DOI: 10.3389/fpsyg.2024.1275142.].,https://pubmed.ncbi.nlm.nih.gov/39188869/,https://pubmed.ncbi.nlm.nih.gov/39188869/,English,Include,,Corrigendum: Music-evoked emotions classification using vision transformer in EEG signals.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39187152,pubmed:39187152,PubMed,pubmed:39187152,High frequency oscillations may improve somatosensory evoked potential detection of good outcomes in disorders of consciousness secondary to acute neurologic injury.,Siena Duarte;Ze Ou;Mingfeng Cao;Sung-Min Cho;Nitish V Thakor;Eva K Ritzl;Romergryko G Geocadin,2024,10.1016/j.resuscitation.2024.110377,"Somatosensory evoked potentials (SEPs) are highly specific predictors of poor prognosis in hypoxic-ischemic coma when cortical responses (N20s) are absent. However, bilateral N20 presence is nonspecific for good outcomes. High-frequency oscillations (HFOs) in the SEP waveform predict neurologic recovery in animals, but clinical applications are poorly understood. We sought to develop a clinical measure of HFOs to potentially improve detection of good outcomes in coma. We collected SEP waveform data from all comatose inpatients (GCS<=8) who underwent neurologic prognostication from 2020 to 2022 at Johns Hopkins Hospital. We developed a novel measure - HFO evoked to spontaneous ratios (HFO-ESRs) - and applied this to those patients with bilaterally present N20s using both standard univariate classification and cubic kernal vector machine (SVM) models to predict the last documented in-hospital Glasgow Coma Scale (GCS) prior to discharge or death. Of 58 total patients, 34 (58.6%) had bilaterally present N20s. Of these, 14 had final GCS>=9, and 20 had final GCS<=8. Mean age was 52 (+/- 17) years, 20.1% female. Etiologies of coma were primarily global hypoxic-ischemic brain injury (79.4%), intracranial hemorrhage (11.8%), and traumatic brain injury (2.9%). In univariate classification, the addition of averaged HFO-ESRs to bilaterally present N20s predicted final GCS>=9 with 68% specificity. The SVM model further improved specificity to 85%. In this pilot investigation, we developed a novel clinical measure of SEP HFOs. Incorporation of this measure may improve the specificity of the SEP to predict in-hospital GCS outcomes in coma, but requires further validation in specific neurologic injuries and with longitudinal outcomes.",,https://pubmed.ncbi.nlm.nih.gov/39187152/,English,Exclude,Not EEG-BCI focused,High frequency oscillations may improve somatosensory evoked potential detection of good outcomes in disorders of consciousness secondary to acute neurologic injury.,,,,,0.9,0.6,
pubmed:39186838,pubmed:39186838,PubMed,pubmed:39186838,SFT-SGAT: A semi-supervised fine-tuning self-supervised graph attention network for emotion recognition and consciousness detection.,Lina Qiu;Liangquan Zhong;Jianping Li;Weisen Feng;Chengju Zhou;Jiahui Pan,2024,10.1016/j.neunet.2024.106643,"Emotional recognition is highly important in the field of brain-computer interfaces (BCIs). However, due to the individual variability in electroencephalogram (EEG) signals and the challenges in obtaining accurate emotional labels, traditional methods have shown poor performance in cross-subject emotion recognition. In this study, we propose a cross-subject EEG emotion recognition method based on a semi-supervised fine-tuning self-supervised graph attention network (SFT-SGAT). First, we model multi-channel EEG signals by constructing a graph structure that dynamically captures the spatiotemporal topological features of EEG signals. Second, we employ a self-supervised graph attention neural network to facilitate model training, mitigating the impact of signal noise on the model. Finally, a semi-supervised approach is used to fine-tune the model, enhancing its generalization ability in cross-subject classification. By combining supervised and unsupervised learning techniques, the SFT-SGAT maximizes the utility of limited labeled data in EEG emotion recognition tasks, thereby enhancing the model's performance. Experiments based on leave-one-subject-out cross-validation demonstrate that SFT-SGAT achieves state-of-the-art cross-subject emotion recognition performance on the SEED and SEED-IV datasets, with accuracies of 92.04% and 82.76%, respectively. Furthermore, experiments conducted on a self-collected dataset comprising ten healthy subjects and eight patients with disorders of consciousness (DOCs) revealed that the SFT-SGAT attains high classification performance in healthy subjects (maximum accuracy of 95.84%) and was successfully applied to DOC patients, with four patients achieving emotion recognition accuracies exceeding 60%. The experiments demonstrate the effectiveness of the proposed SFT-SGAT model in cross-subject EEG emotion recognition and its potential for assessing levels of consciousness in patients with DOC.",https://pubmed.ncbi.nlm.nih.gov/39186838/,https://pubmed.ncbi.nlm.nih.gov/39186838/,English,Include,,SFT-SGAT: A semi-supervised fine-tuning self-supervised graph attention network for emotion recognition and consciousness detection.,Include,,"ected dataset comprising ten healthy subjects and eight patients with disorders of consciousness (DOCs) revealed that the SFT-SGAT attains high classification performance in healthy subjects (maximum accuracy of 95.84%) and was successfully applied to DOC patients, with four patients achieving emotion recognition accuracies exceeding 60%. The experiments demonstrate the effectiveness of the propos",,0.95,0.25,cv_reported
pubmed:39186316,pubmed:39186316,PubMed,pubmed:39186316,Sensitivity and specificity of the Salzburg EEG criteria for nonconvulsive status epilepticus.,Line B Ulvin;Kristian B Nilsen;Erik Taubøll;Lars Etholm;Kjell Heuser,2024,10.1002/acn3.52184,"The Salzburg EEG criteria for nonconvulsive status epilepticus (NCSE) have been proposed as consensus criteria for NCSE. We aimed to perform an independent study of their diagnostic accuracy. A prospective study was carried out at Oslo University Hospital, including all consecutive patients ≥15 years old who were referred for an EEG with an explicit or implicit question of NCSE from February 2020 to February 2022. Two independent EEG readers scored the included EEGs according to the Salzburg criteria and blinded to the clinical data. The reference standard was defined as the clinical diagnosis the patient received based on all available clinical and paraclinical data. Diagnostic accuracy in identifying ""certain/possible NCSE"" was assessed by calculating sensitivity, specificity, positive predictive value, and negative predictive value with their 95% confidence intervals. In total, 469 patients/EEGs were included in the study. The prevalence of NCSE according to the reference standard was 11% (n = 53). The criteria showed a sensitivity of 94% (95% CI: 92-96%), a specificity of 77% (95% CI: 73-81%), a positive predictive value of 34% (95% CI: 30-39%), and a negative predictive value of 99% (95% CI: 98-100%). False positives for ""certain NCSE"" (n = 16) included many serial seizures and stimulus-induced rhythmic and periodic discharges (SIRPIDs), as well as a focal cortical dysplasia. False positives for ""possible NCSE"" (n = 79) were mainly represented by different encephalopathies and postictality. The low specificity of the Salzburg criteria calls for refinement before implementation into daily clinical practice.",https://pubmed.ncbi.nlm.nih.gov/39186316/,https://pubmed.ncbi.nlm.nih.gov/39186316/,English,Include,,Sensitivity and specificity of the Salzburg EEG criteria for nonconvulsive status epilepticus.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39185861,pubmed:39185861,PubMed,pubmed:39185861,Memorization-Based Training and Testing Paradigm for Robust Vocal Identity Recognition in Expressive Speech Using Event-Related Potentials Analysis.,Wenjun Chen;Xiaoming Jiang,2024,10.3791/66913,"Recognizing familiar speakers from vocal streams is a fundamental aspect of human verbal communication. However, it remains unclear how listeners can still discern the speaker's identity in expressive speech. This study develops a memorization-based individual speaker identity recognition approach and an accompanying electroencephalogram (EEG) data analysis pipeline, which monitors how listeners recognize familiar speakers and tell unfamiliar ones apart. EEG data captures online cognitive processes during new versus old speaker distinction based on voice, offering a real-time measure of brain activity, overcoming limits of reaction times and accuracy measurements. The paradigm comprises three steps: listeners establish associations between three voices and their names (training); listeners indicate the name corresponding to a voice from three candidates (checking); listeners distinguish between three old and three new speaker voices in a two-alternative forced-choice task (testing). The speech prosody in testing was either confident or doubtful. EEG data were collected using a 64-channel EEG system, followed by preprocessing and imported into RStudio for ERP and statistical analysis and MATLAB for brain topography. Results showed an enlarged late positive component (LPC) was elicited in the old-talker compared to the new-talker condition in the 400-850 ms window in the Pz and other wider range of electrodes in both prosodies. Yet, the old/new effect was robust in central and posterior electrodes for doubtful prosody perception, whereas the anterior, central, and posterior electrodes are for confident prosody condition. This study proposes that this experiment design can serve as a reference for investigating speaker-specific cue-binding effects in various scenarios (e.g., anaphoric expression) and pathologies in patients like phonagnosia.",https://pubmed.ncbi.nlm.nih.gov/39185861/,https://pubmed.ncbi.nlm.nih.gov/39185861/,English,Include,,Memorization-Based Training and Testing Paradigm for Robust Vocal Identity Recognition in Expressive Speech Using Event-Related Potentials Analysis.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39185530,pubmed:39185530,PubMed,pubmed:39185530,Prediction of Postoperative Delirium in Older Adults from Preoperative Cognition and Occipital Alpha Power from Resting-State Electroencephalogram.,Matthew Ning;Andrei Rodionov;Jessica M Ross;Recep A Ozdemir;Maja Burch;Shu Jing Lian;David Alsop;Michele Cavallari;Bradford C Dickerson;Tamara G Fong;Richard N Jones;Towia A Libermann;Edward R Marcantonio;Emiliano Santarnecchi;Eva M Schmitt;Alexandra Touroutoglou;Thomas G Travison;Leah Acker;Melody Reese;Haoqi Sun;Brandon Westover;Miles Berger;Alvaro Pascual-Leone;Sharon K Inouye;Mouhsin M Shafi,2024,10.1101/2024.08.15.24312053,"Postoperative delirium is the most common complication following surgery among older adults, and has been consistently associated with increased mortality and morbidity, cognitive decline, and loss of independence, as well as markedly increased health-care costs. Electroencephalography (EEG) spectral slowing has frequently been observed during episodes of delirium, whereas intraoperative frontal alpha power is associated with postoperative delirium. We sought to identify preoperative predictors that could identify individuals at high risk for postoperative delirium, which could guide clinical decision-making and enable targeted interventions to potentially decrease delirium incidence and postoperative delirium-related complications. In this prospective observational study, we used machine learning to evaluate whether baseline (preoperative) cognitive function and resting-state EEG could be used to identify patients at risk for postoperative delirium. Preoperative resting-state EEGs and the Montreal Cognitive Assessment were collected from 85 patients (age = 73 ± 6.4 years, 12 cases of delirium) undergoing elective surgery. The model with the highest f1-score was subsequently validated in an independent, prospective cohort of 51 older adults (age = 68 ± 5.2 years, 6 cases of delirium) undergoing elective surgery. Occipital alpha powers have higher f1-score than frontal alpha powers and EEG spectral slowing in the training cohort. Occipital alpha powers were able to predict postoperative delirium with AUC, specificity and accuracy all >90%, and sensitivity >80%, in the validation cohort. Notably, models incorporating transformed alpha powers and cognitive scores outperformed models incorporating occipital alpha powers alone or cognitive scores alone. While requiring prospective validation in larger cohorts, these results suggest that strong prediction of postoperative delirium may be feasible in clinical settings using simple and widely available clinical tools. Additionally, our results suggested that the thalamocortical circuit exhibits different EEG patterns under different stressors, with occipital alpha powers potentially reflecting baseline vulnerabilities.",https://pubmed.ncbi.nlm.nih.gov/39185530/,https://pubmed.ncbi.nlm.nih.gov/39185530/,English,Include,,Prediction of Postoperative Delirium in Older Adults from Preoperative Cognition and Occipital Alpha Power from Resting-State Electroencephalogram.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39183533,pubmed:39183533,PubMed,pubmed:39183533,Neural Decoding of the Speech Envelope: Effects of Intelligibility and Spectral Degradation.,Alexis Deighton MacIntyre;Robert P Carlyon;Tobias Goehring,2024,10.1016/j.bandl.2022.105128,"During continuous speech perception, endogenous neural activity becomes time-locked to acoustic stimulus features, such as the speech amplitude envelope. This speech-brain coupling can be decoded using non-invasive brain imaging techniques, including electroencephalography (EEG). Neural decoding may provide clinical use as an objective measure of stimulus encoding by the brain-for example during cochlear implant listening, wherein the speech signal is severely spectrally degraded. Yet, interplay between acoustic and linguistic factors may lead to top-down modulation of perception, thereby complicating audiological applications. To address this ambiguity, we assess neural decoding of the speech envelope under spectral degradation with EEG in acoustically hearing listeners (",,https://pubmed.ncbi.nlm.nih.gov/39183533/,English,Exclude,Not classification-focused,Neural Decoding of the Speech Envelope: Effects of Intelligibility and Spectral Degradation.,,,,,0.85,0.6,
pubmed:39181919,pubmed:39181919,PubMed,pubmed:39181919,Alignment of behaviour and tDCS stimulation site induces maximum response: evidence from online tDCS and ERP.,Sagarika Bhattacharjee;Rajan Kashyap;Kaviraja Udupa;Shahid Bashir;Ganesan Venkatsubramanian;Kenichi Oishi;John E Desmond;Brenda Rapp;S H Annabel Chen,2024,10.1016/j.brainres.2015.12.001,"tDCS modulates the activity of the neuronal networks to induce the desired behavioural changes. Two factors determine its effectiveness- (1) whether the network being stimulated is relevant to the task, and (2) if there is a scope for improvement in behavioral performance. To explore this, both dorsal (sub-lexical) and ventral (lexical) reading networks were stimulated (20 min, 2 mA) in 25 healthy young volunteers. Participants performed two reading tasks with different levels of lexical involvement: word fragment completion tasks (WCT) and word association tasks (WAT), while event-related potentials (ERPs) were recorded simultaneously. The study used a within-subject design over three sessions, comparing various electrode montages targeting the dorsal pathway's left inferior parietal lobule or the ventral reading pathway's left middle temporal lobule, as well as sham stimulation. The impact of tDCS sessions (dorsal, ventral, & sham) and task type (WCT & WAT) on priming effects (primed vs. unprimed) of behavioral performance (accuracy and reaction times), and ERP parameters (N400 amplitudes and latencies) were statistically analyzed.It was found that tDCS modulated the performance of WAT only (a task with a lower priming effect). The failure to modulate WCT (larger priming effect) indicated that tDCS was effective for conditions with room for improvement compared to a task where performance has reached the ceiling. Ventral stimulation enhanced accuracy in the WAT condition and shortened the N400 latency of the priming effect. In contrast, dorsal stimulation delayed the priming effect reaction time in the WAT condition and enhanced the N400 amplitude. To conclude, enhancement in performance due to tDCS occurs when the network (ventral) being stimulated aligns with the cognitive demands of the task and there is a scope for improvement.",,https://pubmed.ncbi.nlm.nih.gov/39181919/,English,Exclude,Not EEG-BCI focused,Alignment of behaviour and tDCS stimulation site induces maximum response: evidence from online tDCS and ERP.,,,,,0.9,0.8,small_sample_mentioned
pubmed:39180634,pubmed:39180634,PubMed,pubmed:39180634,Emotional text messages affect the early processing of emoticons depending on their emotional congruence: evidence from the N170 and EPN event related potentials.,Nerea Aldunate;Vladimir López;Felipe Rojas-Thomas;Mario Villena-González;Ismael Palacios;Claudio Artigas;Eugenio Rodríguez;Conrado A Bosman,2024,10.1007/s10339-024-01223-y,"Emoticons have been considered pragmatic cues that enhance emotional expressivity during computer-mediated communication. Yet, it is unclear how emoticons are processed in ambiguous text-based communication due to incongruences between the emoticon's emotional valence and its context. In this study, we investigated the electrophysiological correlates of contextual influence on the early emotional processing of emoticons, during an emotional congruence judgment task. Participants were instructed to judge the congruence between a text message expressing an emotional situation (positive or negative), and a subsequent emoticon expressing positive or negative emotions. We analyzed early event-related potentials elicited by emoticons related to face processing (N170) and emotional salience in visual perception processing (Early Posterior Negativity, EPN). Our results show that accuracy and Reaction Times depend on the interaction between the emotional valence of the context and the emoticon. Negative emoticons elicited a larger N170, suggesting that the emotional information of the emoticon is integrated at the early stages of the perceptual process. During emoticon processing, a valence effect was observed with enhanced EPN amplitudes in occipital areas for emoticons representing negative valences. Moreover, we observed a congruence effect in parieto-temporal sites within the same time-window, with larger amplitudes for the congruent condition. We conclude that, similar to face processing, emoticons are processed differently according to their emotional content and the context in which they are embedded. A congruent context might enhance the emotional salience of the emoticon (and therefore, its emotional expression) during the early stages of their processing.",,https://pubmed.ncbi.nlm.nih.gov/39180634/,English,Exclude,Not EEG-BCI focused,Emotional text messages affect the early processing of emoticons depending on their emotional congruence: evidence from the N170 and EPN event related potentials.,,,,,0.9,0.8,small_sample_mentioned
pubmed:39180417,pubmed:39180417,PubMed,pubmed:39180417,Oscillatory and nonoscillatory sleep electroencephalographic biomarkers of the epileptic network.,Véronique Latreille;Justin Corbin-Lapointe;Laure Peter-Derex;John Thomas;Jean-Marc Lina;Birgit Frauscher,2024,10.1111/epi.18088,"In addition to the oscillatory brain activity, the nonoscillatory (scale-free) components of the background electroencephalogram (EEG) may provide further information about the complexity of the underlying neuronal network. As epilepsy is considered a network disease, such scale-free metrics might help to delineate the epileptic network. Here, we performed an analysis of the sleep oscillatory (spindle, slow wave, and rhythmic spectral power) and nonoscillatory (H exponent) intracranial EEG using multiple interictal features to estimate whether and how they deviate from normalcy in 38 adults with drug-resistant epilepsy. To quantify intracranial EEG abnormalities within and outside the seizure onset areas, patients' values were adjusted based on normative maps derived from the open-access Montreal Neurological Institute open iEEG Atlas. In a subset of 29 patients who underwent resective surgery, we estimated the predictive value of these features to identify the epileptogenic zone in those with a good postsurgical outcome. We found that distinct sleep oscillatory and nonoscillatory metrics behave differently across the epileptic network, with the strongest differences observed for (1) a reduction in spindle activity (spindle rates and rhythmic sigma power in the 10-16 Hz band), (2) a higher rhythmic gamma power (30-80 Hz), and (3) a higher H exponent (steeper 1/f slope). As expected, epileptic spikes were also highest in the seizure onset areas. Furthermore, in surgical patients, the H exponent achieved the highest performance (balanced accuracy of .76) for classifying resected versus nonresected channels in good outcome patients. This work suggests that nonoscillatory components of the intracranial EEG signal could serve as promising interictal sleep candidates of epileptogenicity in patients with drug-resistant epilepsy. Our findings further advance the understanding of epilepsy as a disease, whereby absence or loss of sleep physiology may provide information complementary to pathological epileptic processes.",https://pubmed.ncbi.nlm.nih.gov/39180417/,https://pubmed.ncbi.nlm.nih.gov/39180417/,English,Include,,Oscillatory and nonoscillatory sleep electroencephalographic biomarkers of the epileptic network.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39180407,pubmed:39180407,PubMed,pubmed:39180407,Interictal stereo-electroencephalography features below 45 Hz are sufficient for correct localization of the epileptogenic zone and postsurgical outcome prediction.,Petr Klimes;Petr Nejedly;Valentina Hrtonova;Jan Cimbalnik;Vojtech Travnicek;Martin Pail;Laure Peter-Derex;Jeffery Hall;Raluca Pana;Josef Halamek;Pavel Jurak;Milan Brazdil;Birgit Frauscher,2024,10.1111/epi.18081,"Evidence suggests that the most promising results in interictal localization of the epileptogenic zone (EZ) are achieved by a combination of multiple stereo-electroencephalography (SEEG) biomarkers in machine learning models. These biomarkers usually include SEEG features calculated in standard frequency bands, but also high-frequency (HF) bands. Unfortunately, HF features require extra effort to record, store, and process. Here we investigate the added value of these HF features for EZ localization and postsurgical outcome prediction. In 50 patients we analyzed 30 min of SEEG recorded during non-rapid eye movement sleep and tested a logistic regression model with three different sets of features. The first model used broadband features (1-500 Hz); the second model used low-frequency features up to 45 Hz; and the third model used HF features above 65 Hz. The EZ localization by each model was evaluated by various metrics including the area under the precision-recall curve (AUPRC) and the positive predictive value (PPV). The differences between the models were tested by the Wilcoxon signed-rank tests and Cliff's Delta effect size. The differences in outcome predictions based on PPV values were further tested by the McNemar test. The AUPRC score of the random chance classifier was .098. The models (broad-band, low-frequency, high-frequency) achieved median AUPRCs of .608, .582, and .522, respectively, and correctly predicted outcomes in 38, 38, and 33 patients. There were no statistically significant differences in AUPRC or any other metric between the three models. Adding HF features to the model did not have any additional contribution. Low-frequency features are sufficient for correct localization of the EZ and outcome prediction with no additional value when considering HF features. This finding allows significant simplification of the feature calculation process and opens the possibility of using these models in SEEG recordings with lower sampling rates, as commonly performed in clinical routines.",https://pubmed.ncbi.nlm.nih.gov/39180407/,https://pubmed.ncbi.nlm.nih.gov/39180407/,English,Include,,Interictal stereo-electroencephalography features below 45 Hz are sufficient for correct localization of the epileptogenic zone and postsurgical outcome prediction.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39179743,pubmed:39179743,PubMed,pubmed:39179743,Ictal-onset localization through effective connectivity analysis based on RNN-GC with intracranial EEG signals in patients with epilepsy.,Xiaojia Wang;Yanchao Liu;Chunfeng Yang,2024,10.2307/3033543,"Epilepsy is one of the most common clinical diseases of the nervous system. The occurrence of epilepsy will bring many serious consequences, and some patients with epilepsy will develop drug-resistant epilepsy. Surgery is an effective means to treat this kind of patients, and lesion localization can provide a basis for surgery. The purpose of this study was to explore the functional types and connectivity evolution patterns of relevant regions of the brain during seizures. We used intracranial EEG signals from patients with epilepsy as the research object, and the method used was GRU-GC. The role of the corresponding area of each channel in the seizure process was determined by the introduction of group analysis. The importance of each area was analysed by introducing the betweenness centrality and PageRank centrality. The experimental results show that the classification method based on effective connectivity has high accuracy, and the role of the different regions of the brain could also change during the seizures. The relevant methods in this study have played an important role in preoperative assessment and revealing the functional evolution patterns of various relevant regions of the brain during seizures.",https://pubmed.ncbi.nlm.nih.gov/39179743/,https://pubmed.ncbi.nlm.nih.gov/39179743/,English,Include,,Ictal-onset localization through effective connectivity analysis based on RNN-GC with intracranial EEG signals in patients with epilepsy.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39179642,pubmed:39179642,PubMed,pubmed:39179642,Evaluation of perceived urgency from single-trial EEG data elicited by upper-body vibration feedback using deep learning.,Haneen Alsuradi;Jiacheng Shen;Wanjoo Park;Mohamad Eid,2024,10.1016/j.ijpsycho.2007.05.017,"Notification systems that convey urgency without adding cognitive burden are crucial in human-computer interaction. Haptic feedback systems, particularly those utilizing vibration feedback, have emerged as a compelling solution, capable of providing desirable levels of urgency depending on the application. High-risk applications require an evaluation of the urgency level elicited during critical notifications. Traditional evaluations of perceived urgency rely on subjective self-reporting and performance metrics, which, while useful, are not real-time and can be distracting from the task at hand. In contrast, EEG technology offers a direct, non-intrusive method of assessing the user's cognitive state. Leveraging deep learning, this study introduces a novel approach to evaluate perceived urgency from single-trial EEG data, induced by vibration stimuli on the upper body, utilizing our newly collected urgency-via-vibration dataset. The proposed model combines a 2D convolutional neural network with a temporal convolutional network to capture spatial and temporal EEG features, outperforming several established EEG models. The proposed model achieves an average classification accuracy of 83% through leave-one-subject-out cross-validation across three urgency classes (not urgent, urgent, and very urgent) from a single trial of EEG data. Furthermore, explainability analysis showed that the prefrontal brain region, followed by the central brain region, are the most influential in predicting the urgency level. A follow-up neural statistical analysis revealed an increase in event-related synchronization (ERS) in the theta frequency band (4-7 Hz) with the increased level of urgency, which is associated with high arousal and attention in the neuroscience literature. A limitation of this study is that the proposed model's performance was tested only the urgency-via-vibration dataset, which may affect the generalizability of the findings.",https://pubmed.ncbi.nlm.nih.gov/39179642/,https://pubmed.ncbi.nlm.nih.gov/39179642/,English,Include,,Evaluation of perceived urgency from single-trial EEG data elicited by upper-body vibration feedback using deep learning.,Include,," neural network with a temporal convolutional network to capture spatial and temporal EEG features, outperforming several established EEG models. The proposed model achieves an average classification accuracy of 83% through leave-one-subject-out cross-validation across three urgency classes (not urgent, urgent, and very urgent) from a single trial of EEG data. Furthermore, explainability analysis ",,0.95,0.25,cv_reported
pubmed:39178898,pubmed:39178898,PubMed,pubmed:39178898,Distraction impact of concurrent conversation on event-related potential based brain-computer interfaces.,Minju Kim;Sung-Phil Kim,2024,10.1088/1741-2552/ad731e,,,https://pubmed.ncbi.nlm.nih.gov/39178898/,English,Exclude,Not classification-focused,Distraction impact of concurrent conversation on event-related potential based brain-computer interfaces.,,,,,0.85,0.6,
pubmed:39178805,pubmed:39178805,PubMed,pubmed:39178805,SpectroCVT-Net: A convolutional vision transformer architecture and channel attention for classifying Alzheimer's disease using spectrograms.,Mario Alejandro Bravo-Ortiz;Ernesto Guevara-Navarro;Sergio Alejandro Holguín-García;Mariana Rivera-Garcia;Oscar Cardona-Morales;Gonzalo A Ruz;Reinel Tabares-Soto,2024,10.1016/j.compbiomed.2024.109022,"Dementia arises from various brain-affecting diseases and injuries, with Alzheimer's disease being the most prevalent, impacting around 55 million people globally. Current clinical diagnosis often relies on biomarkers indicative of Alzheimer's distinctive features. Electroencephalography (EEG) serves as a cost-effective, user-friendly, and safe biomarker for early Alzheimer's detection. This study utilizes EEG signals processed with Short-Time Fourier Transform (STFT) to generate spectrograms, facilitating visualization of EEG signal properties. Leveraging the Brainlat database, we propose SpectroCVT-Net, a novel convolutional vision transformer architecture incorporating channel attention mechanisms. SpectroCVT-Net integrates convolutional and attention mechanisms to capture local and global dependencies within spectrograms. Comprising feature extraction and classification stages, the model enhances Alzheimer's disease classification accuracy compared to transfer learning methods, achieving 92.59 ± 2.3% accuracy across Alzheimer's, healthy controls, and behavioral variant frontotemporal dementia (bvFTD). This article introduces a new architecture and evaluates its efficacy with unconventional data for Alzheimer's diagnosis, contributing: SpectroCVT-Net, tailored for EEG spectrogram classification without reliance on transfer learning; a convolutional vision transformer (CVT) module in the classification stage, integrating local feature extraction with attention heads for global context analysis; Grad-CAM analysis for network decision insight, identifying critical layers, frequencies, and electrodes influencing classification; and enhanced interpretability through spectrograms, illuminating key brain wave contributions to Alzheimer's, frontotemporal dementia, and healthy control classifications, potentially aiding clinical diagnosis and management.",https://pubmed.ncbi.nlm.nih.gov/39178805/,https://pubmed.ncbi.nlm.nih.gov/39178805/,English,Include,,SpectroCVT-Net: A convolutional vision transformer architecture and channel attention for classifying Alzheimer's disease using spectrograms.,Include,,"l and attention mechanisms to capture local and global dependencies within spectrograms. Comprising feature extraction and classification stages, the model enhances Alzheimer's disease classification accuracy compared to transfer learning methods, achieving 92.59 ± 2.3% accuracy across Alzheimer's, healthy controls, and behavioral variant frontotemporal dementia (bvFTD). This article introduces a ",,0.95,0.6,
pubmed:39178550,pubmed:39178550,PubMed,pubmed:39178550,An approach to the detection of pain from autonomic and cortical correlates.,F Chouchou;C Fauchon;C Perchet;L Garcia-Larrea,2024,10.1016/j.clinph.2024.07.018,"To assess the value of combining brain and autonomic measures to discriminate the subjective perception of pain from other sensory-cognitive activations. 20 healthy individuals received 2 types of tonic painful stimulation delivered to the hand: electrical stimuli and immersion in 10 Celsius degree (°C) water, which were contrasted with non-painful immersion in 15 °C water, and stressful cognitive testing. High-density electroencephalography (EEG) and autonomic measures (pupillary, electrodermal and cardiovascular) were continuously recorded, and the accuracy of pain detection based on combinations of electrophysiological features was assessed using machine learning procedures. Painful stimuli induced a significant decrease in contralateral EEG alpha power. Cardiac, electrodermal and pupillary reactivities occurred in both painful and stressful conditions. Classification models, trained on leave-one-out cross-validation folds, showed low accuracy (61-73%) of cortical and autonomic features taken independently, while their combination significantly improved accuracy to 93% in individual reports. Changes in cortical oscillations reflecting somatosensory salience and autonomic changes reflecting arousal can be triggered by many activating signals other than pain; conversely, the simultaneous occurrence of somatosensory activation plus strong autonomic arousal has great probability of reflecting pain uniquely. Combining changes in cortical and autonomic reactivities appears critical to derive accurate indexes of acute pain perception.",https://pubmed.ncbi.nlm.nih.gov/39178550/,https://pubmed.ncbi.nlm.nih.gov/39178550/,English,Include,,An approach to the detection of pain from autonomic and cortical correlates.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.25,cv_reported
pubmed:39178469,pubmed:39178469,PubMed,pubmed:39178469,Safety and accuracy of stereoelectroencephalography for pediatric and young adult patients with prior craniotomy.,Peter H Yang;Nathan Wulfekammer;Amanda V Jenson;Elliot G Neal;Stuart Tomko;John Zempel;Peter Brunner;Sean D McEvoy;Matthew D Smyth;Jarod L Roland,2024,10.3171/2024.6.peds24198,"The authors assessed the safety and accuracy of stereoelectroencephalography (SEEG) electrode implantation in pediatric patients who had previously undergone craniotomy compared to those without prior cranial surgery. The authors performed a retrospective analysis of patients under 25 years of age with medically refractory epilepsy at a single institution who underwent SEEG electrode placement between March 2016 and July 2023. Surgical history and demographic characteristics were collected from the electronic medical records. The coordinates of the anchor bolts and their respective SEEG electrode contacts were manually annotated using postoperative head CT scans. Bolt coordinates were used to calculate the initiated electrode trajectory set by the bolt by using the least-squares method to define a line along the bolt, projected along the length of the electrode. The shortest distance from each electrode contact to this line was calculated to obtain the error measurement. Statistical analysis was conducted using the Kolmogorov-Smirnov test to compare the distribution of errors between groups, the Student t-test was used for continuous variables, and the chi-square/Fisher's exact test was used for categorical variables. Fifty-eight patients underwent a total of 60 SEEG placements and met the inclusion criteria. Eighteen had a history of prior craniotomy and 40 without prior surgery, indicating entirely native cranial bone. Mean age, sex, and mean number of electrodes implanted per surgery were similar between groups. For the electrode contact furthest from the bolt, a mean (IQR) deviation of 1.32 (0.73-2.53) mm was noted for the prior craniotomy group and 1.08 (0.65-1.55) mm for the native bone group (p < 0.0001). A greater number of outliers for the contact furthest from the bolt, defined as > 6 mm from the initiated electrode trajectory, was seen in the prior craniotomy group (p < 0.0001). The complication rate was low and not statistically different between groups. The authors' analysis draws attention to the effect of the intracranial biomechanical environment along the path of the electrode after traversing past the anchor bolt and found that prior craniotomy was associated with a higher number of contacts with a significant deviation from the initiated trajectory. Despite these deviations, we did not find a difference in the overall low complication rate in both groups. Therefore, the authors conclude that SEEG electrode placement is a safe option in pediatric patients even after prior craniotomy.",https://pubmed.ncbi.nlm.nih.gov/39178469/,https://pubmed.ncbi.nlm.nih.gov/39178469/,English,Include,,Safety and accuracy of stereoelectroencephalography for pediatric and young adult patients with prior craniotomy.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39177685,pubmed:39177685,PubMed,pubmed:39177685,Research on low-power driving fatigue monitoring method based on spiking neural network.,Tianshu Gu;Wanchao Yao;Fuwang Wang;Rongrong Fu,2024,10.1016/j.compbiomed.2022.105718,"Fatigue driving is one of the leading causes of traffic accidents, and the rapid and accurate detection of driver fatigue is of paramount importance for enhancing road safety. However, the application of deep learning models in fatigue driving detection has long been constrained by high computational costs and power consumption. To address this issue, this study proposes an approach that combines Self-Organizing Map (SOM) and Spiking Neural Networks (SNN) to develop a low-power model capable of accurately recognizing the driver's mental state. Initially, spatial features are extracted from electroencephalogram (EEG) signals using the SOM network. Subsequently, the extracted weight vectors are encoded and fed into the SNN for fatigue driving classification. The research results demonstrate that the proposed method effectively considers the spatiotemporal characteristics of EEG signals, achieving efficient fatigue detection. Simultaneously, this approach successfully reduces the model's power consumption. When compared to traditional artificial neural networks, our method reduces energy consumption by approximately 12.21-42.59%.",https://pubmed.ncbi.nlm.nih.gov/39177685/,https://pubmed.ncbi.nlm.nih.gov/39177685/,English,Include,,Research on low-power driving fatigue monitoring method based on spiking neural network.,Exclude,No performance metrics reported,No metrics found in full text,,0.9,0.6,
pubmed:39176950,pubmed:39176950,PubMed,pubmed:39176950,Assessment of Valance Emotional State Using EEG-EDA Coupling and Explainable Classifiers.,Sourabh Banik;Himanshu Kumar;Nagarajan Ganapathy;Ramakrishnan Swaminathan,2024,10.3233/shti240569,"Emotion influences human life and impacts daily life activities. During emotional processes, physiological signals interact with each other instead of functioning separately. Although unimodal and multimodal approaches have been explored for emotion classification, there is a lack of inclusion of central and peripheral nervous system signal interaction-based approaches. In this study, an attempt has been made to characterize valance emotional states using Electroencephalogram (EEG)- Electrodermal activity (EDA) based coupling. For this, multimodal signals are obtained from the publicly available DEAP database (n=32 subjects). The EEG signals are decomposed into θ, α, β, and bands and EDA signals are decomposed into phasic and tonic components. Then two EEG, three EDA, and two EEG-EDA coupling-based features are extracted and applied to three classifiers namely Random Forest (RF), Linear discriminant analysis, and Adaptive boosting. In addition, SHAP analysis is performed to explain classifiers' performance with respect to features. The result shows that the proposed approach is able to classify valence emotional states. The feature combination of EEG, EDA, and EEG-EDA coupling-based features with an RF classifier performs best with an F1-score of 68.21%. SHAP analysis in frontal electrodes with γ band obtained better discrimination among different valance states. This study underscores the significance of the coupling studies of EEG with EDA in classifying emotion. Therefore, the proposed approach can be extended to emotional state assessment in clinical settings.",https://pubmed.ncbi.nlm.nih.gov/39176950/,https://pubmed.ncbi.nlm.nih.gov/39176950/,English,Include,,Assessment of Valance Emotional State Using EEG-EDA Coupling and Explainable Classifiers.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39175939,pubmed:39175939,PubMed,pubmed:39175939,Prognostic value of the 5-SENSE Score to predict focality of the seizure-onset zone as assessed by stereoelectroencephalography: a prospective international multicentre validation study.,Alexandra Astner-Rohracher;Alyssa Ho;John Archer;Fabrice Bartolomei;Milan Brazdil;Melita Cacic Hribljan;James Castellano;Irena Dolezalova;Martin Ejler Fabricius;Mercedes Garcés-Sanchez;Kahina Hammam;Akio Ikeda;Kristin Ikeda;Philippe Kahane;Giridhar Kalamangalam;Gudrun Kalss;Mays Khweileh;Katsuya Kobayashi;Patrick Kwan;Joshua Andrew Laing;Markus Leitinger;Samden Lhatoo;Julia Makhalova;Aileen McGonigal;Iona Mindruta;Mary Margaret Mizera;Andrew Neal;Irina Oane;Prachi Parikh;Piero Perucca;Francesca Pizzo;Rodrigo Rocamora;Philippe Ryvlin;Victoria San Antonio Arce;Stephan Schuele;Andreas Schulze-Bonhage;Ana Suller Marti;Alexandra Urban;Vincente Villanueva;Laura Vilella Bertran;Benjamin Whatley;Sandor Beniczky;Eugen Trinka;Georg Zimmermann;Birgit Frauscher,2024,10.1016/j.jocn.2018.04.064,"Epilepsy surgery is the only curative treatment for patients with drug-resistant focal epilepsy. Stereoelectroencephalography (SEEG) is the gold standard to delineate the seizure-onset zone (SOZ). However, up to 40% of patients are subsequently not operated as no focal non-eloquent SOZ can be identified. The 5-SENSE Score is a 5-point score to predict whether a focal SOZ is likely to be identified by SEEG. This study aims to validate the 5-SENSE Score, improve score performance by incorporating auxiliary diagnostic methods and evaluate its concordance with expert decisions. Non-interventional, observational, multicentre, prospective study including 200 patients with drug-resistant epilepsy aged ≥15 years undergoing SEEG for identification of a focal SOZ and 200 controls at 22 epilepsy surgery centres worldwide. The primary objective is to assess the diagnostic accuracy and generalisability of the 5-SENSE in predicting focality in SEEG in a prospective cohort. Secondary objectives are to optimise score performance by incorporating auxiliary diagnostic methods and to analyse concordance of the 5-SENSE Score with the expert decisions made in the multidisciplinary team discussion. Prospective multicentre validation of the 5-SENSE score may lead to its implementation into clinical practice to assist clinicians in the difficult decision of whether to proceed with implantation. This study will be conducted in accordance with the Tri-Council Policy Statement: Ethical Conduct for Research Involving Humans (2014). We plan to publish the study results in a peer-reviewed full-length original article and present its findings at scientific conferences. NCT06138808.",,https://pubmed.ncbi.nlm.nih.gov/39175939/,English,Exclude,Review/survey papers,Prognostic value of the 5-SENSE Score to predict focality of the seizure-onset zone as assessed by stereoelectroencephalography: a prospective international multicentre validation study.,,,,,0.95,0.6,
pubmed:39175558,pubmed:39175558,PubMed,pubmed:39175558,Comparative Study of Frequency Recognition Techniques for Steady-State Visual Evoked Potentials According to the Frequency Harmonics and Stimulus Number.,Maedeh Azadi Moghadam;Ali Maleki,2024,10.1186/1743-0003-8-39,"A key challenge in steady-state visual evoked potential (SSVEP)-based brain-computer interface (BCI) systems is to effectively recognize frequencies within a short time window. To address this challenge, the specific characteristics of the data are needed to select the frequency recognition method. These characteristics include factors, such as the number of stimulation targets and the presence of harmonic frequencies, resulting in optimizing the performance and accuracy of SSVEP-based BCI systems. The current study aimed to examine the effect of data characteristics on frequency recognition accuracy. In this analytical study, five commonly used frequency recognition methods were examined, used to various datasets containing different numbers of frequencies, including sub-data with and without frequency harmonics. The increase in the number of frequencies in the Multivariate Linear Regression (MLR) method has led to a decrease in frequency recognition accuracy by 9%. Additionally, the presence of harmonic frequencies resulted in an 8% decrease in accuracy for the MLR method. Frequency recognition using the MLR method reduces the effect of the number of different frequencies and harmonics of the stimulation frequencies on the frequency recognition accuracy.",https://pubmed.ncbi.nlm.nih.gov/39175558/,https://pubmed.ncbi.nlm.nih.gov/39175558/,English,Include,,Comparative Study of Frequency Recognition Techniques for Steady-State Visual Evoked Potentials According to the Frequency Harmonics and Stimulus Number.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39173778,pubmed:39173778,PubMed,pubmed:39173778,Impairment of inhibitory control due to repetitive subconcussions from indirect brain impacts: Evidence from event-related potentials and resting-state EEG complexity in parachuters.,Zhenghao Fu;Min Liu;Shuochen Wang;Haoran Zhang;Yuanyi Sun;Yang Zhou;Xiang Li;Pingjing Ming;Jian Song;Guozheng Xu,2024,10.1016/j.brainresbull.2024.111053,"The present study aims to investigate the unknown relationship between inhibitory control and repetitive subconcussion induced by the indirect brain impacts. We enrolled 28 parachuters exposed to repetitive subconcussion (SC) and 27 matched health controls (HC). Parachuters who have completed at least 70 actual parachuting (71-112 times) and at least 1500 simulated platform jumps (1500-4500 times) were included in the SC group. The SC group had a reduced accuracy rate in both the Stroop congruent and incongruent conditions. Larger N2 and N450 amplitudes were elicited in the frontal regions of the SC group, which indicate compensatory adaptations to the deficit in conflict monitoring. The reduced frontal resting-state EEG complexity in full-band (1-40 Hz) may demonstrate the frontal structural damage following the indirect brain impacts of repetitive subconcussion. Pearson correlation analysis showed that in the SC group, the frontal beta-band sample entropy values are positively correlated with the accuracy rate of the Stroop incongruent condition, suggesting the frontal beta-band sample entropy values may serve as potential electrophysiological markers of impaired inhibitory control after indirectly repetitive brain impacts. This study provides the robust evidence that repetitive subconcussion resulting from indirect brain impacts may lead to impairment of inhibitory control.",https://pubmed.ncbi.nlm.nih.gov/39173778/,https://pubmed.ncbi.nlm.nih.gov/39173778/,English,Include,,Impairment of inhibitory control due to repetitive subconcussions from indirect brain impacts: Evidence from event-related potentials and resting-state EEG complexity in parachuters.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39173485,pubmed:39173485,PubMed,pubmed:39173485,Continual learning for seizure prediction via memory projection strategy.,Yufei Shi;Shishi Tang;Yuxuan Li;Zhipeng He;Shengsheng Tang;Ruixuan Wang;Weishi Zheng;Ziyi Chen;Yi Zhou,2024,10.1016/j.compbiomed.2024.109028,"Despite extensive algorithms for epilepsy prediction via machine learning, most models are tailored for offline scenarios and cannot handle actual scenarios where data changes over time. Catastrophic forgetting(CF) for learned electroencephalogram(EEG) data occurs when EEG changes dynamically in the clinical setting. This paper implements a continual learning(CL) strategy Memory Projection(MP) for epilepsy prediction, which can be combined with other algorithms to avoid CF. Such a strategy enables the model to learn EEG data from each patient in dynamic subspaces with weak correlation layer by layer to minimize interference and promote knowledge transfer. Regularization Loss Reconstruction Algorithm and Matrix Dimensionality Reduction Algorithm are introduced into the core of MP. Experimental results show that MP exhibits excellent performance and low forgetting rates in sequential learning of seizure prediction. The forgetting rate of accuracy and sensitivity under multiple experiments are below 5%. When learning from multi-center datasets, the forgetting rates for accuracy and sensitivity decrease to 0.65% and 1.86%, making it comparable to state-of-the-art CL strategies. Through ablation experiments, we have analyzed that MP can operate with minimal storage and computational cost, which demonstrates practical potential for seizure prediction in clinical scenarios.",https://pubmed.ncbi.nlm.nih.gov/39173485/,https://pubmed.ncbi.nlm.nih.gov/39173485/,English,Include,,Continual learning for seizure prediction via memory projection strategy.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39173295,pubmed:39173295,PubMed,pubmed:39173295,An interpretable tinnitus prediction framework using gap-prepulse inhibition in auditory late response and electroencephalogram.,Iqram Hussain;Chiheon Kwon;Tae-Soo Noh;Hee Chan Kim;Myung-Whan Suh;Yunseo Ku,2024,10.1016/j.cmpb.2024.108371,"Tinnitus is a neuropathological condition that results in mild buzzing or ringing of the ears without an external sound source. Current tinnitus diagnostic methods often rely on subjective assessment and require intricate medical examinations. This study aimed to propose an interpretable tinnitus diagnostic framework using auditory late response (ALR) and electroencephalogram (EEG), inspired by the gap-prepulse inhibition (GPI) paradigm. We collected spontaneous EEG and ALR data from 44 patients with tinnitus and 47 hearing loss-matched controls using specialized hardware to capture responses to sound stimuli with embedded gaps. In this cohort study of tinnitus and control groups, we examined EEG spectral and ALR features of N-P complexes, comparing the responses to gap durations of 50 and 20 ms alongside no-gap conditions. To this end, we developed an interpretable tinnitus diagnostic model using ALR and EEG metrics, boosting machine learning architecture, and explainable feature attribution approaches. Our proposed model achieved 90 % accuracy in identifying tinnitus, with an area under the performance curve of 0.89. The explainable artificial intelligence approaches have revealed gap-embedded ALR features such as the GPI ratio of N1-P2 and EEG spectral ratio, which can serve as diagnostic metrics for tinnitus. Our method successfully provides personalized prediction explanations for tinnitus diagnosis using gap-embedded auditory and neurological features. Deficits in GPI alongside activity in the EEG alpha-beta ratio offer a promising screening tool for assessing tinnitus risk, aligning with current clinical insights from hearing research.",https://pubmed.ncbi.nlm.nih.gov/39173295/,https://pubmed.ncbi.nlm.nih.gov/39173295/,English,Include,,An interpretable tinnitus prediction framework using gap-prepulse inhibition in auditory late response and electroencephalogram.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39171023,pubmed:39171023,PubMed,pubmed:39171023,Application of EEG in the Diagnosis and Classification of Migraine: A Scoping Review.,Lakshana Raghuraman;Shiv H Joshi,2024,10.7759/cureus.64961,"Migraine is a chronic debilitating disease affecting a significant number of people, more often women than men. The gold standard for diagnosis is the International Classification of Headache Disorders-3 (ICHD-3). Authors have identified multiple tight spots in the present method of diagnosis. An alternative method of diagnosis has always been coveted. Electroencephalogram (EEG) is one of the most researched of such alternatives. The visually evoked potential is the most studied; auditory evoked potentials and transcranial direct current stimulation are also being studied. Cortical hyperexcitability and habituation deficit to sensory stimuli are some of the consistent findings. Alpha oscillations are among the most frequently studied bands; spectral analysis of EEG waves has often shown more reliable and consistent results than features read off the EEG directly. EEG microstate is a novel and promising method showing characteristic identifiable features that may help diagnose Migraine patients. An alternative to the ICHD-3 criterion for diagnosing Migraines would be instrumental in promptly diagnosing the disease. EEG is one of the most explored alternatives within which enumerable features can be used to identify Migraines, of which the most promising are EEG microstates.",,https://pubmed.ncbi.nlm.nih.gov/39171023/,English,Exclude,Review/survey papers,Application of EEG in the Diagnosis and Classification of Migraine: A Scoping Review.,,,,,0.95,0.6,
pubmed:39170680,pubmed:39170680,PubMed,pubmed:39170680;pubmed:39156825,Vagus nerve electroneurogram-based detection of acute kainic acid induced seizures.,Elena Acedo Reina;Enrique Germany Morrison;Ayse S Dereli;Elise Collard;Romain Raffoul;Antoine Nonclercq;Riëm El Tahry,2024,10.1109/fbie.2008.41,"Seizures produce autonomic symptoms, mainly sympathetic but also parasympathetic in origin. Within this context, the vagus nerve is a key player as it carries information from the different organs to the brain and vice versa. Hence, exploiting vagal neural traffic for seizure detection might be a promising tool to improve the efficacy of closed-loop Vagus Nerve Stimulation. This study developed a VENG detection algorithm that effectively detects seizures by emphasizing the loss of spontaneous rhythmicity associated with respiration in acute intrahippocampal Kainic Acid rat model. Among 20 induced seizures in six anesthetized rats, 13 were detected (sensitivity: 65%, accuracy: 92.86%), with a mean VENG-detection delay of 25.3 ± 13.5 s after EEG-based seizure onset. Despite variations in detection parameters, 7 out of 20 seizures exhibited no ictal VENG modifications and remained undetected. Statistical analysis highlighted a significant difference in Delta, Theta and Beta band evolution between detected and undetected seizures, in addition to variations in the magnitude of HR changes. Binomial logistic regression analysis confirmed that an increase in delta and theta band activity was associated with a decreased likelihood of seizure detection. This results suggest the possibility of distinct seizure spreading patterns between the two groups which may results in differential activation of the autonomic central network. Despite notable progress, limitations, particularly the absence of respiration recording, underscore areas for future exploration and refinement in closed-loop stimulation strategies for epilepsy management. This study constitutes the initial phase of a longitudinal investigation, which will subsequently involve reproducing these experiments in awake conditions with spontaneous recurrent seizures.",https://pubmed.ncbi.nlm.nih.gov/39170680/,https://pubmed.ncbi.nlm.nih.gov/39170680/,English,Include,,Vagus nerve electroneurogram-based detection of acute kainic acid induced seizures.,Exclude,Duplicate study,Duplicate group,,0.99,0.6,
pubmed:39170600,pubmed:39170600,PubMed,pubmed:39170600,The decoder design and performance comparative analysis for closed-loop brain-machine interface system.,Hongguang Pan;Yunpeng Fu;Qi Zhang;Jingyuan Zhang;Xuebin Qin,2024,10.1109/tai.2021.3098253,"Brain-machine interface (BMI) can convert electroencephalography signals (EEGs) into the control instructions of external devices, and the key of control performance is the accuracy and efficiency of decoder. However, the performance of different decoders obtaining control instructions from complex and variable EEG signals is very different and irregular in the different neural information transfer model. Aiming at this problem, the off-line and on-line performance of eight decoders based on the improved single-joint information transmission (SJIT) model is compared and analyzed in this paper, which can provide a theoretical guidance for decoder design. Firstly, in order to avoid the different types of neural activities in the decoding process on the decoder performance, eight decoders based on the improved SJIT model are designed. And then the off-line decoding performance of these decoders is tested and compared. Secondly, a closed-loop BMI system which combining by the designed decoder and the random forest encoder based on the improved SJIT model is constructed. Finally, based on the constructed closed-loop BMI system, the on-line decoding performance of decoders is compared and analyzed. The results show that the LSTM-based decoder has better on-line decoding performance than others in the improved SJIT model.",https://pubmed.ncbi.nlm.nih.gov/39170600/,https://pubmed.ncbi.nlm.nih.gov/39170600/,English,Include,,The decoder design and performance comparative analysis for closed-loop brain-machine interface system.,Include,,"Brain-machine interface (BMI) can convert electroencephalography signals (EEGs) into the control instructions of external devices, and the key of control performance is the accuracy and efficiency of decoder. However, the performance of different decoders obtaining control instructions from complex and variable EEG signals is very different and irregular in the different",,0.95,0.6,
pubmed:39170428,pubmed:39170428,PubMed,pubmed:39170428,Home-video EEG monitoring in a pediatric setting.,Yael Michaeli;Lubov Blumkin;Mordekhay Medvedovsky;Ilan Dalal;Andreea Nissenkorn,2024,10.1016/j.heliyon.2024.e35108,"Pediatric video-EEG monitoring is a standard procedure in epilepsy clinics, typically conducted in in-hospital settings.However, hospitalizationis sometimesunnecessary and imposes a burden on children and their families. In response to the rise of telehealth, home video-EEG monitoring has emerged, utilizing portable EEG equipment and video-cameras. The aim of this study was to assess the feasibility of home video-EEGin a pediatric population. We conducteda prospective pilot study of twentyhome video-EEG tests in children. We evaluated the quality of EEG and video recordings using a 5-point scale.Demographic, clinical and quality data were comparedto a similar group undergoing in-hospital video-EEG monitoring. Twenty children aged 2.1-17.2 years (mean 9.57 ± 1.01), 12 females (60 %), underwent home video-EEG. A higher proportion of children with intellectual disability/autism were observed in the home-EEG group compared to the in-hospital group: 12 patients (60 %) vs. 5 (25 %) (p < 0.05*, Fisher exact test). In the ambulatory group patients with developmental and epileptic encephalopathy were overrepresented (7 i.e., 35 % vs. 0), while those withself-limited childhood epilepsy were more prevalent in the in-hospital group (5 i.e., 25 % vs 0) (p < 0.05*, Chi square). In the ambulatory group the reasons for referral were seizure localization/classification in 11 patients (55 %), paroxysmal event classification in 5 (25 %) and quantification of sleep epileptic activity in 4(20 %),similar to the in-hospital group (40 %, 40 % and 20 % respectively, p > 0.05, Chi square). The quality of the EEG recording was higher compared to in-hospital tests: median 5 [IQR 3.25-5] vs 4[IQR 3-4] (p < 0.05*, Mann-Whitney  Home video-EEG monitoring is apromising option forlong-termpediatric EEG monitoring, particularlyfor children with special needs.",https://pubmed.ncbi.nlm.nih.gov/39170428/,https://pubmed.ncbi.nlm.nih.gov/39170428/,English,Include,,Home-video EEG monitoring in a pediatric setting.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39167520,pubmed:39167520,PubMed,pubmed:39167520,Accurate Mental Stress Detection Using Sequential Backward Selection and Adaptive Synthetic Methods.,Hui-Chun Tseng;Kuang-Yi Tai;Yu-Zheng Ma;Lan-Da Van;Li-Wei Ko;Tzyy-Ping Jung,2024,10.1109/tnsre.2024.3447274,"The daily experience of mental stress profoundly influences our health and work performance while concurrently triggering alterations in brain electrical activity. Electroencephalogram (EEG) is a widely adopted method for assessing cognitive and affective states. This study delves into the EEG correlates of stress and the potential use of resting EEG in evaluating stress levels. Over 13 weeks, our longitudinal study focuses on the real-life experiences of college students, collecting data from each of the 18 participants across multiple days in classroom settings. To tackle the complexity arising from the multitude of EEG features and the imbalance in data samples across stress levels, we use the sequential backward selection (SBS) method for feature selection and the adaptive synthetic (ADASYN) sampling algorithm for imbalanced data. Our findings unveil that delta and theta features account for approximately 50% of the selected features through the SBS process. In leave-one-out (LOO) cross-validation, the combination of band power and pair-wise coherence (COH) achieves a maximum balanced accuracy of 94.8% in stress-level detection for the above daily stress dataset. Notably, using ADASYN and borderline synthesized minority over-sampling technique (borderline-SMOTE) methods enhances model accuracy compared to the traditional SMOTE approach. These results provide valuable insights into using EEG signals for assessing stress levels in real-life scenarios, shedding light on potential strategies for managing stress more effectively.",https://pubmed.ncbi.nlm.nih.gov/39167520/,https://pubmed.ncbi.nlm.nih.gov/39167520/,English,Include,,Accurate Mental Stress Detection Using Sequential Backward Selection and Adaptive Synthetic Methods.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.45,cv_reported;small_sample_mentioned
pubmed:39167519,pubmed:39167519,PubMed,pubmed:39167519,Driving Fatigue Detection Based on Hybrid Electroencephalography and Eye Tracking.,Zequan Lian;Tao Xu;Zhen Yuan;Junhua Li;Nitish Thakor;Hongtao Wang,2024,10.1109/jbhi.2024.3446952,"EEG-based unimodal method has demonstrated significant success in the detection of driving fatigue. Nonetheless, data from a single modality might be not sufficient to optimize fatigue detection due to incomplete information. To address this limitation and enhance the performance of driving fatigue detection, a novel multimodal architecture combining hybrid electroencephalograph (EEG) and eye tracking data was proposed in this work. Specifically, the EEG and eye tracking data were separately input into encoders, generating two one-dimensional (1D) features. Subsequently, these 1D features were fed into a cross-modal predictive alignment module to improve fusion efficiency and two 1D attention modules to enhance feature representation. Furthermore, the fused features were recognized by a linear classifier. To evaluate the effectiveness of the proposed multimodal method, comprehensive validation tasks were conducted, including intra-session, cross-session, and cross-subject evaluations. In the intra-session task, the proposed architecture achieves an exceptional average accuracy of 99.93%. Moreover, in the cross-session task, our method demonstrates an average accuracy of 88.67%, surpassing the performance of EEG-only approach by 8.52%, eye tracking-only method by 5.92%, multimodal deep canonical correlation analysis (DCCA) technique by 0.42%, and multimodal deep generalized canonical correlation analysis (DGCCA) approach by 0.84%. Similarly, in the cross-subject task, the proposed approach achieves an average accuracy of 78.19%, outperforming EEG-only method by 5.87%, eye tracking-only approach by 4.21%, DCCA method by 0.55%, and DGCCA approach by 0.44%. The experimental results conclusively illustrate the superior effectiveness of the proposed method compared to both single modality approaches and canonical correlation analysis-based multimodal methods.",https://pubmed.ncbi.nlm.nih.gov/39167519/,https://pubmed.ncbi.nlm.nih.gov/39167519/,English,Include,,Driving Fatigue Detection Based on Hybrid Electroencephalography and Eye Tracking.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39167115,pubmed:39167115,PubMed,pubmed:39167115,HyEpiSeiD: a hybrid convolutional neural network and gated recurrent unit model for epileptic seizure detection from electroencephalogram signals.,Rajdeep Bhadra;Pawan Kumar Singh;Mufti Mahmud,2024,10.32604/cmc.2021.018239,"Epileptic seizure (ES) detection is an active research area, that aims at patient-specific ES detection with high accuracy from electroencephalogram (EEG) signals. The early detection of seizure is crucial for timely medical intervention and prevention of further injuries of the patients. This work proposes a robust deep learning framework called HyEpiSeiD that extracts self-trained features from the pre-processed EEG signals using a hybrid combination of convolutional neural network followed by two gated recurrent unit layers and performs prediction based on those extracted features. The proposed HyEpiSeiD framework is evaluated on two public datasets, the UCI Epilepsy and Mendeley datasets. The proposed HyEpiSeiD model achieved 99.01% and 97.50% classification accuracy, respectively, outperforming most of the state-of-the-art methods in epilepsy detection domain.",https://pubmed.ncbi.nlm.nih.gov/39167115/,https://pubmed.ncbi.nlm.nih.gov/39167115/,English,Include,,HyEpiSeiD: a hybrid convolutional neural network and gated recurrent unit model for epileptic seizure detection from electroencephalogram signals.,Include,,"Epileptic seizure (ES) detection is an active research area, that aims at patient-specific ES detection with high accuracy from electroencephalogram (EEG) signals. The early detection of seizure is crucial for timely medical intervention and prevention of further injuries of the patients. This work proposes a rob",,0.95,0.6,
pubmed:39166947,pubmed:39166947,PubMed,pubmed:39166947,Brain-computer interfaces: the innovative key to unlocking neurological conditions.,Hongyu Zhang;Le Jiao;Songxiang Yang;Haopeng Li;Xinzhan Jiang;Jing Feng;Shuhuai Zou;Qiang Xu;Jianheng Gu;Xuefeng Wang;Baojian Wei,2024,10.1109/jbhi.2024.3392412,"Neurological disorders such as Parkinson's disease, stroke, and spinal cord injury can pose significant threats to human mortality, morbidity, and functional independence. Brain-Computer Interface (BCI) technology, which facilitates direct communication between the brain and external devices, emerges as an innovative key to unlocking neurological conditions, demonstrating significant promise in this context. This comprehensive review uniquely synthesizes the latest advancements in BCI research across multiple neurological disorders, offering an interdisciplinary perspective on both clinical applications and emerging technologies. We explore the progress in BCI research and its applications in addressing various neurological conditions, with a particular focus on recent clinical studies and prospective developments. Initially, the review provides an up-to-date overview of BCI technology, encompassing its classification, operational principles, and prevalent paradigms. It then critically examines specific BCI applications in movement disorders, disorders of consciousness, cognitive and mental disorders, as well as sensory disorders, highlighting novel approaches and their potential impact on patient care. This review reveals emerging trends in BCI applications, such as the integration of artificial intelligence and the development of closed-loop systems, which represent significant advancements over previous technologies. The review concludes by discussing the prospects and directions of BCI technology, underscoring the need for interdisciplinary collaboration and ethical considerations. It emphasizes the importance of prioritizing bidirectional and high-performance BCIs, areas that have been underexplored in previous reviews. Additionally, we identify crucial gaps in current research, particularly in long-term clinical efficacy and the need for standardized protocols. The role of neurosurgery in spearheading the clinical translation of BCI research is highlighted. Our comprehensive analysis presents BCI technology as an innovative key to unlocking neurological disorders, offering a transformative approach to diagnosing, treating, and rehabilitating neurological conditions, with substantial potential to enhance patients' quality of life and advance the field of neurotechnology.",,https://pubmed.ncbi.nlm.nih.gov/39166947/,English,Exclude,Review/survey papers,Brain-computer interfaces: the innovative key to unlocking neurological conditions.,,,,,0.95,0.6,
pubmed:39166916,pubmed:39166916,PubMed,pubmed:39166916,A model for electroencephalogram emotion recognition: Residual block-gated recurrent unit with attention mechanism.,Yujie Wang;Xiu Zhang;Xin Zhang;Baiwei Sun;Bingyue Xu,2024,10.1063/5.0221637,"Electroencephalogram (EEG) signals, serving as a tool to objectively reflect real emotional states, hold a crucial position in emotion recognition research. In recent years, deep learning approaches have been widely applied in emotion recognition research, and the results have demonstrated their effectiveness in this field. Nevertheless, the challenge remains in selecting effective features, ensuring their retention as the network depth increases, and preventing the loss of crucial information. In order to address the issues, a novel emotion recognition method is proposed, which is named Res-CRANN. In the proposed method, the raw EEG signals are transformed into four dimensional spatial-frequency-temporal information, which can provide a more enriched and complex feature representation. First, the residual block is incorporated into the convolutional layers to extract spatial and frequency domain information. Subsequently, gated recurrent unit (GRU) is employed to capture temporal information from the convolutional neural network outputs. Following GRU, attention mechanisms are applied to enhance awareness of key information and diminish interference from irrelevant details. By reducing attention to irrelevant or noisy temporal steps, it ultimately improves the accuracy and robustness of the classification process. The Res-CRANN method exhibits excellent performance on the DEAP dataset, with an accuracy of 96.63% for valence and 96.87% for arousal, confirming its effectiveness.",https://pubmed.ncbi.nlm.nih.gov/39166916/,https://pubmed.ncbi.nlm.nih.gov/39166916/,English,Include,,A model for electroencephalogram emotion recognition: Residual block-gated recurrent unit with attention mechanism.,Include,,"chanisms are applied to enhance awareness of key information and diminish interference from irrelevant details. By reducing attention to irrelevant or noisy temporal steps, it ultimately improves the accuracy and robustness of the classification process. The Res-CRANN method exhibits excellent performance on the DEAP dataset, with an accuracy of 96.63% for valence and 96.87% for arousal, confirmin",,0.95,0.6,
pubmed:39166397,pubmed:39166397,PubMed,pubmed:39166397,The effects of different types of emotion words on emotion picture processing - evidence from event-related potential.,Songhan Liu;Shuyi Liu;Yaru Li;Liyuan Liu;Yue Shen,2024,10.1097/wnr.0000000000002060,"Emotional information can be seen everywhere in daily life. Research on emotional words often employs lexical decision tasks to judge the veracity of words, involving only superficial processing and not the deep processing of emotional significance. Therefore, the purpose of this study is to explore the effect of types of emotional words on the processing of emotional pictures. Participants were publicly recruited for a button-press experiment to discuss the impact of emotional words on the processing of emotional pictures from both behavioral and physiological mechanisms. The results of experiment 1 show: (a) in terms of reaction time, the processing speed for negative emotional words was slower, with longer reaction times; (b) In terms of accuracy, positive emotional words had a higher correct rate than negative emotional words. The results of experiment 2 found: (a) a significant main effect of emotional word type in the late processing stage; (b) a significant interaction between emotional word type and congruency. Previously presented emotional words affect the processing of subsequently presented emotional pictures, with differences in the processing of the four types of words, indicating a significant role of language in emotional processing.",,https://pubmed.ncbi.nlm.nih.gov/39166397/,English,Exclude,Not EEG-BCI focused,The effects of different types of emotion words on emotion picture processing - evidence from event-related potential.,,,,,0.9,0.8,small_sample_mentioned
pubmed:39164731,pubmed:39164731,PubMed,pubmed:39164731,Nociception level index variations in ICU: curarized vs non-curarized patients - a pilot study.,Emilio Bonvecchio;Davide Vailati;Federica Della Mura;Giovanni Marino,2024,10.1213/ane.0b013e3181a9fc38,"Pain is a major physiological stressor that can worsen critical medical conditions in many ways. Currently, there is no reliable monitoring tool which is available for pain monitoring in the deeply sedated ± curarized critically ill patients. This study aims to assess the effectiveness of the multiparameter nociception index (NOL®) in the critical care setting. We compared NOL with traditionally used neurovegetative signs and examined its correlation with sedation depth measured by bispectral index (BIS®) electroencephalographic (EEG) monitoring. This retrospective monocentric cohort study was conducted in a general intensive care unit, including patients who required moderate-to-deep levels of sedation with or without continuous neuromuscular blockade. The performance of NOL was evaluated both in the entire studied population, as well as in two subgroups: curarized and non-curarized patients. NOL demonstrated greater accuracy than all other indicators in pain detection in the overall population. In the non-curare subgroup, all indices correctly recognized painful stimulation, while in the patients subjected to neuromuscular blocking agent's infusion, only NOL properly identified nociception. In the former group, EEG's relation to nociception was on the border of statistical significance, whereas in the latter BIS showed no correlation with NOL. NOL emerges as a promising device for pain assessment in the critical care setting and exhibits its best performance precisely in the clinical context where reliable pain assessment methods are most lacking. Furthermore, our research confirms the distinction between sedation and analgesia, highlighting the necessity for distinct monitoring instruments to accurately assess them.",https://pubmed.ncbi.nlm.nih.gov/39164731/,https://pubmed.ncbi.nlm.nih.gov/39164731/,English,Include,,Nociception level index variations in ICU: curarized vs non-curarized patients - a pilot study.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39163898,pubmed:39163898,PubMed,pubmed:39163898,Towards discovery and implementation of neurophysiologic biomarkers of Alzheimer's disease using entropy methods.,Leif E R Simmatis;Emma E Russo;Yasemin Altug;Vijairam Murugathas;Josh Janevski;Donghun Oh;Queenny Chiu;Irene E Harmsen;Nardin Samuel,2024,10.1016/j.neuroscience.2024.08.017,"Alzheimer's disease (AD) is a prevalent and debilitating neurodegenerative disease that leads to substantial loss of quality of life. Therapies currently available for AD do not modify the disease course and have limited efficacy in symptom control. As such, novel and precise therapies tailored to individual patients' neurophysiologic profiles are needed. Functional neuroimaging tools have demonstrated substantial potential to provide quantifiable insight into brain function in various neurologic disorders, particularly AD. Entropy, a novel analysis for better understanding the nonlinear nature of neurophysiological data, has demonstrated consistent accuracy in disease detection. This literature review characterizes the use of entropy-based analyses from functional neuroimaging tools, including electroencephalography (EEG) and magnetoencephalography (MEG), in patients with AD for disease detection, therapeutic response measurement, and providing clinical insights.",,https://pubmed.ncbi.nlm.nih.gov/39163898/,English,Exclude,Review/survey papers,Towards discovery and implementation of neurophysiologic biomarkers of Alzheimer's disease using entropy methods.,,,,,0.95,0.6,
pubmed:39163173,pubmed:39163173,PubMed,pubmed:39163173,Characterizing Autism Spectrum Disorder Through Fusion of Local Cortical Activation and Global Functional Connectivity Using Game-Based Stimuli and a Mobile EEG System.,Yi-Li Tseng;Chia-Hsin Lee;Yen-Nan Chiu;Wen-Che Tsai;Jui-Sheng Wang;Wei-Chen Wu;Yi-Ling Chien,2024,10.1109/tnsre.2024.3417210,"The deficit in social interaction skills among individuals with autism spectrum disorder (ASD) is strongly influenced by personal experiences and social environments. Neuroimaging studies have previously highlighted the link between social impairment and brain activity in ASD. This study aims to develop a method for assessing and identifying ASD using a social cognitive game-based paradigm combined with electroencephalo-graphy (EEG) signaling features. Typically developing (TD) participants and autistic preadolescents and teenagers were recruited to participate in a social game while 12-channel EEG signals were recorded. The EEG signals underwent preprocessing to analyze local brain activities, including event-related potentials (ERPs) and time-frequency features. Additionally, the global brain network's functional connectivity between brain regions was evaluated using phase-lag indices (PLIs). Subsequently, machine learning models were employed to assess the neurophysiological features. Results indicated pronounced ERP components, particularly the late positive potential (LPP), in parietal regions during social training. Autistic preadolescents and teenagers exhibited lower LPP amplitudes and larger P200 amplitudes compared to TD participants. Reduced theta synchronization was also observed in the ASD group. Aberrant functional connectivity within certain time intervals was noted in the ASD group. Machine learning analysis revealed that support-vector machines achieved a sensitivity of 100%, specificity of 91.7%, and accuracy of 95.8% as part of the performance evaluation when utilizing ERP and brain oscillation features for ASD characterization. These findings suggest that social interaction difficulties in autism are linked to specific brain activation patterns. Traditional behavioral assessments face challenges of subjectivity and accuracy, indicating the potential use of social training interfaces and EEG features for cognitive assessment in ASD.",https://pubmed.ncbi.nlm.nih.gov/39163173/,https://pubmed.ncbi.nlm.nih.gov/39163173/,English,Include,,Characterizing Autism Spectrum Disorder Through Fusion of Local Cortical Activation and Global Functional Connectivity Using Game-Based Stimuli and a Mobile EEG System.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39162772,pubmed:39162772,PubMed,pubmed:39162772,Combined value of interictal markers and stimulated seizures to estimate the seizure onset zone in stereoelectroencephalography.,Lauri Rekola;Maria Peltola;Jukka Vanhanen;Juha Wilenius;Eeva-Liisa Metsähonkala;Leena Kämppi;Leena Lauronen;Päivi Nevalainen,2024,10.1111/epi.18083,"This study was undertaken to investigate the potential of interictal electroencephalographic (EEG) findings and electrically stimulated seizures during stereo-EEG (SEEG) as surrogate markers for the spontaneous seizure onset zone (spSOZ). We hypothesized that combining the localizing information of these markers would allow clinically meaningful estimation of the spSOZ. We included all patients (n = 63) who underwent SEEG between January 2013 and March 2020 at Helsinki University Hospital and had spontaneous seizures during the recording. We scored spikes, gamma activity, and background abnormality on each channel visually during a 12-h epoch containing waking state and sleep. Based on semiology, we classified stimulated seizures as typical or atypical/unclassifiable and estimated the stimulated SOZ (stimSOZ) for typical seizures. To assess which markers increased the odds of channel inclusion in the spSOZ, we fitted mixed effects logistic regression models. A combined regression model including the stimSOZ and interictal markers scored during sleep performed better in estimating which channels were part of the spSOZ than models based on stimSOZ (p < .001) or interictal markers (p < .001) alone. Of the individual markers, the effect sizes were greatest for inclusion of a channel in the stimSOZ (odds ratio [OR] = 60, 95% confidence interval [CI] = 37-97, p < .001) and for continuous (OR = 25, 95% CI = 12-55, p < .001) and subcontinuous (OR = 36, 95% CI = 21-64, p < .001) interictal spiking. At the individual level, the model's accuracy to predict spSOZ inclusion varied markedly (median accuracy = 85.7, range = 54.4-100), which was not explained by etiology (p > .05). Compared to either marker alone, combining visually rated interictal SEEG markers and stimulated seizures improved prediction of which SEEG channels belonged to the spSOZ. Inclusion in the stimSOZ and continuous or subcontinuous spikes increased the odds of spSOZ inclusion the most. Future studies should investigate whether suboptimal sampling of the true epileptogenic zone can explain the model's poor performance in certain patients.",https://pubmed.ncbi.nlm.nih.gov/39162772/,https://pubmed.ncbi.nlm.nih.gov/39162772/,English,Include,,Combined value of interictal markers and stimulated seizures to estimate the seizure onset zone in stereoelectroencephalography.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39160031,pubmed:39160031,PubMed,pubmed:39160031,"Automated explainable wavelet-based sleep scoring system for a population suspected with insomnia, apnea and periodic leg movement.",Manisha Ingle;Manish Sharma;Shresth Verma;Nishant Sharma;Ankit Bhurane;U Rajendra Acharya,2024,10.1016/j.medengphy.2024.104208,"Sleep is an integral and vital component of human life, contributing significantly to overall health and well-being, but a considerable number of people worldwide experience sleep disorders. Sleep disorder diagnosis heavily depends on accurately classifying sleep stages. Traditionally, this classification has been performed manually by trained sleep technologists that visually inspect polysomnography records. However, in order to mitigate the labor-intensive nature of this process, automated approaches have been developed. These automated methods aim to streamline and facilitate sleep stage classification. This study aims to classify sleep stages in a dataset comprising subjects with insomnia, PLM, and sleep apnea. The dataset consists of PSG recordings from the multi-ethnic study of atherosclerosis (MESA) cohort of the national sleep research resource (NSRR), including 2056 subjects. Among these subjects, 130 have insomnia, 39 suffer from PLM, 156 have sleep apnea, and the remaining 1731 are classified as good sleepers. This study proposes an automated computerized technique to classify sleep stages, developing a machine-learning model with explainable artificial intelligence (XAI) capabilities using wavelet-based Hjorth parameters. An optimal biorthogonal wavelet filter bank (BOWFB) has been employed to extract subbands (SBs) from 30 seconds of electroencephalogram (EEG) epochs. Three EEG channels, namely: Fz_Cz, Cz_Oz, and C4_M1, are employed to yield an optimum outcome. The Hjorth parameters extracted from SBs were then fed to different machine learning algorithms. To gain an understanding of the model, in this study, we used SHAP (Shapley Additive explanations) method. For subjects suffering from the aforementioned diseases, the model utilized features derived from all channels and employed an ensembled bagged trees (EnBT) classifier. The highest accuracy of 86.8%, 87.3%, 85.0%, 84.5%, and 83.8% is obtained for the insomniac, PLM, apniac, good sleepers and complete datasets, respectively. Using these techniques and datasets, the study aims to enhance sleep stage classification accuracy and improve understanding of sleep disorders such as insomnia, PLM, and sleep apnea.",https://pubmed.ncbi.nlm.nih.gov/39160031/,https://pubmed.ncbi.nlm.nih.gov/39160031/,English,Include,,"Automated explainable wavelet-based sleep scoring system for a population suspected with insomnia, apnea and periodic leg movement.",Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39160030,pubmed:39160030,PubMed,pubmed:39160030,Automatic diagnosis of epileptic seizures using entropy-based features and multimodel deep learning approaches.,Noor Kamal Al-Qazzaz;Maher Alrahhal;Sumai Hamad Jaafer;Sawal Hamid Bin Mohd Ali;Siti Anom Ahmad,2024,10.1016/j.medengphy.2024.104206,"Epilepsy is one of the most common brain diseases, characterised by repeated seizures that occur on a regular basis. During a seizure, a patient's muscles flex uncontrollably, causing a loss of mobility and balance, which can be harmful or even fatal. Developing an automatic approach for warning patients of oncoming seizures necessitates substantial research. Analyzing the electroencephalogram (EEG) output from the human brain's scalp region can help predict seizures. EEG data were analyzed to extract time domain features such as Hurst exponent (Hur), Tsallis entropy (TsEn), enhanced permutation entropy (impe), and amplitude-aware permutation entropy (AAPE). In order to automatically diagnose epileptic seizure in children from normal children, this study conducted two sessions. In the first session, the extracted features from the EEG dataset were classified using three machine learning (ML)-based models, including support vector machine (SVM), K nearest neighbor (KNN), or decision tree (DT), and in the second session, the dataset was classified using three deep learning (DL)-based recurrent neural network (RNN) classifiers in The EEG dataset was obtained from the Neurology Clinic of the Ibn Rushd Training Hospital. In this regard, extensive explanations and research from the time domain and entropy characteristics demonstrate that employing GRU, LSTM, and BiLSTM RNN deep learning classifiers on the All-time-entropy fusion feature improves the final classification results.",https://pubmed.ncbi.nlm.nih.gov/39160030/,https://pubmed.ncbi.nlm.nih.gov/39160030/,English,Include,,Automatic diagnosis of epileptic seizures using entropy-based features and multimodel deep learning approaches.,Exclude,No performance metrics reported,No metrics found in full text,,0.9,0.6,
pubmed:39160021,pubmed:39160021,PubMed,pubmed:39160021,An efficient channel recurrent Criss-cross attention network for epileptic seizure prediction.,Lei Zhu;Wentao Wang;Aiai Huang;Nanjiao Ying;Ping Xu;Jianhai Zhang,2024,10.1016/j.medengphy.2024.104213,"Epilepsy is a chronic disease caused by repeated abnormal discharge of neurons in the brain. Accurately predicting the onset of epilepsy can effectively improve the quality of life for patients with the condition. While there are many methods for detecting epilepsy, EEG is currently considered one of the most effective analytical tools due to the abundant information it provides about brain activity. The aim of this study is to explore potential time-frequency and channel features from multi-channel epileptic EEG signals and to develop a patient-specific seizure prediction network. In this paper, an epilepsy EEG signal classification algorithm called Channel Recurrent Criss-cross Attention Network (CRCANet) is proposed. Firstly, the spectrograms processed by the short-time fourier transform is input into a Convolutional Neural Network (CNN). Then, the spectrogram feature map obtained in the previous step is input into the channel attention module to establish correlations between channels. Subsequently, the feature diagram containing channel attention characteristics is input into the recurrent criss-cross attention module to enhance the information content of each pixel. Finally, two fully connected layers are used for classification. We validated the method on 13 patients in the public CHB-MIT scalp EEG dataset, achieving an average accuracy of 93.8 %, sensitivity of 94.3 %, and specificity of 93.5 %. The experimental results indicate that CRCANet can effectively capture the time-frequency and channel characteristics of EEG signals while improving training efficiency.",https://pubmed.ncbi.nlm.nih.gov/39160021/,https://pubmed.ncbi.nlm.nih.gov/39160021/,English,Include,,An efficient channel recurrent Criss-cross attention network for epileptic seizure prediction.,Include,,"nformation content of each pixel. Finally, two fully connected layers are used for classification. We validated the method on 13 patients in the public CHB-MIT scalp EEG dataset, achieving an average accuracy of 93.8 %, sensitivity of 94.3 %, and specificity of 93.5 %. The experimental results indicate that CRCANet can effectively capture the time-frequency and channel characteristics of EEG signa",,0.95,0.6,
pubmed:39159703,pubmed:39159703,PubMed,pubmed:39159703,Heartbeat-related spectral perturbation of electroencephalogram reflects dynamic interoceptive attention states in the trial-by-trial classification analysis.,Wooyong Lee;Euisun Kim;Jiyoung Park;Jinseok Eo;Bumseok Jeong;Hae-Jeong Park,2024,10.1016/j.neuroimage.2024.120797,"Attending to heartbeats for interoceptive awareness initiates distinct electrophysiological responses synchronized with the R-peaks of an electrocardiogram (ECG), such as the heartbeat-evoked potential (HEP). Beyond HEP, this study proposes heartbeat-related spectral perturbation (HRSP), a time-frequency map of the R-peak locked electroencephalogram (EEG), and explores its characteristics in identifying interoceptive attention states using a classification approach. HRSPs of EEG brain components specified by independent component analysis (ICA) were used for the offline and online classification of interoceptive states. A convolutional neural network (CNN) designed specifically for HRSP was applied to publicly available data from a binary-state experiment (attending to self-heartbeats and white noise) and data from our four-state classification experiment (attending to self-heartbeats, white noise, time passage, and toe) with diverse input feature conditions of HRSP. From the dynamic state perspective, we evaluated the primary frequency bands of HRSP and the minimal number of averaging epochs required to reflect changing interoceptive attention states without compromising accuracy. We also assessed the utility of group ICA and models for classifying HRSP in new participants. The CNN for trial-by-trial HRSP with actual R-peaks demonstrated significantly higher classification accuracy than HRSP with sham, i.e., randomly positioned, R-peaks. Gradient-weighted class activation mapping highlighted the prominent role of theta and alpha bands between 200-600 ms post-R-peak-features absent in classifications using sham HRSPs. Online classification benefits from employing a group ICA and classification model, ensuring reliable accuracy without individual EEG precollection. These results suggest HRSP's potential to reflect interoceptive attention states, proposing transformative implications for clinical applications.",https://pubmed.ncbi.nlm.nih.gov/39159703/,https://pubmed.ncbi.nlm.nih.gov/39159703/,English,Include,,Heartbeat-related spectral perturbation of electroencephalogram reflects dynamic interoceptive attention states in the trial-by-trial classification analysis.,Include,,"dynamic state perspective, we evaluated the primary frequency bands of HRSP and the minimal number of averaging epochs required to reflect changing interoceptive attention states without compromising accuracy. We also assessed the utility of group ICA and models for classifying HRSP in new participants. The CNN for trial-by-trial HRSP with actual R-peaks demonstrated significantly higher classific",,0.95,0.8,small_sample_mentioned
pubmed:39159023,pubmed:39159023,PubMed,pubmed:39159023,ABR-Attention: An Attention-Based Model for Precisely Localizing Auditory Brainstem Response.,Junyu Ji;Xin Wang;Xiaobei Jing;Mingxing Zhu;Hongguang Pan;Desheng Jia;Chunrui Zhao;Xu Yong;Yangjie Xu;Guoru Zhao;Poly Z H Sun;Guanglin Li;Shixiong Chen,2024,10.1109/tnsre.2024.3445936,"Auditory Brainstem Response (ABR) is an evoked potential in the brainstem's neural centers in response to sound stimuli. Clinically, characteristic waves, especially Wave V latency, extracted from ABR can objectively indicate auditory loss and diagnose diseases. Several methods have been developed for the extraction of characteristic waves. To ensure the effectiveness of the method, most of the methods are time-consuming and rely on the heavy workloads of clinicians. To reduce the workload of clinicians, automated extraction methods have been developed. However, the above methods also have limitations. This study introduces a novel deep learning network for automatic extraction of Wave V latency, named ABR-Attention. ABR-Attention model includes a self-attention module, first and second-derivative attention module, and regressor module. Experiments are conducted on the accuracy with 10-fold cross-validation, the effects on different sound pressure levels (SPLs), the effects of different error scales and the effects of ablation. ABR-Attention shows efficacy in extracting Wave V latency of ABR, with an overall accuracy of 96.76 ± 0.41 % and an error scale of 0.1ms, and provides a new solution for objective localization of ABR characteristic waves.",,https://pubmed.ncbi.nlm.nih.gov/39159023/,English,Exclude,Not EEG-BCI focused,ABR-Attention: An Attention-Based Model for Precisely Localizing Auditory Brainstem Response.,,,,,0.9,0.25,cv_reported
pubmed:39156814,pubmed:39156814,PubMed,pubmed:39156814,Evaluating EEG neurofeedback in sport psychology: a systematic review of RCT studies for insights into mechanisms and performance improvement.,Ming-Yang Cheng;Chien-Lin Yu;Xin An;Letong Wang;Chi-Lun Tsai;Fengxue Qi;Kuo-Pin Wang,2024,10.1177/0883073813479999,"Electroencephalographic Neurofeedback Training (EEG NFT) aims to improve sport performance by teaching athletes to control their mental states, leading to better cognitive, emotional, and physical outcomes. The psychomotor efficiency hypothesis suggests that optimizing brain function could enhance athletic ability, indicating the potential of EEG NFT. However, evidence for EEG-NFT's ability to alter critical brain activity patterns, such as sensorimotor rhythm and frontal midline theta-key for concentration and relaxation-is not fully established. Current research lacks standardized methods and comprehensive studies. This shortfall is due to inconsistent EEG target selection and insufficient focus on coherence in training. This review aims to provide empirical support for EEG target selection, conduct detailed control analyses, and examine the specificity of electrodes and frequencies to relation to the psychomotor efficiency hypothesis. Following the PRISMA method, 2,869 empirical studies were identified from PubMed, Science Direct, Web of Science, Embase, CNKI, and PsycINFO. Thirteen studies met the inclusion criteria: (i) proficient skill levels; (ii) use of EEG; (iii) neurofeedback training (NFT); (iv) motor performance metrics (reaction time, precision, dexterity, balance); (v) control group for NFT comparison; (vi) peer-reviewed English-language publication; and (vii) randomized controlled trial (RCT) design. Studies indicate that NFT can enhance sports performance, including improvements in shooting accuracy, golf putting, and overall motor skills, as supported by the psychomotor efficiency hypothesis. EEG NFT demonstrates potential in enhancing sports performance by optimizing performers' mental states and psychomotor efficiency. However, the current body of research is hampered by inconsistent methodologies and a lack of standardized EEG target selection. To strengthen the empirical evidence supporting EEG NFT, future studies need to focus on standardizing target selection, employing rigorous control analyses, and investigating underexplored EEG markers. These steps are vital to bolster the evidence for EEG NFT and enhance its effectiveness in boosting sport performance.",,https://pubmed.ncbi.nlm.nih.gov/39156814/,English,Exclude,Review/survey papers,Evaluating EEG neurofeedback in sport psychology: a systematic review of RCT studies for insights into mechanisms and performance improvement.,,,,,0.95,0.6,
pubmed:39154048,pubmed:39154048,PubMed,pubmed:39154048,"Neural encoding of linguistic speech cues is unaffected by cognitive decline, but decreases with increasing hearing impairment.",Elena Bolt;Nathalie Giroud,2024,10.5555/1953048.2078195,"The multivariate temporal response function (mTRF) is an effective tool for investigating the neural encoding of acoustic and complex linguistic features in natural continuous speech. In this study, we investigated how neural representations of speech features derived from natural stimuli are related to early signs of cognitive decline in older adults, taking into account the effects of hearing. Participants without ( ",,https://pubmed.ncbi.nlm.nih.gov/39154048/,English,Exclude,Not EEG-BCI focused,"Neural encoding of linguistic speech cues is unaffected by cognitive decline, but decreases with increasing hearing impairment.",,,,,0.9,0.8,small_sample_mentioned
pubmed:39153459,pubmed:39153459,PubMed,pubmed:39153459,Early automated classification of neonatal hypoxic-ischemic encephalopathy - An aid to the decision to use therapeutic hypothermia.,Laure Lacan;Nacim Betrouni;Laurence Chaton;Marie-Dominique Lamblin;Florence Flamein;Mohamed Riadh Boukhris;Philippe Derambure;Sylvie Nguyen The Tich,2024,10.1016/j.clinph.2024.07.015,"The study aimed to address the challenge of early assessment of neonatal hypoxic-ischemic encephalopathy (HIE) severity to identify candidates for therapeutic hypothermia (TH). The objective was to develop an automated classification model for neonatal EEGs, enabling accurate HIE severity assessment 24/7. EEGs recorded within 6 h of life after perinatal anoxia were visually graded into 3 severity groups (HIE French Classification) and quantified using 6 qEEG markers measuring amplitude, continuity and frequency content. Machine learning models were developed on a dataset of 90 EEGs and validated on an independent dataset of 60 EEGs. The selected model achieved an overall accuracy of 80.6% in the development phase and 80% in the validation phase. Notably, the model accurately identified 28 out of 30 children for whom TH was indicated after visual EEG analysis, with only 2 cases (moderate EEG abnormalities) not recommended for cooling. The combination of clinically relevant qEEG markers led to the development of an effective automated EEG classification model, particularly suited for the post-anoxic latency phase. This model successfully discriminated neonates requiring TH. The proposed model has potential as a bedside clinical decision support tool for TH.",https://pubmed.ncbi.nlm.nih.gov/39153459/,https://pubmed.ncbi.nlm.nih.gov/39153459/,English,Include,,Early automated classification of neonatal hypoxic-ischemic encephalopathy - An aid to the decision to use therapeutic hypothermia.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39151721,pubmed:39151721,PubMed,pubmed:39151721,Performance of the ERC/ESICM-recommendations for neuroprognostication after cardiac arrest: Insights from a prospective multicenter cohort.,Wulfran Bougouin;Jean-Baptiste Lascarrou;Jonathan Chelly;Sarah Benghanem;Guillaume Geri;Julien Maizel;Nicolas Fage;Ghada Sboui;Nicolas Pichon;Cédric Daubin;Bertrand Sauneuf;Nicolas Mongardon;Fabio Taccone;Bertrand Hermann;Gwenhaël Colin;Olivier Lesieur;Nicolas Deye;Nicolas Chudeau;Martin Cour;Jeremy Bourenne;Kada Klouche;Thomas Klein;Jean-Herlé Raphalen;Grégoire Muller;Arnaud Galbois;Cédric Bruel;Sophie Jacquier;Marine Paul;Claudio Sandroni;Alain Cariou,2024,10.1016/j.resuscitation.2024.110362,"To investigate the performance of the 2021 ERC/ESICM-recommended algorithm for predicting poor outcome after cardiac arrest (CA) and potential tools for predicting neurological recovery in patients with indeterminate outcome. Prospective, multicenter study on out-of-hospital CA survivors from 28 ICUs of the AfterROSC network. In patients comatose with a Glasgow Coma Scale motor score ≤3 at ≥72 h after resuscitation, we measured: (1) the accuracy of neurological examination, biomarkers (neuron-specific enolase, NSE), electrophysiology (EEG and SSEP) and neuroimaging (brain CT and MRI) for predicting poor outcome (modified Rankin scale score ≥4 at 90 days), and (2) the ability of low or decreasing NSE levels and benign EEG to predict good outcome in patients whose prognosis remained indeterminate. Among 337 included patients, the ERC-ESICM algorithm predicted poor neurological outcome in 175 patients, and the positive predictive value for an unfavourable outcome was 100% [98-100]%. The specificity of individual predictors ranged from 90% for EEG to 100% for clinical examination and SSEP. Among the remaining 162 patients with indeterminate outcome, a combination of 2 favourable signs predicted good outcome with 99[96-100]% specificity and 23[11-38]% sensitivity. All comatose resuscitated patients who fulfilled the ERC-ESICM criteria for poor outcome after CA had poor outcome at three months, even if a self-fulfilling prophecy cannot be completely excluded. In patients with indeterminate outcome (half of the population), favourable signs predicted neurological recovery, reducing prognostic uncertainty.",https://pubmed.ncbi.nlm.nih.gov/39151721/,https://pubmed.ncbi.nlm.nih.gov/39151721/,English,Include,,Performance of the ERC/ESICM-recommendations for neuroprognostication after cardiac arrest: Insights from a prospective multicenter cohort.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39151658,pubmed:39151658,PubMed,pubmed:39151658,Attention-based CNN-BiLSTM for sleep state classification of spatiotemporal wide-field calcium imaging data.,Xiaohui Zhang;Eric C Landsness;Hanyang Miao;Wei Chen;Michelle J Tang;Lindsey M Brier;Joseph P Culver;Jin-Moo Lee;Mark A Anastasio,2024,10.3389/fpubh.2022.946833,"Wide-field calcium imaging (WFCI) with genetically encoded calcium indicators allows for spatiotemporal recordings of neuronal activity in mice. When applied to the study of sleep, WFCI data are manually scored into the sleep states of wakefulness, non-REM (NREM) and REM by use of adjunct EEG and EMG recordings. However, this process is time-consuming, invasive and often suffers from low inter- and intra-rater reliability. Therefore, an automated sleep state classification method that operates on spatiotemporal WFCI data is desired. A hybrid network architecture consisting of a convolutional neural network (CNN) to extract spatial features of image frames and a bidirectional long short-term memory network (BiLSTM) with attention mechanism to identify temporal dependencies among different time points was proposed to classify WFCI data into states of wakefulness, NREM and REM sleep. Sleep states were classified with an accuracy of 84 % and Cohen's κ of 0.64. Gradient-weighted class activation maps revealed that the frontal region of the cortex carries more importance when classifying WFCI data into NREM sleep while posterior area contributes most to the identification of wakefulness. The attention scores indicated that the proposed network focuses on short- and long-range temporal dependency in a state-specific manner. On a held out, repeated 3-hour WFCI recording, the CNN-BiLSTM achieved a κ of 0.67, comparable to a κ of 0.65 corresponding to the human EEG/EMG-based scoring. The CNN-BiLSTM effectively classifies sleep states from spatiotemporal WFCI data and will enable broader application of WFCI in sleep research.",https://pubmed.ncbi.nlm.nih.gov/39151658/,https://pubmed.ncbi.nlm.nih.gov/39151658/,English,Include,,Attention-based CNN-BiLSTM for sleep state classification of spatiotemporal wide-field calcium imaging data.,Include,,"tention mechanism to identify temporal dependencies among different time points was proposed to classify WFCI data into states of wakefulness, NREM and REM sleep. Sleep states were classified with an accuracy of 84 % and Cohen's κ of 0.64. Gradient-weighted class activation maps revealed that the frontal region of the cortex carries more importance when classifying WFCI data into NREM sleep while ",,0.95,0.6,
pubmed:39151656,pubmed:39151656,PubMed,pubmed:39151656,Decoding micro-electrocorticographic signals by using explainable 3D convolutional neural network to predict finger movements.,Chao-Hung Kuo;Guan-Tze Liu;Chi-En Lee;Jing Wu;Kaitlyn Casimo;Kurt E Weaver;Yu-Chun Lo;You-Yin Chen;Wen-Cheng Huang;Jeffrey G Ojemann,2024,10.1016/j.jneumeth.2024.110251,"Electroencephalography (EEG) and electrocorticography (ECoG) recordings have been used to decode finger movements by analyzing brain activity. Traditional methods focused on single bandpass power changes for movement decoding, utilizing machine learning models requiring manual feature extraction. This study introduces a 3D convolutional neural network (3D-CNN) model to decode finger movements using ECoG data. The model employs adaptive, explainable AI (xAI) techniques to interpret the physiological relevance of brain signals. ECoG signals from epilepsy patients during awake craniotomy were processed to extract power spectral density across multiple frequency bands. These data formed a 3D matrix used to train the 3D-CNN to predict finger trajectories. The 3D-CNN model showed significant accuracy in predicting finger movements, with root-mean-square error (RMSE) values of 0.26-0.38 for single finger movements and 0.20-0.24 for combined movements. Explainable AI techniques, Grad-CAM and SHAP, identified the high gamma (HG) band as crucial for movement prediction, showing specific cortical regions involved in different finger movements. These findings highlighted the physiological significance of the HG band in motor control. The 3D-CNN model outperformed traditional machine learning approaches by effectively capturing spatial and temporal patterns in ECoG data. The use of xAI techniques provided clearer insights into the model's decision-making process, unlike the ""black box"" nature of standard deep learning models. The proposed 3D-CNN model, combined with xAI methods, enhances the decoding accuracy of finger movements from ECoG data. This approach offers a more efficient and interpretable solution for brain-computer interface (BCI) applications, emphasizing the HG band's role in motor control.",https://pubmed.ncbi.nlm.nih.gov/39151656/,https://pubmed.ncbi.nlm.nih.gov/39151656/,English,Include,,Decoding micro-electrocorticographic signals by using explainable 3D convolutional neural network to predict finger movements.,Include,,"processed to extract power spectral density across multiple frequency bands. These data formed a 3D matrix used to train the 3D-CNN to predict finger trajectories. The 3D-CNN model showed significant accuracy in predicting finger movements, with root-mean-square error (RMSE) values of 0.26-0.38 for single finger movements and 0.20-0.24 for combined movements. Explainable AI techniques, Grad-CAM an",,0.95,0.6,
pubmed:39151459,pubmed:39151459,PubMed,pubmed:39151459,Emotion recognition of EEG signals based on contrastive learning graph convolutional model.,Yiling Zhang;Yuan Liao;Wei Chen;Xiruo Zhang;Liya Huang,2024,10.1088/1741-2552/ad7060,,,https://pubmed.ncbi.nlm.nih.gov/39151459/,English,Exclude,Not classification-focused,Emotion recognition of EEG signals based on contrastive learning graph convolutional model.,,,,,0.85,0.6,
pubmed:39151325,pubmed:39151325,PubMed,pubmed:39151325,The utility of Multicentre Epilepsy Lesion Detection (MELD) algorithm in identifying epileptic activity and predicting seizure freedom in MRI lesion-negative paediatric patients.,Aimee Goel;Stefano Seri;Shakti Agrawal;Ratna Kumar;Annapurna Sudarsanam;Bryony Carr;Andrew Lawley;Lesley Macpherson;Adam J Oates;Helen Williams;A Richard Walsh;William B Lo;Joshua Pepper,2024,10.1016/j.eplepsyres.2024.107429,"Paediatric patients with drug-resistant focal epilepsy (DRFE) who have no clear focal lesion identified on conventional structural magnetic resonance imaging (MRI) are a particularly challenging cohort to treat and form an increasing part of epilepsy surgery programs. A recently developed deep-learning-based MRI lesion detection algorithm, the Multicentre Lesion Detection (MELD) algorithm, has been shown to aid detection of focal cortical dysplasia (FCD). We applied this algorithm retrospectively to a cohort of MRI-negative children with refractory focal epilepsy who underwent stereoelectroencephalography (SEEG) to determine its accuracy in identifying unseen epileptic lesions, seizure onset zones and clinical outcomes. We retrospectively applied the MELD algorithm to a consecutive series of MRI-negative patients who underwent SEEG at our tertiary Paediatric Epilepsy Surgery centre. We assessed the extent to which the identified MELD cluster or lesion area corresponded with the clinical seizure hypothesis, the epileptic network, and the positron emission tomography (PET) focal hypometabolic area. In those who underwent resective surgery, we analysed whether the region of MELD abnormality corresponded with the surgical target and to what extent this was associated with seizure freedom. We identified 37 SEEG studies in 28 MRI-negative children in whom we could run the MELD algorithm. Of these, 14 (50 %) children had clusters identified on MELD. Nine (32 %) children had clusters concordant with seizure hypothesis, 6 (21 %) had clusters concordant with PET imaging, and 5 (18 %) children had at least one cluster concordant with SEEG electrode placement. Overall, 4 MELD clusters in 4 separate children correctly predicted either seizure onset zone or irritative zone based on SEEG stimulation data. Sixteen children (57 %) went on to have resective or lesional surgery. Of these, only one patient (4 %) had a MELD cluster which co-localised with the resection cavity and this child had an Engel 1 A outcome. In our paediatric cohort of MRI-negative patients with drug-resistant focal epilepsy, the MELD algorithm identified abnormal clusters or lesions in half of cases, and identified one radiologically occult focal cortical dysplasia. Machine-learning-based lesion detection is a promising area of research with the potential to improve seizure outcomes in this challenging cohort of radiologically occult FCD cases. However, its application should be approached with caution, especially with regards to its specificity in detecting FCD lesions, and there is still work to be done before it adds to diagnostic utility.",https://pubmed.ncbi.nlm.nih.gov/39151325/,https://pubmed.ncbi.nlm.nih.gov/39151325/,English,Include,,The utility of Multicentre Epilepsy Lesion Detection (MELD) algorithm in identifying epileptic activity and predicting seizure freedom in MRI lesion-negative paediatric patients.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39150815,pubmed:39150815,PubMed,pubmed:39150815,Online Privacy-Preserving EEG Classification by Source-Free Transfer Learning.,Hanrui Wu;Zhengyan Ma;Zhenpeng Guo;Yanxin Wu;Jia Zhang;Guoxu Zhou;Jinyi Long,2024,10.1109/tnsre.2024.3445115,"Electroencephalogram (EEG) signals play an important role in brain-computer interface (BCI) applications. Recent studies have utilized transfer learning to assist the learning task in the new subject, i.e., target domain, by leveraging beneficial information from previous subjects, i.e., source domains. Nevertheless, EEG signals involve sensitive personal mental and health information. Thus, privacy concern becomes a critical issue. In addition, existing methods mostly assume that a portion of the new subject's data is available and perform alignment or adaptation between the source and target domains. However, in some practical scenarios, new subjects prefer prompt BCI utilization over the time-consuming process of collecting data for calibration and adaptation, which makes the above assumption difficult to hold. To address the above challenges, we propose Online Source-Free Transfer Learning (OSFTL) for privacy-preserving EEG classification. Specifically, the learning procedure contains offline and online stages. At the offline stage, multiple model parameters are obtained based on the EEG samples from multiple source subjects. OSFTL only needs access to these source model parameters to preserve the privacy of the source subjects. At the online stage, a target classifier is trained based on the online sequence of EEG instances. Subsequently, OSFTL learns a weighted combination of the source and target classifiers to obtain the final prediction for each target instance. Moreover, to ensure good transferability, OSFTL dynamically updates the transferred weight of each source domain based on the similarity between each source classifier and the target classifier. Comprehensive experiments on both simulated and real-world applications demonstrate the effectiveness of the proposed method, indicating the potential of OSFTL to facilitate the deployment of BCI applications outside of controlled laboratory settings.",https://pubmed.ncbi.nlm.nih.gov/39150815/,https://pubmed.ncbi.nlm.nih.gov/39150815/,English,Include,,Online Privacy-Preserving EEG Classification by Source-Free Transfer Learning.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39150811,pubmed:39150811,PubMed,pubmed:39150811,EEG-Derived Markers to Improve Prognostic Evaluation of Disorders of Consciousness.,Jlenia Toppi;Ilaria Quattrociocchi;Angela Riccio;Mariagrazia D'Ippolito;Marta Aloisi;Emma Colamarino;Floriana Pichiorri;Febo Cincotti;Rita Formisano;Donatella Mattia,2024,10.1109/jbhi.2024.3445118,"Disorders of consciousness (DoC) are characterized by alteration in arousal and/or awareness commonly caused by severe brain injury. There exists a consensus on adopting advanced neuroimaging and electrophysiological procedures to improve diagnosis/prognosis of DoC patients. Currently, these procedures are prevalently applied in a research-oriented context and their translation into clinical practice is yet to come. The aim of the study consisted in the identification of measures derived from routinary electroencephalography (EEG) able to support clinicians in the prediction of DoC patients' outcome. In the present study, a routine EEG was recorded during rest from a sample of 58 DoC patients clinically diagnosed as Unresponsive Wakefulness State (UWS) and Minimally Conscious State (MCS) and followed-up for 3 months. EEG-based features characterizing brain activity in terms of spectral content and resting state networks organization were used in a predictive machine learning model to i) identify which were the most promising features in predicting patients' exit from the DoC, regardless of the clinical diagnosis and ii) verify whether such features would have been the same best discriminating UWS from MCS or specific of the outcome prediction. A predictive machine learning model was built on EEG features related to spectral content and resting state networks which returned up to 85% of performance accuracy in outcome prediction and 76% in DoC state recognition (UWS vs MCS). We provided preliminary evidence for the exploitation of a routine EEG to improve the clinical management of non-communicative patients to be confirmed in a larger DoC population.",https://pubmed.ncbi.nlm.nih.gov/39150811/,https://pubmed.ncbi.nlm.nih.gov/39150811/,English,Include,,EEG-Derived Markers to Improve Prognostic Evaluation of Disorders of Consciousness.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39149605,pubmed:39149605,PubMed,pubmed:39149605,A deep neural network-based approach for seizure activity recognition of epilepsy sufferers.,Danial Khurshid;Fazli Wahid;Sikandar Ali;Abdu H Gumaei;Samah M Alzanin;Mogeeb A A Mosleh,2024,10.1186/s12864-019-6413-7,"Epilepsy is one of the most frequent neurological illnesses caused by epileptic seizures and the second most prevalent neurological ailment after stroke, affecting millions of people worldwide. People with epileptic disease are considered a category of people with disabilities. It significantly impairs a person's capacity to perform daily tasks, especially those requiring focusing or remembering. Electroencephalogram (EEG) signals are commonly used to diagnose people with epilepsy. However, it is tedious, time-consuming, and subjected to human errors. Several machine learning techniques have been applied to recognize epilepsy previously, but they have some limitations. This study proposes a deep neural network (DNN) machine learning model to determine the existing limitations of previous studies by improving the recognition efficiency of epileptic disease. A public dataset is used in this study and classified into training and testing sets. Experiments were performed to evaluate the DNN model with different dataset classification ratios (80:20), (70:30), (60:40), and (50:50) for training and testing, respectively. Results were evaluated by using different performance metrics including validations, and comparison processes that allow the assessment of the model's effectiveness. The experimental results showed that the overall efficiency of the proposed model is the highest compared with previous works, with an accuracy rate of 97%. Thus, this study is more accurate and efficient than the existing seizure detection approaches. DNN model has great potential for recognizing epileptic patient activity using a numerical EEG dataset offering a data-driven approach to improve the accuracy and reliability of seizure detection systems for the betterment of patient care and management of epilepsy.",https://pubmed.ncbi.nlm.nih.gov/39149605/,https://pubmed.ncbi.nlm.nih.gov/39149605/,English,Include,,A deep neural network-based approach for seizure activity recognition of epilepsy sufferers.,Include,,"rocesses that allow the assessment of the model's effectiveness. The experimental results showed that the overall efficiency of the proposed model is the highest compared with previous works, with an accuracy rate of 97%. Thus, this study is more accurate and efficient than the existing seizure detection approaches. DNN model has great potential for recognizing epileptic patient activity using a n",,0.95,0.6,
pubmed:39147592,pubmed:39147592,PubMed,pubmed:39147592,Medial Prefrontal Cortex Stimulation Reduces Retrieval-Induced Forgetting via Fronto-parietal Beta Desynchronization.,Ahsan Khan;Chun Hang Eden Ti;Kai Yuan;Maite Crespo Garcia;Michael C Anderson;Raymond Kai-Yu Tong,2024,10.1016/j.clinph.2015.11.012,"The act of recalling memories can paradoxically lead to the forgetting of other associated memories, a phenomenon known as retrieval-induced forgetting (RIF). Inhibitory control mechanisms, primarily mediated by the prefrontal cortex, are thought to contribute to RIF. In this study, we examined whether stimulating the medial prefrontal cortex (mPFC) with transcranial direct current stimulation modulates RIF and investigated the associated electrophysiological correlates. In a randomized study, 50 participants (27 males and 23 females) received either real or sham stimulation before performing retrieval practice on target memories. After retrieval practice, a final memory test to assess RIF was administered. We found that stimulation selectively increased the retrieval accuracy of competing memories, thereby decreasing RIF, while the retrieval accuracy of target memories remained unchanged. The reduction in RIF was associated with a more pronounced beta desynchronization within the left dorsolateral prefrontal cortex (left-DLPFC), in an early time window (<500 ms) after cue onset during retrieval practice. This led to a stronger beta desynchronization within the parietal cortex in a later time window, an established marker for successful memory retrieval. Together, our results establish the causal involvement of the mPFC in actively suppressing competing memories and demonstrate that while forgetting arises as a consequence of retrieving specific memories, these two processes are functionally independent. Our findings suggest that stimulation potentially disrupted inhibitory control processes, as evidenced by reduced RIF and stronger beta desynchronization in fronto-parietal brain regions during memory retrieval, although further research is needed to elucidate the specific mechanisms underlying this effect.",,https://pubmed.ncbi.nlm.nih.gov/39147592/,English,Exclude,Not EEG-BCI focused,Medial Prefrontal Cortex Stimulation Reduces Retrieval-Induced Forgetting via Fronto-parietal Beta Desynchronization.,,,,,0.9,0.8,small_sample_mentioned
pubmed:39147289,pubmed:39147289,PubMed,pubmed:39147289,Brain correlates of attentional load processing reflect degree of bilingual engagement: Evidence from EEG.,Sergio Miguel Pereira Soares;Yanina Prystauka;Vincent DeLuca;Claudia Poch;Jason Rothman,2024,10.1016/j.neuroimage.2024.120786,"The present study uses electroencephalography (EEG) with an N-back task (0-, 1-, and 2-back) to investigate if and how individual bilingual experiences modulate brain activity and cognitive processes. The N-back is an especially appropriate task given recent proposals situating bilingual effects on neurocognition within the broader attentional control system (Bialystok and Craik, 2022). Beyond its working memory component, the N-Back task builds in complexity incrementally, progressively taxing the attentional system. EEG, behavioral and language/social background data were collected from 60 bilinguals. Two cognitive loads were calculated: low (1-back minus 0-back) and high (2-back minus 0-back). Behavioral performance and brain recruitment were modeled as a function of individual differences in bilingual engagement. We predicted task performance as modulated by bilingual engagement would reflect cognitive demands of increased complexity: slower reaction times and lower accuracy, and increase in theta, decrease in alpha and modulated N2/P3 amplitudes. The data show no modulation of the expected behavioral effects by degree of bilingual engagement. However, individual differences analyses reveal significant correlations between non-societal language use in Social contexts and alpha in the low cognitive load condition and age of acquisition of the L2/2L1 with theta in the high cognitive load. These findings lend some initial support to Bialystok and Craik (2022), showing how certain adaptations at the brain level take place in order to deal with the cognitive demands associated with variations in bilingual language experience and increases in attentional load. Furthermore, the present data highlight how these effects can play out differentially depending on cognitive testing/modalities - that is, effects were found at the TFR level but not behaviorally or in the ERPs, showing how the choice of analysis can be deterministic when investigating bilingual effects.",https://pubmed.ncbi.nlm.nih.gov/39147289/,https://pubmed.ncbi.nlm.nih.gov/39147289/,English,Include,,Brain correlates of attentional load processing reflect degree of bilingual engagement: Evidence from EEG.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39146339,pubmed:39146339,PubMed,pubmed:39146339,Event-related potentials study on the effects of high neuroticism on senile false memory.,Wenju Zhang;Yibin Zhou;Yan Zhang;Xianghong Zhan,2024,10.1126/science.aau8956,"To study the false memory among senile normal people with high neuroticism and low neuroticism using neuropsychological scales and event-related potentials (ERPs), and to explore the effects of high neuroticism on false memory and its neuroelectrophysiological mechanism. A cross-sectional study was conducted, in which the general situation questionnaire, adult version of Eysenck personality questionnaire (EPQ) and Montreal cognitive assessment (MoCA) scale were used to establish a multi-dimensional survey in senile normal people over 60 years old from communities in Zhengzhou, and the EPQ and general situation questionnaire were used to comprehensively screen and divide the study subjects into high neuroticism group and low neuroticism group from 206 senile people. The population was matched by 1:1 according to gender, age (±2 years), and years of education (±2 years), and 40 subjects were finally enrolled for detection of electroencephalograph (EEG) components using ERPs. The Deese-Roediger-McDermott (DRM) paradigm of false memory was designed using E-prime2.0 system, and the stimulus program was presented. The EEG signals of the study subjects were recorded in real time and acquired using 64-channel Neuroscan EEG signals acquisition system. High neuroticism group was evidently lower in the mean accuracy than low neuroticism group, and the difference in the mean accuracy was statistically significant (P = 0.013), but the difference in reaction time was not statistically significant. 2. The mean amplitude of EEG component N400: The difference in the main effect of N400 in the brain region was significantly different (P<0.001), and the mean amplitude of N400 was the largest in frontal region, followed by central region and parietal region successively (all P<0.05). There was no statistically significant difference in the neurotic main effect or the interaction effect of neuroticism and brain region. The latency of N400: There was no significant difference in the neurotic main effect, main effect of the brain region or the interaction effect of neuroticism and brain region. 3. The mean amplitude of EEG component LPC: The difference in the main effect of the brain region was significantly different (P<0.001), and the mean amplitude of LPC was the largest in frontal region, followed by central region and parietal region successively (all P<0.05). There was no significant difference in the neurotic main effect, neuroticism or the interaction effect of neuroticism and brain region. As to the latency of LPC, there was significant difference in the main effect of the brain region (P = 0.025), and the latency of LPC was shorter in frontal region than that in central region (P<0.05). The differences in the neurotic main effect, interaction effect of neuroticism and brain region were not statistically significant. High neuroticism can significantly increase the false memory of senile normal people. The EEG components N400 and LPC are potential early indicators of high neuroticism affecting false memory. High neuroticism may influence false memory by affecting the frontal cortex function.",,https://pubmed.ncbi.nlm.nih.gov/39146339/,English,Exclude,Review/survey papers,Event-related potentials study on the effects of high neuroticism on senile false memory.,,,,,0.95,0.6,
pubmed:39145233,pubmed:39145233,PubMed,pubmed:39145233,Developing a tablet-based brain-computer interface and robotic prototype for upper limb rehabilitation.,Kishor Lakshminarayanan;Vadivelan Ramu;Rakshit Shah;Md Samiul Haque Sunny;Deepa Madathil;Brahim Brahmi;Inga Wang;Raouf Fareh;Mohammad Habibur Rahman,2024,10.3390/s20174749,"The current study explores the integration of a motor imagery (MI)-based BCI system with robotic rehabilitation designed for upper limb function recovery in stroke patients. We developed a tablet deployable BCI control of the virtual iTbot for ease of use. Twelve right-handed healthy adults participated in this study, which involved a novel BCI training approach incorporating tactile vibration stimulation during MI tasks. The experiment utilized EEG signals captured  Results showed varying accuracies in motor intention detection across participants, with an average true positive rate of 63.33% in classifying MI signals. The study highlights the potential of MI-based BCI in robotic rehabilitation, particularly in terms of engagement and personalization. The findings underscore the feasibility of BCI technology in rehabilitation and its potential use for stroke survivors with upper limb dysfunctions.",https://pubmed.ncbi.nlm.nih.gov/39145233/,https://pubmed.ncbi.nlm.nih.gov/39145233/,English,Include,,Developing a tablet-based brain-computer interface and robotic prototype for upper limb rehabilitation.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39143372,pubmed:39143372,PubMed,pubmed:39143372,The influence of mental calculations on brain regions and heart rates.,Morteza Jafari Malali;Yashar Sarbaz;Sepideh Zolfaghari;Armin Khodayarlou,2024,10.3390/app12136681,"Performing mathematical calculations is a cognitive activity that can affect biological signals. This study aims to examine the changes in electroencephalogram (EEG) and electrocardiogram (ECG) signals of 36 healthy subjects during the performance of arithmetic tasks. To process EEG signals in different frequency bands, the energy and entropy of entropy (EoE) were extracted from the power spectrum and phase spectrum, respectively. Statistical analysis was conducted to determine meaningful features. These features were sent into support vector machine (SVM) and multi-layer perception (MLP) classifiers to assess their capability in separating math and rest classes. Results indicated the highest classification accuracy of 98.4% for classifying good counters in math and rest state using the MLP method. Based on the majority of features selected for each EEG channel, discriminative brain areas were identified. Analyzing EEG signals proved that math calculation may have multiple influences on various parts of the brain. By comparing good counters' brain activities to those in a resting state, prominent changes were observed in the F",https://pubmed.ncbi.nlm.nih.gov/39143372/,https://pubmed.ncbi.nlm.nih.gov/39143372/,English,Include,,The influence of mental calculations on brain regions and heart rates.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39142534,pubmed:39142534,PubMed,pubmed:39142534,A Deep Learning-Derived Transdiagnostic Signature Indexing Hypoarousal and Impulse Control: Implications for Treatment Prediction in Psychiatric Disorders.,Hannah Meijs;Jurjen J Luykx;Nikita van der Vinne;Rien Breteler;Evian Gordon;Alexander T Sack;Hanneke van Dijk;Martijn Arns,2025,10.1016/j.bpsc.2024.07.027,"Psychiatric disorders are traditionally classified within diagnostic categories, but this approach has limitations. The Research Domain Criteria (RDoC) constitute a research classification system for psychiatric disorders based on dimensions within domains that cut across these psychiatric diagnoses. The overall aim of RDoC is to better understand mental illness in terms of dysfunction in fundamental neurobiological and behavioral systems, leading to better diagnosis, prevention, and treatment. A unique electroencephalographic feature, referred to as spindling excessive beta, has been studied in relation to impulse control and sleep as part of the arousal/regulatory system RDoC domain. Here, we studied electroencephalographic frontal beta activity as a potential transdiagnostic biomarker capable of diagnosing and predicting impulse control and sleep problems. We showed in the first dataset (n = 3279) that the probability of having spindling excessive beta, classified by a deep learning algorithm, was associated with poor sleep maintenance and low daytime impulse control. Furthermore, in 2 additional, independent datasets (iSPOT-A [International Study to Predict Optimized Treatment in ADHD], n = 336; iSPOT-D [International Study to Predict Optimized Treatment in Depression], n = 1008), we revealed that conventional frontocentral beta power and/or spindling excessive beta probability, referred to as Brainmarker-III, is associated with a diagnosis of attention-deficit/hyperactivity disorder, with remission to methylphenidate in children with attention-deficit/hyperactivity disorder in a sex-specific manner, and with remission to antidepressant medication in adults with major depressive disorder in a drug-specific manner. Our results demonstrate the value of the RDoC approach in psychiatry research for the discovery of biomarkers with diagnostic and treatment prediction capacities.",,https://pubmed.ncbi.nlm.nih.gov/39142534/,English,Exclude,Outside date range,A Deep Learning-Derived Transdiagnostic Signature Indexing Hypoarousal and Impulse Control: Implications for Treatment Prediction in Psychiatric Disorders.,,,,,0.95,0.6,
pubmed:39141467,pubmed:39141467,PubMed,pubmed:39141467,"Integrating Large Language Model, EEG, and Eye-Tracking for Word-Level Neural State Classification in Reading Comprehension.",Yuhong Zhang;Qin Li;Sujal Nahata;Tasnia Jamal;Shih-Kuen Cheng;Gert Cauwenberghs;Tzyy-Ping Jung,2024,10.1109/tnsre.2024.3435460,"With the recent proliferation of large language models (LLMs), such as Generative Pre-trained Transformers (GPT), there has been a significant shift in exploring human and machine comprehension of semantic language meaning. This shift calls for interdisciplinary research that bridges cognitive science and natural language processing (NLP). This pilot study aims to provide insights into individuals' neural states during a semantic inference reading-comprehension task. We propose jointly analyzing LLMs, eye-gaze, and electroencephalographic (EEG) data to study how the brain processes words with varying degrees of relevance to a keyword during reading. We also use feature engineering to improve the fixation-related EEG data classification while participants read words with high versus low relevance to the keyword. The best validation accuracy in this word-level classification is over 60% across 12 subjects. Words highly relevant to the inference keyword received significantly more eye fixations per word: 1.0584 compared to 0.6576, including words with no fixations. This study represents the first attempt to classify brain states at a word level using LLM-generated labels. It provides valuable insights into human cognitive abilities and Artificial General Intelligence (AGI), and offers guidance for developing potential reading-assisted technologies.",https://pubmed.ncbi.nlm.nih.gov/39141467/,https://pubmed.ncbi.nlm.nih.gov/39141467/,English,Include,,"Integrating Large Language Model, EEG, and Eye-Tracking for Word-Level Neural State Classification in Reading Comprehension.",Include,,"uring reading. We also use feature engineering to improve the fixation-related EEG data classification while participants read words with high versus low relevance to the keyword. The best validation accuracy in this word-level classification is over 60% across 12 subjects. Words highly relevant to the inference keyword received significantly more eye fixations per word: 1.0584 compared to 0.6576,",,0.95,0.8,small_sample_mentioned
pubmed:39141314,pubmed:39141314,PubMed,pubmed:39141314,Directional information flow analysis in memory retrieval: a comparison between exaggerated and normal pictures.,Mani Farajzadeh Zanjani;Majid Ghoshuni,2025,10.1016/j.neuroimage.2009.10.003,"Working memory plays an important role in cognitive science and is a basic process for learning. While working memory is limited in regard to capacity and duration, different cognitive tasks are designed to overcome these difficulties. This study investigated information flow during a novel visual working memory task in which participants respond to exaggerated and normal pictures. Ten healthy men (mean age 28.5 ± 4.57 years) participated in two stages of the encoding and retrieval tasks. The electroencephalogram (EEG) signals are recorded. Moreover, the adaptive directed transfer function (ADTF) method is used as a computational tool to investigate the dynamic process of visual working memory retrieval on the extracted event-related potentials (ERPs) from the EEG signal. Network connectivity and P300 sub-components (P3a, P3b, and LPC) are also extracted during visual working memory retrieval. Then, the nonparametric Wilcoxon test and five classifiers are applied to network properties for features selection and classification between exaggerated-old and normal-old pictures. The Z-values of Ge is more distinctive rather than other network properties. In terms of the machine learning approach, the accuracy, F1-score, and specificity of the k-nearest neighbors (KNN), classifiers are 81%, 77%, and 81%, respectively. KNN classifier ranked first compared with other classifiers. Furthermore, the results of in-degree/out-degree matrices show that the information flows continuously in the right hemisphere during the retrieval of exaggerated pictures, from P3a to P3b. During the retrieval of visual working memory, the networks associated with attentional processes show greater activation for exaggerated pictures compared to normal pictures. This suggests that the exaggerated pictures may have captured more attention and thus required greater cognitive resources for retrieval.",,https://pubmed.ncbi.nlm.nih.gov/39141314/,English,Exclude,Outside date range,Directional information flow analysis in memory retrieval: a comparison between exaggerated and normal pictures.,,,,,0.95,0.8,small_sample_mentioned
pubmed:39141002,pubmed:39141002,PubMed,pubmed:39141002,Generalizability of electroencephalographic interpretation using artificial intelligence: An external validation study.,Daniel Mansilla;Jesper Tveit;Harald Aurlien;Tamir Avigdor;Victoria Ros-Castello;Alyssa Ho;Chifaou Abdallah;Jean Gotman;Sándor Beniczky;Birgit Frauscher,2024,10.1111/epi.18082,"The automated interpretation of clinical electroencephalograms (EEGs) using artificial intelligence (AI) holds the potential to bridge the treatment gap in resource-limited settings and reduce the workload at specialized centers. However, to facilitate broad clinical implementation, it is essential to establish generalizability across diverse patient populations and equipment. We assessed whether SCORE-AI demonstrates diagnostic accuracy comparable to that of experts when applied to a geographically different patient population, recorded with distinct EEG equipment and technical settings. We assessed the diagnostic accuracy of a ""fixed-and-frozen"" AI model, using an independent dataset and external gold standard, and benchmarked it against three experts blinded to all other data. The dataset comprised 50% normal and 50% abnormal routine EEGs, equally distributed among the four major classes of EEG abnormalities (focal epileptiform, generalized epileptiform, focal nonepileptiform, and diffuse nonepileptiform). To assess diagnostic accuracy, we computed sensitivity, specificity, and accuracy of the AI model and the experts against the external gold standard. We analyzed EEGs from 104 patients (64 females, median age = 38.6 [range = 16-91] years). SCORE-AI performed equally well compared to the experts, with an overall accuracy of 92% (95% confidence interval [CI] = 90%-94%) versus 94% (95% CI = 92%-96%). There was no significant difference between SCORE-AI and the experts for any metric or category. SCORE-AI performed well independently of the vigilance state (false classification during awake: 5/41 [12.2%], false classification during sleep: 2/11 [18.2%]; p = .63) and normal variants (false classification in presence of normal variants: 4/14 [28.6%], false classification in absence of normal variants: 3/38 [7.9%]; p = .07). SCORE-AI achieved diagnostic performance equal to human experts in an EEG dataset independent of the development dataset, in a geographically distinct patient population, recorded with different equipment and technical settings than the development dataset.",https://pubmed.ncbi.nlm.nih.gov/39141002/,https://pubmed.ncbi.nlm.nih.gov/39141002/,English,Include,,Generalizability of electroencephalographic interpretation using artificial intelligence: An external validation study.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.35,external_test_reported
pubmed:39139499,pubmed:39139499,PubMed,pubmed:39139499,An epilepsy classification based on FFT and fully convolutional neural network nested LSTM.,Jianhao Nie;Huazhong Shu;Fuzhi Wu,2024,10.1016/j.cmpb.2014.04.001,"Epilepsy, which is associated with neuronal damage and functional decline, typically presents patients with numerous challenges in their daily lives. An early diagnosis plays a crucial role in managing the condition and alleviating the patients' suffering. Electroencephalogram (EEG)-based approaches are commonly employed for diagnosing epilepsy due to their effectiveness and non-invasiveness. In this study, a classification method is proposed that use fast Fourier Transform (FFT) extraction in conjunction with convolutional neural networks (CNN) and long short-term memory (LSTM) models. Most methods use traditional frameworks to classify epilepsy, we propose a new approach to this problem by extracting features from the source data and then feeding them into a network for training and recognition. It preprocesses the source data into training and validation data and then uses CNN and LSTM to classify the style of the data. Upon analyzing a public test dataset, the top-performing features in the fully CNN nested LSTM model for epilepsy classification are FFT features among three types of features. Notably, all conducted experiments yielded high accuracy rates, with values exceeding 96% for accuracy, 93% for sensitivity, and 96% for specificity. These results are further benchmarked against current methodologies, showcasing consistent and robust performance across all trials. Our approach consistently achieves an accuracy rate surpassing 97.00%, with values ranging from 97.95 to 99.83% in individual experiments. Particularly noteworthy is the superior accuracy of our method in the AB versus (vs.) CDE comparison, registering at 99.06%. Our method exhibits precise classification abilities distinguishing between epileptic and non-epileptic individuals, irrespective of whether the participant's eyes are closed or open. Furthermore, our technique shows remarkable performance in effectively categorizing epilepsy type, distinguishing between epileptic ictal and interictal states versus non-epileptic conditions. An inherent advantage of our automated classification approach is its capability to disregard EEG data acquired during states of eye closure or eye-opening. Such innovation holds promise for real-world applications, potentially aiding medical professionals in diagnosing epilepsy more efficiently.",https://pubmed.ncbi.nlm.nih.gov/39139499/,https://pubmed.ncbi.nlm.nih.gov/39139499/,English,Include,,An epilepsy classification based on FFT and fully convolutional neural network nested LSTM.,Include,,"est dataset, the top-performing features in the fully CNN nested LSTM model for epilepsy classification are FFT features among three types of features. Notably, all conducted experiments yielded high accuracy rates, with values exceeding 96% for accuracy, 93% for sensitivity, and 96% for specificity. These results are further benchmarked against current methodologies, showcasing consistent and rob",,0.95,0.6,
pubmed:39139046,pubmed:39139046,PubMed,pubmed:39139046,Deciphering the impairment of perimenopausal insomnia on visual search from a neurocognitive processing perspective.,Liyong Yu;Yucai Luo;Wenting Lin;Zeyang Dou;Daijie Hu;Wei Wei;Yuqi He;Keli Zhu;Xiaojuan Hong;Qi Zhang;Siyi Yu,2024,10.1093/sleep/zsae188,"Perimenopausal insomnia (PMI) is associated with observable performance impairments in visual search tasks. This study examines how various cognitive processing stages contribute to search performance delays in PMI compared to healthy controls (HCs). We recruited 76 participants diagnosed with PMI and 63 HCs. Event-related potentials (ERPs) were recorded as participants engaged in a visual search task, reporting the orientation of a color popout target within an array of ellipses. We analyzed group differences in behavioral performance and ERP components across cognitive processing stages. Compared to HCs, PMI patients exhibited behavioral response delays, although accuracy was not different between groups. Electrophysiological analyses revealed group differences across several ERP components. Firstly, the N1 component's amplitude increased bilaterally, suggesting enhanced visual sensory processing. Secondly, a slower and smaller N2pc indicated reduced attentional orienting. Thirdly, a decreased sustained posterior-contralateral negativity amplitude pointed to deficits in target discrimination. Fourthly, an increased amplitude of the stimulus-locked lateralized readiness potential (LRP), with unchanged latency, suggested heightened neural inputs for maintaining motor initiation speed. Fifthly, prolonged response-locked LRP latency indicated slower motor execution. Finally, these changes in ERP components, along with significant correlations between LRP components and insomnia symptoms, suggest potential neural biomarkers for PMI. Our findings provide high-temporal-resolution insights into the neurocognitive disruptions associated with PMI, highlighting how sleep disturbances affect cognitive processing in visual tasks. These insights enhance our understanding of PMI and contribute to discussions on neural mechanisms driving behavioral performance in various conditions.",,https://pubmed.ncbi.nlm.nih.gov/39139046/,English,Exclude,Not EEG-BCI focused,Deciphering the impairment of perimenopausal insomnia on visual search from a neurocognitive processing perspective.,,,,,0.9,0.8,small_sample_mentioned
pubmed:39137069,pubmed:39137069,PubMed,pubmed:39137069,Assessing Consciousness in Patients With Disorders of Consciousness Using a Musical Stimulation Paradigm and Verifiable Criteria.,Jiahui Pan;Yue Chen;Qiuyi Xiao;Zerong Chen;Honghua Cai;Qi You;Lina Qiu;Qiuyou Xie,2024,10.1109/tnsre.2024.3442788,"Numerous studies have shown that musical stimulation can activate corresponding functional brain areas. Electroencephalogram (EEG) activity during musical stimulation can be used to assess the consciousness states of patients with disorders of consciousness (DOC). In this study, a musical stimulation paradigm and verifiable criteria were used for consciousness assessment. Twenty-nine participants (13 healthy subjects, 6 patients in a minimally conscious state (MCS) and 10 patients in a vegetative state (VS)) were recruited, and EEG signals were collected while participants listened to preferred and relaxing music. Fusion features based on differential entropy (DE), common spatial pattern (CSP), and EEG-based network pattern (ENP) features were extracted from EEG signals, and a convolutional neural network-long short-term memory (CNN-LSTM) model was employed to classify preferred and relaxing music.The results showed that the average classification accuracy for healthy subjects reached 85.58%. For two of the patients in the MCS group, the classification accuracies reached 78.18% and 66.14%, and they were diagnosed with emergence from MCS (EMCS) two months later. The accuracies of three patients in the VS group were 58.18%, 64.32% and 62.05%, with two patients showing slight increases in scale scores. Our study suggests that musical stimulation could be an effective method for consciousness detection, with significant diagnostic implications for patients with DOC.",https://pubmed.ncbi.nlm.nih.gov/39137069/,https://pubmed.ncbi.nlm.nih.gov/39137069/,English,Include,,Assessing Consciousness in Patients With Disorders of Consciousness Using a Musical Stimulation Paradigm and Verifiable Criteria.,Include,,"d from EEG signals, and a convolutional neural network-long short-term memory (CNN-LSTM) model was employed to classify preferred and relaxing music.The results showed that the average classification accuracy for healthy subjects reached 85.58%. For two of the patients in the MCS group, the classification accuracies reached 78.18% and 66.14%, and they were diagnosed with emergence from MCS (EMCS) ",,0.95,0.8,small_sample_mentioned
pubmed:39136190,pubmed:39136190,PubMed,pubmed:39136190,Cross-Subject Seizure Detection via Unsupervised Domain-Adaptation.,Shuai Wang;Hailing Feng;Hongbin Lv;Chenxi Nie;Wenqian Feng;Hao Peng;Lin Zhang;Yanna Zhao,2024,10.1142/s0129065724500552,"Automatic seizure detection from Electroencephalography (EEG) is of great importance in aiding the diagnosis and treatment of epilepsy due to the advantages of convenience and economy. Existing seizure detection methods are usually patient-specific, the training and testing are carried out on the same patient, limiting their scalability to other patients. To address this issue, we propose a cross-subject seizure detection method via unsupervised domain adaptation. The proposed method aims to obtain seizure specific information through shallow and deep feature alignments. For shallow feature alignment, we use convolutional neural network (CNN) to extract seizure-related features. The distribution gap of the shallow features between different patients is minimized by multi-kernel maximum mean discrepancies (MK-MMD). For deep feature alignment, adversarial learning is utilized. The feature extractor tries to learn feature representations that try to confuse the domain classifier, making the extracted deep features more generalizable to new patients. The performance of our method is evaluated on the CHB-MIT and Siena databases in epoch-based experiments. Additionally, event-based experiments are also conducted on the CHB-MIT dataset. The results validate the feasibility of our method in diminishing the domain disparities among different patients.",https://pubmed.ncbi.nlm.nih.gov/39136190/,https://pubmed.ncbi.nlm.nih.gov/39136190/,English,Include,,Cross-Subject Seizure Detection via Unsupervised Domain-Adaptation.,Exclude,No performance metrics reported,No metrics found in full text,,0.9,0.6,
pubmed:39134021,pubmed:39134021,PubMed,pubmed:39134021,Neural subspaces of imagined movements in parietal cortex remain stable over several years in humans.,L Bashford;I A Rosenthal;S Kellis;D Bjånes;K Pejsa;B W Brunton;R A Andersen,2024,10.1088/1741-2552/abda0b,,,https://pubmed.ncbi.nlm.nih.gov/39134021/,English,Exclude,Not EEG-BCI focused,Neural subspaces of imagined movements in parietal cortex remain stable over several years in humans.,,,,,0.9,0.6,
pubmed:39128676,pubmed:39128676,PubMed,pubmed:39128676,Our brains sense the future through a new quantum-like implicit learning mechanism.,Álex Escolà-Gascón,2024,10.1016/j.brainresbull.2024.111048,"Imagine if our brains could unconsciously predict future events. This study explores this concept, presenting evidence for an inherent 'foreseeing' ability, termed anomalous cognition (AC). We introduce a new experimentally verifiable approach to explain anomalous information anticipation (AIA), a type of AC, based on an innovative, quantum-like model of implicit learning, grounded in Nonlocal Plasticity Theory (NPT). Our research involved 203 participants using methods such as continuous flash suppression, random dot motion, and advanced 3D EEG neuroimaging, along with IBM quantum random event generators for precise measurements across 144 trials. These trials tested contingencies between undetectable sensory stimuli and dot movements, focusing on participants' prediction abilities. The design conditions were strictly experimental, violating fundamental classical learning principles, particularly reflex conditioning. If these principles were immutable, their violation would prevent any systematic behavioral changes, resulting in random responses. This violation was implemented through two quantum physics concepts: the mathematical principle of nonlocality and entanglement. Despite the sensory stimulus being inaccessible, our results showed a significant prediction between the contingencies and an increase in AIA accuracy, with explained variances between 25 % and 48 %. EEG findings supported this, showing a positive link between brain activity in specific regions and AIA success. Electrochemical activations were detected in the posterior occipital cortex, the intraparietal sulcus, and the medial temporal gyri. AIA hits exceeded the threshold value corresponding to one standard deviation above the expected mean, showing moderate effect sizes in the experimental group (Cohen's d = 0.461). Analyzing the learning curve using the derivation technique, we identified the acceleration point of the wave function, indicating systematic implicit learning. This result showed that from repetition 63 onwards, AIA hits increased significantly. The results suggest that, despite violating fundamental classical learning principles, cognitive processes produced changes in participants' responses susceptible to neuromodulation, considering quantum physics principles of nonlocality and entanglement (both present in NPT). We discuss (a) why the priming effect does not explain the significant results; (b) the potential discovery of a new form of quantum-like implicit learning, which could scientifically resolve phenomena associated with anomalous cognitions (e.g., AIA); and (c) future research directions, including potential applications and clinical impact.",https://pubmed.ncbi.nlm.nih.gov/39128676/,https://pubmed.ncbi.nlm.nih.gov/39128676/,English,Include,,Our brains sense the future through a new quantum-like implicit learning mechanism.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39125495,pubmed:39125495,PubMed,pubmed:39125495,EEG-Based Detection of Mild Cognitive Impairment Using DWT-Based Features and Optimization Methods.,Majid Aljalal;Saeed A Aldosari;Khalil AlSharabi;Fahd A Alturki,2024,10.1109/tevc.2004.826067,"In recent years, electroencephalography (EEG) has been investigated for identifying brain disorders. This technique involves placing multiple electrodes (channels) on the scalp to measure the brain's activities. This study focuses on accurately detecting mild cognitive impairment (MCI) from the recorded EEG signals. To achieve this, this study first introduced discrete wavelet transform (DWT)-based approaches to generate reliable biomarkers for MCI. These approaches decompose each channel's signal using DWT into a set of distinct frequency band signals, then extract features using a non-linear measure such as band power, energy, or entropy. Various machine learning approaches then classify the generated features. We investigated these methods on EEGs recorded using 19 channels from 29 MCI patients and 32 healthy subjects. In the second step, the study explored the possibility of decreasing the number of EEG channels while preserving, or even enhancing, classification accuracy. We employed multi-objective optimization techniques, such as the non-dominated sorting genetic algorithm (NSGA) and particle swarm optimization (PSO), to achieve this. The results show that the generated DWT-based features resulted in high full-channel classification accuracy scores. Furthermore, selecting fewer channels carefully leads to better accuracy scores. For instance, with a DWT-based approach, the full-channel accuracy achieved was 99.84%. With only four channels selected by NSGA-II, NSGA-III, or PSO, the accuracy increased to 99.97%. Furthermore, NSGA-II selects five channels, achieving an accuracy of 100%. The results show that the suggested DWT-based approaches are promising to detect MCI, and picking the most useful EEG channels makes the accuracy even higher. The use of a small number of electrodes paves the way for EEG-based diagnosis in clinical practice.",https://pubmed.ncbi.nlm.nih.gov/39125495/,https://pubmed.ncbi.nlm.nih.gov/39125495/,English,Include,,EEG-Based Detection of Mild Cognitive Impairment Using DWT-Based Features and Optimization Methods.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39124036,pubmed:39124036,PubMed,pubmed:39124036,Exploring Feature Selection and Classification Techniques to Improve the Performance of an Electroencephalography-Based Motor Imagery Brain-Computer Interface System.,Md Humaun Kabir;Nadim Ibne Akhtar;Nishat Tasnim;Abu Saleh Musa Miah;Hyoun-Sup Lee;Si-Woong Jang;Jungpil Shin,2024,10.3389/fnins.2023.1113593,"The accuracy of classifying motor imagery (MI) activities is a significant challenge when using brain-computer interfaces (BCIs). BCIs allow people with motor impairments to control external devices directly with their brains using electroencephalogram (EEG) patterns that translate brain activity into control signals. Many researchers have been working to develop MI-based BCI recognition systems using various time-frequency feature extraction and classification approaches. However, the existing systems still face challenges in achieving satisfactory performance due to large amount of non-discriminative and ineffective features. To get around these problems, we suggested a multiband decomposition-based feature extraction and classification method that works well, along with a strong feature selection method for MI tasks. Our method starts by splitting the preprocessed EEG signal into four sub-bands. In each sub-band, we then used a common spatial pattern (CSP) technique to pull out narrowband-oriented useful features, which gives us a high-dimensional feature vector. Subsequently, we utilized an effective feature selection method, Relief-F, which reduces the dimensionality of the final features. Finally, incorporating advanced classification techniques, we classified the final reduced feature vector. To evaluate the proposed model, we used the three different EEG-based MI benchmark datasets, and our proposed model achieved better performance accuracy than existing systems. Our model's strong points include its ability to effectively reduce feature dimensionality and improve classification accuracy through advanced feature extraction and selection methods.",https://pubmed.ncbi.nlm.nih.gov/39124036/,https://pubmed.ncbi.nlm.nih.gov/39124036/,English,Include,,Exploring Feature Selection and Classification Techniques to Improve the Performance of an Electroencephalography-Based Motor Imagery Brain-Computer Interface System.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39123966,pubmed:39123966,PubMed,pubmed:39123966,Latent Prototype-Based Clustering: A Novel Exploratory Electroencephalography Analysis Approach.,Sun Zhou;Pengyi Zhang;Huazhen Chen,2024,10.1016/j.eswa.2023.121040,"Electroencephalography (EEG)-based applications in brain-computer interfaces (BCIs), neurological disease diagnosis, rehabilitation, etc., rely on supervised approaches such as classification that requires given labels. However, with the ever-increasing amount of EEG data, incomplete or incorrectly labeled or unlabeled EEG data are increasing. It likely degrades the performance of supervised approaches. In this work, we put forward a novel unsupervised exploratory EEG analysis solution by clustering based on low-dimensional prototypes in latent space that are associated with the respective clusters. Having the prototype as a baseline of each cluster, a compositive similarity is defined to act as the critic function in clustering, which incorporates similarities on three levels. The approach is implemented with a Generative Adversarial Network (GAN), termed W-SLOGAN, by extending the Stein Latent Optimization for GANs (SLOGAN). The Gaussian Mixture Model (GMM) is utilized as the latent distribution to adapt to the diversity of EEG signal patterns. The W-SLOGAN ensures that images generated from each Gaussian component belong to the associated cluster. The adaptively learned Gaussian mixing coefficients make the model remain effective in dealing with an imbalanced dataset. By applying the proposed approach to two public EEG or intracranial EEG (iEEG) epilepsy datasets, our experiments demonstrate that the clustering results are close to the classification of the data. Moreover, we present several findings that were discovered by intra-class clustering and cross-analysis of clustering and classification. They show that the approach is attractive in practice in the diagnosis of the epileptic subtype, multiple labelling of EEG data, etc.",https://pubmed.ncbi.nlm.nih.gov/39123966/,https://pubmed.ncbi.nlm.nih.gov/39123966/,English,Include,,Latent Prototype-Based Clustering: A Novel Exploratory Electroencephalography Analysis Approach.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39123882,pubmed:39123882,PubMed,pubmed:39123882,CATM: A Multi-Feature-Based Cross-Scale Attentional Convolutional EEG Emotion Recognition Model.,Hongde Yu;Xin Xiong;Jianhua Zhou;Ren Qian;Kaiwen Sha,2024,10.3390/brainsci14040344,"Aiming at the problem that existing emotion recognition methods fail to make full use of the information in the time, frequency, and spatial domains in the EEG signals, which leads to the low accuracy of EEG emotion classification, this paper proposes a multi-feature, multi-frequency band-based cross-scale attention convolutional model (CATM). The model is mainly composed of a cross-scale attention module, a frequency-space attention module, a feature transition module, a temporal feature extraction module, and a depth classification module. First, the cross-scale attentional convolution module extracts spatial features at different scales for the preprocessed EEG signals; then, the frequency-space attention module assigns higher weights to important channels and spatial locations; next, the temporal feature extraction module extracts temporal features of the EEG signals; and, finally, the depth classification module categorizes the EEG signals into emotions. We evaluated the proposed method on the DEAP dataset with accuracies of 99.70% and 99.74% in the valence and arousal binary classification experiments, respectively; the accuracy in the valence-arousal four-classification experiment was 97.27%. In addition, considering the application of fewer channels, we also conducted 5-channel experiments, and the binary classification accuracies of valence and arousal were 97.96% and 98.11%, respectively. The valence-arousal four-classification accuracy was 92.86%. The experimental results show that the method proposed in this paper exhibits better results compared to other recent methods, and also achieves better results in few-channel experiments.",https://pubmed.ncbi.nlm.nih.gov/39123882/,https://pubmed.ncbi.nlm.nih.gov/39123882/,English,Include,,CATM: A Multi-Feature-Based Cross-Scale Attentional Convolutional EEG Emotion Recognition Model.,Include,,"Aiming at the problem that existing emotion recognition methods fail to make full use of the information in the time, frequency, and spatial domains in the EEG signals, which leads to the low accuracy of EEG emotion classification, this paper proposes a multi-feature, multi-frequency band-based cross-scale attention convolutional model (CATM). The model is mainly composed of a cross-scale ",,0.95,0.6,
pubmed:39123876,pubmed:39123876,PubMed,pubmed:39123876,Detection of Unfocused EEG Epochs by the Application of Machine Learning Algorithm.,Rafia Akhter;Fred R Beyette,2024,10.3390/s23063143,"Electroencephalography (EEG) is a non-invasive method used to track human brain activity over time. The time-locked EEG to an external event is known as event-related potential (ERP). ERP can be a biomarker of human perception and other cognitive processes. The success of ERP research depends on the laboratory conditions and attentiveness of the test subjects. Specifically, the inability to control experimental variables has reduced ERP research in the real world. This study collected EEG data under various experimental circumstances within an auditory oddball paradigm experiment to enable the use of ERP as an active biomarker in normal laboratory conditions. Then, ERP epochs were analyzed to identify unfocused epochs, affected by typical artifacts and external distortion. For the initial comparison, the ability of four unsupervised machine learning algorithms (MLAs) was evaluated to identify unfocused epochs. Then, their accuracy was compared with the human inspection and a current EEG analysis tool (EEGLab). All four MLAs were typically 95-100% accurate. In summary, our analysis finds that humans might miss subtle differences in the regular ERP patterns, but MLAs could efficiently identify those. Thus, our analysis suggests that unsupervised MLAs perform better for detecting unfocused ERP epochs compared with the other two standard methods.",https://pubmed.ncbi.nlm.nih.gov/39123876/,https://pubmed.ncbi.nlm.nih.gov/39123876/,English,Include,,Detection of Unfocused EEG Epochs by the Application of Machine Learning Algorithm.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39122554,pubmed:39122554,PubMed,pubmed:39122554,Sensory and Perceptual Decisional Processes Underlying the Perception of Reverberant Auditory Environments.,Haydée G García-Lázaro;Santani Teng,2024,10.1073/pnas.1801614115,"Reverberation, a ubiquitous feature of real-world acoustic environments, exhibits statistical regularities that human listeners leverage to self-orient, facilitate auditory perception, and understand their environment. Despite the extensive research on sound source representation in the auditory system, it remains unclear how the brain represents real-world reverberant environments. Here, we characterized the neural response to reverberation of varying realism by applying multivariate pattern analysis to electroencephalographic (EEG) brain signals. Human listeners (12 males and 8 females) heard speech samples convolved with real-world and synthetic reverberant impulse responses and judged whether the speech samples were in a ""real"" or ""fake"" environment, focusing on the reverberant background rather than the properties of speech itself. Participants distinguished real from synthetic reverberation with ∼75% accuracy; EEG decoding reveals a multistage decoding time course, with dissociable components early in the stimulus presentation and later in the perioffset stage. The early component predominantly occurred in temporal electrode clusters, while the later component was prominent in centroparietal clusters. These findings suggest distinct neural stages in perceiving natural acoustic environments, likely reflecting sensory encoding and higher-level perceptual decision-making processes. Overall, our findings provide evidence that reverberation, rather than being largely suppressed as a noise-like signal, carries relevant environmental information and gains representation along the auditory system. This understanding also offers various applications; it provides insights for including reverberation as a cue to aid navigation for blind and visually impaired people. It also helps to enhance realism perception in immersive virtual reality settings, gaming, music, and film production.",https://pubmed.ncbi.nlm.nih.gov/39122554/,https://pubmed.ncbi.nlm.nih.gov/39122554/,English,Include,,Sensory and Perceptual Decisional Processes Underlying the Perception of Reverberant Auditory Environments.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39121995,pubmed:39121995,PubMed,pubmed:39121995,"Task-specific relationships between error-related ERPs and behavior: Flanker, Stroop, and Go/Nogo tasks.",Bohyun Park;Amanda Holbrook;Miranda C Lutz;Scott A Baldwin;Michael J Larson;Peter E Clayson,2024,10.1016/j.ijpsycho.2024.112409,"Performance monitoring has been widely studied during different forced-choice response tasks. Participants typically show longer response times (RTs) and increased accuracy following errors, but there are inconsistencies regarding the connection between error-related event-related brain potentials (ERPs) and behavior, such as RT and accuracy. The specific task in any given study could contribute to these inconsistencies, as different tasks may require distinct cognitive processes that impact ERP-behavior relationships. The present study sought to determine whether task moderates ERP-behavior relationships and whether these relationships are robustly observed when tasks and stimuli are treated as random effects. ERPs and behavioral indices (RTs and accuracy) recorded during flanker, Stroop, and Go/Nogo tasks from 180 people demonstrated a task-specific effect on ERP-behavior relationships, such that larger previous-trial error-related negativity (ERN) predicted longer RTs and greater likelihood of a correct response on subsequent trials during flanker and Stroop tasks but not during Go/Nogo task. Additionally, larger previous-trial error positivity (Pe) predicted faster RTs and smaller variances of RTs on subsequent trials for Stroop and Go/Nogo tasks but not for flanker task. When tasks and stimuli were treated as random effects, ERP-behavior relationships were not observed. These findings support the need to consider the task used for recording performance monitoring measures when interpreting results across studies.",,https://pubmed.ncbi.nlm.nih.gov/39121995/,English,Exclude,Not EEG-BCI focused,"Task-specific relationships between error-related ERPs and behavior: Flanker, Stroop, and Go/Nogo tasks.",,,,,0.9,0.8,small_sample_mentioned
pubmed:39121709,pubmed:39121709,PubMed,pubmed:39121709,EEG based depression detection by machine learning: Does inner or overt speech condition provide better biomarkers when using emotion words as experimental cues?,Máté Kapitány-Fövény;Mihály Vetró;Gábor Révy;Dániel Fabó;Danuta Szirmai;Gábor Hullám,2024,10.1016/j.jpsychires.2024.08.002,"Objective diagnostic approaches need to be tested to enhance the efficacy of depression detection. Non-invasive EEG-based identification represents a promising area. The present EEG study addresses two central questions: 1) whether inner or overt speech condition result in higher diagnositc accuracy of depression detection; and 2) does the affective nature of the presented emotion words count in such diagnostic approach. A matched case-control sample consisting of 10 depressed subjects and 10 healthy controls was assessed. An EEG headcap containing 64 electrodes measured neural responses to experimental cues presented in the form of 15 different words that belonged to three emotional categories: neutral, positive, and negative. 120 experimental cues was presented for every participant, each containing an ""inner speech"" and an ""overt speech"" segment. An EEGNet neural network was utilized. The highest diagnostic accuracy of the EEGNet model was observed in the case of the overt speech condition (i.e. 69.5%), while a an overall subject-wise accuracy of 80% was achieved by the model. Only a negligible difference in diagnostic accuracy could be found between aggregated emotion word categories, with the highest accuracy (i.e. 70.2%) associated with the presentation of positive emotion words. Model decision was primarily influenced by electrodes representing the regions of the left parietal, the left temporal lobe and the middle frontal areas. While the generalizability of our results is limited by the small sample size and potentially uncontrolled confounders, depression was associated with sensitive and presumably network-like aspects of these brain areas, potentially implying a higher level of emotion regulation that increases primarily in open communication.",https://pubmed.ncbi.nlm.nih.gov/39121709/,https://pubmed.ncbi.nlm.nih.gov/39121709/,English,Include,,EEG based depression detection by machine learning: Does inner or overt speech condition provide better biomarkers when using emotion words as experimental cues?,Include,,ction. Non-invasive EEG-based identification represents a promising area. The present EEG study addresses two central questions: 1) whether inner or overt speech condition result in higher diagnositc accuracy of depression detection; and 2) does the affective nature of the presented emotion words count in such diagnostic approach. A matched case-control sample consisting of 10 depressed subjects a,,0.95,0.6,
pubmed:39120777,pubmed:39120777,PubMed,pubmed:39120777,MFCC-CNN: A patient-independent seizure prediction model.,Fan Zhang;Boyan Zhang;Siyuan Guo;Xinhong Zhang,2024,10.1016/j.eswa.2022.117733,"Automatic prediction of seizures is a major goal in the field of epilepsy. However, the high variability of Electroencephalogram (EEG) signals in different patients limits the use of prediction models in clinical applications. This paper proposes a patient-independent seizure prediction model, named MFCC-CNN, to improve the generalization ability. MFCC-CNN model introduces Mel-Frequency Cepstrum Coefficients (MFCC) features and Linear Predictive Cepstral Coefficients (LPCC) features concentrated in the low frequency region, which contains more detailed information. Convolutional neural network (CNN) is used to construct a seizure prediction model. Experimental results showed that the proposed model obtained accuracy of 96  MFCC-CNN model does not need to be specifically customized for different patients. As a patient-independent seizure prediction model, it has good generalization ability.",https://pubmed.ncbi.nlm.nih.gov/39120777/,https://pubmed.ncbi.nlm.nih.gov/39120777/,English,Include,,MFCC-CNN: A patient-independent seizure prediction model.,Include,,"ency region, which contains more detailed information. Convolutional neural network (CNN) is used to construct a seizure prediction model. Experimental results showed that the proposed model obtained accuracy of 96  MFCC-CNN model does not need to be specifically customized for different patients. As a patient-independent seizure prediction model, it has good generalization ability.",,0.95,0.6,
pubmed:39119215,pubmed:39119215,PubMed,pubmed:39119215,A novel methodology for emotion recognition through 62-lead EEG signals: multilevel heterogeneous recurrence analysis.,Yujie Wang;Cheng-Bang Chen;Toshihiro Imamura;Ignacio E Tapia;Virend K Somers;Phyllis C Zee;Diane C Lim,2024,10.1109/taffc.2017.2712143,"Recognizing emotions from electroencephalography (EEG) signals is a challenging task due to the complex, nonlinear, and nonstationary characteristics of brain activity. Traditional methods often fail to capture these subtle dynamics, while deep learning approaches lack explainability. In this research, we introduce a novel three-phase methodology integrating manifold embedding, multilevel heterogeneous recurrence analysis (MHRA), and ensemble learning to address these limitations in EEG-based emotion recognition. The proposed methodology was evaluated using the SJTU-SEED IV database. We first applied uniform manifold approximation and projection (UMAP) for manifold embedding of the 62-lead EEG signals into a lower-dimensional space. We then developed MHRA to characterize the complex recurrence dynamics of brain activity across multiple transition levels. Finally, we employed tree-based ensemble learning methods to classify four emotions (neutral, sad, fear, happy) based on the extracted MHRA features. Our approach achieved high performance, with an accuracy of 0.7885 and an AUC of 0.7552, outperforming existing methods on the same dataset. Additionally, our methodology provided the most consistent recognition performance across different emotions. Sensitivity analysis revealed specific MHRA metrics that were strongly associated with each emotion, offering valuable insights into the underlying neural dynamics. This study presents a novel framework for EEG-based emotion recognition that effectively captures the complex nonlinear and nonstationary dynamics of brain activity while maintaining explainability. The proposed methodology offers significant potential for advancing our understanding of emotional processing and developing more reliable emotion recognition systems with broad applications in healthcare and beyond.",https://pubmed.ncbi.nlm.nih.gov/39119215/,https://pubmed.ncbi.nlm.nih.gov/39119215/,English,Include,,A novel methodology for emotion recognition through 62-lead EEG signals: multilevel heterogeneous recurrence analysis.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39117064,pubmed:39117064,PubMed,pubmed:39117064,Neural correlates of listening to nonnative-accented speech in multi-talker background noise.,Yushuang Liu;Janet G van Hell,2024,10.1016/j.neuropsychologia.2024.108968,"We examined the neural correlates underlying the semantic processing of native- and nonnative-accented sentences, presented in quiet or embedded in multi-talker noise. Implementing a semantic violation paradigm, 36 English monolingual young adults listened to American-accented (native) and Chinese-accented (nonnative) English sentences with or without semantic anomalies, presented in quiet or embedded in multi-talker noise, while EEG was recorded. After hearing each sentence, participants verbally repeated the sentence, which was coded and scored as an offline comprehension accuracy measure. In line with earlier behavioral studies, the negative impact of background noise on sentence repetition accuracy was higher for nonnative-accented than for native-accented sentences. At the neural level, the N400 effect for semantic anomaly was larger for native-accented than for nonnative-accented sentences, and was also larger for sentences presented in quiet than in noise, indicating impaired lexical-semantic access when listening to nonnative-accented speech or sentences embedded in noise. No semantic N400 effect was observed for nonnative-accented sentences presented in noise. Furthermore, the frequency of neural oscillations in the alpha frequency band (an index of online cognitive listening effort) was higher when listening to sentences in noise versus in quiet, but no difference was observed across the accent conditions. Semantic anomalies presented in background noise also elicited higher theta activity, whereas processing nonnative-accented anomalies was associated with decreased theta activity. Taken together, we found that listening to nonnative accents or background noise is associated with processing challenges during online semantic access, leading to decreased comprehension accuracy. However, the underlying cognitive mechanism (e.g., associated listening efforts) might manifest differently across accented speech processing and speech in noise processing.",https://pubmed.ncbi.nlm.nih.gov/39117064/,https://pubmed.ncbi.nlm.nih.gov/39117064/,English,Include,,Neural correlates of listening to nonnative-accented speech in multi-talker background noise.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39116892,pubmed:39116892,PubMed,pubmed:39116892,Wasserstein generative adversarial network with gradient penalty and convolutional neural network based motor imagery EEG classification.,Hui Xiong;Jiahe Li;Jinzhen Liu;Jinlong Song;Yuqing Han,2024,10.1088/1741-2552/ad6cf5,,https://pubmed.ncbi.nlm.nih.gov/39116892/,https://pubmed.ncbi.nlm.nih.gov/39116892/,English,Include,,Wasserstein generative adversarial network with gradient penalty and convolutional neural network based motor imagery EEG classification.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39116352,pubmed:39116352,PubMed,pubmed:39116352,A Complementary Dual-Mode Ion-Electron Conductive Hydrogel Enables Sustained Conductivity for Prolonged Electroencephalogram Recording.,Hengjie Su;Linna Mao;Xiaoqi Chen;Peishuai Liu;Jiangbo Pu;Zhuo Mao;Tomoko Fujiwara;Yue Ma;Xinyang Mao;Ting Li,2024,10.1002/advs.202405273,"Conductive gel interface materials are widely employed as reliable agents for electroencephalogram (EEG) recording. However, prolonged EEG recording poses challenges in maintaining stable and efficient capture due to inevitable evaporation in hydrogels, which restricts sustained high conductivity. This study introduces a novel ion-electron dual-mode conductive hydrogel synthesized through a cost-effective and streamlined process. By embedding graphite nanoparticles into ionic hyaluronic acid (HAGN), the hydrogel maintains higher conductivity for over 72 h, outperforming commercial gels. Additionally, it exhibits superior low skin contact impedance, considerable electrochemical capability, and excellent tensile and adhesion performance in both dry and wet conditions. The biocompatibility of the HAGN hydrogel, verified through in vitro cell viability assays and in vivo skin irritation tests, underscores its suitability for prolonged skin contact without eliciting adverse reactions. Furthermore, in vivo EEG tests confirm the HAGN hydrogel's capability to provide high-fidelity signal acquisition across multiple EEG protocols. The HAGN hydrogel proves to be an effective interface for prolonged high-quality EEG recording, facilitating high-performance capture and classification of evoked potentials, thereby providing a reliable conductive medium for EEG-based systems.",https://pubmed.ncbi.nlm.nih.gov/39116352/,https://pubmed.ncbi.nlm.nih.gov/39116352/,English,Include,,A Complementary Dual-Mode Ion-Electron Conductive Hydrogel Enables Sustained Conductivity for Prolonged Electroencephalogram Recording.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39116183,pubmed:39116183,PubMed,pubmed:39116183,Convolutional neural networks can identify brain interactions involved in decoding spatial auditory attention.,Keyvan Mahjoory;Andreas Bahmer;Molly J Henry,2024,10.1016/j.neuroimage.2014.06.073,"Human listeners have the ability to direct their attention to a single speaker in a multi-talker environment. The neural correlates of selective attention can be decoded from a single trial of electroencephalography (EEG) data. In this study, leveraging the source-reconstructed and anatomically-resolved EEG data as inputs, we sought to employ CNN as an interpretable model to uncover task-specific interactions between brain regions, rather than simply to utilize it as a black box decoder. To this end, our CNN model was specifically designed to learn pairwise interaction representations for 10 cortical regions from five-second inputs. By exclusively utilizing these features for decoding, our model was able to attain a median accuracy of 77.56% for within-participant and 65.14% for cross-participant classification. Through ablation analysis together with dissecting the features of the models and applying cluster analysis, we were able to discern the presence of alpha-band-dominated inter-hemisphere interactions, as well as alpha- and beta-band dominant interactions that were either hemisphere-specific or were characterized by a contrasting pattern between the right and left hemispheres. These interactions were more pronounced in parietal and central regions for within-participant decoding, but in parietal, central, and partly frontal regions for cross-participant decoding. These findings demonstrate that our CNN model can effectively utilize features known to be important in auditory attention tasks and suggest that the application of domain knowledge inspired CNNs on source-reconstructed EEG data can offer a novel computational framework for studying task-relevant brain interactions.",https://pubmed.ncbi.nlm.nih.gov/39116183/,https://pubmed.ncbi.nlm.nih.gov/39116183/,English,Include,,Convolutional neural networks can identify brain interactions involved in decoding spatial auditory attention.,Include,,"lly designed to learn pairwise interaction representations for 10 cortical regions from five-second inputs. By exclusively utilizing these features for decoding, our model was able to attain a median accuracy of 77.56% for within-participant and 65.14% for cross-participant classification. Through ablation analysis together with dissecting the features of the models and applying cluster analysis, ",,0.95,0.6,
pubmed:39116138,pubmed:39116138,PubMed,pubmed:39116138,EEG and ERP biosignatures of mild cognitive impairment for longitudinal monitoring of early cognitive decline in Alzheimer's disease.,Amir H Meghdadi;David Salat;Joanne Hamilton;Yue Hong;Bradley F Boeve;Erik K St Louis;Ajay Verma;Chris Berka,2024,10.1002/trc2.12435,"Cognitive decline in Alzheimer's disease is associated with electroencephalographic (EEG) biosignatures even at early stages of mild cognitive impairment (MCI). The aim of this work is to provide a unified measure of cognitive decline by aggregating biosignatures from multiple EEG modalities and to evaluate repeatability of the composite measure at an individual level. These modalities included resting state EEG (eyes-closed) and two event-related potential (ERP) tasks on visual memory and attention. We compared individuals with MCI (n = 38) to age-matched healthy controls HC (n = 44). In resting state EEG, the MCI group exhibited higher power in Theta (3-7Hz) and lower power in Beta (13-20Hz) frequency bands. In both ERP tasks, the MCI group exhibited reduced ERP late positive potential (LPP), delayed ERP early component latency, slower reaction time, and decreased response accuracy. Cluster-based permutation analysis revealed significant clusters of difference between the MCI and HC groups in the frequency-channel and time-channel spaces. Cluster-based measures and performance measures (12 biosignatures in total) were selected as predictors of MCI. We trained a support vector machine (SVM) classifier achieving AUC = 0.89, accuracy = 77% in cross-validation using all data. Split-data validation resulted in (AUC = 0.87, accuracy = 76%) and (AUC = 0.75, accuracy = 70%) on testing data at baseline and follow-up visits, respectively. Classification scores at baseline and follow-up visits were correlated (r = 0.72, p<0.001, ICC = 0.84), supporting test-retest reliability of EEG biosignature. These results support the utility of EEG/ERP for prognostic testing, repeated assessments, and tracking potential treatment outcomes in the limited duration of clinical trials.",https://pubmed.ncbi.nlm.nih.gov/39116138/,https://pubmed.ncbi.nlm.nih.gov/39116138/,English,Include,,EEG and ERP biosignatures of mild cognitive impairment for longitudinal monitoring of early cognitive decline in Alzheimer's disease.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.25,cv_reported
pubmed:39112022,pubmed:39112022,PubMed,pubmed:39112022,Automated remote sleep monitoring needs uncertainty quantification.,Elisabeth R M Heremans;Laura Van den Bulcke;Nabeel Seedat;Astrid Devulder;Pascal Borzée;Bertien Buyse;Dries Testelmans;Maarten Van Den Bossche;Mihaela van der Schaar;Maarten De Vos,2025,10.1111/jsr.14300,"Wearable electroencephalography devices emerge as a cost-effective and ergonomic alternative to gold-standard polysomnography, paving the way for better health monitoring and sleep disorder screening. Machine learning allows to automate sleep stage classification, but trust and reliability issues have hampered its adoption in clinical applications. Estimating uncertainty is a crucial factor in enhancing reliability by identifying regions of heightened and diminished confidence. In this study, we used an uncertainty-centred machine learning pipeline, U-PASS, to automate sleep staging in a challenging real-world dataset of single-channel electroencephalography and accelerometry collected with a wearable device from an elderly population. We were able to effectively limit the uncertainty of our machine learning model and to reliably inform clinical experts of which predictions were uncertain to improve the machine learning model's reliability. This increased the five-stage sleep-scoring accuracy of a state-of-the-art machine learning model from 63.9% to 71.2% on our dataset. Remarkably, the machine learning approach outperformed the human expert in interpreting these wearable data. Manual review by sleep specialists, without specific training for sleep staging on wearable electroencephalography, proved ineffective. The clinical utility of this automated remote monitoring system was also demonstrated, establishing a strong correlation between the predicted sleep parameters and the reference polysomnography parameters, and reproducing known correlations with the apnea-hypopnea index. In essence, this work presents a promising avenue to revolutionize remote patient care through the power of machine learning by the use of an automated data-processing pipeline enhanced with uncertainty estimation.",,https://pubmed.ncbi.nlm.nih.gov/39112022/,English,Exclude,Outside date range,Automated remote sleep monitoring needs uncertainty quantification.,,,,,0.95,0.6,
pubmed:39111643,pubmed:39111643,PubMed,pubmed:39111643,The influence of task-irrelevant color perception on flanker task performance: Insights from behavioral and ERP data.,Ying Chen;Wenwen Cheng;Xiaoqing Deng;Yan Yang;Zhantao Li;Junhua Zhong;Weijie Li;Bin Cheng,2024,10.1016/j.physbeh.2024.114654,"Perception of color as a task-relevant stimulus can affect cognition and behavior in the flanker task; however, it remains unclear whether it has the same impact when it is a task-irrelevant stimulus dimension. To this end, we applied four-letter flanker tasks with or without colored (red/blue) to 23 healthy young adults, while recording the event-related potentials (ERPs) and behavioral performance. The flanker task included four kinds of color types: non-color letter (NC), all color letter (AC), flanker color letter (FC), and target color letter (TC), each flanker task included congruent and incongruent conditions. The behavioral data demonstrated the classic conflict effect across all color types of flanker tasks in both reaction times (RTs) and accuracy, the significant interaction and main effect of color type factors were only observed in accuracy. The ERP results showed significant interaction between conflict factor (congruent, incongruent) and color type (NC, AC, FC, and TC), and the color type factor enhanced the fronto-central P2 (180-200 ms), descended the fronto-centro-parietal N2b (260-320 ms), and increased the fronto-central P3b (360-520 ms). The fronto-central P2 and the fronto-central P3b were larger for TC than NC, AC, and FC in the congruent condition, while the fronto-central P3b was smaller for NC than AC, FC, and TC in the incongruent condition. Furthermore, the fronto-centro-parietal N2b was decreased successively in NC, AC, FC, and TC in both congruent and incongruent conditions. Overall, our findings suggested that the task-irrelevant stimuli dimension of color can capture some attentional resources and is affected by the location of color (target/flanker) and the type of task trial (congruent/incongruent) in the flanker task.",,https://pubmed.ncbi.nlm.nih.gov/39111643/,English,Exclude,Not EEG-BCI focused,The influence of task-irrelevant color perception on flanker task performance: Insights from behavioral and ERP data.,,,,,0.9,0.6,
pubmed:39111412,pubmed:39111412,PubMed,pubmed:39111412,Human-robot interaction in motor imagery: A system based on the STFCN for unilateral upper limb rehabilitation assistance.,Hui Tian,2024,10.1016/j.jneumeth.2024.110240,"Rehabilitation training based on the brain-computer interface of motor imagery (MI-BCI) can help restore the connection between the brain and movement. However, the performance of most popular MI-BCI system is coarse-level, which means that they are good at guiding the rehabilitation exercises of different parts of the body, but not for the individual component. In this paper, we designed a fine-level MI-BCI system for unilateral upper limb rehabilitation assistance. Besides, due to the low discrimination of different sample classes in a single part, a classification algorithm called spatial-temporal filtering convolutional network (STFCN) was proposed that used spatial filtering and deep learning. Our STFCN outperforms popular methods in recent years using BCI IV 2a and 2b data sets. To verify the effectiveness of our system, we recruited 6 volunteers and collected their data for a four-classification online experiments, resulting in an average accuracy of 62.7 %. This fine-level MI-BCI system has good appli-cation prospects, and inspires more exploration of rehabilitation in a single part of the human body.",https://pubmed.ncbi.nlm.nih.gov/39111412/,https://pubmed.ncbi.nlm.nih.gov/39111412/,English,Include,,Human-robot interaction in motor imagery: A system based on the STFCN for unilateral upper limb rehabilitation assistance.,Include,,"s using BCI IV 2a and 2b data sets. To verify the effectiveness of our system, we recruited 6 volunteers and collected their data for a four-classification online experiments, resulting in an average accuracy of 62.7 %. This fine-level MI-BCI system has good appli-cation prospects, and inspires more exploration of rehabilitation in a single part of the human body.",,0.95,0.6,
pubmed:39111203,pubmed:39111203,PubMed,pubmed:39111203,EEG Analyses of visual cue effects on executed movements.,Patrick Suwandjieff;Gernot R Müller-Putz,2024,10.1016/j.jneumeth.2024.110241,"In electroencephalographic (EEG) or electrocorticographic (ECoG) experiments, visual cues are commonly used for timing synchronization but may inadvertently induce neural activity and cognitive processing, posing challenges when decoding self-initiated tasks. To address this concern, we introduced four new visual cues (Fade, Rotation, Reference, and Star) and investigated their impact on brain signals. Our objective was to identify a cue that minimizes its influence on brain activity, facilitating cue-effect free classifier training for asynchronous applications, particularly aiding individuals with severe paralysis. 22 able-bodied, right-handed participants aged 18-30 performed hand movements upon presentation of the visual cues. Analysis of time-variability between movement onset and cue-aligned data, grand average MRCP, and classification outcomes revealed significant differences among cues. Rotation and Reference cue exhibited favorable results in minimizing temporal variability, maintaining MRCP patterns, and achieving comparable accuracy to self-paced signals in classification. Our study contrasts with traditional cue-based paradigms by introducing novel visual cues designed to mitigate unintended neural activity. We demonstrate the effectiveness of Rotation and Reference cue in eliciting consistent and accurate MRCPs during motor tasks, surpassing previous methods in achieving precise timing and high discriminability for classifier training. Precision in cue timing is crucial for training classifiers, where both Rotation and Reference cue demonstrate minimal variability and high discriminability, highlighting their potential for accurate classifications in online scenarios. These findings offer promising avenues for refining brain-computer interface systems, particularly for individuals with motor impairments, by enabling more reliable and intuitive control mechanisms.",https://pubmed.ncbi.nlm.nih.gov/39111203/,https://pubmed.ncbi.nlm.nih.gov/39111203/,English,Include,,EEG Analyses of visual cue effects on executed movements.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39110623,pubmed:39110623,PubMed,pubmed:39110623,Dual-Alpha: a large EEG study for dual-frequency SSVEP brain-computer interface.,Yike Sun;Liyan Liang;Yuhan Li;Xiaogang Chen;Xiaorong Gao,2024,10.5524/102557,"The domain of brain-computer interface (BCI) technology has experienced significant expansion in recent years. However, the field continues to face a pivotal challenge due to the dearth of high-quality datasets. This lack of robust datasets serves as a bottleneck, constraining the progression of algorithmic innovations and, by extension, the maturation of the BCI field. This study details the acquisition and compilation of electroencephalogram data across 3 distinct dual-frequency steady-state visual evoked potential (SSVEP) paradigms, encompassing over 100 participants. Each experimental condition featured 40 individual targets with 5 repetitions per target, culminating in a comprehensive dataset consisting of 21,000 trials of dual-frequency SSVEP recordings. We performed an exhaustive validation of the dataset through signal-to-noise ratio analyses and task-related component analysis, thereby substantiating its reliability and effectiveness for classification tasks. The extensive dataset presented is set to be a catalyst for the accelerated development of BCI technologies. Its significance extends beyond the BCI sphere and holds considerable promise for propelling research in psychology and neuroscience. The dataset is particularly invaluable for discerning the complex dynamics of binocular visual resource distribution.",https://pubmed.ncbi.nlm.nih.gov/39110623/,https://pubmed.ncbi.nlm.nih.gov/39110623/,English,Include,,Dual-Alpha: a large EEG study for dual-frequency SSVEP brain-computer interface.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39107944,pubmed:39107944,PubMed,pubmed:39107944,Electroencephalography microstate alterations reflect potential double-edged cognitive adaptation in Ménière's disease.,Yi-Ni Li;Jie Li;Peng-Jun Wang;Dong-Zhen Yu;Zheng-Nong Chen;Zheng-Yu Shi;Ya-Qin Wu;Wei-Dong Qi;Wen Lu;Hai-Bo Shi,2024,10.3389/fnins.2019.00563,"To explore the microstate characteristics and underlying brain network activity of Ménière's disease (MD) patients based on high-density electroencephalography (EEG), elucidate the association between microstate dynamics and clinical manifestation, and explore the potential of EEG microstate features as future neurobiomarkers for MD. Thirty-two patients diagnosed with MD and 29 healthy controls (HC) matched for demographic characteristics were included in the study. Dysfunction and subjective symptom severity were assessed by neuropsychological questionnaires, pure tone audiometry, and vestibular function tests. Resting-state EEG recordings were obtained using a 256-channel EEG system, and the electric field topographies were clustered into four dominant microstate classes (A, B, C, and D). The dynamic parameters of each microstate were analyzed and utilized as input for a support vector machine (SVM) classifier to identify significant microstate signatures associated with MD. The clinical significance was further explored through Spearman correlation analysis. MD patients exhibited an increased presence of microstate class C and a decreased frequency of transitions between microstate class A and B, as well as between class A and D. The transitions from microstate class A to C were also elevated. Further analysis revealed a positive correlation between equilibrium scores and the transitions from microstate class A to C under somatosensory challenging conditions. Conversely, transitions between class A and B were negatively correlated with vertigo symptoms. No significant correlations were detected between these characteristics and auditory test results or emotional scores. Utilizing the microstate features identified via sequential backward selection, the linear SVM classifier achieved a sensitivity of 86.21% and a specificity of 90.61% in distinguishing MD patients from HC. We identified several EEG microstate characteristics in MD patients that facilitate postural control yet exacerbate subjective symptoms, and effectively discriminate MD from HC. The microstate features may offer a new approach for optimizing cognitive compensation strategies and exploring potential neurobiological markers in MD.",https://pubmed.ncbi.nlm.nih.gov/39107944/,https://pubmed.ncbi.nlm.nih.gov/39107944/,English,Include,,Electroencephalography microstate alterations reflect potential double-edged cognitive adaptation in Ménière's disease.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39106199,pubmed:39106199,PubMed,pubmed:39106199,Neural Decoding of Spontaneous Overt and Intended Speech.,Debadatta Dash;Paul Ferrari;Jun Wang,2024,10.11989/jest.1674-862x.80904120,"The aim of this study was to decode intended and overt speech from neuromagnetic signals while the participants performed spontaneous overt speech tasks without cues or prompts (stimuli). Magnetoencephalography (MEG), a noninvasive neuroimaging technique, was used to collect neural signals from seven healthy adult English speakers performing spontaneous, overt speech tasks. The participants randomly spoke the words yes or no at a self-paced rate without cues. Two machine learning models, namely, linear discriminant analysis (LDA) and one-dimensional convolutional neural network (1D CNN), were employed to classify the two words from the recorded MEG signals. LDA and 1D CNN achieved average decoding accuracies of 79.02% and 90.40%, respectively, in decoding overt speech, significantly surpassing the chance level (50%). The accuracy for decoding intended speech was 67.19% using 1D CNN. This study showcases the possibility of decoding spontaneous overt and intended speech directly from neural signals in the absence of perceptual interference. We believe that these findings make a steady step toward the future spontaneous speech-based brain-computer interface.",https://pubmed.ncbi.nlm.nih.gov/39106199/,https://pubmed.ncbi.nlm.nih.gov/39106199/,English,Include,,Neural Decoding of Spontaneous Overt and Intended Speech.,Include,,"s from the recorded MEG signals. LDA and 1D CNN achieved average decoding accuracies of 79.02% and 90.40%, respectively, in decoding overt speech, significantly surpassing the chance level (50%). The accuracy for decoding intended speech was 67.19% using 1D CNN. This study showcases the possibility of decoding spontaneous overt and intended speech directly from neural signals in the absence of per",,0.95,0.8,small_sample_mentioned
pubmed:39106143,pubmed:39106143,PubMed,pubmed:39106143,Combination of Channel Reordering Strategy and Dual CNN-LSTM for Epileptic Seizure Prediction Using Three iEEG Datasets.,Xiaoshuang Wang;Ziheng Gao;Meiyan Zhang;Ying Wang;Lin Yang;Jianwen Lin;Tommi Karkkainen;Fengyu Cong,2024,10.1109/jbhi.2024.3438829,"Intracranial electroencephalogram (iEEG) signals are generally recorded using multiple channels, and channel selection is therefore a significant means in studying iEEG-based seizure prediction. For n channels, [Formula: see text] channel cases can be generated for selection. However, by this means, an increase in n can cause an exponential increase in computational consumption, which may result in a failure of channel selection when n is too large. Hence, it is necessary to explore reasonable channel selection strategies under the premise of controlling computational consumption and ensuring high classification accuracy. Given this, we propose a novel method of channel reordering strategy combined with dual CNN-LSTM for effectively predicting seizures. First, for each patient with n channels, interictal and preictal iEEG samples from each single channel are input into the CNN-LSTM model for classification. Then, the F1-score of each single channel is calculated, and the channels are reordered in descending order according to the size of F1-scores (channel reordering strategy). Next, iEEG signals with an increasing number of channels are successively fed into the CNN-LSTM model for classification again. Finally, according to the classification results from n channel cases, the channel case with the highest classification rate is selected. Our method is evaluated on the three iEEG datasets: the Freiburg, the SWEC-ETHZ and the American Epilepsy Society Seizure Prediction Challenge (AES-SPC). At the event-based level, the sensitivities of 100%, 100% and 90.5%, and the false prediction rates (FPRs) of 0.10/h, 0/h and 0.47/h, are achieved for the three datasets, respectively. Moreover, compared to an unspecific random predictor, our method also shows a better performance for all patients and dogs from the three datasets. At the segment-based level, the sensitivities-specificities-accuracies-AUCs of 88.1%-94.0%-93.5%-0.9101, 99.1%-99.7%-99.6%-0.9935, and 69.2%-79.9%-78.2%-0.7373, are attained for the three datasets, respectively. Our method can effectively predict seizures and address the challenge of an excessive number of channels during channel selection.",https://pubmed.ncbi.nlm.nih.gov/39106143/,https://pubmed.ncbi.nlm.nih.gov/39106143/,English,Include,,Combination of Channel Reordering Strategy and Dual CNN-LSTM for Epileptic Seizure Prediction Using Three iEEG Datasets.,Include,,"el selection when n is too large. Hence, it is necessary to explore reasonable channel selection strategies under the premise of controlling computational consumption and ensuring high classification accuracy. Given this, we propose a novel method of channel reordering strategy combined with dual CNN-LSTM for effectively predicting seizures. First, for each patient with n channels, interictal and ",,0.95,0.6,
pubmed:39104699,pubmed:39104699,PubMed,pubmed:39104699,Deep learning networks based decision fusion model of EEG and fNIRS for classification of cognitive tasks.,Md Hasin Raihan Rabbani;Sheikh Md Rabiul Islam,2024,10.3390/s23041932,"The detection of the cognitive tasks performed by a subject during data acquisition of a neuroimaging method has a wide range of applications: functioning of brain-computer interface (BCI), detection of neuronal disorders, neurorehabilitation for disabled patients, and many others. Recent studies show that the combination or fusion of electroencephalography (EEG) and functional near-infrared spectroscopy (fNIRS) demonstrates improved classification and detection performance compared to sole-EEG and sole-fNIRS. Deep learning (DL) networks are suitable for the classification of large volume time-series data like EEG and fNIRS. This study performs the decision fusion of EEG and fNIRS. The classification of EEG, fNIRS, and decision-fused EEG-fNIRSinto cognitive task labels is performed by DL networks. Two different open-source datasets of simultaneously recorded EEG and fNIRS are examined in this study. Dataset 01 is comprised of 26 subjects performing 3 cognitive tasks: n-back, discrimination or selection response (DSR), and word generation (WG). After data acquisition, fNIRS is converted to oxygenated hemoglobin (HbO",https://pubmed.ncbi.nlm.nih.gov/39104699/,https://pubmed.ncbi.nlm.nih.gov/39104699/,English,Include,,Deep learning networks based decision fusion model of EEG and fNIRS for classification of cognitive tasks.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39104696,pubmed:39104696,PubMed,pubmed:39104696,Channel attention convolutional aggregation network based on video-level features for EEG emotion recognition.,Xin Feng;Ping Cong;Lin Dong;Yongxian Xin;Fengbo Miao;Ruihao Xin,2024,10.1109/taffc.2020.2994159,"Electroencephalogram (EEG) emotion recognition plays a vital role in affective computing. A limitation of the EEG emotion recognition task is that the features of multiple domains are rarely included in the analysis simultaneously because of the lack of an effective feature organization form. This paper proposes a video-level feature organization method to effectively organize the temporal, frequency and spatial domain features. In addition, a deep neural network, Channel Attention Convolutional Aggregation Network, is designed to explore deeper emotional information from video-level features. The network uses a channel attention mechanism to adaptively captures critical EEG frequency bands. Then the frame-level representation of each time point is obtained by multi-layer convolution. Finally, the frame-level features are aggregated through NeXtVLAD to learn the time-sequence-related features. The method proposed in this paper achieves the best classification performance in SEED and DEAP datasets. The mean accuracy and standard deviation of the SEED dataset are 95.80% and 2.04%. In the DEAP dataset, the average accuracy with the standard deviation of arousal and valence are 98.97% ± 1.13% and 98.98% ± 0.98%, respectively. The experimental results show that our approach based on video-level features is effective for EEG emotion recognition tasks.",https://pubmed.ncbi.nlm.nih.gov/39104696/,https://pubmed.ncbi.nlm.nih.gov/39104696/,English,Include,,Channel attention convolutional aggregation network based on video-level features for EEG emotion recognition.,Include,,"eatures are aggregated through NeXtVLAD to learn the time-sequence-related features. The method proposed in this paper achieves the best classification performance in SEED and DEAP datasets. The mean accuracy and standard deviation of the SEED dataset are 95.80% and 2.04%. In the DEAP dataset, the average accuracy with the standard deviation of arousal and valence are 98.97% ± 1.13% and 98.98% ± 0",,0.95,0.6,
pubmed:39104684,pubmed:39104684,PubMed,pubmed:39104684,ADHD/CD-NET: automated EEG-based characterization of ADHD and CD using explainable deep neural network technique.,Hui Wen Loh;Chui Ping Ooi;Shu Lih Oh;Prabal Datta Barua;Yi Ren Tan;U Rajendra Acharya;Daniel Shuen Sheng Fung,2024,10.1155/2022/5222136,"In this study, attention deficit hyperactivity disorder (ADHD), a childhood neurodevelopmental disorder, is being studied alongside its comorbidity, conduct disorder (CD), a behavioral disorder. Because ADHD and CD share commonalities, distinguishing them is difficult, thus increasing the risk of misdiagnosis. It is crucial that these two conditions are not mistakenly identified as the same because the treatment plan varies depending on whether the patient has CD or ADHD. Hence, this study proposes an electroencephalogram (EEG)-based deep learning system known as ADHD/CD-NET that is capable of objectively distinguishing ADHD, ADHD + CD, and CD. The 12-channel EEG signals were first segmented and converted into channel-wise continuous wavelet transform (CWT) correlation matrices. The resulting matrices were then used to train the convolutional neural network (CNN) model, and the model's performance was evaluated using 10-fold cross-validation. Gradient-weighted class activation mapping (Grad-CAM) was also used to provide explanations for the prediction result made by the 'black box' CNN model. Internal private dataset (45 ADHD, 62 ADHD + CD and 16 CD) and external public dataset (61 ADHD and 60 healthy controls) were used to evaluate ADHD/CD-NET. As a result, ADHD/CD-NET achieved classification accuracy, sensitivity, specificity, and precision of 93.70%, 90.83%, 95.35% and 91.85% for the internal evaluation, and 98.19%, 98.36%, 98.03% and 98.06% for the external evaluation. Grad-CAM also identified significant channels that contributed to the diagnosis outcome. Therefore, ADHD/CD-NET can perform temporal localization and choose significant EEG channels for diagnosis, thus providing objective analysis for mental health professionals and clinicians to consider when making a diagnosis. The online version contains supplementary material available at 10.1007/s11571-023-10028-2.",https://pubmed.ncbi.nlm.nih.gov/39104684/,https://pubmed.ncbi.nlm.nih.gov/39104684/,English,Include,,ADHD/CD-NET: automated EEG-based characterization of ADHD and CD using explainable deep neural network technique.,Include,,"nal private dataset (45 ADHD, 62 ADHD + CD and 16 CD) and external public dataset (61 ADHD and 60 healthy controls) were used to evaluate ADHD/CD-NET. As a result, ADHD/CD-NET achieved classification accuracy, sensitivity, specificity, and precision of 93.70%, 90.83%, 95.35% and 91.85% for the internal evaluation, and 98.19%, 98.36%, 98.03% and 98.06% for the external evaluation. Grad-CAM also ide",,0.95,0.25,cv_reported
pubmed:39104682,pubmed:39104682,PubMed,pubmed:39104682,EEGNet classification of sleep EEG for individual specialization based on data augmentation.,Mo Xia;Xuyang Zhao;Rui Deng;Zheng Lu;Jianting Cao,2024,10.1007/s11571-022-09857-4,"Sleep is an essential part of human life, and the quality of one's sleep is also an important indicator of one's health. Analyzing the Electroencephalogram (EEG) signals of a person during sleep makes it possible to understand the sleep status and give relevant rest or medical advice. In this paper, a decent amount of artificial data generated with a data augmentation method based on Discrete Cosine Transform from a small amount of real experimental data of a specific individual is introduced. A classification model with an accuracy of 92.85% has been obtained. By mixing the data augmentation with the public database and training with the EEGNet, we obtained a classification model with significantly higher accuracy for the specific individual. The experiments have demonstrated that we can circumvent the subject-independent problem in sleep EEG in this way and use only a small amount of labeled data to customize a dedicated classification model with high accuracy.",https://pubmed.ncbi.nlm.nih.gov/39104682/,https://pubmed.ncbi.nlm.nih.gov/39104682/,English,Include,,EEGNet classification of sleep EEG for individual specialization based on data augmentation.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39104678,pubmed:39104678,PubMed,pubmed:39104678,An EEG-based marker of functional connectivity: detection of major depressive disorder.,Ling Li;Xianshuo Wang;Jiahui Li;Yanping Zhao,2024,10.3389/fnins.2018.01037,"Major depressive disorder (MDD) is a prevalent psychiatric disorder globally. There are many assays for MDD, but rapid and reliable detection remains a pressing challenge. In this study, we present a fusion feature called P-MSWC, as a novel marker to construct brain functional connectivity matrices and utilize the convolutional neural network (CNN) to identify MDD based on electroencephalogram (EEG) signal. Firstly, we combine synchrosqueezed wavelet transform and coherence theory to get synchrosqueezed wavelet coherence. Then, we obtain the fusion feature by incorporating synchrosqueezed wavelet coherence value and phase-locking value, which outperforms conventional functional connectivity markers by comprehensively capturing the original EEG signal's information and demonstrating notable noise-resistance capabilities. Finally, we propose a lightweight CNN model that effectively utilizes the high-dimensional connectivity matrix of the brain, constructed using our novel marker, to enable more accurate and efficient detection of MDD. The proposed method achieves 99.92% accuracy on a single dataset and 97.86% accuracy on a combined dataset. Moreover, comparison experiments have shown that the performance of the proposed method is superior to traditional machine learning methods. Furthermore, visualization experiments reveal differences in the distribution of brain connectivity between MDD patients and healthy subjects, including decreased connectivity in the T7, O1, F8, and C3 channels of the gamma band. The results of the experiments indicate that the fusion feature can be utilized as a new marker for constructing functional brain connectivity, and the combination of deep learning and functional connectivity matrices can provide more help for the detection of MDD.",https://pubmed.ncbi.nlm.nih.gov/39104678/,https://pubmed.ncbi.nlm.nih.gov/39104678/,English,Include,,An EEG-based marker of functional connectivity: detection of major depressive disorder.,Include,,"ctively utilizes the high-dimensional connectivity matrix of the brain, constructed using our novel marker, to enable more accurate and efficient detection of MDD. The proposed method achieves 99.92% accuracy on a single dataset and 97.86% accuracy on a combined dataset. Moreover, comparison experiments have shown that the performance of the proposed method is superior to traditional machine learn",,0.95,0.6,
pubmed:39104677,pubmed:39104677,PubMed,pubmed:39104677,A delayed matching task-based study on action sequence of motor imagery.,Mengfan Li;Enming Qi;Guizhi Xu;Jing Jin;Qi Zhao;Miaomiao Guo;Wenzhe Liao,2024,10.1007/s11571-019-09560-x,"The way people imagine greatly affects performance of brain-computer interface (BCI) based on motion imagery (MI). Action sequence is a basic unit of imitation, learning, and memory for motor behavior. Whether it influences the MI-BCI is unknown, and how to manifest this influence is difficult since the MI is a spontaneous brain activity. To investigate the influence of the action sequence, this study proposes a novel paradigm named action sequences observing and delayed matching task to use images and videos to guide people to observe, match and reinforce the memory of sequence. Seven subjects' ERPs and MI performance are analyzed under four different levels of complexities or orders of the sequence. Results demonstrated that the action sequence in terms of complexity and sequence order significantly affects the MI. The complex action in positive order obtains stronger ERD/ERS and more pronounced MI feature distributions, and yields an MI classification accuracy that is 12.3% higher than complex action in negative order (",https://pubmed.ncbi.nlm.nih.gov/39104677/,https://pubmed.ncbi.nlm.nih.gov/39104677/,English,Include,,A delayed matching task-based study on action sequence of motor imagery.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39103539,pubmed:39103539,PubMed,pubmed:39103539,Critical dynamics in spontaneous EEG predict anesthetic-induced loss of consciousness and perturbational complexity.,Charlotte Maschke;Jordan O'Byrne;Michele Angelo Colombo;Melanie Boly;Olivia Gosseries;Steven Laureys;Mario Rosanova;Karim Jerbi;Stefanie Blain-Moraes,2024,10.1111/ejn.15800,"Consciousness has been proposed to be supported by electrophysiological patterns poised at criticality, a dynamical regime which exhibits adaptive computational properties, maximally complex patterns and divergent sensitivity to perturbation. Here, we investigate dynamical properties of the resting-state electroencephalogram (EEG) of healthy subjects undergoing general anesthesia with propofol, xenon or ketamine. Importantly, all participants were unresponsive under anesthesia, while consciousness was retained only during ketamine anesthesia (in the form of vivid dreams), enabling an experimental dissociation between unresponsiveness and unconsciousness. For each condition, we measure (i) avalanche criticality, (ii) chaoticity, and (iii) criticality-related metrics, revealing that states of unconsciousness are characterized by a distancing from both avalanche criticality and the edge of chaos. We then ask whether these same dynamical properties are predictive of the perturbational complexity index (PCI), a TMS-based measure that has shown remarkably high sensitivity in detecting consciousness independently of behavior. We successfully predict individual subjects' PCI values with considerably high accuracy from resting-state EEG dynamical properties alone. Our results establish a firm link between perturbational complexity and criticality, and provide further evidence that criticality is a necessary condition for the emergence of consciousness.",https://pubmed.ncbi.nlm.nih.gov/39103539/,https://pubmed.ncbi.nlm.nih.gov/39103539/,English,Include,,Critical dynamics in spontaneous EEG predict anesthetic-induced loss of consciousness and perturbational complexity.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39103399,pubmed:39103399,PubMed,pubmed:39103399,A Multimodal Dataset for Mixed Emotion Recognition.,Pei Yang;Niqi Liu;Xinge Liu;Yezhi Shu;Wenqi Ji;Ziqi Ren;Jenny Sheng;Minjing Yu;Ran Yi;Dan Zhang;Yong-Jin Liu,2024,10.1371/journal.pone.0086041,"Mixed emotions have attracted increasing interest recently, but existing datasets rarely focus on mixed emotion recognition from multimodal signals, hindering the affective computing of mixed emotions. On this basis, we present a multimodal dataset with four kinds of signals recorded while watching mixed and non-mixed emotion videos. To ensure effective emotion induction, we first implemented a rule-based video filtering step to select the videos that could elicit stronger positive, negative, and mixed emotions. Then, an experiment with 80 participants was conducted, in which the data of EEG, GSR, PPG, and frontal face videos were recorded while they watched the selected video clips. We also recorded the subjective emotional rating on PANAS, VAD, and amusement-disgust dimensions. In total, the dataset consists of multimodal signal data and self-assessment data from 73 participants. We also present technical validations for emotion induction and mixed emotion classification from physiological signals and face videos. The average accuracy of the 3-class classification (i.e., positive, negative, and mixed) can reach 80.96% when using SVM and features from all modalities, which indicates the possibility of identifying mixed emotional states.",https://pubmed.ncbi.nlm.nih.gov/39103399/,https://pubmed.ncbi.nlm.nih.gov/39103399/,English,Include,,A Multimodal Dataset for Mixed Emotion Recognition.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39103043,pubmed:39103043,PubMed,pubmed:39103043,EEG-VTTCNet: A loss joint training model based on the vision transformer and the temporal convolution network for EEG-based motor imagery classification.,Xingbin Shi;Baojiang Li;Wenlong Wang;Yuxin Qin;Haiyan Wang;Xichao Wang,2024,10.1016/j.neuroscience.2024.07.051,"Brain-computer interface (BCI) is a technology that directly connects signals between the human brain and a computer or other external device. Motor imagery electroencephalographic (MI-EEG) signals are considered a promising paradigm for BCI systems, with a wide range of potential applications in medical rehabilitation, human-computer interaction, and virtual reality. Accurate decoding of MI-EEG signals poses a significant challenge due to issues related to the quality of the collected EEG data and subject variability. Therefore, developing an efficient MI-EEG decoding network is crucial and warrants research. This paper proposes a loss joint training model based on the vision transformer (VIT) and the temporal convolutional network (EEG-VTTCNet) to classify MI-EEG signals. To take advantage of multiple modules together, the EEG-VTTCNet adopts a shared convolution strategy and a dual-branching strategy. The dual-branching modules perform complementary learning and jointly train shared convolutional modules with better performance. We conducted experiments on the BCI Competition IV-2a and IV-2b datasets, and the proposed network outperformed the current state-of-the-art techniques with an accuracy of 84.58% and 90.94%, respectively, for the subject-dependent mode. In addition, we used t-SNE to visualize the features extracted by the proposed network, further demonstrating the effectiveness of the feature extraction framework. We also conducted extensive ablation and hyperparameter tuning experiments to construct a robust network architecture that can be well generalized.",https://pubmed.ncbi.nlm.nih.gov/39103043/,https://pubmed.ncbi.nlm.nih.gov/39103043/,English,Include,,EEG-VTTCNet: A loss joint training model based on the vision transformer and the temporal convolution network for EEG-based motor imagery classification.,Include,,"tional modules with better performance. We conducted experiments on the BCI Competition IV-2a and IV-2b datasets, and the proposed network outperformed the current state-of-the-art techniques with an accuracy of 84.58% and 90.94%, respectively, for the subject-dependent mode. In addition, we used t-SNE to visualize the features extracted by the proposed network, further demonstrating the effective",,0.95,0.6,
pubmed:39102943,pubmed:39102943,PubMed,pubmed:39102943,A data augmentation procedure to improve detection of spike ripples in brain voltage recordings.,Emily D Schlafly;Daniel Carbonero;Catherine J Chu;Mark A Kramer,2025,10.3389/fncom.2019.00006,"Epilepsy is a major neurological disorder characterized by recurrent, spontaneous seizures. For patients with drug-resistant epilepsy, treatments include neurostimulation or surgical removal of the epileptogenic zone (EZ), the brain region responsible for seizure generation. Precise targeting of the EZ requires reliable biomarkers. Spike ripples - high-frequency oscillations that co-occur with large amplitude epileptic discharges - have gained prominence as a candidate biomarker. However, spike ripple detection remains a challenge. The gold-standard approach requires an expert manually visualize and interpret brain voltage recordings, which limits reproducibility and high-throughput analysis. Addressing these limitations requires more objective, efficient, and automated methods for spike ripple detection, including approaches that utilize deep neural networks. Despite advancements, dataset heterogeneity and scarcity severely limit machine learning performance. Our study explores long-short term memory (LSTM) neural network architectures for spike ripple detection, leveraging data augmentation to improve classifier performance. We highlight the potential of combining training on augmented and in vivo data for enhanced spike ripple detection and ultimately improving diagnostic accuracy in epilepsy treatment.",,https://pubmed.ncbi.nlm.nih.gov/39102943/,English,Exclude,Outside date range,A data augmentation procedure to improve detection of spike ripples in brain voltage recordings.,,,,,0.95,0.6,
pubmed:39102329,pubmed:39102329,PubMed,pubmed:39102329,Multiband Convolutional Riemannian Network With Band-Wise Riemannian Triplet Loss for Motor Imagery Classification.,Jinhyo Shin;Wonzoo Chung,2024,10.1109/jbhi.2024.3438167,"This paper presents a novel motor imagery classification algorithm that uses an overlapping multiscale multiband convolutional Riemannian network with band-wise Riemannian triplet loss to improve classification performance. Despite the superior performance of the Riemannian approach over the common spatial pattern filter approach, deep learning methods that generalize the Riemannian approach have received less attention. The proposed algorithm develops a state-of-the-art multiband Riemannian network that reduces the potential overfitting problem of Riemannian networks, a drawback of Riemannian networks due to their inherent large feature dimension from covariance matrix, by using fewer subbands with discriminative frequency diversity, by inserting convolutional layers before computing the subband covariance matrix, and by regularizing subband networks with Riemannian triplet loss. The proposed method is evaluated using the publicly available datasets, the BCI Competition IV dataset 2a and the OpenBMI dataset. The experimental results confirm that the proposed method improves performance, in particular achieving state-of-the-art classification accuracy among the currently studied Riemannian networks.",https://pubmed.ncbi.nlm.nih.gov/39102329/,https://pubmed.ncbi.nlm.nih.gov/39102329/,English,Include,,Multiband Convolutional Riemannian Network With Band-Wise Riemannian Triplet Loss for Motor Imagery Classification.,Include,,"ets, the BCI Competition IV dataset 2a and the OpenBMI dataset. The experimental results confirm that the proposed method improves performance, in particular achieving state-of-the-art classification accuracy among the currently studied Riemannian networks.",,0.95,0.8,overfit_terms_found
pubmed:39102324,pubmed:39102324,PubMed,pubmed:39102324,Stimulus Inversion and Emotional Expressions Independently Affect Face and Body Perception: An ERP Study.,Francesco Bossi;Paola Ricciardelli;Davide Rivolta,2024,10.1109/tnsre.2024.3439129,"Faces and bodies provide critical cues for social interaction and communication. Their structural encoding depends on configural processing, as suggested by the detrimental effect of stimulus inversion for both faces (i.e., face inversion effect - FIE) and bodies (body inversion effect - BIE). An occipito-temporal negative event-related potential (ERP) component peaking around 170 ms after stimulus onset (N170) is consistently elicited by human faces and bodies and is affected by the inversion of these stimuli. Albeit it is known that emotional expressions can boost structural encoding (resulting in larger N170 components for emotional than for neutral faces), little is known about body emotional expressions. Thus, the current study investigated the effects of different emotional expressions on structural encoding in combination with FIE and BIE. Three ERP components (P1, N170, P2) were recorded using a 128-channel electroencephalogram (EEG) when participants were presented with (upright and inverted) faces and bodies conveying four possible emotions (happiness, sadness, anger, fear) or no emotion (neutral). Results demonstrated that inversion and emotional expressions independently affected the Accuracy and amplitude of all ERP components (P1, N170, P2). In particular, faces showed specific effects of emotional expressions during the structural encoding stage (N170), while P2 amplitude (representing top-down conceptualisation) was modified by emotional body perception. Moreover, the task performed by participants (i.e., implicit vs. explicit processing of emotional information) differently influenced Accuracy and ERP components. These results support integrated theories of visual perception, thus speaking in favour of the functional independence of the two neurocognitive pathways (one for structural encoding and one for emotional expression analysis) involved in social stimuli processing. Results are discussed highlighting the neurocognitive and computational advantages of the independence between the two pathways.",https://pubmed.ncbi.nlm.nih.gov/39102324/,https://pubmed.ncbi.nlm.nih.gov/39102324/,English,Include,,Stimulus Inversion and Emotional Expressions Independently Affect Face and Body Perception: An ERP Study.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39102323,pubmed:39102323,PubMed,pubmed:39102323,Toward Interpretable Sleep Stage Classification Using Cross-Modal Transformers.,Jathurshan Pradeepkumar;Mithunjha Anandakumar;Vinith Kugathasan;Dhinesh Suntharalingham;Simon L Kappel;Anjula C De Silva;Chamira U S Edussooriya,2024,10.1109/tnsre.2024.3438610,"Accurate sleep stage classification is significant for sleep health assessment. In recent years, several machine-learning based sleep staging algorithms have been developed, and in particular, deep-learning based algorithms have achieved performance on par with human annotation. Despite improved performance, a limitation of most deep-learning based algorithms is their black-box behavior, which have limited their use in clinical settings. Here, we propose a cross-modal transformer, which is a transformer-based method for sleep stage classification. The proposed cross-modal transformer consists of a cross-modal transformer encoder architecture along with a multi-scale one-dimensional convolutional neural network for automatic representation learning. The performance of our method is on-par with the state-of-the-art methods and eliminates the black-box behavior of deep-learning models by utilizing the interpretability aspect of the attention modules. Furthermore, our method provides considerable reductions in the number of parameters and training time compared to the state-of-the-art methods. Our code is available at https://github.com/Jathurshan0330/Cross-Modal-Transformer. A demo of our work can be found at https://bit.ly/Cross_modal_transformer_demo.",,https://pubmed.ncbi.nlm.nih.gov/39102323/,English,Exclude,Not EEG-BCI focused,Toward Interpretable Sleep Stage Classification Using Cross-Modal Transformers.,,,,,0.9,0.6,
pubmed:39102321,pubmed:39102321,PubMed,pubmed:39102321,Visual Feedback Gain Modulates the Activation of Task-Related Networks and the Suppression of Non-Task Networks During Precise Grasping.,Zhixian Gao;Shiyang Lv;Xiangying Ran;Mengsheng Xia;Mengyue Qiu;Junming Wang;Yinping Wei;Zhenpeng Shao;Xuezhi Zhou;Yehong Zhang;Zongya Zhao;Yi Yu,2024,10.1109/tnsre.2024.3438674,"Visual feedback gain is a crucial factor influencing the performance of precision grasping tasks, involving multiple brain regions of the visual motor system during task execution. However, the dynamic changes in brain network during this process remain unclear. The aim of this study is to investigate the impact of changes in visual feedback gain during precision grasping on brain network dynamics. Sixteen participants performed precision grip tasks at 15% of MVC under low (0.1°), medium (1°), and high (3°) visual feedback gain conditions, with simultaneous recording of EEG and right-hand precision grip data during the tasks. Utilizing electroencephalogram (EEG) microstate analysis, multiple parameters (Duration, Occurrence, Coverage, Transition probability(TP)) were extracted to assess changes in brain network dynamics. Precision grip accuracy and stability were evaluated using root mean square error(RMSE) and coefficient of variation(CV) of grip force. Compared to low visual feedback gain, under medium/high gain, the Duration, Occurrence, and Coverage of microstates B and D increase, while those of microstates A and C decrease. The Transition probability from microstates A, C, and D to B all increase. Additionally, RMSE and CV of grip force decrease. Occurrence and Coverage of microstates B and C are negatively correlated with RMSE and CV. These findings suggest that visual feedback gain affects the brain network dynamics during precision grasping; moderate increase in visual feedback gain can enhance the accuracy and stability of grip force, whereby the increased Occurrence and Coverage of microstates B and C contribute to improved performance in precision grasping. Our results play a crucial role in better understanding the impact of visual feedback gain on the motor control of precision grasping.",https://pubmed.ncbi.nlm.nih.gov/39102321/,https://pubmed.ncbi.nlm.nih.gov/39102321/,English,Include,,Visual Feedback Gain Modulates the Activation of Task-Related Networks and the Suppression of Non-Task Networks During Precise Grasping.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39101832,pubmed:39101832,PubMed,pubmed:39101832,Exploring role of prefrontal cortex region of brain in children having ADHD with machine learning: Implications and insights.,Manjusha Pradeep Deshmukh;Mahi Khemchandani;Paramjit Mahesh Thakur,2024,10.1080/21622965.2024.2378464,"Attention deficit hyperactivity disorder (ADHD), is a general neurodevelopmental syndrome. This affects both adults and children, causing issues like hyperactivity, inattention, and impulsivity. Diagnosis, typically reliant on patient narratives and questionnaires, can sometimes be inaccurate, leading to distress. We propose utilizing empirical mode decomposition (EMD) for feature extraction and a machine learning (ML) algorithm to categorize ADHD and control. Publicly available Kaggle dataset is used for research. The EMD technique decomposes an electroencephalogram (EEG) waveform to 12 intrinsic mode functions (IMFs). Thirty-one statistical parameters are generated over the first 6 IMFs to create an input feature vector for the deep belief network (DBN) classifier. Principal component analysis (PCA) is utilized to reduce dimension. Experimental results are compared on prefrontal cortex channels Fp1 and Fp2. After an in-depth evaluation of all metrics, it is observed that, in patients with ADHD, the prefrontal cortex regulates attention, behavior, and emotion. Our findings align with established neuroscience. The critical functions of the brain, such as organization, planning, attention, and decision making, are performed by the frontal lobe. Our work provides a novel approach to understanding the disorder's underlying neurobiological mechanisms. It has the potential to deepen our understanding of the condition, improve diagnostic accuracy, personalize treatment methods, and, ultimately, improve outcomes for those affected.",https://pubmed.ncbi.nlm.nih.gov/39101832/,https://pubmed.ncbi.nlm.nih.gov/39101832/,English,Include,,Exploring role of prefrontal cortex region of brain in children having ADHD with machine learning: Implications and insights.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39100745,pubmed:39100745,PubMed,pubmed:39100745,Tensor Methods in Biomedical Image Analysis.,Farnaz Sedighin,2024,10.4103/jmss.jmss_55_23,"In the past decade, tensors have become increasingly attractive in different aspects of signal and image processing areas. The main reason is the inefficiency of matrices in representing and analyzing multimodal and multidimensional datasets. Matrices cannot preserve the multidimensional correlation of elements in higher-order datasets and this highly reduces the effectiveness of matrix-based approaches in analyzing multidimensional datasets. Besides this, tensor-based approaches have demonstrated promising performances. These together, encouraged researchers to move from matrices to tensors. Among different signal and image processing applications, analyzing biomedical signals and images is of particular importance. This is due to the need for extracting accurate information from biomedical datasets which directly affects patient's health. In addition, in many cases, several datasets have been recorded simultaneously from a patient. A common example is recording electroencephalography (EEG) and functional magnetic resonance imaging (fMRI) of a patient with schizophrenia. In such a situation, tensors seem to be among the most effective methods for the simultaneous exploitation of two (or more) datasets. Therefore, several tensor-based methods have been developed for analyzing biomedical datasets. Considering this reality, in this paper, we aim to have a comprehensive review on tensor-based methods in biomedical image analysis. The presented study and classification between different methods and applications can show the importance of tensors in biomedical image enhancement and open new ways for future studies.",,https://pubmed.ncbi.nlm.nih.gov/39100745/,English,Exclude,Review/survey papers,Tensor Methods in Biomedical Image Analysis.,,,,,0.95,0.6,
pubmed:39100116,pubmed:39100116,PubMed,pubmed:39100116,Default mode network aberrance in subjects of alcohol and opioid use disorders during working memory task: An exploratory EEG microstates study.,Shaon Ghosh Dastidar;Chaithanya Leon;Nishi Pegwal;Yatan Pal Singh Balhara;M Suriya Prakash;Prashant Tayade;Ratna Sharma;Simran Kaur,2024,10.4103/indianjpsychiatry.indianjpsychiatry_930_23,"Aberrance in switching from default mode network (DMN) to fronto-parietal network (FPN) is proposed to underlie working memory deficits in subjects with substance use disorders, which can be studied using neuro-imaging techniques during cognitive tasks. The current study used EEG to investigate pre-stimulus microstates during the performance of Sternberg's working memory task in subjects with substance use disorders. 128-channel EEG was acquired and processed in ten age and gender-matched subjects, each with alcohol use disorder, opioid use disorder, and controls while they performed Sternberg's task. Behavioral parameters, pre-stimulus EEG microstate, and underlying sources were analyzed and compared between subjects with substance use disorders and controls. Both alcohol and opioid use disorder subjects had significantly lower accuracy ( Reduced mean durations in Map 3 and 2 in subjects of alcohol and opioid use disorder can underlie their poorer performance in Sternberg's task. Furthermore, cortical sources revealed higher activity in both groups of substance use disorders in the parahippocampal gyrus- a hub of DMN; superior and middle temporal gyri associated with impulsivity; and insula that maintains balance between executive reflective system and impulsive system. EEG microstates can be used to envisage neural underpinnings implicated for working memory deficits in subjects of alcohol and opioid use disorders, reflected by aberrant switching between neural networks and information processing mechanisms.",https://pubmed.ncbi.nlm.nih.gov/39100116/,https://pubmed.ncbi.nlm.nih.gov/39100116/,English,Include,,Default mode network aberrance in subjects of alcohol and opioid use disorders during working memory task: An exploratory EEG microstates study.,Include,,"lus EEG microstate, and underlying sources were analyzed and compared between subjects with substance use disorders and controls. Both alcohol and opioid use disorder subjects had significantly lower accuracy ( Reduced mean durations in Map 3 and 2 in subjects of alcohol and opioid use disorder can underlie their poorer performance in Sternberg's task. Furthermore, cortical sources revealed higher",,0.95,0.6,
pubmed:39099770,pubmed:39099770,PubMed,pubmed:39099770,EEG-based emotion recognition using graph convolutional neural network with dual attention mechanism.,Wei Chen;Yuan Liao;Rui Dai;Yuanlin Dong;Liya Huang,2024,10.1109/access.2020.2993876,"EEG-based emotion recognition is becoming crucial in brain-computer interfaces (BCI). Currently, most researches focus on improving accuracy, while neglecting further research on the interpretability of models, we are committed to analyzing the impact of different brain regions and signal frequency bands on emotion generation based on graph structure. Therefore, this paper proposes a method named Dual Attention Mechanism Graph Convolutional Neural Network (DAMGCN). Specifically, we utilize graph convolutional neural networks to model the brain network as a graph to extract representative spatial features. Furthermore, we employ the self-attention mechanism of the Transformer model which allocates more electrode channel weights and signal frequency band weights to important brain regions and frequency bands. The visualization of attention mechanism clearly demonstrates the weight allocation learned by DAMGCN. During the performance evaluation of our model on the DEAP, SEED, and SEED-IV datasets, we achieved the best results on the SEED dataset, showing subject-dependent experiments' accuracy of 99.42% and subject-independent experiments' accuracy of 73.21%. The results are demonstrably superior to the accuracies of most existing models in the realm of EEG-based emotion recognition.",https://pubmed.ncbi.nlm.nih.gov/39099770/,https://pubmed.ncbi.nlm.nih.gov/39099770/,English,Include,,EEG-based emotion recognition using graph convolutional neural network with dual attention mechanism.,Include,,"EEG-based emotion recognition is becoming crucial in brain-computer interfaces (BCI). Currently, most researches focus on improving accuracy, while neglecting further research on the interpretability of models, we are committed to analyzing the impact of different brain regions and signal frequency bands on emotion generation base",,0.95,0.6,
pubmed:39096822,pubmed:39096822,PubMed,pubmed:39096822,Neuroelectrophysiological alteration associated with cognitive flexibility after 24 h sleep deprivation in adolescents.,Xirui Zhang;Shuqing Feng;Xiaochen Yang;Yunwen Peng;Mei Du;Rui Zhang;Jiashan Sima;Feng Zou;Xin Wu;Yufeng Wang;Xiaomeng Gao;Yanyan Luo;Meng Zhang,2024,10.1016/j.concog.2024.103734,"The cognitive neural mechanisms by which sleep deprivation affects cognitive flexibility are poorly understood. Therefore, the study investigated the neuroelectrophysiological basis of the effect of 24 h sleep deprivation on cognitive flexibility in adolescents. 72 participants (36 females, mean age ± SD=20.46 ± 2.385 years old) participated in the study and were randomly assigned to the sleep deprivation group and control group. They were instructed to complete a task switch paradigm, during which participants' behavioral and electroencephalographic data were recorded. Behaviorally, there were significant between-group differences in accuracy. The results of event-related potential showed that the P2, N2 and P3 components had significant group effects or interaction effects. At the time-frequency level, there were statistically significant differences between the delta and theta bands. These results suggested that 24 h sleep deprivation affected problem-solving effectiveness rather than efficiency, mainly because it systematically impaired cognitive processing associated with cognitive flexibility.",,https://pubmed.ncbi.nlm.nih.gov/39096822/,English,Exclude,Not EEG-BCI focused,Neuroelectrophysiological alteration associated with cognitive flexibility after 24 h sleep deprivation in adolescents.,,,,,0.9,0.8,small_sample_mentioned
pubmed:39096751,pubmed:39096751,PubMed,pubmed:39096751,DGSD: Dynamical graph self-distillation for EEG-based auditory spatial attention detection.,Cunhang Fan;Hongyu Zhang;Wei Huang;Jun Xue;Jianhua Tao;Jiangyan Yi;Zhao Lv;Xiaopei Wu,2024,10.1016/j.neunet.2024.106580,"Auditory Attention Detection (AAD) aims to detect the target speaker from brain signals in a multi-speaker environment. Although EEG-based AAD methods have shown promising results in recent years, current approaches primarily rely on traditional convolutional neural networks designed for processing Euclidean data like images. This makes it challenging to handle EEG signals, which possess non-Euclidean characteristics. In order to address this problem, this paper proposes a dynamical graph self-distillation (DGSD) approach for AAD, which does not require speech stimuli as input. Specifically, to effectively represent the non-Euclidean properties of EEG signals, dynamical graph convolutional networks are applied to represent the graph structure of EEG signals, which can also extract crucial features related to auditory spatial attention in EEG signals. In addition, to further improve AAD detection performance, self-distillation, consisting of feature distillation and hierarchical distillation strategies at each layer, is integrated. These strategies leverage features and classification results from the deepest network layers to guide the learning of shallow layers. Our experiments are conducted on two publicly available datasets, KUL and DTU. Under a 1-second time window, we achieve results of 90.0% and 79.6% accuracy on KUL and DTU, respectively. We compare our DGSD method with competitive baselines, and the experimental results indicate that the detection performance of our proposed DGSD method is not only superior to the best reproducible baseline but also significantly reduces the number of trainable parameters by approximately 100 times.",https://pubmed.ncbi.nlm.nih.gov/39096751/,https://pubmed.ncbi.nlm.nih.gov/39096751/,English,Include,,DGSD: Dynamical graph self-distillation for EEG-based auditory spatial attention detection.,Include,,"work layers to guide the learning of shallow layers. Our experiments are conducted on two publicly available datasets, KUL and DTU. Under a 1-second time window, we achieve results of 90.0% and 79.6% accuracy on KUL and DTU, respectively. We compare our DGSD method with competitive baselines, and the experimental results indicate that the detection performance of our proposed DGSD method is not on",,0.95,0.6,
pubmed:39095608,pubmed:39095608,PubMed,pubmed:39095608,GRU-powered sleep stage classification with permutation-based EEG channel selection.,Luis Alfredo Moctezuma;Yoko Suzuki;Junya Furuki;Marta Molinas;Takashi Abe,2024,10.1111/opo.12131,"We present a new approach to classifying the sleep stage that incorporates a computationally inexpensive method based on permutations for channel selection and takes advantage of deep learning power, specifically the gated recurrent unit (GRU) model, along with other deep learning methods. By systematically permuting the electroencephalographic (EEG) channels, different combinations of EEG channels are evaluated to identify the most informative subset for the classification of the 5-class sleep stage. For analysis, we used an EEG dataset that was collected at the International Institute for Integrative Sleep Medicine (WPI-IIIS) at the University of Tsukuba in Japan. The results of these explorations provide many new insights such as the (1) drastic decrease in performance when channels are fewer than 3, (2) 3-random channels selected by permutation provide the same or better prediction than the 3 channels recommended by the American Academy of Sleep Medicine (AASM), (3) N1 class suffers the most in prediction accuracy as the channels drop from 128 to 3 random or 3 AASM, and (4) no single channel provides acceptable levels of accuracy in the prediction of 5 classes. The results obtained show the GRU's ability to retain essential temporal information from EEG data, which allows capturing the underlying patterns associated with each sleep stage effectively. Using permutation-based channel selection, we enhance or at least maintain as high model efficiency as when using high-density EEG, incorporating only the most informative EEG channels.",https://pubmed.ncbi.nlm.nih.gov/39095608/,https://pubmed.ncbi.nlm.nih.gov/39095608/,English,Include,,GRU-powered sleep stage classification with permutation-based EEG channel selection.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39095399,pubmed:39095399,PubMed,pubmed:39095399,Wireless ear EEG to monitor drowsiness.,Ryan Kaveh;Carolyn Schwendeman;Leslie Pu;Ana C Arias;Rikky Muller,2024,10.1016/j.clinph.2006.03.011,"Neural wearables can enable life-saving drowsiness and health monitoring for pilots and drivers. While existing in-cabin sensors may provide alerts, wearables can enable monitoring across more environments. Current neural wearables are promising but most require wet-electrodes and bulky electronics. This work showcases in-ear, dry-electrode earpieces used to monitor drowsiness with compact hardware. The employed system integrates additive-manufacturing for dry, user-generic earpieces, existing wireless electronics, and offline classification algorithms. Thirty-five hours of electrophysiological data were recorded across nine subjects performing drowsiness-inducing tasks. Three classifier models were trained with user-specific, leave-one-trial-out, and leave-one-user-out splits. The support-vector-machine classifier achieved an accuracy of 93.2% while evaluating users it has seen before and 93.3% when evaluating a never-before-seen user. These results demonstrate wireless, dry, user-generic earpieces used to classify drowsiness with comparable accuracies to existing state-of-the-art, wet electrode in-ear and scalp systems. Further, this work illustrates the feasibility of population-trained classification in future electrophysiological applications.",https://pubmed.ncbi.nlm.nih.gov/39095399/,https://pubmed.ncbi.nlm.nih.gov/39095399/,English,Include,,Wireless ear EEG to monitor drowsiness.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39094326,pubmed:39094326,PubMed,pubmed:39094326,Quantifying instability in neurological disorders EEG based on phase space DTM function.,Tianming Cai;Guoying Zhao;Junbin Zang;Chen Zong;Zhidong Zhang;Chenyang Xue,2024,10.1016/j.compbiomed.2024.108951,"Classifying individuals with neurological disorders and healthy subjects using EEG is a crucial area of research. The current feature extraction approach focuses on the frequency domain features in each of the EEG frequency bands and functional brain networks. In recent years, researchers have discovered and extensively studied stability differences in the electroencephalograms (EEG) of patients with neurological disorders. Based on this, this paper proposes a feature descriptor to characterize EEG instability. The proposed method starts by forming a signal point cloud through Phase Space Reconstruction (PSR). Subsequently, a pseudo-metric space is constructed, and pseudo-distances are calculated based on the consistent measure of the point cloud. Finally, Distance to Measure (DTM) Function are generated to replace the distance function in the original metric space. We calculated the relative distances in the point cloud by measuring signal similarity and, based on this, summarized the point cloud structures formed by EEG with different stabilities after PSR. This process demonstrated that Multivariate Kernel Density Estimation (MKDE) based on a Gaussian kernel can effectively separate the mappings of different stable components within the signal in the phase space. The two average DTM values are then proposed as feature descriptors for EEG instability.In the validation phase, the proposed feature descriptor is tested on three typical neurological disorders: epilepsy, Alzheimer's disease, and Parkinson's disease, using the Bonn dataset, CHB-MIT, the Florida State University dataset, and the Iowa State University dataset. DTM values are used as feature inputs for four different machine learning classifiers, and The results show that the best classification accuracy of the proposed method reaches 98.00 %, 96.25 %, 96.71 % and 95.34 % respectively, outperforming commonly used nonlinear descriptors. Finally, the proposed method is tested and analyzed using noisy signals, demonstrating its robustness compared to other methods.",https://pubmed.ncbi.nlm.nih.gov/39094326/,https://pubmed.ncbi.nlm.nih.gov/39094326/,English,Include,,Quantifying instability in neurological disorders EEG based on phase space DTM function.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39094245,pubmed:39094245,PubMed,pubmed:39094245,"Retrospective study on neonatal seizures in a tertiary center of northern Italy after ILAE classification: Incidence, seizure type, EEG and etiology.",Robertino Dilena;Maria T Molisso;Agnese De Carli;Eleonora Mauri;Alberta Circiello;Alessia Di Benedetto;Silvia Pisoni;Laura Bassi;Cristina Bana;Alberto M Cappellari;Dario Consonni;Massimo Mastrangelo;Tiziana Granata;Francesca La Briola;Cinzia Peruzzi;Federico Raviglione;Pasquale Striano;Sergio Barbieri;Fabio Mosca;Monica Fumagalli,2024,10.1016/j.yebeh.2024.109971,"We aimed to evaluate epidemiology, seizure type, EEG, and etiology of neonatal seizures (NS) in a tertiary neonatal intensive care unit. Data on infants with a neurophysiological confirmation of NS were collected between 2009 and 2022. Seizure types and epileptic syndromes were classified by the ILAE classification and EEG by the Italian Neonatal Seizure Collaborative Network (INNESCO) score. Out of 91,253 neonates, 145 presented with NS; 69.7 % were born at term and 30.3 % were preterm infants. The incidence of NS in neonates born at our center was 1.2 per 1,000 live newborns (96/80697 neonates) while in the entire neonatal population admitted to our center it was 1.6 per 1,000 live births, increasing with lower preterm age. Compared to previous studies, we found a lower proportion of hypoxic-ischemic encephalopathy (HIE) (23.4 %) and a higher rate of genetic contribution (26.2 %). The infection rate was higher in preterm (31.8 %) than in full term (9.9 %) infants. Electrographic seizures were associated with acute provoked seizures (35.9 %), preterm age (52.3 %), and HIE (52.9 %). Vascular etiology was associated with focal clonic seizures (56.8 %). Non-structural neonatal genetic epilepsy was associated with sequential seizures (68.2 %), particularly KCNQ2 and SCN2A epilepsy. Background EEG was abnormal in all HIE, infections (85.7 %) and metabolic NS (83.3 %). In genetic epilepsy, background EEG depended on the epileptic syndrome: normal in 80 % of self-limited neonatal epilepsy and abnormal in 77.8 % of developmental and epileptic encephalopathy. Electroclinical seizures were associated with focal onset, while electrographic seizures correlated with a multifocal onset. A low incidence of HIE and a high incidence of genetic etiology were observed in our cohort of NS. Seizure type and EEG features are fundamental to address etiology.",https://pubmed.ncbi.nlm.nih.gov/39094245/,https://pubmed.ncbi.nlm.nih.gov/39094245/,English,Include,,"Retrospective study on neonatal seizures in a tertiary center of northern Italy after ILAE classification: Incidence, seizure type, EEG and etiology.",Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39090502,pubmed:39090502,PubMed,pubmed:39090502,"From data to decisions: AI and functional connectivity for diagnosis, prognosis, and recovery prediction in stroke.",Alessia Cacciotti;Chiara Pappalettera;Francesca Miraglia;Claudia Carrarini;Cristiano Pecchioli;Paolo Maria Rossini;Fabrizio Vecchio,2025,10.1007/s11357-024-01301-1,"Stroke is a severe medical condition which may lead to permanent disability conditions. The initial 8 weeks following a stroke are crucial for rehabilitation, as most recovery occurs during this period. Personalized approaches and predictive biomarkers are needed for tailored rehabilitation. In this context, EEG brain connectivity and Artificial Intelligence (AI) can play a crucial role in diagnosing and predicting stroke outcomes efficiently. In the present study, 127 patients with subacute ischemic lesions and 90 age- and gender-matched healthy controls were enrolled. EEG recordings were obtained from each participant within 15 days of stroke onset. Clinical evaluations were performed at baseline and at 40-days follow-up using the National Institutes of Health Stroke Scale (NIHSS). Functional connectivity analysis was conducted using Total Coherence (TotCoh) and Small Word (SW). Quadratic support vector machines (SVM) algorithms were implemented to classify healthy subjects compared to stroke patients (Healthy vs Stroke), determine the affected hemisphere (Left vs Right Hemisphere), and predict functional recovery (Functional Recovery Prediction). In the classification for Functional Recovery Prediction, an accuracy of 94.75%, sensitivity of 96.27% specificity of 92.33%, and AUC of 0.95 were achieved; for Healthy vs Stroke, an accuracy of 99.09%, sensitivity of 100%, specificity of 98.46%, and AUC of 0.99 were achieved. For Left vs Right Hemisphere classification, accuracy was 86.77%, sensitivity was 91.44%, specificity was 80.33%, and AUC was 0.87. These findings highlight the potential of utilizing functional connectivity measures based on EEG in combination with AI algorithms to improve patient outcomes by targeted rehabilitation interventions.",,https://pubmed.ncbi.nlm.nih.gov/39090502/,English,Exclude,Outside date range,"From data to decisions: AI and functional connectivity for diagnosis, prognosis, and recovery prediction in stroke.",,,,,0.95,0.6,
pubmed:39087560,pubmed:39087560,PubMed,pubmed:39087560,Analysis of individual alpha frequency in a large cohort from a tertiary memory center.,Giordano Cecchetti;Federica Agosta;Elisa Canu;Silvia Basaia;Giulia Rugarli;Davide G Curti;Federico Coraglia;Marco Cursi;Edoardo G Spinelli;Roberto Santangelo;Francesca Caso;Giovanna Franca Fanelli;Giuseppe Magnani;Massimo Filippi,2024,10.1111/ene.16424,"Precise and timely diagnosis is crucial for the optimal use of emerging disease-modifying treatments for Alzheimer disease (AD). Electroencephalography (EEG), which is noninvasive and cost-effective, can capture neural abnormalities linked to various dementias. This study explores the use of individual alpha frequency (IAF) derived from EEG as a diagnostic and prognostic tool in cognitively impaired patients. This retrospective study included 375 patients from the tertiary Memory Clinic of IRCCS San Raffaele Hospital, Milan, Italy. Participants underwent clinical and neuropsychological assessments, brain imaging, cerebrospinal fluid biomarker analysis, and resting-state EEG. Patients were categorized by amyloid status, the AT(N) classification system, clinical diagnosis, and mild cognitive impairment (MCI) progression to AD dementia. IAF was calculated and compared among study groups. Receiver operating characteristic (ROC) analysis was used to calculate its discriminative performance. IAF was higher in amyloid-negative subjects and varied significantly across AT(N) groups. ROC analysis confirmed IAF's ability to distinguish A-T-N- from the A+T+N+ and A+T-N+ groups. IAF was lower in AD and Lewy body dementia patients compared to MCI and other dementia types, with moderate discriminatory capability. Among A+ MCI patients, IAF was significantly lower in those who converted to AD within 2 years compared to stable MCI patients and predicted time to conversion (p < 0.001, R = 0.38). IAF is a valuable tool for dementia diagnosis and prognosis, correlating with amyloid status and neurodegeneration. It effectively predicts MCI progression to AD, supporting its use in early, targeted interventions in the context of disease-modifying treatments.",https://pubmed.ncbi.nlm.nih.gov/39087560/,https://pubmed.ncbi.nlm.nih.gov/39087560/,English,Include,,Analysis of individual alpha frequency in a large cohort from a tertiary memory center.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39086629,pubmed:39086629,PubMed,pubmed:39086629,Data-driven retrieval of population-level EEG features and their role in neurodegenerative diseases.,Wentao Li;Yogatheesan Varatharajah;Ellen Dicks;Leland Barnard;Benjamin H Brinkmann;Daniel Crepeau;Gregory Worrell;Winnie Fan;Walter Kremers;Bradley Boeve;Hugo Botha;Venkatsampath Gogineni;David T Jones,2024,10.1109/iembs.2009.5332915,"Electrophysiologic disturbances due to neurodegenerative disorders such as Alzheimer's disease and Lewy Body disease are detectable by scalp EEG and can serve as a functional measure of disease severity. Traditional quantitative methods of EEG analysis often require an a-priori selection of clinically meaningful EEG features and are susceptible to bias, limiting the clinical utility of routine EEGs in the diagnosis and management of neurodegenerative disorders. We present a data-driven tensor decomposition approach to extract the top 6 spectral and spatial features representing commonly known sources of EEG activity during eyes-closed wakefulness. As part of their neurologic evaluation at Mayo Clinic, 11 001 patients underwent 12 176 routine, standard 10-20 scalp EEG studies. From these raw EEGs, we developed an algorithm based on posterior alpha activity and eye movement to automatically select awake-eyes-closed epochs and estimated average spectral power density (SPD) between 1 and 45 Hz for each channel. We then created a three-dimensional (3D) tensor (record × channel × frequency) and applied a canonical polyadic decomposition to extract the top six factors. We further identified an independent cohort of patients meeting consensus criteria for mild cognitive impairment (30) or dementia (39) due to Alzheimer's disease and dementia with Lewy Bodies (31) and similarly aged cognitively normal controls (36). We evaluated the ability of the six factors in differentiating these subgroups using a Naïve Bayes classification approach and assessed for linear associations between factor loadings and Kokmen short test of mental status scores, fluorodeoxyglucose (FDG) PET uptake ratios and CSF Alzheimer's Disease biomarker measures. Factors represented biologically meaningful brain activities including posterior alpha rhythm, anterior delta/theta rhythms and centroparietal beta, which correlated with patient age and EEG dysrhythmia grade. These factors were also able to distinguish patients from controls with a moderate to high degree of accuracy (Area Under the Curve (AUC) 0.59-0.91) and Alzheimer's disease dementia from dementia with Lewy Bodies (AUC 0.61). Furthermore, relevant EEG features correlated with cognitive test performance, PET metabolism and CSF AB42 measures in the Alzheimer's subgroup. This study demonstrates that data-driven approaches can extract biologically meaningful features from population-level clinical EEGs without artefact rejection or a-priori selection of channels or frequency bands. With continued development, such data-driven methods may improve the clinical utility of EEG in memory care by assisting in early identification of mild cognitive impairment and differentiating between different neurodegenerative causes of cognitive impairment.",https://pubmed.ncbi.nlm.nih.gov/39086629/,https://pubmed.ncbi.nlm.nih.gov/39086629/,English,Include,,Data-driven retrieval of population-level EEG features and their role in neurodegenerative diseases.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39086374,pubmed:39086374,PubMed,pubmed:39086374,A generic error-related potential classifier based on simulated subjects.,Aline Xavier Fidêncio;Christian Klaes;Ioannis Iossifidis,2024,10.1088/1741-2552/acabe9,"Error-related potentials (ErrPs) are brain signals known to be generated as a reaction to erroneous events. Several works have shown that not only self-made errors but also mistakes generated by external agents can elicit such event-related potentials. The possibility of reliably measuring ErrPs through non-invasive techniques has increased the interest in the brain-computer interface (BCI) community in using such signals to improve performance, for example, by performing error correction. Extensive calibration sessions are typically necessary to gather sufficient trials for training subject-specific ErrP classifiers. This procedure is not only time-consuming but also boresome for participants. In this paper, we explore the effectiveness of ErrPs in closed-loop systems, emphasizing their dependency on precise single-trial classification. To guarantee the presence of an ErrPs signal in the data we employ and to ensure that the parameters defining ErrPs are systematically varied, we utilize the open-source toolbox SEREEGA for data simulation. We generated training instances and evaluated the performance of the generic classifier on both simulated and real-world datasets, proposing a promising alternative to conventional calibration techniques. Results show that a generic support vector machine classifier reaches balanced accuracies of 72.9%, 62.7%, 71.0%, and 70.8% on each validation dataset. While performing similarly to a leave-one-subject-out approach for error class detection, the proposed classifier shows promising generalization across different datasets and subjects without further adaptation. Moreover, by utilizing SEREEGA, we can systematically adjust parameters to accommodate the variability in the ErrP, facilitating the systematic validation of closed-loop setups. Furthermore, our objective is to develop a universal ErrP classifier that captures the signal's variability, enabling it to determine the presence or absence of an ErrP in real EEG data.",https://pubmed.ncbi.nlm.nih.gov/39086374/,https://pubmed.ncbi.nlm.nih.gov/39086374/,English,Include,,A generic error-related potential classifier based on simulated subjects.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.45,cv_reported;small_sample_mentioned
pubmed:39086252,pubmed:39086252,PubMed,pubmed:39086252,Classification of mental workload with EEG analysis by using effective connectivity and a hybrid model of CNN and LSTM.,MohammadReza Safari;Reza Shalbaf;Sara Bagherzadeh;Ahmad Shalbaf,2024,10.1080/10255842.2024.2386325,"Estimation of mental workload from electroencephalogram (EEG) signals aims to accurately measure the cognitive demands placed on an individual during multitasking mental activities. By analyzing the brain activity of the subject, we can determine the level of mental effort required to perform a task and optimize the workload to prevent cognitive overload or underload. This information can be used to enhance performance and productivity in various fields such as healthcare, education, and aviation. In this paper, we propose a method that uses EEG and deep neural networks to estimate the mental workload of human subjects during multitasking mental activities. Notably, our proposed method employs subject-independent classification. We use the ""STEW"" dataset, which consists of two tasks, namely ""No task"" and ""simultaneous capacity (SIMKAP)-based multitasking activity"". We estimate the different workload levels of two tasks using a composite framework consisting of brain connectivity and deep neural networks. After the initial preprocessing of EEG signals, an analysis of the relationships between the 14 EEG channels is conducted to evaluate effective brain connectivity. This assessment illustrates the information flow between various brain regions, utilizing the direct Directed Transfer Function (dDTF) method. Then, we propose a deep hybrid model based on pre-trained Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) for the classification of workload levels. The accuracy of the proposed deep model achieved 83.12% according to the subject-independent leave-subject-out (LSO) approach. The pre-trained CNN + LSTM approaches to EEG data have been found to be an accurate method for assessing the mental workload.",https://pubmed.ncbi.nlm.nih.gov/39086252/,https://pubmed.ncbi.nlm.nih.gov/39086252/,English,Include,,Classification of mental workload with EEG analysis by using effective connectivity and a hybrid model of CNN and LSTM.,Include,," Function (dDTF) method. Then, we propose a deep hybrid model based on pre-trained Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) for the classification of workload levels. The accuracy of the proposed deep model achieved 83.12% according to the subject-independent leave-subject-out (LSO) approach. The pre-trained CNN + LSTM approaches to EEG data have been found to be an ac",,0.95,0.6,
pubmed:39085370,pubmed:39085370,PubMed,pubmed:39085370,A portable affective computing system for identifying mate preference.,Guangjie Yuan;Tao Wang;Wei Ju;Sai Fu,2024,10.1002/int.22551,"Recognizing an individual's preference state for potential romantic partners based on electroencephalogram (EEG) signals holds significant practical value in enhancing matchmaking success rates and preventing romance fraud. Despite some progress has been made in this field, challenges such as high-dimensional feature space and channel redundancy limited the technology's practical application. The aim of this study is to explore the most discriminative EEG features and channels, in order to enhance the recognition performance of the system, while maximizing the portable and practical value of EEG-based systems for recognizing romantic attraction. To achieve this goal, we first conducted an interesting simulated dating experiment to collect the necessary data. Next, EEG features were extracted from various dimensions, including band power and asymmetry index features. Then, we introduced a novel method for EEG feature and channel selection that combines the sequential forward selection (SFS) algorithm with the frequency-based feature subset integration (FFSI) algorithm. Finally, we used the random forest classifier (RFC) to determine a person's preference state for potential romantic partners. Experimental results indicate that the optimal feature subset, selected using the SFS-FFSI method, attained an average classification accuracy of 88.42%. Notably, these features were predominantly sourced from asymmetry index features of electrodes situated in the frontal, parietal, and occipital lobes.",https://pubmed.ncbi.nlm.nih.gov/39085370/,https://pubmed.ncbi.nlm.nih.gov/39085370/,English,Include,,A portable affective computing system for identifying mate preference.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
pubmed:39084451,pubmed:39084451,PubMed,pubmed:39084451,Neuroimaging biomarkers for the diagnosis and prognosis of patients with disorders of consciousness.,Jiaying Wang;Qiantu Lai;Junrong Han;Pengmin Qin;Hang Wu,2024,10.1016/j.brainres.2024.149133,"The progress in neuroimaging and electrophysiological techniques has shown substantial promise in improving the clinical assessment of disorders of consciousness (DOC). Through the examination of both stimulus-induced and spontaneous brain activity, numerous comprehensive investigations have explored variations in brain activity patterns among patients with DOC, yielding valuable insights for clinical diagnosis and prognostic purposes. Nonetheless, reaching a consensus on precise neuroimaging biomarkers for patients with DOC remains a challenge. Therefore, in this review, we begin by summarizing the empirical evidence related to neuroimaging biomarkers for DOC using various paradigms, including active, passive, and resting-state approaches, by employing task-based fMRI, resting-state fMRI (rs-fMRI), electroencephalography (EEG), and positron emission tomography (PET) techniques. Subsequently, we conducted a review of studies examining the neural correlates of consciousness in patients with DOC, with the findings holding potential value for the clinical application of DOC. Notably, previous research indicates that neuroimaging techniques have the potential to unveil covert awareness that conventional behavioral assessments might overlook. Furthermore, when integrated with various task paradigms or analytical approaches, this combination has the potential to significantly enhance the accuracy of both diagnosis and prognosis in DOC patients. Nonetheless, the stability of these neural biomarkers still needs additional validation, and future directions may entail integrating diagnostic and prognostic methods with big data and deep learning approaches.",,https://pubmed.ncbi.nlm.nih.gov/39084451/,English,Exclude,Review/survey papers,Neuroimaging biomarkers for the diagnosis and prognosis of patients with disorders of consciousness.,,,,,0.95,0.6,
pubmed:39082290,pubmed:39082290,PubMed,pubmed:39082290,The Roles of Segments and Tone in Mandarin Lexical Processing: An ERP Study.,Dan Du;Minghu Jiang,2024,10.31083/j.jin2307139,"Segments and tone are important sub-syllabic units that play large roles in lexical processing in tonal languages. However, their roles in lexical processing remain unclear, and the event-related potential (ERP) technique will benefit the exploration of the cognitive mechanism in lexical processing. The high temporal resolution of ERP enables the technique to interpret rapidly changing spoken language performances. The present ERP study examined the different roles of segments and tone in Mandarin Chinese lexical processing. An auditory priming experiment was designed that included five types of priming stimuli: consonant mismatch, vowel mismatch, tone mismatch, unrelated mismatch, and identity. Participants were asked to judge whether the target of the prime-target pair was a real Mandarin disyllabic word or not. Behavioral results including reaction time and response accuracy and ERP results were collected. Results were different from those of previous studies that showed the dominant role of consonants in lexical access in mainly non-tonal languages like English. Our results showed that consonants and vowels play comparable roles, whereas tone plays a less important role than do consonants and vowels in lexical processing in Mandarin. These results have implications for understanding the brain mechanisms in lexical processing of tonal languages.",,https://pubmed.ncbi.nlm.nih.gov/39082290/,English,Exclude,Not EEG-BCI focused,The Roles of Segments and Tone in Mandarin Lexical Processing: An ERP Study.,,,,,0.9,0.8,small_sample_mentioned
pubmed:39082285,pubmed:39082285,PubMed,pubmed:39082285,Review on the Use of Brain Computer Interface Rehabilitation Methods for Treating Mental and Neurological Conditions.,Vladimir Khorev;Semen Kurkin;Artem Badarin;Vladimir Antipov;Elena Pitsik;Andrey Andreev;Vadim Grubov;Oxana Drapkina;Anton Kiselev;Alexander Hramov,2024,10.31083/j.jin2307125,"This review provides a comprehensive examination of recent developments in both neurofeedback and brain-computer interface (BCI) within the medical field and rehabilitation. By analyzing and comparing results obtained with various tools and techniques, we aim to offer a systematic understanding of BCI applications concerning different modalities of neurofeedback and input data utilized. Our primary objective is to address the existing gap in the area of meta-reviews, which provides a more comprehensive outlook on the field, allowing for the assessment of the current landscape and developments within the scope of BCI. Our main methodologies include meta-analysis, search queries employing relevant keywords, and a network-based approach. We are dedicated to delivering an unbiased evaluation of BCI studies, elucidating the primary vectors of research development in this field. Our review encompasses a diverse range of applications, incorporating the use of brain-computer interfaces for rehabilitation and the treatment of various diagnoses, including those related to affective spectrum disorders. By encompassing a wide variety of use cases, we aim to offer a more comprehensive perspective on the utilization of neurofeedback treatments across different contexts. The structured and organized presentation of information, complemented by accompanying visualizations and diagrams, renders this review a valuable resource for scientists and researchers engaged in the domains of biofeedback and brain-computer interfaces.",,https://pubmed.ncbi.nlm.nih.gov/39082285/,English,Exclude,Review/survey papers,Review on the Use of Brain Computer Interface Rehabilitation Methods for Treating Mental and Neurological Conditions.,,,,,0.95,0.6,
pubmed:39082284,pubmed:39082284,PubMed,pubmed:39082284,Spindle Detection Based on Elastic Time Window and Spatial Pyramid Pooling.,Yiting Ou;Fei Wang;Bai Feng;Liren Tang;Jiahui Pan,2024,10.31083/j.jin2307134,"Sleep spindles have emerged as valuable biomarkers for assessing cognitive abilities and related disorders, underscoring the importance of their detection in clinical research. However, template matching-based algorithms using fixed templates may not be able to fully adapt to spindles of different durations. Moreover, inspired by the multiscale feature extraction of images, the use of multiscale feature extraction methods can be used to better adapt to spindles of different frequencies and durations. Therefore, this study proposes a novel automatic spindle detection algorithm based on elastic time windows and spatial pyramid pooling (SPP) for extracting multiscale features. The algorithm utilizes elastic time windows to segment electroencephalogram (EEG) signals, enabling the extraction of features across multiple scales. This approach accommodates significant variations in spindle duration and polarization positioning during different EEG epochs. Additionally, spatial pyramid pooling is integrated into a depthwise separable convolutional (DSC) network to perform multiscale pooling on the segmented spindle signal features at different scales. Compared with existing template matching algorithms, this algorithm's spindle wave polarization positioning is more consistent with the real situation. Experimental results conducted on the public dataset DREAMS show that the average accuracy of this algorithm reaches 95.75%, with an average negative predictive value (NPV) of 96.55%, indicating its advanced performance. The effectiveness of each module was verified through thorough ablation experiments. More importantly, the algorithm shows strong robustness when faced with changes in different experimental subjects. This feature makes the algorithm more accurate at identifying sleep spindles and is expected to help experts automatically detect spindles in sleep EEG signals, reduce the workload and time of manual detection, and improve efficiency.",https://pubmed.ncbi.nlm.nih.gov/39082284/,https://pubmed.ncbi.nlm.nih.gov/39082284/,English,Include,,Spindle Detection Based on Elastic Time Window and Spatial Pyramid Pooling.,Include,,"tching algorithms, this algorithm's spindle wave polarization positioning is more consistent with the real situation. Experimental results conducted on the public dataset DREAMS show that the average accuracy of this algorithm reaches 95.75%, with an average negative predictive value (NPV) of 96.55%, indicating its advanced performance. The effectiveness of each module was verified through thoroug",,0.95,0.6,
pubmed:39081290,pubmed:39081290,PubMed,pubmed:39081290,Effect of excessive internet gaming on inhibitory control based on resting EEG and ERP.,Jiayi Xu;Lu Shen;Huajia Fei;Wenbin Zhou;Feng Wan;Wenya Nan,2024,10.1037/0033-2909.109.2.163,"Previous research indicates that individuals with Internet gaming disorder (IGD) show impaired inhibitory control and abnormal EEG/ERP patterns. However, it is unclear how those individuals with excessive Internet game use (EUG) but without addiction differ. This study examined inhibitory control, resting EEG, and ERP in EUG gamers compared to non-gamers. Fifteen participants in each group underwent 4-min eyes-closed EEG recordings and a color-word Stroop task. Results showed no significant differences in reaction time, accuracy, or P3 amplitude between EUG gamers and non-gamers. However, EUG gamers exhibited shortened P3 latency, which may suggest enhanced inhibitory control. Additionally, EUG gamers showed reduced theta and alpha band power during the resting state compared to non-gamers. These findings suggest that excessive gaming without addiction may enhance inhibitory control and influence brain activity differently from IGD.",https://pubmed.ncbi.nlm.nih.gov/39081290/,https://pubmed.ncbi.nlm.nih.gov/39081290/,English,Include,,Effect of excessive internet gaming on inhibitory control based on resting EEG and ERP.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.8,small_sample_mentioned
pubmed:39080312,pubmed:39080312,PubMed,pubmed:39080312,Human-centred physical neuromorphics with visual brain-computer interfaces.,Gao Wang;Giulia Marcucci;Benjamin Peters;Maria Chiara Braidotti;Lars Muckli;Daniele Faccio,2024,10.1063/5.0157919,"Steady-state visual evoked potentials (SSVEPs) are widely used for brain-computer interfaces (BCIs) as they provide a stable and efficient means to connect the computer to the brain with a simple flickering light. Previous studies focused on low-density frequency division multiplexing techniques, i.e. typically employing one or two light-modulation frequencies during a single flickering light stimulation. Here we show that it is possible to encode information in SSVEPs excited by high-density frequency division multiplexing, involving hundreds of frequencies. We then demonstrate the ability to transmit entire images from the computer to the brain/EEG read-out in relatively short times. High-density frequency multiplexing also allows to implement a photonic neural network utilizing SSVEPs, that is applied to simple classification tasks and exhibits promising scalability properties by connecting multiple brains in series. Our findings open up new possibilities for the field of neural interfaces, holding potential for various applications, including assistive technologies and cognitive enhancements, to further improve human-machine interactions.",https://pubmed.ncbi.nlm.nih.gov/39080312/,https://pubmed.ncbi.nlm.nih.gov/39080312/,English,Include,,Human-centred physical neuromorphics with visual brain-computer interfaces.,Exclude,No performance metrics reported,No metrics found in full text,,0.9,0.6,
pubmed:39076791,pubmed:39076791,PubMed,pubmed:39076791,Epileptic seizure detection using CHB-MIT dataset: The overlooked perspectives.,Emran Ali;Maia Angelova;Chandan Karmakar,2024,10.6084/m9.figshare.c.7184012,"Epilepsy is a life-threatening neurological condition. Manual detection of epileptic seizures (ES) is laborious and burdensome. Machine learning techniques applied to electroencephalography (EEG) signals are widely used for automatic seizure detection. Some key factors are worth considering for the real-world applicability of such systems: (i) continuous EEG data typically has a higher class imbalance; (ii) higher variability across subjects is present in physiological signals such as EEG; and (iii) seizure event detection is more practical than random segment detection. Most prior studies failed to address these crucial factors altogether for seizure detection. In this study, we intend to investigate a generalized cross-subject seizure event detection system using the continuous EEG signals from the CHB-MIT dataset that considers all these overlooked aspects. A 5-second non-overlapping window is used to extract 92 features from 22 EEG channels; however, the most significant 32 features from each channel are used in experimentation. Seizure classification is done using a Random Forest (RF) classifier for segment detection, followed by a post-processing method used for event detection. Adopting all the above-mentioned essential aspects, the proposed event detection system achieved 72.63% and 75.34% sensitivity for subject-wise 5-fold and leave-one-out analyses, respectively. This study presents the real-world scenario for ES event detectors and furthers the understanding of such detection systems.",https://pubmed.ncbi.nlm.nih.gov/39076791/,https://pubmed.ncbi.nlm.nih.gov/39076791/,English,Include,,Epileptic seizure detection using CHB-MIT dataset: The overlooked perspectives.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.25,cv_reported
pubmed:39075138,pubmed:39075138,PubMed,pubmed:39075138,Analyzing brain-activation responses to auditory stimuli improves the diagnosis of a disorder of consciousness by non-linear dynamic analysis of the EEG.,Sheng Qu;Xinchun Wu;Yaxiu Tang;Qi Zhang;Laigang Huang;Baojuan Cui;Shengxiu Jiao;Qiangsan Sun;Fanshuo Zeng,2024,10.1142/s0129065722500186,"Although auditory stimuli benefit patients with disorders of consciousness (DOC), the optimal stimulus remains unclear. We explored the most effective electroencephalography (EEG)-tracking method for eliciting brain responses to auditory stimuli and assessed its potential as a neural marker to improve DOC diagnosis. We collected 58 EEG recordings from patients with DOC to evaluate the classification model's performance and optimal auditory stimulus. Using non-linear dynamic analysis (approximate entropy [ApEn]), we assessed EEG responses to various auditory stimuli (resting state, preferred music, subject's own name [SON], and familiar music) in 40 patients. The diagnostic performance of the optimal stimulus-induced EEG classification for vegetative state (VS)/unresponsive wakefulness syndrome (UWS) and minimally conscious state (MCS) was compared with the Coma Recovery Scale-Revision in 18 patients using the machine learning cascade forward backpropagation neural network model. Regardless of patient status, preferred music significantly activated the cerebral cortex. Patients in MCS showed increased activity in the prefrontal pole and central, occipital, and temporal cortices, whereas those in VS/UWS showed activity in the prefrontal and anterior temporal lobes. Patients in VS/UWS exhibited the lowest preferred music-induced ApEn differences in the central, middle, and posterior temporal lobes compared with those in MCS. The resting state ApEn value of the prefrontal pole (0.77) distinguished VS/UWS from MCS with 61.11% accuracy. The cascade forward backpropagation neural network tested for ApEn values in the resting state and preferred music-induced ApEn differences achieved an average of 83.33% accuracy in distinguishing VS/UWS from MCS (based on K-fold cross-validation). EEG non-linear analysis quantifies cortical responses in patients with DOC, with preferred music inducing more intense EEG responses than SON and familiar music. Machine learning algorithms combined with auditory stimuli showed strong potential for improving DOC diagnosis. Future studies should explore the optimal multimodal sensory stimuli tailored for individual patients.Trial registration: The study is registered in the Chinese Registry of Clinical Trials (Approval no: KYLL-2023-414, Registration code: ChiCTR2300079310).",https://pubmed.ncbi.nlm.nih.gov/39075138/,https://pubmed.ncbi.nlm.nih.gov/39075138/,English,Include,,Analyzing brain-activation responses to auditory stimuli improves the diagnosis of a disorder of consciousness by non-linear dynamic analysis of the EEG.,Include,," ApEn differences in the central, middle, and posterior temporal lobes compared with those in MCS. The resting state ApEn value of the prefrontal pole (0.77) distinguished VS/UWS from MCS with 61.11% accuracy. The cascade forward backpropagation neural network tested for ApEn values in the resting state and preferred music-induced ApEn differences achieved an average of 83.33% accuracy in distingu",,0.95,0.25,cv_reported
pubmed:39074541,pubmed:39074541,PubMed,pubmed:39074541,The association of dispositional anxiety with the NoGo N2 under relaxation instruction vs. speed/accuracy instruction.,André Beauducel;Vera Scheuble-Cabrera;Jürgen Hennig;Johannes Hewig;Andrea Hildebrandt;Corinna Kührt;Leon Lange;Erik Malte Mueller;Roman Osinsky;Katharina Paul;Elisa Porth;Anja Riesel;Johannes Rodrigues;Christoph Scheffel;Cassie Short;Jutta Stahl;Alexander Strobel;Jan Wacker,2024,10.1016/j.biopsycho.2024.108850,"Prior research suggests that cognitive control, indicated by NoGo N2 amplitudes in Go/NoGo tasks, is associated with dispositional anxiety. This negative association tends to be reduced in anxiety-enhancing experimental conditions. However, anxiety-reducing conditions have not yet been investigated systematically. Thus, the present study compares the effect of a relaxation instruction with the conventional speed/accuracy instruction in a Go/NoGo task on the correlation of the NoGo N2 with two subconstructs of dispositional anxiety, namely anxious apprehension and anxious arousal. As the test of differences between correlations needs considerable statistical power, the present study was included into the multi-lab CoScience Project. The hypotheses, manipulation checks, and the main path of pre-processing and statistical analysis were preregistered. Complete data sets of 777 participants were available for data analysis. Preregistered general linear models revealed that the different instructions of the task (speed/accuracy vs. relaxation) had no effect on the association between dispositional anxiety and the NoGo N2 amplitude in general. This result was supported by Cooperative-Forking-Path analysis. In contrast, a preregistered latent growth model with categorical variables revealed that anxious arousal was a negative predictor of the NoGo N2 intercept and a positive predictor of the NoGo N2 slope. Non-preregistered growth models, allowing for correlations of anxious apprehension with anxious arousal, revealed that higher anxious apprehension scores were associated with more negative NoGo N2 amplitudes with increased relaxation. Results are discussed in the context of the compensatory error monitoring hypothesis and the revised Reinforcement Sensitivity Theory.",,https://pubmed.ncbi.nlm.nih.gov/39074541/,English,Exclude,Not EEG-BCI focused,The association of dispositional anxiety with the NoGo N2 under relaxation instruction vs. speed/accuracy instruction.,,,,,0.9,0.8,small_sample_mentioned
crossref:10.1109/bci51272.2021.9385333,crossref:10.1109/bci51272.2021.9385333,CrossRef,crossref:10.1109/bci51272.2021.9385333,Subject-Independent Object Classification Based on Convolutional Neural Network from EEG Signals,Jenifer Kalafatovich;Minji Lee,2021,10.1109/bci51272.2021.9385333,,https://doi.org/10.1109/bci51272.2021.9385333,https://doi.org/10.1109/bci51272.2021.9385333,English,Include,,Subject-Independent Object Classification Based on Convolutional Neural Network from EEG Signals,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
crossref:10.1109/iww-bci.2017.7858158,crossref:10.1109/iww-bci.2017.7858158,CrossRef,crossref:10.1109/iww-bci.2017.7858158,Learning suite of kernel feature spaces enhances SMR-based EEG-BCI classification,Berdakh Abibullaev,2017,10.1109/iww-bci.2017.7858158,,,https://doi.org/10.1109/iww-bci.2017.7858158,English,Exclude,Outside date range,Learning suite of kernel feature spaces enhances SMR-based EEG-BCI classification,,,,,0.95,0.6,
crossref:10.1088/1741-2552/ac4430,crossref:10.1088/1741-2552/ac4430,CrossRef,crossref:10.1088/1741-2552/ac4430,A 1D CNN for high accuracy classification and transfer learning in motor imagery EEG-based brain-computer interface,F Mattioli;C Porcaro;G Baldassarre,2021,10.1088/1741-2552/ac4430,"<jats:title>Abstract</jats:title>
               <jats:p>
                  <jats:italic>Objective.</jats:italic> Brain-computer interface (BCI) aims to establish communication paths between the brain processes and external devices. Different methods have been used to extract human intentions from electroencephalography (EEG) recordings. Those based on motor imagery (MI) seem to have a great potential for future applications. These approaches rely on the extraction of EEG distinctive patterns during imagined movements. Techniques able to extract patterns from raw signals represent an important target for BCI as they do not need labor-intensive data pre-processing. <jats:italic>Approach.</jats:italic> We propose a new approach based on a 10-layer one-dimensional convolution neural network (1D-CNN) to classify five brain states (four MI classes plus a ‘baseline’ class) using a data augmentation algorithm and a limited number of EEG channels. In addition, we present a transfer learning method used to extract critical features from the EEG group dataset and then to customize the model to the single individual by training its late layers with only 12-min individual-related data. <jats:italic>Main results.</jats:italic> The model tested with the ‘EEG Motor Movement/Imagery Dataset’ outperforms the current state-of-the-art models by achieving a <jats:inline-formula>
                     <jats:tex-math/>
                     <mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML"" overflow=""scroll"">
                        <mml:mrow>
                           <mml:mn>99.38</mml:mn>
                           <mml:mi>%</mml:mi>
                        </mml:mrow>
                     </mml:math>
                     <jats:inline-graphic xmlns:xlink=""http://www.w3.org/1999/xlink"" xlink:href=""jneac4430ieqn1.gif"" xlink:type=""simple""/>
                  </jats:inline-formula> accuracy at the group level. In addition, the transfer learning approach we present achieves an average accuracy of <jats:inline-formula>
                     <jats:tex-math/>
                     <mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML"" overflow=""scroll"">
                        <mml:mrow>
                           <mml:mn>99.46</mml:mn>
                           <mml:mi>%</mml:mi>
                        </mml:mrow>
                     </mml:math>
                     <jats:inline-graphic xmlns:xlink=""http://www.w3.org/1999/xlink"" xlink:href=""jneac4430ieqn2.gif"" xlink:type=""simple""/>
                  </jats:inline-formula>. <jats:italic>Significance.</jats:italic> The proposed methods could foster the development of future BCI applications relying on few-channel portable recording devices and individual-based training.</jats:p>",https://doi.org/10.1088/1741-2552/ac4430,https://doi.org/10.1088/1741-2552/ac4430,English,Include,,A 1D CNN for high accuracy classification and transfer learning in motor imagery EEG-based brain-computer interface,Include,,"        </mml:math>
                     <jats:inline-graphic xmlns:xlink=""http://www.w3.org/1999/xlink"" xlink:href=""jneac4430ieqn1.gif"" xlink:type=""simple""/>
                  </jats:inline-formula> accuracy at the group level. In addition, the transfer learning approach we present achieves an average accuracy of <jats:inline-formula>
                     <jats:tex-math/>
                     <mm",,0.95,0.6,
crossref:10.1109/bci48061.2020.9061622,crossref:10.1109/bci48061.2020.9061622,CrossRef,crossref:10.1109/bci48061.2020.9061622,Multi-Class Classification of Motor Imagery EEG Signals Using Image-Based Deep Recurrent Convolutional Neural Network,Ward Fadel;Csaba Kollod;Moutz Wahdow;Yahya Ibrahim;Istvan Ulbert,2020,10.1109/bci48061.2020.9061622,,https://doi.org/10.1109/bci48061.2020.9061622,https://doi.org/10.1109/bci48061.2020.9061622,English,Include,,Multi-Class Classification of Motor Imagery EEG Signals Using Image-Based Deep Recurrent Convolutional Neural Network,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
crossref:10.1109/iww-bci.2019.8737343,crossref:10.1109/iww-bci.2019.8737343,CrossRef,crossref:10.1109/iww-bci.2019.8737343,Classification of Working Memory Performance from EEG with Deep Artificial Neural Networks,Youngchul Kwak;Woo-Jin Song;Seong-Eun Kim,2019,10.1109/iww-bci.2019.8737343,,https://doi.org/10.1109/iww-bci.2019.8737343,https://doi.org/10.1109/iww-bci.2019.8737343,English,Include,,Classification of Working Memory Performance from EEG with Deep Artificial Neural Networks,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
crossref:10.1109/bci57258.2023.10078681,crossref:10.1109/bci57258.2023.10078681,CrossRef,crossref:10.1109/bci57258.2023.10078681,Classification of Distraction Levels Using Hybrid Deep Neural Networks From EEG Signals,Dae-Hyeok Lee;Sung-Jin Kim;Yeon-Woo Choi,2023,10.1109/bci57258.2023.10078681,,https://doi.org/10.1109/bci57258.2023.10078681,https://doi.org/10.1109/bci57258.2023.10078681,English,Include,,Classification of Distraction Levels Using Hybrid Deep Neural Networks From EEG Signals,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
crossref:10.32657/10356/166652,crossref:10.32657/10356/166652,CrossRef,crossref:10.32657/10356/166652,Electroencephalography (EEG) brain computer interface (BCI) for mental states detection,;Aung Phyo Wai Aung,,10.32657/10356/166652,,,https://doi.org/10.32657/10356/166652,English,Exclude,Not classification-focused,Electroencephalography (EEG) brain computer interface (BCI) for mental states detection,,,,,0.85,0.6,
crossref:10.1109/bci51272.2021.9385289,crossref:10.1109/bci51272.2021.9385289,CrossRef,crossref:10.1109/bci51272.2021.9385289,Meta-learning: Towards Fast Adaptation in Multi-Subject EEG Classification,Seungjin Choi,2021,10.1109/bci51272.2021.9385289,,https://doi.org/10.1109/bci51272.2021.9385289,https://doi.org/10.1109/bci51272.2021.9385289,English,Include,,Meta-learning: Towards Fast Adaptation in Multi-Subject EEG Classification,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
crossref:10.1109/bci48061.2020.9061635,crossref:10.1109/bci48061.2020.9061635,CrossRef,crossref:10.1109/bci48061.2020.9061635,Transform based feature construction utilizing magnitude and phase for convolutional neural network in EEG signal classification,Jeonghyun Kim;Yongkoo Park;Wonzoo Chung,2020,10.1109/bci48061.2020.9061635,,https://doi.org/10.1109/bci48061.2020.9061635,https://doi.org/10.1109/bci48061.2020.9061635,English,Include,,Transform based feature construction utilizing magnitude and phase for convolutional neural network in EEG signal classification,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
crossref:10.1109/bci48061.2020.9061651,crossref:10.1109/bci48061.2020.9061651,CrossRef,crossref:10.1109/bci48061.2020.9061651,Deep learning classification features visualization for arm movement brain-computer interface,Seokbeen Lim;Dong Pyo Jang;Hoseok Choi,2020,10.1109/bci48061.2020.9061651,,https://doi.org/10.1109/bci48061.2020.9061651,https://doi.org/10.1109/bci48061.2020.9061651,English,Include,,Deep learning classification features visualization for arm movement brain-computer interface,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
crossref:10.20944/preprints202206.0053.v1,crossref:10.20944/preprints202206.0053.v1,CrossRef,crossref:10.20944/preprints202206.0053.v1,Classification of EEG Motor Imagery Using Deep Learning for Brain-Computer Interface Systems,Alessandro Gallo;Manh Duong Phung,2022,10.20944/preprints202206.0053.v1,"<jats:p>Objective A trained T1 class Convolutional Neural Network (CNN) model will be used to examine its ability to successfully identify motor imagery when fed pre-processed electroencephalography (EEG) data. In theory, and if the model has been trained accurately, it should be able to identify a class and label it accordingly. The CNN model will then be restored and used to try and identify the same class of motor imagery data using much smaller sampled data in an attempt to simulate live data. Approach PyCharm, a Python platform, will be used to house and process the CNN. The raw data used for the training of the CNN will be sourced from the PhysioBank website. The EEG signal data will then be pre-processed using Brainstorm software that is a toolbox used in conjunction with MATLAB. The sample data used to validate and test the trained CNN, will be also be extracted from Brainstorm but in a much smaller size compared to the training data which is comprised of thousands of images. The sample size would be comparable to a person wearing a Brain Computer Interface (BCI), offering approximately 20 seconds of motor imagery signal data. Results The raw EEG data was successfully extracted and pre-processed. The deep learning model was trained using the extracted image data along with their corresponding labels. After training, it was able to accurately identify the T1 class label at 100 percent. The python coding was then modified to restore the trained model and feed it test sample data in which it was found to recognise 6 out of 10 lines of T1 signal image data. The result suggested that the initial training of the model required a different, more varying approach, so that it would be able to detect varying sample signal image data. The outcome of which could mean that the model could be used in applications for multiple patients wearing the same BCI hardware to control a device or interface.</jats:p>",https://doi.org/10.20944/preprints202206.0053.v1,https://doi.org/10.20944/preprints202206.0053.v1,English,Include,,Classification of EEG Motor Imagery Using Deep Learning for Brain-Computer Interface Systems,Include,,"<jats:p>Objective A trained T1 class Convolutional Neural Network (CNN) model will be used to examine its ability to successfully identify motor imagery when fed pre-processed electroencephalography (EEG) data. In theory, and if the model has been trained accurately, it should be able to identify a class and label it accordingly. The CNN model will then be restored",,0.95,0.6,
crossref:10.1109/bci51272.2021.9385368,crossref:10.1109/bci51272.2021.9385368,CrossRef,crossref:10.1109/bci51272.2021.9385368,Deep Neural Network for Drowsiness Detection from EEG,Chungho Lee;Rock-Hyun Choi;Jinung An,2021,10.1109/bci51272.2021.9385368,,,https://doi.org/10.1109/bci51272.2021.9385368,English,Exclude,Not classification-focused,Deep Neural Network for Drowsiness Detection from EEG,,,,,0.85,0.6,
crossref:10.1109/bci60775.2024.10480446,crossref:10.1109/bci60775.2024.10480446,CrossRef,crossref:10.1109/bci60775.2024.10480446,Convolutional Transformer-in-Transformer for Automatic Sleep Stage Classification,Moogyeong Kim;Wonzoo Chung,2024,10.1109/bci60775.2024.10480446,,,https://doi.org/10.1109/bci60775.2024.10480446,English,Exclude,Not EEG-BCI focused,Convolutional Transformer-in-Transformer for Automatic Sleep Stage Classification,,,,,0.9,0.6,
crossref:10.48084/etasr.9945,crossref:10.48084/etasr.9945,CrossRef,crossref:10.48084/etasr.9945,Development of a CNN-LSTM Deep Learning Model for Motor Imagery EEG Classification for BCI Applications,Aaqib Raza;Mohd Zuki Yusoff,2025,10.48084/etasr.9945,"<jats:p>Brain-Computer Interface (BCI) systems offer a groundbreaking method for the human brain to directly communicate with external devices, serving applications, such as assistive technology, smart environments, and healthcare. Motor Imagery (MI) brain signals derived from Electroencephalography (EEG) are commonly utilized in various BCI fields. However, accurately classifying MI-based EEG signals remains a significant challenge, with traditional classification techniques struggling to effectively capture both spatial and temporal features, resulting in suboptimal performance. Therefore, this study introduces a novel hybrid Convolutional Neural Network-Long Short-Term Memory (CNN-LSTM) framework designed for EEG-MI task classification. The model combines adaptive learning with optimal training to significantly improve classification performance using the Berlin BCI Dataset 1 from BCI Competition IV. The proposed CNN-LSTM model achieves a classification accuracy of 98.38% on subject independence evaluation. This research compares subject-dependent and subject-independent evaluation with traditional Machine Learning (ML) methods, such as Support Vector Machines (SVM), Random Forest (RF), and Linear Discriminant Analysis (LDA), as well as Deep Learning (DL) models, such as EEGNet, K-nearest Neighbor (KNN), and Convolutional Neural Network (CNN). Extensive evaluations and cross-validation prove the model's superior performance, thus this work sets a benchmark for real-time MI-EEG classification, offering a scalable solution for practical BCI applications.</jats:p>",,https://doi.org/10.48084/etasr.9945,English,Exclude,Outside date range,Development of a CNN-LSTM Deep Learning Model for Motor Imagery EEG Classification for BCI Applications,,,,,0.95,0.25,cv_reported
crossref:10.1109/iww-bci.2018.8311522,crossref:10.1109/iww-bci.2018.8311522,CrossRef,crossref:10.1109/iww-bci.2018.8311522,EEG-based classification of learning strategies : Model-based and model-free reinforcement learning,Dongjae Kim;Charles Weston;Sang Wan Lee,2018,10.1109/iww-bci.2018.8311522,,,https://doi.org/10.1109/iww-bci.2018.8311522,English,Exclude,Outside date range,EEG-based classification of learning strategies : Model-based and model-free reinforcement learning,,,,,0.95,0.6,
crossref:10.1109/iww-bci.2018.8311517,crossref:10.1109/iww-bci.2018.8311517,CrossRef,crossref:10.1109/iww-bci.2018.8311517,Classification of motor imagery for Ear-EEG based brain-computer interface,Yong-Jeong Kim;No-Sang Kwak;Seong-Whan Lee,2018,10.1109/iww-bci.2018.8311517,,,https://doi.org/10.1109/iww-bci.2018.8311517,English,Exclude,Outside date range,Classification of motor imagery for Ear-EEG based brain-computer interface,,,,,0.95,0.6,
crossref:10.1109/bci57258.2023.10078663,crossref:10.1109/bci57258.2023.10078663,CrossRef,crossref:10.1109/bci57258.2023.10078663,EEG-Based Multioutput Classification of Sleep Stage and Apnea Using Deep Learning,Donghyeok Jo;Choel-Hui Lee;Hakseung Kim;Hayom Kim;Jung Bin Kim;Dong-Joo Kim,2023,10.1109/bci57258.2023.10078663,,https://doi.org/10.1109/bci57258.2023.10078663,https://doi.org/10.1109/bci57258.2023.10078663,English,Include,,EEG-Based Multioutput Classification of Sleep Stage and Apnea Using Deep Learning,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
crossref:10.1109/bci65088.2025.10931312,crossref:10.1109/bci65088.2025.10931312,CrossRef,crossref:10.1109/bci65088.2025.10931312,A Transfer-Learning Approach for Cross-Subjects EEG Data Classification,Sébastien Angelliaume;Claire Deshayes;Bruno Berberian;Stefania C. Ficarella,2025,10.1109/bci65088.2025.10931312,,,https://doi.org/10.1109/bci65088.2025.10931312,English,Exclude,Outside date range,A Transfer-Learning Approach for Cross-Subjects EEG Data Classification,,,,,0.95,0.6,
crossref:10.1109/bci57258.2023.10078607,crossref:10.1109/bci57258.2023.10078607,CrossRef,crossref:10.1109/bci57258.2023.10078607,Automatic Sleep Stage Classification Method based on Transformer-in-Transformer,Moogyeong Kim;Koohong Jung;Wonzoo Chung,2023,10.1109/bci57258.2023.10078607,,,https://doi.org/10.1109/bci57258.2023.10078607,English,Exclude,Not EEG-BCI focused,Automatic Sleep Stage Classification Method based on Transformer-in-Transformer,,,,,0.9,0.6,
crossref:10.1109/bci48061.2020.9061668,crossref:10.1109/bci48061.2020.9061668,CrossRef,crossref:10.1109/bci48061.2020.9061668,VIGNet: A Deep Convolutional Neural Network for EEG-based Driver Vigilance Estimation,Wonjun Ko;Kwanseok Oh;Eunjin Jeon;Heung-Il Suk,2020,10.1109/bci48061.2020.9061668,,,https://doi.org/10.1109/bci48061.2020.9061668,English,Exclude,Not classification-focused,VIGNet: A Deep Convolutional Neural Network for EEG-based Driver Vigilance Estimation,,,,,0.85,0.6,
crossref:10.32604/iasc.2023.035905,crossref:10.32604/iasc.2023.035905,CrossRef,crossref:10.32604/iasc.2023.035905,CNN-LSTM: A Novel Hybrid Deep Neural Network Model for Brain Tumor Classification,R. D. Dhaniya;K. M. Umamaheswari,2023,10.32604/iasc.2023.035905,,,https://doi.org/10.32604/iasc.2023.035905,English,Exclude,Not EEG-BCI focused,CNN-LSTM: A Novel Hybrid Deep Neural Network Model for Brain Tumor Classification,,,,,0.9,0.6,
crossref:10.1109/smc.2019.8914623,crossref:10.1109/smc.2019.8914623,CrossRef,crossref:10.1109/smc.2019.8914623,Can a Single Model Deep Learning Approach Enhance Classification Accuracy of an EEG-based Brain-Computer Interface?,Sujit Roy;Karl McCreadie;Girijesh Prasad,2019,10.1109/smc.2019.8914623,,https://doi.org/10.1109/smc.2019.8914623,https://doi.org/10.1109/smc.2019.8914623,English,Include,,Can a Single Model Deep Learning Approach Enhance Classification Accuracy of an EEG-based Brain-Computer Interface?,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
crossref:10.1109/bci48061.2020.9061612,crossref:10.1109/bci48061.2020.9061612,CrossRef,crossref:10.1109/bci48061.2020.9061612,Deep Learning Solutions for Motor Imagery Classification: A Comparison Study,Na Lu;Tao Yin;Xue Jing,2020,10.1109/bci48061.2020.9061612,,,https://doi.org/10.1109/bci48061.2020.9061612,English,Exclude,Not EEG-BCI focused,Deep Learning Solutions for Motor Imagery Classification: A Comparison Study,,,,,0.9,0.6,
crossref:10.7717/peerj-cs.2669/fig-13,crossref:10.7717/peerj-cs.2669/fig-13,CrossRef,crossref:10.7717/peerj-cs.2669/fig-13,"Figure 13: Results of 3-class sentiment classification using deep learning (CNN-custom, BiLSTM-custom, LSTM-CNN-custom).",,,10.7717/peerj-cs.2669/fig-13,,,https://doi.org/10.7717/peerj-cs.2669/fig-13,English,Exclude,Not EEG-BCI focused,"Figure 13: Results of 3-class sentiment classification using deep learning (CNN-custom, BiLSTM-custom, LSTM-CNN-custom).",,,,,0.9,0.6,
crossref:10.7717/peerj-cs.2669/fig-10,crossref:10.7717/peerj-cs.2669/fig-10,CrossRef,crossref:10.7717/peerj-cs.2669/fig-10,"Figure 10: Results of 3-class sentiment classification using deep learning (CNN-rand, BiLSTM-rand, LSTM-CNN-rand).",,,10.7717/peerj-cs.2669/fig-10,,,https://doi.org/10.7717/peerj-cs.2669/fig-10,English,Exclude,Not EEG-BCI focused,"Figure 10: Results of 3-class sentiment classification using deep learning (CNN-rand, BiLSTM-rand, LSTM-CNN-rand).",,,,,0.9,0.6,
crossref:10.1109/bci51272.2021.9385367,crossref:10.1109/bci51272.2021.9385367,CrossRef,crossref:10.1109/bci51272.2021.9385367,Classification of Visual Perception and Imagery based EEG Signals Using Convolutional Neural Networks,Ji-Seon Bang;Ji-Hoon Jeong;Dong-Ok Won,2021,10.1109/bci51272.2021.9385367,,https://doi.org/10.1109/bci51272.2021.9385367,https://doi.org/10.1109/bci51272.2021.9385367,English,Include,,Classification of Visual Perception and Imagery based EEG Signals Using Convolutional Neural Networks,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
crossref:10.53555/kuey.v29i4.10364,crossref:10.53555/kuey.v29i4.10364,CrossRef,crossref:10.53555/kuey.v29i4.10364,"Comparative Analysis of CNN, RNN, LSTM, and Transformer Architectures in Deep Learning",Prof. Dishita Mashru,2023,10.53555/kuey.v29i4.10364,,,https://doi.org/10.53555/kuey.v29i4.10364,English,Exclude,Not EEG-BCI focused,"Comparative Analysis of CNN, RNN, LSTM, and Transformer Architectures in Deep Learning",,,,,0.9,0.6,
crossref:10.7717/peerj-cs.2669/fig-11,crossref:10.7717/peerj-cs.2669/fig-11,CrossRef,crossref:10.7717/peerj-cs.2669/fig-11,"Figure 11: Results of 3-class sentiment classification using deep learning (CNN-static, BiLSTM-static, LSTM-CNN-static).",,,10.7717/peerj-cs.2669/fig-11,,,https://doi.org/10.7717/peerj-cs.2669/fig-11,English,Exclude,Not EEG-BCI focused,"Figure 11: Results of 3-class sentiment classification using deep learning (CNN-static, BiLSTM-static, LSTM-CNN-static).",,,,,0.9,0.6,
crossref:10.1109/bci51272.2021.9385305,crossref:10.1109/bci51272.2021.9385305,CrossRef,crossref:10.1109/bci51272.2021.9385305,Rank-based Discriminative Feature Learning for Motor Imagery Classification in EEG signals,Byung Hyung Kim;Jin Woo Choi;Sungho Jo,2021,10.1109/bci51272.2021.9385305,,https://doi.org/10.1109/bci51272.2021.9385305,https://doi.org/10.1109/bci51272.2021.9385305,English,Include,,Rank-based Discriminative Feature Learning for Motor Imagery Classification in EEG signals,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
crossref:10.1109/bci51272.2021.9385293,crossref:10.1109/bci51272.2021.9385293,CrossRef,crossref:10.1109/bci51272.2021.9385293,Attention-based spatio-temporal-spectral feature learning for subject-specific EEG classification,Dong-Hee Ko;Dong-Hee Shin;Tae-Eui Kam,2021,10.1109/bci51272.2021.9385293,,https://doi.org/10.1109/bci51272.2021.9385293,https://doi.org/10.1109/bci51272.2021.9385293,English,Include,,Attention-based spatio-temporal-spectral feature learning for subject-specific EEG classification,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
crossref:10.1109/iww-bci.2013.6506621,crossref:10.1109/iww-bci.2013.6506621,CrossRef,crossref:10.1109/iww-bci.2013.6506621,BMFLC with neural network and DE for better event classification,Yubo Wang;Venkateswarlu Gonuguntla;Ghufran Shafiq;Kalyana C. Veluvolu,2013,10.1109/iww-bci.2013.6506621,,,https://doi.org/10.1109/iww-bci.2013.6506621,English,Exclude,Outside date range,BMFLC with neural network and DE for better event classification,,,,,0.95,0.6,
crossref:10.1109/ccip.2015.7100718,crossref:10.1109/ccip.2015.7100718,CrossRef,crossref:10.1109/ccip.2015.7100718,Planning and relaxed state EEG signal classification using complex valued neural classifier for brain computer interface,M. Sivachitra;S. Vijayachitra,2015,10.1109/ccip.2015.7100718,,,https://doi.org/10.1109/ccip.2015.7100718,English,Exclude,Outside date range,Planning and relaxed state EEG signal classification using complex valued neural classifier for brain computer interface,,,,,0.95,0.6,
crossref:10.1088/1741-2552/aaaf82,crossref:10.1088/1741-2552/aaaf82,CrossRef,crossref:10.1088/1741-2552/aaaf82,Deep learning for hybrid EEG-fNIRS brain–computer interface: application to motor imagery classification,Antonio Maria Chiarelli;Pierpaolo Croce;Arcangelo Merla;Filippo Zappasodi,2018,10.1088/1741-2552/aaaf82,,,https://doi.org/10.1088/1741-2552/aaaf82,English,Exclude,Outside date range,Deep learning for hybrid EEG-fNIRS brain–computer interface: application to motor imagery classification,,,,,0.95,0.6,
crossref:10.23883/ijrter.2017.3058.xdmno,crossref:10.23883/ijrter.2017.3058.xdmno,CrossRef,crossref:10.23883/ijrter.2017.3058.xdmno,CLASSIFICATION OF MENTAL TASK FOR BRAIN COMPUTER INTERFACE USING ARTIFICIAL NEURAL NETWORK,,2017,10.23883/ijrter.2017.3058.xdmno,,,https://doi.org/10.23883/ijrter.2017.3058.xdmno,English,Exclude,Outside date range,CLASSIFICATION OF MENTAL TASK FOR BRAIN COMPUTER INTERFACE USING ARTIFICIAL NEURAL NETWORK,,,,,0.95,0.6,
crossref:10.1143/jpsj.75.104801,crossref:10.1143/jpsj.75.104801,CrossRef,crossref:10.1143/jpsj.75.104801,EEG-Based Classification of New Imagery Tasks Using Three-Layer Feedforward Neural Network Classifier for Brain–Computer Interface,Montri Phothisonothai;Masahiro Nakagawa,2006,10.1143/jpsj.75.104801,,,https://doi.org/10.1143/jpsj.75.104801,English,Exclude,Outside date range,EEG-Based Classification of New Imagery Tasks Using Three-Layer Feedforward Neural Network Classifier for Brain–Computer Interface,,,,,0.95,0.6,
crossref:10.5772/55801,crossref:10.5772/55801,CrossRef,crossref:10.5772/55801,Optimal Fractal Feature and Neural Network: EEG Based BCI Applications,Montri Phothisonothai;Katsumi Watanabe,2013,10.5772/55801,,,https://doi.org/10.5772/55801,English,Exclude,Outside date range,Optimal Fractal Feature and Neural Network: EEG Based BCI Applications,,,,,0.95,0.6,
crossref:10.5220/0013510700004619,crossref:10.5220/0013510700004619,CrossRef,crossref:10.5220/0013510700004619,Enhancing Facial Emotion Recognition Through Deep Learning: Integrating CNN and RNN-LSTM Models,Jianhui Xu,2024,10.5220/0013510700004619,,,https://doi.org/10.5220/0013510700004619,English,Exclude,Not EEG-BCI focused,Enhancing Facial Emotion Recognition Through Deep Learning: Integrating CNN and RNN-LSTM Models,,,,,0.9,0.6,
crossref:10.1109/bci53720.2022.9734935,crossref:10.1109/bci53720.2022.9734935,CrossRef,crossref:10.1109/bci53720.2022.9734935,Evolutionary Reinforcement Learning for Automated Hyperparameter Optimization in EEG Classification,Dong-Hee Shin;Dong-Hee Ko;Ji-Wung Han;Tae-Eui Kam,2022,10.1109/bci53720.2022.9734935,,https://doi.org/10.1109/bci53720.2022.9734935,https://doi.org/10.1109/bci53720.2022.9734935,English,Include,,Evolutionary Reinforcement Learning for Automated Hyperparameter Optimization in EEG Classification,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
crossref:10.46281/bjmsr.v9i3.2230,crossref:10.46281/bjmsr.v9i3.2230,CrossRef,crossref:10.46281/bjmsr.v9i3.2230,MUSIC EMOTION RECOGNITION AND CLASSIFICATION USING HYBRID CNN-LSTM DEEP NEURAL NETWORK,,2024,10.46281/bjmsr.v9i3.2230,"<jats:p>In music information retrieval (MIR), emotion-based classification is a complex and challenging task for researchers. In modern-day information technology, understanding music emotions through human-computer interaction plays a vital role in capturing the attention of both researchers and the music industry. This paper presents a learning algorithm by adopting the decision tree, random forest, k-nearest neighbors, multi-layer perceptron (MLP), long short-term memory (LSTM) neural network, convolutional neural networks (CNNs), and CNN-LSTM hybrid deep learning approaches with relevant feature extraction techniques. Many researchers have performed emotion recognition in music for different languages such as English, Chinese, Spanish, Turkish, Hindi, etc. However, languages like Assamese have drawn very little attention in the research of music emotion recognition (MER). This work aims to perform a novel approach to emotion recognition in Assamese songs. In this study, a newly created Assamese dataset of 200 song samples is used with four different emotions and another dataset used is the RAVDESS emotional song database which consists of 1012 song samples with six different music emotions. Relevant features such as mel-frequency cepstrum coefficients (MFCC), mel spectrogram, and chroma features are extracted from the song samples to investigate the performance of the proposed method. A comparative analysis using different classifiers is carried out and the findings of this study suggest that the CNN-LSTM model has shown better accuracy with both datasets. The accuracy is 85.00% with the Assamese dataset, and with the RAVDESS dataset, the accuracy is 89.66% compared to the other classifiers used in this work.</jats:p>",,https://doi.org/10.46281/bjmsr.v9i3.2230,English,Exclude,Not EEG-BCI focused,MUSIC EMOTION RECOGNITION AND CLASSIFICATION USING HYBRID CNN-LSTM DEEP NEURAL NETWORK,,,,,0.9,0.6,
crossref:10.1109/bci51272.2021.9385338,crossref:10.1109/bci51272.2021.9385338,CrossRef,crossref:10.1109/bci51272.2021.9385338,Application of High-accuracy Silent Speech BCI to Biometrics using Deep Learning,Nobuaki Kobayashi;Takahiro Morooka,2021,10.1109/bci51272.2021.9385338,,https://doi.org/10.1109/bci51272.2021.9385338,https://doi.org/10.1109/bci51272.2021.9385338,English,Include,,Application of High-accuracy Silent Speech BCI to Biometrics using Deep Learning,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
crossref:10.1109/icnc.2010.5582892,crossref:10.1109/icnc.2010.5582892,CrossRef,crossref:10.1109/icnc.2010.5582892,EEG classification based on Small-World neural network for Brain-Computer Interface,Ting Li;Jun Hong;Jinhua Zhang,2010,10.1109/icnc.2010.5582892,,,https://doi.org/10.1109/icnc.2010.5582892,English,Exclude,Outside date range,EEG classification based on Small-World neural network for Brain-Computer Interface,,,,,0.95,0.6,
crossref:10.1016/j.matpr.2020.09.619,crossref:10.1016/j.matpr.2020.09.619,CrossRef,crossref:10.1016/j.matpr.2020.09.619,WITHDRAWN: Classification of mammography image with CNN-RNN based semantic features and extra tree classifier approach using LSTM,Kiranpreet Kaur;S.K. Mittal,2020,10.1016/j.matpr.2020.09.619,,,https://doi.org/10.1016/j.matpr.2020.09.619,English,Exclude,Not EEG-BCI focused,WITHDRAWN: Classification of mammography image with CNN-RNN based semantic features and extra tree classifier approach using LSTM,,,,,0.9,0.6,
crossref:10.1007/s00221-013-3699-6,crossref:10.1007/s00221-013-3699-6,CrossRef,crossref:10.1007/s00221-013-3699-6,Electroencephalography (EEG)-based neurofeedback training for brain–computer interface (BCI),Kyuwan Choi,2013,10.1007/s00221-013-3699-6,,,https://doi.org/10.1007/s00221-013-3699-6,English,Exclude,Outside date range,Electroencephalography (EEG)-based neurofeedback training for brain–computer interface (BCI),,,,,0.95,0.6,
crossref:10.3390/brainsci9120347,crossref:10.3390/brainsci9120347,CrossRef,crossref:10.3390/brainsci9120347,Peak Detection with Online Electroencephalography (EEG) Artifact Removal for Brain–Computer Interface (BCI) Purposes,Mihaly Benda;Ivan Volosyak,2019,10.3390/brainsci9120347,"<jats:p>Brain–computer interfaces (BCIs) measure brain activity and translate it to control computer programs or external devices. However, the activity generated by the BCI makes measurements for objective fatigue evaluation very difficult, and the situation is further complicated due to different movement artefacts. The BCI performance could be increased if an online method existed to measure the fatigue objectively and accurately. While BCI-users are moving, a novel automatic online artefact removal technique is used to filter out these movement artefacts. The effects of this filter on BCI performance and mainly on peak frequency detection during BCI use were investigated in this paper. A successful peak alpha frequency measurement can lead to more accurately determining objective user fatigue. Fifteen subjects performed various imaginary and actual movements in separate tasks, while fourteen electroencephalography (EEG) electrodes were used. Afterwards, a steady-state visual evoked potential (SSVEP)-based BCI speller was used, and the users were instructed to perform various movements. An offline curve fitting method was used for alpha peak detection to assess the effect of the artefact filtering. Peak detection was improved by the filter, by finding 10.91% and 9.68% more alpha peaks during simple EEG recordings and BCI use, respectively. As expected, BCI performance deteriorated from movements, and also from artefact removal. Average information transfer rates (ITRs) were 20.27 bit/min, 16.96 bit/min, and 14.14 bit/min for the (1) movement-free, (2) the moving and unfiltered, and (3) the moving and filtered scenarios, respectively.</jats:p>",,https://doi.org/10.3390/brainsci9120347,English,Exclude,Not classification-focused,Peak Detection with Online Electroencephalography (EEG) Artifact Removal for Brain–Computer Interface (BCI) Purposes,,,,,0.85,0.6,
crossref:10.5772/56146,crossref:10.5772/56146,CrossRef,crossref:10.5772/56146,Bayesian Sequential Learning for EEG-Based BCI Classification Problems,S. Shigezumi;H. Hara;H. Namba;C. Serizawa;Y. Dobashi;A. Takemoto;K. Nakamura;T. Matsumoto,2013,10.5772/56146,,,https://doi.org/10.5772/56146,English,Exclude,Outside date range,Bayesian Sequential Learning for EEG-Based BCI Classification Problems,,,,,0.95,0.6,
crossref:10.1109/cvidl65390.2025.11085992,crossref:10.1109/cvidl65390.2025.11085992,CrossRef,crossref:10.1109/cvidl65390.2025.11085992,CNN-Transformer based Automated Neural Architecture Search for Ultrasonic Railway Track Defect Classification,Yulan Zeng;Wansu Lim,2025,10.1109/cvidl65390.2025.11085992,,,https://doi.org/10.1109/cvidl65390.2025.11085992,English,Exclude,Outside date range,CNN-Transformer based Automated Neural Architecture Search for Ultrasonic Railway Track Defect Classification,,,,,0.95,0.6,
crossref:10.1109/iww-bci.2018.8311492,crossref:10.1109/iww-bci.2018.8311492,CrossRef,crossref:10.1109/iww-bci.2018.8311492,BCI classification using locally generated CSP features,Yongkoo Park;Wonzoo Chung,2018,10.1109/iww-bci.2018.8311492,,,https://doi.org/10.1109/iww-bci.2018.8311492,English,Exclude,Outside date range,BCI classification using locally generated CSP features,,,,,0.95,0.6,
crossref:10.7717/peerj-cs.2669/fig-12,crossref:10.7717/peerj-cs.2669/fig-12,CrossRef,crossref:10.7717/peerj-cs.2669/fig-12,"Figure 12: Results of 3-class sentiment classification using deep learning (CNN-non-static, BiLSTM-non-static, LSTM-CNN-non-static).",,,10.7717/peerj-cs.2669/fig-12,,,https://doi.org/10.7717/peerj-cs.2669/fig-12,English,Exclude,Not EEG-BCI focused,"Figure 12: Results of 3-class sentiment classification using deep learning (CNN-non-static, BiLSTM-non-static, LSTM-CNN-non-static).",,,,,0.9,0.6,
crossref:10.1088/1741-2552/ab9842,crossref:10.1088/1741-2552/ab9842,CrossRef,crossref:10.1088/1741-2552/ab9842,Deep learning-based BCI for gait decoding from EEG with LSTM recurrent neural network,Stefano Tortora;Stefano Ghidoni;Carmelo Chisari;Silvestro Micera;Fiorenzo Artoni,2020,10.1088/1741-2552/ab9842,,,https://doi.org/10.1088/1741-2552/ab9842,English,Exclude,Not classification-focused,Deep learning-based BCI for gait decoding from EEG with LSTM recurrent neural network,,,,,0.85,0.6,
crossref:10.1109/iww-bci.2016.7457462,crossref:10.1109/iww-bci.2016.7457462,CrossRef,crossref:10.1109/iww-bci.2016.7457462,Deep feature learning for pulmonary nodule classification in a lung CT,Bum-Chae Kim;Yu Sub Sung;Heung-Il Suk,2016,10.1109/iww-bci.2016.7457462,,,https://doi.org/10.1109/iww-bci.2016.7457462,English,Exclude,Outside date range,Deep feature learning for pulmonary nodule classification in a lung CT,,,,,0.95,0.6,
crossref:10.1109/bci60775.2024.10480506,crossref:10.1109/bci60775.2024.10480506,CrossRef,crossref:10.1109/bci60775.2024.10480506,Pioneering EEG Motor Imagery Classification Through Counterfactual Analysis,Kang Yin;Hye-Bin Shin;Hee-Dong Kim,2024,10.1109/bci60775.2024.10480506,,https://doi.org/10.1109/bci60775.2024.10480506,https://doi.org/10.1109/bci60775.2024.10480506,English,Include,,Pioneering EEG Motor Imagery Classification Through Counterfactual Analysis,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
crossref:10.1109/bci65088.2025.10931755,crossref:10.1109/bci65088.2025.10931755,CrossRef,crossref:10.1109/bci65088.2025.10931755,HiRENet: Novel Convolutional Neural Network Architecture Using Hilbert-Transformed and Raw Electroencephalogram for Subject-Independent Emotion Classification,Minsu Kim;Chang-Hwan Im,2025,10.1109/bci65088.2025.10931755,,,https://doi.org/10.1109/bci65088.2025.10931755,English,Exclude,Outside date range,HiRENet: Novel Convolutional Neural Network Architecture Using Hilbert-Transformed and Raw Electroencephalogram for Subject-Independent Emotion Classification,,,,,0.95,0.6,
crossref:10.1109/bci65088.2025.10931379,crossref:10.1109/bci65088.2025.10931379,CrossRef,crossref:10.1109/bci65088.2025.10931379,"Multimodal Classification of Motion Sickness Using EEG, fNIRS, and IMU Signals",Hyunmin Lee;Taehun Kim;Jinung An,2025,10.1109/bci65088.2025.10931379,,,https://doi.org/10.1109/bci65088.2025.10931379,English,Exclude,Outside date range,"Multimodal Classification of Motion Sickness Using EEG, fNIRS, and IMU Signals",,,,,0.95,0.6,
crossref:10.1007/s00521-025-11403-2,crossref:10.1007/s00521-025-11403-2,CrossRef,crossref:10.1007/s00521-025-11403-2,Data augmentation and feature extraction using deep learning for motor imagery EEG-based brain–computer interface classification,Marzieh Anjerani;Mir Mohsen Pedram;Mitra Mirzarezaee,2025,10.1007/s00521-025-11403-2,,,https://doi.org/10.1007/s00521-025-11403-2,English,Exclude,Outside date range,Data augmentation and feature extraction using deep learning for motor imagery EEG-based brain–computer interface classification,,,,,0.95,0.6,
crossref:10.1109/bci53720.2022.9735124,crossref:10.1109/bci53720.2022.9735124,CrossRef,crossref:10.1109/bci53720.2022.9735124,EEG-Transformer: Self-attention from Transformer Architecture for Decoding EEG of Imagined Speech,Young-Eun Lee;Seo-Hyun Lee,2022,10.1109/bci53720.2022.9735124,,,https://doi.org/10.1109/bci53720.2022.9735124,English,Exclude,Not classification-focused,EEG-Transformer: Self-attention from Transformer Architecture for Decoding EEG of Imagined Speech,,,,,0.85,0.6,
crossref:10.21203/rs.3.rs-1599383/v1,crossref:10.21203/rs.3.rs-1599383/v1,CrossRef,crossref:10.21203/rs.3.rs-1599383/v1,Brain Tumor Segmentation and Classification using hybrid Deep CNN with LuNet Classifier,T. Balamurugan;E. Gnanamanoharan,2022,10.21203/rs.3.rs-1599383/v1,"<jats:title>Abstract</jats:title>
        <jats:p>The early diagnosis of brain tumors is critical to enhancing patient survival and prospects. The magnetic resonance imaging (MRI) brain tumor images must be physically analyzed in this work. As a result, computerized approaches for more precise tumor diagnostics are required. However, evaluating shape, volume, borders, Tumor detection, size, segmentation, and classification remains challenging. This work proposes a hybrid Deep Convolutional Neural Network (DCNN) classifier using an enhanced LuNet classifier algorithm in this proposed work. The primary intention of this work is to determine the area of the tumor site and classify brain tumors as benign or malignant. Initially, we split the data using the extended LuNet algorithm. Grey-level co-occurrence matrix (GLCM) and VGG16 extracted the features, yielding 13 classification features. For pretreatment, the Laplacian of Gaussian filter (LOG) is used. Overall, the proposed approach tries to increase the performance of non-deep learning classifiers. Traditional classifiers are superior deep learning methods because they require fewer training data sets, have lower computing complexity, lower user costs, and are easier to use by people with less training experience. The proposed algorithm achieves a better accuracy rate of 99.7%. Compared to the existing algorithm, the proposed approach outperforms them.</jats:p>",,https://doi.org/10.21203/rs.3.rs-1599383/v1,English,Exclude,Not EEG-BCI focused,Brain Tumor Segmentation and Classification using hybrid Deep CNN with LuNet Classifier,,,,,0.9,0.6,
crossref:10.1109/bci57258.2023.10078542,crossref:10.1109/bci57258.2023.10078542,CrossRef,crossref:10.1109/bci57258.2023.10078542,Subject-Aware User State Classification with Deep Learning Models: An Exploratory Study,Haram Kwon;Jaehoon Choi;Jin Woo Choi;Sungho Jo,2023,10.1109/bci57258.2023.10078542,,,https://doi.org/10.1109/bci57258.2023.10078542,English,Exclude,Not EEG-BCI focused,Subject-Aware User State Classification with Deep Learning Models: An Exploratory Study,,,,,0.9,0.6,
crossref:10.3390/s22062241,crossref:10.3390/s22062241,CrossRef,crossref:10.3390/s22062241,An Unsupervised Deep-Transfer-Learning-Based Motor Imagery EEG Classification Scheme for Brain–Computer Interface,Xuying Wang;Rui Yang;Mengjie Huang,2022,10.3390/s22062241,"<jats:p>Brain–computer interface (BCI) research has attracted worldwide attention and has been rapidly developed. As one well-known non-invasive BCI technique, electroencephalography (EEG) records the brain’s electrical signals from the scalp surface area. However, due to the non-stationary nature of the EEG signal, the distribution of the data collected at different times or from different subjects may be different. These problems affect the performance of the BCI system and limit the scope of its practical application. In this study, an unsupervised deep-transfer-learning-based method was proposed to deal with the current limitations of BCI systems by applying the idea of transfer learning to the classification of motor imagery EEG signals. The Euclidean space data alignment (EA) approach was adopted to align the covariance matrix of source and target domain EEG data in Euclidean space. Then, the common spatial pattern (CSP) was used to extract features from the aligned data matrix, and the deep convolutional neural network (CNN) was applied for EEG classification. The effectiveness of the proposed method has been verified through the experiment results based on public EEG datasets by comparing with the other four methods.</jats:p>",https://doi.org/10.3390/s22062241,https://doi.org/10.3390/s22062241,English,Include,,An Unsupervised Deep-Transfer-Learning-Based Motor Imagery EEG Classification Scheme for Brain–Computer Interface,Exclude,No performance metrics reported,No metrics found in full text,,0.9,0.6,
crossref:10.1109/ie49459.2020.9155016,crossref:10.1109/ie49459.2020.9155016,CrossRef,crossref:10.1109/ie49459.2020.9155016,A CNN-LSTM Deep Learning Classifier for Motor Imagery EEG Detection Using a Low-invasive and Low-Cost BCI Headband,Francisco M. Garcia-Moreno;Maria Bermudez-Edo;Maria Jose Rodriguez-Fortiz;Jose Luis Garrido,2020,10.1109/ie49459.2020.9155016,,https://doi.org/10.1109/ie49459.2020.9155016,https://doi.org/10.1109/ie49459.2020.9155016,English,Include,,A CNN-LSTM Deep Learning Classifier for Motor Imagery EEG Detection Using a Low-invasive and Low-Cost BCI Headband,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
crossref:10.21817/indjcse/2022/v13i6/221306085,crossref:10.21817/indjcse/2022/v13i6/221306085,CrossRef,crossref:10.21817/indjcse/2022/v13i6/221306085,Improved Multi-Label Image Classification Performance using Supervised CNN-LSTM Deep Neural Network,Joseph James S;Lakshmi C,2022,10.21817/indjcse/2022/v13i6/221306085,,,https://doi.org/10.21817/indjcse/2022/v13i6/221306085,English,Exclude,Not EEG-BCI focused,Improved Multi-Label Image Classification Performance using Supervised CNN-LSTM Deep Neural Network,,,,,0.9,0.6,
crossref:10.1109/bci53720.2022.9734940,crossref:10.1109/bci53720.2022.9734940,CrossRef,crossref:10.1109/bci53720.2022.9734940,Motor Imagery Classification based on Multi-Kernel CNN with the amalgamated Cross Entropy Loss,Jinhyo Shin;Wonzoo Chung,2022,10.1109/bci53720.2022.9734940,,,https://doi.org/10.1109/bci53720.2022.9734940,English,Exclude,Not EEG-BCI focused,Motor Imagery Classification based on Multi-Kernel CNN with the amalgamated Cross Entropy Loss,,,,,0.9,0.6,
crossref:10.1109/bci57258.2023.10078589,crossref:10.1109/bci57258.2023.10078589,CrossRef,crossref:10.1109/bci57258.2023.10078589,High Accuracy Silent Speech BCI Using Compact Deep Learning Model for Edge Computing,Nobuaki Kobayashi;Tomoya Nemoto;Takahiro Morooka,2023,10.1109/bci57258.2023.10078589,,https://doi.org/10.1109/bci57258.2023.10078589,https://doi.org/10.1109/bci57258.2023.10078589,English,Include,,High Accuracy Silent Speech BCI Using Compact Deep Learning Model for Edge Computing,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
crossref:10.1109/siu.2015.7130442,crossref:10.1109/siu.2015.7130442,CrossRef,crossref:10.1109/siu.2015.7130442,Improving classification accuracy of EEG based brain computer interface signals,Onder Aydemir,2015,10.1109/siu.2015.7130442,,,https://doi.org/10.1109/siu.2015.7130442,English,Exclude,Outside date range,Improving classification accuracy of EEG based brain computer interface signals,,,,,0.95,0.6,
crossref:10.1007/s00221-014-3860-x,crossref:10.1007/s00221-014-3860-x,CrossRef,crossref:10.1007/s00221-014-3860-x,Erratum to: Electroencephalography (EEG)-based neurofeedback training for brain–computer interface (BCI),Kyuwan Choi,2014,10.1007/s00221-014-3860-x,,,https://doi.org/10.1007/s00221-014-3860-x,English,Exclude,Outside date range,Erratum to: Electroencephalography (EEG)-based neurofeedback training for brain–computer interface (BCI),,,,,0.95,0.6,
crossref:10.2139/ssrn.3274806,crossref:10.2139/ssrn.3274806,CrossRef,crossref:10.2139/ssrn.3274806,"The Development of an Electroencephalography (EEG)-Derived, 3D-Printed Brain-Computer Interface (BCI) NeuroProsthesis Utilizing Machine Learning for Chronic Impairment",Thriaksh Rajan;Joel D. Valliath,2018,10.2139/ssrn.3274806,,,https://doi.org/10.2139/ssrn.3274806,English,Exclude,Outside date range,"The Development of an Electroencephalography (EEG)-Derived, 3D-Printed Brain-Computer Interface (BCI) NeuroProsthesis Utilizing Machine Learning for Chronic Impairment",,,,,0.95,0.6,
crossref:10.1016/s0013-4694(96)95689-8,crossref:10.1016/s0013-4694(96)95689-8,CrossRef,crossref:10.1016/s0013-4694(96)95689-8,On-line EEG classification during externally-paced hand movements using a neural network-based classifier,G. Pfurtscheller;J. Kalcher;Ch. Neuper;D. Flotzinger;M. Pregenzer,1996,10.1016/s0013-4694(96)95689-8,,,https://doi.org/10.1016/s0013-4694(96)95689-8,English,Exclude,Outside date range,On-line EEG classification during externally-paced hand movements using a neural network-based classifier,,,,,0.95,0.6,
crossref:10.3389/fpsyg.2023.1141801,crossref:10.3389/fpsyg.2023.1141801,CrossRef,crossref:10.3389/fpsyg.2023.1141801,Multi-Input CNN-LSTM deep learning model for fear level classification based on EEG and peripheral physiological signals,Nagisa Masuda;Ikuko Eguchi Yairi,2023,10.3389/fpsyg.2023.1141801,"<jats:p>Objective and accurate classification of fear levels is a socially important task that contributes to developing treatments for Anxiety Disorder, Obsessive–compulsive Disorder, Post-Traumatic Stress Disorder (PTSD), and Phobia. This study examines a deep learning model to automatically estimate human fear levels with high accuracy using multichannel EEG signals and multimodal peripheral physiological signals in the DEAP dataset. The Multi-Input CNN-LSTM classification model combining Convolutional Neural Network (CNN) and Long Sort-Term Memory (LSTM) estimated four fear levels with an accuracy of 98.79% and an F1 score of 99.01% in a 10-fold cross-validation. This study contributes to the following; (1) to present the possibility of recognizing fear emotion with high accuracy using a deep learning model from physiological signals without arbitrary feature extraction or feature selection, (2) to investigate effective deep learning model structures for high-accuracy fear recognition and to propose Multi-Input CNN-LSTM, and (3) to examine the model’s tolerance to individual differences in physiological signals and the possibility of improving accuracy through additional learning.</jats:p>",https://doi.org/10.3389/fpsyg.2023.1141801,https://doi.org/10.3389/fpsyg.2023.1141801,English,Include,,Multi-Input CNN-LSTM deep learning model for fear level classification based on EEG and peripheral physiological signals,Include,,"for Anxiety Disorder, Obsessive–compulsive Disorder, Post-Traumatic Stress Disorder (PTSD), and Phobia. This study examines a deep learning model to automatically estimate human fear levels with high accuracy using multichannel EEG signals and multimodal peripheral physiological signals in the DEAP dataset. The Multi-Input CNN-LSTM classification model combining Convolutional Neural Network (CNN) ",,0.95,0.25,cv_reported
crossref:10.1142/9781786349590_0004,crossref:10.1142/9781786349590_0004,CrossRef,crossref:10.1142/9781786349590_0004,Deep Learning-Based BCI,,2021,10.1142/9781786349590_0004,,,https://doi.org/10.1142/9781786349590_0004,English,Exclude,Not classification-focused,Deep Learning-Based BCI,,,,,0.85,0.6,
crossref:10.1109/bci51272.2021.9385358,crossref:10.1109/bci51272.2021.9385358,CrossRef,crossref:10.1109/bci51272.2021.9385358,Motor Imagery Classification Emphasizing Corresponding Frequency Domain Method based on Deep Learning Framework,Byoung-Hee Kwon;Byeong-Hoo Lee;Ji-Hoon Jeong,2021,10.1109/bci51272.2021.9385358,,,https://doi.org/10.1109/bci51272.2021.9385358,English,Exclude,Not EEG-BCI focused,Motor Imagery Classification Emphasizing Corresponding Frequency Domain Method based on Deep Learning Framework,,,,,0.9,0.6,
crossref:10.1109/iww-bci.2018.8311534,crossref:10.1109/iww-bci.2018.8311534,CrossRef,crossref:10.1109/iww-bci.2018.8311534,Movement state classification for bimanual BCI from non-human primate's epidural ECoG using three-dimensional convolutional neural network,Hoseok Choi;Jeyeon Lee;Jinsick Park;Baek Hwan Cho;Kyoung-Min Lee;Dong Pyo Jang,2018,10.1109/iww-bci.2018.8311534,,,https://doi.org/10.1109/iww-bci.2018.8311534,English,Exclude,Outside date range,Movement state classification for bimanual BCI from non-human primate's epidural ECoG using three-dimensional convolutional neural network,,,,,0.95,0.6,
crossref:10.1109/bci48061.2020.9061644,crossref:10.1109/bci48061.2020.9061644,CrossRef,crossref:10.1109/bci48061.2020.9061644,Decoding Visual Responses based on Deep Neural Networks with Ear-EEG Signals,Young-Eun Lee;Minji Lee,2020,10.1109/bci48061.2020.9061644,,,https://doi.org/10.1109/bci48061.2020.9061644,English,Exclude,Not classification-focused,Decoding Visual Responses based on Deep Neural Networks with Ear-EEG Signals,,,,,0.85,0.6,
crossref:10.1109/bci48061.2020.9061637,crossref:10.1109/bci48061.2020.9061637,CrossRef,crossref:10.1109/bci48061.2020.9061637,Prediction of Visual Memorability with EEG Signals using Deep Neural Networks,Sang-Yeong Jo;Jin-Woo Jeong,2020,10.1109/bci48061.2020.9061637,,,https://doi.org/10.1109/bci48061.2020.9061637,English,Exclude,Not classification-focused,Prediction of Visual Memorability with EEG Signals using Deep Neural Networks,,,,,0.85,0.6,
crossref:10.5220/0013597000004664,crossref:10.5220/0013597000004664,CrossRef,crossref:10.5220/0013597000004664,Improving Disease Classification Accuracy with Hybrid CNN-RNN Architectures for Lung Tumors,Vishal Patil;Vineet Hiremani;Adil Mulimani;Shreeniwas Kolagal;Channabasappa Muttal,2025,10.5220/0013597000004664,,,https://doi.org/10.5220/0013597000004664,English,Exclude,Outside date range,Improving Disease Classification Accuracy with Hybrid CNN-RNN Architectures for Lung Tumors,,,,,0.95,0.6,
crossref:10.1101/2024.12.11.627386,crossref:10.1101/2024.12.11.627386,CrossRef,crossref:10.1101/2024.12.11.627386,Classification of Visual Imagery and Imagined Speech EEG based Brain Computer Interfaces using 1D Convolutional Neural Network,Diane Le,2024,10.1101/2024.12.11.627386,"<jats:title>Abstract</jats:title><jats:p>Non-invasive brain-computer interfaces (BCI) utilising electroencephalogram (EEG) signals are a current popular, affordable and accessible method for establishing communication paths between the mind and external devices. However, the challenges faced are inter-subject variability, BCI illiteracy and poor machine learning decoding performance. Two emerging intuitive mental paradigms, Visual Imagery (VI) and Imagined Speech (IS) show promise to optimise the development of non-invasive BCIs, which involves the extraction of corresponding neural patterns during the imagined tasks. This study took a comprehensive user-centric approach to build on the current foundation of knowledge on VI and IS EEG-BCIs utilising an adapted 1D-CNN to optimise the classification decoding performance. Twenty healthy participants were assessed for their ability to visualise imagery in their minds and performed the VI and IS mental paradigms in two class conditions “push” and “relax”. It was shown that alpha and beta suppression was observed during the “push” condition of VI compared to the “relax” condition, and those that scored higher in the VVIQ had better VI classification accuracy than those who did not. The adapted 1D-CNN model performed well for classification between the two classes “push” and “relax” at 89.3% and 77.87% performance accuracy for VI and IS, respectively. These findings contribute to the current body of work on VI BCI, that it is a dynamic and plausible option compared to standard BCI paradigms, and VI BCI illiteracy could potentially be controlled by VVIQ. It also demonstrated the potential of the 1D-CNN model in classification of VI and IS EEG-BCIs.</jats:p>",https://doi.org/10.1101/2024.12.11.627386,https://doi.org/10.1101/2024.12.11.627386,English,Include,,Classification of Visual Imagery and Imagined Speech EEG based Brain Computer Interfaces using 1D Convolutional Neural Network,Include,,"”. It was shown that alpha and beta suppression was observed during the “push” condition of VI compared to the “relax” condition, and those that scored higher in the VVIQ had better VI classification accuracy than those who did not. The adapted 1D-CNN model performed well for classification between the two classes “push” and “relax” at 89.3% and 77.87% performance accuracy for VI and IS, respectiv",,0.95,0.8,small_sample_mentioned
crossref:10.1109/bci57258.2023.10078628,crossref:10.1109/bci57258.2023.10078628,CrossRef,crossref:10.1109/bci57258.2023.10078628,Effects of Input Neuron Mapping Coordinates in Spiking Neural Network on the Motor Imagery EEG Signals Classification,Gege Zhan;Haolong Su;Pengchao Wang;Lan Niu;Jianxiong Bin;Wei Mu;Xueze Zhang;Haifeng Jiang;Lihua Zhang;Xiaoyang Kang,2023,10.1109/bci57258.2023.10078628,,https://doi.org/10.1109/bci57258.2023.10078628,https://doi.org/10.1109/bci57258.2023.10078628,English,Include,,Effects of Input Neuron Mapping Coordinates in Spiking Neural Network on the Motor Imagery EEG Signals Classification,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
crossref:10.3390/s24103040,crossref:10.3390/s24103040,CrossRef,crossref:10.3390/s24103040,Enhancing Classification Accuracy with Integrated Contextual Gate Network: Deep Learning Approach for Functional Near-Infrared Spectroscopy Brain–Computer Interface Application,Jamila Akhter;Noman Naseer;Hammad Nazeer;Haroon Khan;Peyman Mirtaheri,2024,10.3390/s24103040,"<jats:p>Brain–computer interface (BCI) systems include signal acquisition, preprocessing, feature extraction, classification, and an application phase. In fNIRS-BCI systems, deep learning (DL) algorithms play a crucial role in enhancing accuracy. Unlike traditional machine learning (ML) classifiers, DL algorithms eliminate the need for manual feature extraction. DL neural networks automatically extract hidden patterns/features within a dataset to classify the data. In this study, a hand-gripping (closing and opening) two-class motor activity dataset from twenty healthy participants is acquired, and an integrated contextual gate network (ICGN) algorithm (proposed) is applied to that dataset to enhance the classification accuracy. The proposed algorithm extracts the features from the filtered data and generates the patterns based on the information from the previous cells within the network. Accordingly, classification is performed based on the similar generated patterns within the dataset. The accuracy of the proposed algorithm is compared with the long short-term memory (LSTM) and bidirectional long short-term memory (Bi-LSTM). The proposed ICGN algorithm yielded a classification accuracy of 91.23 ± 1.60%, which is significantly (p &lt; 0.025) higher than the 84.89 ± 3.91 and 88.82 ± 1.96 achieved by LSTM and Bi-LSTM, respectively. An open access, three-class (right- and left-hand finger tapping and dominant foot tapping) dataset of 30 subjects is used to validate the proposed algorithm. The results show that ICGN can be efficiently used for the classification of two- and three-class problems in fNIRS-based BCI applications.</jats:p>",https://doi.org/10.3390/s24103040,https://doi.org/10.3390/s24103040,English,Include,,Enhancing Classification Accuracy with Integrated Contextual Gate Network: Deep Learning Approach for Functional Near-Infrared Spectroscopy Brain–Computer Interface Application,Include,,") systems include signal acquisition, preprocessing, feature extraction, classification, and an application phase. In fNIRS-BCI systems, deep learning (DL) algorithms play a crucial role in enhancing accuracy. Unlike traditional machine learning (ML) classifiers, DL algorithms eliminate the need for manual feature extraction. DL neural networks automatically extract hidden patterns/features within",,0.95,0.8,small_sample_mentioned
crossref:10.1142/9781786349590_0005,crossref:10.1142/9781786349590_0005,CrossRef,crossref:10.1142/9781786349590_0005,Deep Learning-Based BCI Applications,,2021,10.1142/9781786349590_0005,,,https://doi.org/10.1142/9781786349590_0005,English,Exclude,Not classification-focused,Deep Learning-Based BCI Applications,,,,,0.85,0.6,
crossref:10.1109/iww-bci.2016.7457445,crossref:10.1109/iww-bci.2016.7457445,CrossRef,crossref:10.1109/iww-bci.2016.7457445,Finger flexion imagery: EEG classification through physiologically-inspired feature extraction and hierarchical voting,Daniel Furman;Roi Reichart;Hillel Pratt,2016,10.1109/iww-bci.2016.7457445,,,https://doi.org/10.1109/iww-bci.2016.7457445,English,Exclude,Outside date range,Finger flexion imagery: EEG classification through physiologically-inspired feature extraction and hierarchical voting,,,,,0.95,0.6,
crossref:10.1109/bci65088.2025.10931335,crossref:10.1109/bci65088.2025.10931335,CrossRef,crossref:10.1109/bci65088.2025.10931335,Optimized Time Window Segmentation for Motor Imagery EEG Classification: An Ant Colony Optimization-Based Approach,Rosi Indah Agustin;Pisut Raphisak,2025,10.1109/bci65088.2025.10931335,,,https://doi.org/10.1109/bci65088.2025.10931335,English,Exclude,Outside date range,Optimized Time Window Segmentation for Motor Imagery EEG Classification: An Ant Colony Optimization-Based Approach,,,,,0.95,0.6,
crossref:10.1109/bci51272.2021.9385347,crossref:10.1109/bci51272.2021.9385347,CrossRef,crossref:10.1109/bci51272.2021.9385347,Speech Imagery Classification using Length-Wise Training based on Deep Learning,Byeong-Hoo Lee;Byoung-Hee Kwon;Do-Yeun Lee;Ji-Hoon Jeong,2021,10.1109/bci51272.2021.9385347,,,https://doi.org/10.1109/bci51272.2021.9385347,English,Exclude,Not EEG-BCI focused,Speech Imagery Classification using Length-Wise Training based on Deep Learning,,,,,0.9,0.6,
crossref:10.20944/preprints202310.1753.v1,crossref:10.20944/preprints202310.1753.v1,CrossRef,crossref:10.20944/preprints202310.1753.v1,Blood Cell Classification: Convolutional Neural Network (CNN) and Vision Transformer (ViT) under Medical Microscope,Mohamad Abou Ali;Fadi Dornaika;Ignacio Arganda-Carreras,2023,10.20944/preprints202310.1753.v1,"<jats:p>Deep Learning (DL) has made significant advances in computer vision with the advent of Vision Transformers (ViT). Unlike Convolutional Neural Networks (CNNs), ViTs use self-attention to extract both local and global features from image data, and then use residual connections to feed these features directly into a fully networked multilayer perceptron head. In hospitals, hematologists prepare peripheral blood smears (PBSs) and read them under a medical microscope to detect abnormalities in blood counts such as leukemia. However, this task is time-consuming and prone to human error. This study investigates the transfer learning process of Google ViT and ImageNet CNNs to automate the reading of PBSs. The study used two online PBS datasets, PBC and BCCD, and transferred them into balanced datasets to investigate the influence of data amount and noise immunity on both neural networks. The PBC results show that Google ViT is an excellent DL neural solution for data scarcity. The BCCD results show that Google ViT is superior to ImageNet CNNs in dealing with unclean, noisy image data because it is able to extract both global and local features and use residual connections, despite the additional time and computational overhead.</jats:p>",,https://doi.org/10.20944/preprints202310.1753.v1,English,Exclude,Not EEG-BCI focused,Blood Cell Classification: Convolutional Neural Network (CNN) and Vision Transformer (ViT) under Medical Microscope,,,,,0.9,0.6,
crossref:10.1002/aisy.202500393,crossref:10.1002/aisy.202500393,CrossRef,crossref:10.1002/aisy.202500393,Ensemble Deep Learning Approach for Brain Tumor Classification Using Vision Transformer and Convolutional Neural Network,Ismail Oztel,2025,10.1002/aisy.202500393,"<jats:p>The treatment plan for brain tumors varies depending on the type and stage of the tumor. Early diagnosis plays a vital role in determining appropriate treatment. In addition to clinical routines, artificial intelligence‐based systems that produce automated, quantitative, and objective results can assist clinicians and scientists in making early diagnoses. For this motivation, this study proposes a deep learning‐based system that classifies brain tumors obtained by magnetic resonance imaging. In the proposed approach, several wavelet transform approaches are applied to the raw dataset images. Thus, in addition to automated feature extraction in deep learning, it aimed to detect more detailed features. Therefore, four types of datasets have been obtained. Then, using the transfer learning approach, some popular convolutional neural network and vision transformer models are trained separately with the four‐type datasets, and the test results are compared. The networks that produced the highest results are used to make the final decision with the ensemble technique. In the first analysis, the best performance was obtained using original data with an 83.50% accuracy value, and the second highest performance is obtained 81.72% accuracy value using the Daubhecies wavelet before deep learning. The third and fourth high performances are 81.47% and 81.22% accuracy, respectively, using original data. In the ensemble analysis, the highest result is achieved at 85.03% accuracy value using the bagging‐ensemble approach of the networks, namely MobileNet‐v3, vision transformer, ResNeXt, and DenseNet‐201. This study demonstrates that using a hybrid wavelet transform and deep learning approach improves classification performance. This may inspire the use of the same method to solve different classification problems.</jats:p>",,https://doi.org/10.1002/aisy.202500393,English,Exclude,Outside date range,Ensemble Deep Learning Approach for Brain Tumor Classification Using Vision Transformer and Convolutional Neural Network,,,,,0.95,0.6,
crossref:10.1002/2050-7038.13204/v1/review1,crossref:10.1002/2050-7038.13204/v1/review1,CrossRef,crossref:10.1002/2050-7038.13204/v1/review1,"Review for ""CNN / Bi‐LSTM‐based deep learning algorithm for classification of power quality disturbances by using spectrogram images""",,2021,10.1002/2050-7038.13204/v1/review1,,,https://doi.org/10.1002/2050-7038.13204/v1/review1,English,Exclude,Review/survey papers,"Review for ""CNN / Bi‐LSTM‐based deep learning algorithm for classification of power quality disturbances by using spectrogram images""",,,,,0.95,0.6,
crossref:10.1002/2050-7038.13204/v1/review2,crossref:10.1002/2050-7038.13204/v1/review2,CrossRef,crossref:10.1002/2050-7038.13204/v1/review2,"Review for ""CNN / Bi‐LSTM‐based deep learning algorithm for classification of power quality disturbances by using spectrogram images""",,2021,10.1002/2050-7038.13204/v1/review2,,,https://doi.org/10.1002/2050-7038.13204/v1/review2,English,Exclude,Review/survey papers,"Review for ""CNN / Bi‐LSTM‐based deep learning algorithm for classification of power quality disturbances by using spectrogram images""",,,,,0.95,0.6,
crossref:10.1002/2050-7038.13204/v2/review1,crossref:10.1002/2050-7038.13204/v2/review1,CrossRef,crossref:10.1002/2050-7038.13204/v2/review1,"Review for ""CNN / Bi‐LSTM‐based deep learning algorithm for classification of power quality disturbances by using spectrogram images""",,2021,10.1002/2050-7038.13204/v2/review1,,,https://doi.org/10.1002/2050-7038.13204/v2/review1,English,Exclude,Review/survey papers,"Review for ""CNN / Bi‐LSTM‐based deep learning algorithm for classification of power quality disturbances by using spectrogram images""",,,,,0.95,0.6,
crossref:10.5220/0013190900003911,crossref:10.5220/0013190900003911,CrossRef,crossref:10.5220/0013190900003911,Unified CNN-Transformer Model for Mental Workload Classification Using EEG,Fiza Parveen;Arnav Bhavsar,2025,10.5220/0013190900003911,,,https://doi.org/10.5220/0013190900003911,English,Exclude,Outside date range,Unified CNN-Transformer Model for Mental Workload Classification Using EEG,,,,,0.95,0.6,
crossref:10.2174/9789815305395125020043,crossref:10.2174/9789815305395125020043,CrossRef,crossref:10.2174/9789815305395125020043,Deep Sentiment Classification in COVID-19 Using LSTM Recurrent Neural Network,Jatin Khurana,2025,10.2174/9789815305395125020043,"<jats:p>Users (people/patients) concerned about health concerns have an easy outlet
in online medical forums along with other public social media on the Internet. The
World Health Organization declared a global public health emergency in response to
the emergence of a new coronavirus (infection which causes the disease termed
COVID-19) in late December 2019. In this research, we employed a natural language
processing (NLP) technique based on topic modeling to automatically extract COVID19-related talks from social media and discover numerous concerns linked to COVID19 from public viewpoints. As an added bonus, we look into the possibility of
employing a long short-term memory (LSTM) recurrent neural network to accomplish
the same task with COVID-19 remarks. Our research highlights the value of
incorporating public opinion and appropriate computational approaches into the
process of learning about and making decisions on COVID-19. The trials also showed
that the study model was able to reach an accuracy of 81.15 percent, which is greater
than the accuracy attained by many other popular machine-learning methods for
COVID-19 sentiment classification.</jats:p>",,https://doi.org/10.2174/9789815305395125020043,English,Exclude,Outside date range,Deep Sentiment Classification in COVID-19 Using LSTM Recurrent Neural Network,,,,,0.95,0.6,
crossref:10.3390/cancers11121901,crossref:10.3390/cancers11121901,CrossRef,crossref:10.3390/cancers11121901,Parallel Structure Deep Neural Network Using CNN and RNN with an Attention Mechanism for Breast Cancer Histology Image Classification,Hongdou Yao;Xuejie Zhang;Xiaobing Zhou;Shengyan Liu,2019,10.3390/cancers11121901,"<jats:p>In this paper, we present a new deep learning model to classify hematoxylin–eosin-stained breast biopsy images into four classes (normal tissues, benign lesions, in situ carcinomas, and invasive carcinomas). Our model uses a parallel structure consist of a convolutional neural network (CNN) and a recurrent neural network (RNN) for image feature extraction, which is greatly different from the common existed serial method of extracting image features by CNN and then inputting them into RNN. Then, we introduce a special perceptron attention mechanism, which is derived from the natural language processing (NLP) field, to unify the features extracted by the two different neural network structures of the model. In the convolution layer, general batch normalization is replaced by the new switchable normalization method. And the latest regularization technology, targeted dropout, is used to substitute for the general dropout in the last three fully connected layers of the model. In the testing phase, we use the model fusion method and test time augmentation technology on three different datasets of hematoxylin–eosin-stained breast biopsy images. The results demonstrate that our model significantly outperforms state-of-the-art methods.</jats:p>",,https://doi.org/10.3390/cancers11121901,English,Exclude,Not EEG-BCI focused,Parallel Structure Deep Neural Network Using CNN and RNN with an Attention Mechanism for Breast Cancer Histology Image Classification,,,,,0.9,0.6,
crossref:10.1109/bibm58861.2023.10385538,crossref:10.1109/bibm58861.2023.10385538,CrossRef,crossref:10.1109/bibm58861.2023.10385538,Enhanced Classification of Snoring Sounds Using Stacked Classifier Models of Machine Learning with SVM-KNN and Deep Learning with RNN-LSTM,Georges El Khoury;Kabalan Chaccour;Georges Badr;Amir Hajjam El Hassani,2023,10.1109/bibm58861.2023.10385538,,,https://doi.org/10.1109/bibm58861.2023.10385538,English,Exclude,Not EEG-BCI focused,Enhanced Classification of Snoring Sounds Using Stacked Classifier Models of Machine Learning with SVM-KNN and Deep Learning with RNN-LSTM,,,,,0.9,0.6,
crossref:10.1109/bci51272.2021.9385353,crossref:10.1109/bci51272.2021.9385353,CrossRef,crossref:10.1109/bci51272.2021.9385353,Electroencephalography-based a Motor Hotspot Identification Approach Using Deep-Learning,Ga-Young Choi;Won-Seok Kim;Han-Jeong Hwang,2021,10.1109/bci51272.2021.9385353,,,https://doi.org/10.1109/bci51272.2021.9385353,English,Exclude,Not classification-focused,Electroencephalography-based a Motor Hotspot Identification Approach Using Deep-Learning,,,,,0.85,0.6,
crossref:10.1142/9781786349590_0007,crossref:10.1142/9781786349590_0007,CrossRef,crossref:10.1142/9781786349590_0007,Cross-Scenario Classification,,2021,10.1142/9781786349590_0007,,,https://doi.org/10.1142/9781786349590_0007,English,Exclude,Not EEG-BCI focused,Cross-Scenario Classification,,,,,0.9,0.6,
crossref:10.1142/9781786349590_0008,crossref:10.1142/9781786349590_0008,CrossRef,crossref:10.1142/9781786349590_0008,Semi-Supervised Classification,,2021,10.1142/9781786349590_0008,,,https://doi.org/10.1142/9781786349590_0008,English,Exclude,Not EEG-BCI focused,Semi-Supervised Classification,,,,,0.9,0.6,
crossref:10.1109/bibm58861.2023.10385687,crossref:10.1109/bibm58861.2023.10385687,CrossRef,crossref:10.1109/bibm58861.2023.10385687,Automatic Sleep Stage Classification by CNN-Transformer-LSTM using single-channel EEG signal,Duc Thien Pham;Roman Mouček,2023,10.1109/bibm58861.2023.10385687,,https://doi.org/10.1109/bibm58861.2023.10385687,https://doi.org/10.1109/bibm58861.2023.10385687,English,Include,,Automatic Sleep Stage Classification by CNN-Transformer-LSTM using single-channel EEG signal,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
crossref:10.1109/bci48061.2020.9061671,crossref:10.1109/bci48061.2020.9061671,CrossRef,crossref:10.1109/bci48061.2020.9061671,Classification of Upper Limb Movements Using Convolutional Neural Network with 3D Inception Block,Do-Yeun Lee;Ji-Hoon Jeong;Kyung-Hwan Shim;Dong-Joo Kim,2020,10.1109/bci48061.2020.9061671,,,https://doi.org/10.1109/bci48061.2020.9061671,English,Exclude,Not EEG-BCI focused,Classification of Upper Limb Movements Using Convolutional Neural Network with 3D Inception Block,,,,,0.9,0.6,
crossref:10.1007/s00521-024-10633-0,crossref:10.1007/s00521-024-10633-0,CrossRef,crossref:10.1007/s00521-024-10633-0,Enhanced multilevel autism classification for children using eye-tracking and hybrid CNN-RNN deep learning models,Suresh Cheekaty;G. Muneeswari,2024,10.1007/s00521-024-10633-0,,,https://doi.org/10.1007/s00521-024-10633-0,English,Exclude,Not EEG-BCI focused,Enhanced multilevel autism classification for children using eye-tracking and hybrid CNN-RNN deep learning models,,,,,0.9,0.6,
crossref:10.62050/fscp2024.462,crossref:10.62050/fscp2024.462,CrossRef,crossref:10.62050/fscp2024.462,Document Classification in HEIs Using Deep Learning,Abdullahi Abdulkarim;John K. Alhassan;Sulaimon A. Bashir,2025,10.62050/fscp2024.462,"<jats:p> Higher Education Institutions (HEIs) are increasingly confronted with the complexities of evolving rules and requirements, necessitating innovative technology solutions to streamline document handling processes. Traditional paperwork methods are often inefficient and error-prone, leading to potential non-compliance. This research addresses these challenges by developing an AI-powered electronic document management system designed to automate compliance checks and simplify document handling as HEIs grow. The primary objective is to create a document classification model utilizing deep learning techniques, including Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), and a hybrid CNN-RNN approach, to enhance document accuracy and compliance. The study involves collecting and preprocessing a substantial dataset of documents, designing and evaluating various deep learning models, and optimizing hyperparameters. Performance comparisons among the models indicate that the hybrid CNN-RNN architecture outperforms individual models, achieving superior accuracy, recall, and F1-score, alongside a significantly lower mean squared error (MSE). Initial evaluations revealed the CNN, RNN, and CNN-RNN models achieved accuracies of 73%, 44%, and 27%, respectively, on the raw dataset. However, with an upgraded dataset, these models improved to 76%, 48%, and 79% accuracy, respectively, highlighting the hybrid model's enhanced capability in accurately classifying documents. The findings revealed the effectiveness of integrating advanced deep learning techniques to improve document verification processes in HEIs, ultimately facilitating better compliance and operational efficiency.</jats:p>",,https://doi.org/10.62050/fscp2024.462,English,Exclude,Outside date range,Document Classification in HEIs Using Deep Learning,,,,,0.95,0.6,
crossref:10.21203/rs.3.rs-6204645/v1,crossref:10.21203/rs.3.rs-6204645/v1,CrossRef,crossref:10.21203/rs.3.rs-6204645/v1,Enhancing Image Classification Accuracy with Adaptive Learning Convolutional Neural Network (AL-CNN): A Hybrid of AlexNet and LeNet Architectures,Monika Chawla;Rashmi Agrawal,2025,10.21203/rs.3.rs-6204645/v1,"<title>Abstract</title>
        <p>Image classification is a key application of computer vision that finds direct relevance in medical diagnostics, autonomous vehicles, and remote sensing. This paper discusses the use of AL-CNN (Adaptive Learning Convolutional Neural Networks) for image classification with results reported on a large-scale benchmark dataset which have been widely accepted for benchmarking test performance. The AL-CNN architecture integrates the use of both convolutional, pooling, and fully connected layers. This model was systematically trained on a subset of the dataset and then tested on an independent validation subset to test its efficiency and generalization capability. In addition, optimization techniques, including data augmentation, dropout, and advanced activation functions, were used to further enhance model performance. Results in terms of accuracy metrics indicated the successful execution of the AL-CNN model towards reliable and accurate image classification. This paper suggests the utility of AL-CNN technique to address various complexities of the problem of image classification, making room for innovations to take place in this domain.</p>",,https://doi.org/10.21203/rs.3.rs-6204645/v1,English,Exclude,Outside date range,Enhancing Image Classification Accuracy with Adaptive Learning Convolutional Neural Network (AL-CNN): A Hybrid of AlexNet and LeNet Architectures,,,,,0.95,0.6,
crossref:10.1109/bci53720.2022.9734822,crossref:10.1109/bci53720.2022.9734822,CrossRef,crossref:10.1109/bci53720.2022.9734822,Interpretable Convolutional Neural Networks for Subject-Independent Motor Imagery Classification,Ji-Seon Bang;Seong-Whan Lee,2022,10.1109/bci53720.2022.9734822,,,https://doi.org/10.1109/bci53720.2022.9734822,English,Exclude,Not EEG-BCI focused,Interpretable Convolutional Neural Networks for Subject-Independent Motor Imagery Classification,,,,,0.9,0.6,
crossref:10.1109/iww-bci.2013.6506633,crossref:10.1109/iww-bci.2013.6506633,CrossRef,crossref:10.1109/iww-bci.2013.6506633,Emotion classification in movie clips based on 3D fuzzy GIST and EEG signal analysis,Mingu Kwon;Jun-Su Kang;Minho Lee,2013,10.1109/iww-bci.2013.6506633,,,https://doi.org/10.1109/iww-bci.2013.6506633,English,Exclude,Outside date range,Emotion classification in movie clips based on 3D fuzzy GIST and EEG signal analysis,,,,,0.95,0.6,
crossref:10.1109/iww-bci.2019.8737309,crossref:10.1109/iww-bci.2019.8737309,CrossRef,crossref:10.1109/iww-bci.2019.8737309,"Transparent electroencephalography? : Exploring ear-EEG for long-term, mobile electrophysiology",Stefan Debener;Martin G. Bleichner,2019,10.1109/iww-bci.2019.8737309,,,https://doi.org/10.1109/iww-bci.2019.8737309,English,Exclude,Not classification-focused,"Transparent electroencephalography? : Exploring ear-EEG for long-term, mobile electrophysiology",,,,,0.85,0.6,
pubmed:40417535,pubmed:40417535,PubMed,pubmed:40417535,Detection of Short-Form Video Addiction with Wearable Sensors Via Temporally-Coherent Domain Adaptation.,Mahmudur Rahman;Atqiya Munawara Mahi;Sharmin Sultana;Matthew M Churpek;Mohammad Arif Ul Alam,2024,,"Short-form Video Addiction (SVA), a novel digital addiction of the modern world, proliferates among young adults and is not formally diagnosable. SVA detection from resulting bio-signals is crucial to prevent its adverse impacts. Existing formal methods involve large and expensive neuro-imaging devices in laboratory setups that are intrusive and not feasible to use in daily life. A possible non-intrusive solution can be using wearable sensors which is challenging due to the resulting noisy and faint signals. To address this problem, we investigated multi-modal wearable sensing technology to detect SVA in a non-intrusive fashion. However, fusing multi-modal sensors effectively presented different challenges due to the presence of signal heterogeneity. In this study, we proposed a novel multi-modal temporally coherent domain adaptation method to effectively detect SVA using Electroencephalogram (EEG) and Electrodermal Activity (EDA) sensors. We also investigated the nature and properties of SVA with the help of different components of EEG and EDA signals. We evaluated our proposed method for SVA detection and fatigue assessment tasks. Experimental evaluation shown the proposed model's superior performance (10% accuracy) over state-of-art domain adaptation models.",https://pubmed.ncbi.nlm.nih.gov/40417535/,https://pubmed.ncbi.nlm.nih.gov/40417535/,English,Include,,Detection of Short-Form Video Addiction with Wearable Sensors Via Temporally-Coherent Domain Adaptation.,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
github:260119347,github:260119347,Repositories,github:260119347;github:112804646;github:309157434;github:153808437;github:610714781,EEG-DL,SuperBruceJia,,,"A Deep Learning library for EEG Tasks (Signals) Classification, based on TensorFlow.",https://github.com/SuperBruceJia/EEG-DL,https://github.com/SuperBruceJia/EEG-DL,English,Include,,EEG-DL,Exclude,Duplicate study,Duplicate group,,0.99,0.6,
github:167753773,github:167753773,Repositories,github:167753773;github:20489534;github:241780220,DeepEEG,kylemath,,,Deep Learning with Tensor Flow for EEG MNE Epoch Objects,,https://github.com/kylemath/DeepEEG,English,Exclude,Not classification-focused,DeepEEG,,,,,0.85,0.6,
github:232335424,github:232335424,Repositories,github:232335424,braindecode,braindecode,,,"Deep learning software to decode EEG, ECG or MEG signals",,https://github.com/braindecode/braindecode,English,Exclude,Not classification-focused,braindecode,,,,,0.85,0.6,
github:247424389,github:247424389,Repositories,github:247424389,eeg-adapt,zhangks98,,,"Source Code for ""Adaptive Transfer Learning with Deep CNN for EEG Motor Imagery Classification"".",https://github.com/zhangks98/eeg-adapt,https://github.com/zhangks98/eeg-adapt,English,Include,,eeg-adapt,Exclude,No performance metrics reported,No metrics found in full text,,0.9,0.6,
github:112804646,github:112804646,Repositories,github:112804646,dl-eeg-playground,NeuroTechX,,,Deep Learning EEG Playground,,https://github.com/NeuroTechX/dl-eeg-playground,English,Exclude,Not classification-focused,dl-eeg-playground,,,,,0.85,0.6,
github:283370758,github:283370758,Repositories,github:283370758;github:460690677,Deep-Learning-for-BCI,xiangzhang1015,,,"Resources for Book: Deep Learning for EEG-based Brain-Computer Interface: Representations, Algorithms and Applications",,https://github.com/xiangzhang1015/Deep-Learning-for-BCI,English,Exclude,Not classification-focused,Deep-Learning-for-BCI,,,,,0.85,0.6,
github:20489534,github:20489534,Repositories,github:20489534;github:241780220,DeepEEG,EderSantana,,,"Deep learning for EEG analysis. This script was used to generate the results of the paper ""Joint Optimization of Algorithmic Suites for EEG analysis"" at EMBC 2014",,https://github.com/EderSantana/DeepEEG,English,Exclude,Not classification-focused,DeepEEG,,,,,0.85,0.6,
github:273901260,github:273901260,Repositories,github:273901260;github:102040002,EEG_Classification_Deeplearning,basharbme,,,EEG Signal Classification using LSTM on various datasets ,https://github.com/basharbme/EEG_Classification_Deeplearning,https://github.com/basharbme/EEG_Classification_Deeplearning,English,Include,,EEG_Classification_Deeplearning,Exclude,Duplicate study,Duplicate group,,0.99,0.6,
github:269774753,github:269774753,Repositories,github:269774753;github:241780220,Deep-Learning-Emotion-Decoding-using-EEG-data-from-Autism-individuals,meiyor,,,"Code for processing and managing data for EEG-based emotion recognition of individuals with and without Autism. EEG and other clinical data were collected in StonyBrook Social Competence Treatment Lab, for data request evaluation please contact professor Matthew D. Lerner matthew.lerner@stonybrook.edu",https://github.com/meiyor/Deep-Learning-Emotion-Decoding-using-EEG-data-from-Autism-individuals,https://github.com/meiyor/Deep-Learning-Emotion-Decoding-using-EEG-data-from-Autism-individuals,English,Include,,Deep-Learning-Emotion-Decoding-using-EEG-data-from-Autism-individuals,Exclude,Duplicate study,Duplicate group,,0.99,0.6,
github:309157434,github:309157434,Repositories,github:309157434,dl-eeg-tutorial,hubertjb,,,Hands-on tutorial on deep learning for EEG classification.,https://github.com/hubertjb/dl-eeg-tutorial,https://github.com/hubertjb/dl-eeg-tutorial,English,Include,,dl-eeg-tutorial,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
github:153808437,github:153808437,Repositories,github:153808437,dl-eeg-review,hubertjb,,,Supplementary material for systematic literature review on deep learning and EEG. ,,https://github.com/hubertjb/dl-eeg-review,English,Exclude,Review/survey papers,dl-eeg-review,,,,,0.95,0.6,
github:433811120,github:433811120,Repositories,github:433811120,DeepSeparator,ncclabsustech,,,Deep learning model for EEG artifact removal,,https://github.com/ncclabsustech/DeepSeparator,English,Exclude,Not classification-focused,DeepSeparator,,,,,0.85,0.6,
github:305975134,github:305975134,Repositories,github:305975134,AttnSleep,emadeldeen24,,,"[TNSRE 2021] ""An Attention-based Deep Learning Approach for Sleep Stage Classification with Single-Channel EEG""",https://github.com/emadeldeen24/AttnSleep,https://github.com/emadeldeen24/AttnSleep,English,Include,,AttnSleep,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
github:208559036,github:208559036,Repositories,github:208559036;github:241780220,Pre-trained-EEG-for-Deep-Learning,IoBT-VISTEC,,,Universal Joint Feature Extraction for P300 EEG Classification Using Multi-Task Autoencoder (IEEE Access),https://github.com/IoBT-VISTEC/Pre-trained-EEG-for-Deep-Learning,https://github.com/IoBT-VISTEC/Pre-trained-EEG-for-Deep-Learning,English,Include,,Pre-trained-EEG-for-Deep-Learning,Exclude,Duplicate study,Duplicate group,,0.99,0.6,
github:147510468,github:147510468,Repositories,github:147510468;github:241780220,Deep_learning_fMRI_EEG,nmningmei,,,Implementation of deep learning models in decoding fMRI/EEG data in a context of semantic processing,https://github.com/nmningmei/Deep_learning_fMRI_EEG,https://github.com/nmningmei/Deep_learning_fMRI_EEG,English,Include,,Deep_learning_fMRI_EEG,Exclude,Duplicate study,Duplicate group,,0.99,0.6,
github:339990611,github:339990611,Repositories,github:339990611,emotion-classifcation-eeg-seed-ensemble,Abhishek-Iyer1,,,"Using Deep Learning for Emotion Classification on EEG signals (SEED Dataset). CNN, RNN, Hybrid model, and Ensemble",https://github.com/Abhishek-Iyer1/emotion-classifcation-eeg-seed-ensemble,https://github.com/Abhishek-Iyer1/emotion-classifcation-eeg-seed-ensemble,English,Include,,emotion-classifcation-eeg-seed-ensemble,Exclude,No performance metrics reported,No metrics found in full text,,0.9,0.6,
github:610714781,github:610714781,Repositories,github:610714781,eeg_mi_dl,edw4rdyao,,,"A research repository of deep learning on electroencephalographic (EEG) for Motor imagery(MI), including eeg data processing(visualization & analysis), papers(research and summary), deep learning models(reproduction and experiments).",https://github.com/edw4rdyao/eeg_mi_dl,https://github.com/edw4rdyao/eeg_mi_dl,English,Include,,eeg_mi_dl,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
github:112556768,github:112556768,Repositories,github:112556768,CNN-MI-BCI,TianGL,,,"CNN-SAE program for MI-BCI classification. (Based on ""Tabar et al-2016-J Neural Eng. A novel deep learning approach for classification of EEG motor imagery signals"")",https://github.com/TianGL/CNN-MI-BCI,https://github.com/TianGL/CNN-MI-BCI,English,Include,,CNN-MI-BCI,Exclude,No performance metrics reported,No metrics found in full text,,0.9,0.6,
github:817144540,github:817144540,Repositories,github:817144540,ArtifactRemovalTransformer,CNElab-Plus,,,EEG Artifact Removal Deep Learning Techniques,,https://github.com/CNElab-Plus/ArtifactRemovalTransformer,English,Exclude,Not classification-focused,ArtifactRemovalTransformer,,,,,0.85,0.6,
github:128256444,github:128256444,Repositories,github:128256444;github:102040002,Motor-Imagery-Tasks-Classification-using-EEG-data,shariharan205,,,Implementation of Deep Neural Networks in Keras and Tensorflow to classify motor imagery tasks using EEG data,https://github.com/shariharan205/Motor-Imagery-Tasks-Classification-using-EEG-data,https://github.com/shariharan205/Motor-Imagery-Tasks-Classification-using-EEG-data,English,Include,,Motor-Imagery-Tasks-Classification-using-EEG-data,Exclude,Duplicate study,Duplicate group,,0.99,0.6,
github:310185554,github:310185554,Repositories,github:310185554,tinysleepnet,akaraspt,,,"TinySleepNet: An Efficient Deep Learning Model for Sleep Stage Scoring based on Raw Single-Channel EEG by Akara Supratak and Yike Guo from The Faculty of ICT, Mahidol University and Imperial College London respectively",,https://github.com/akaraspt/tinysleepnet,English,Exclude,Not classification-focused,tinysleepnet,,,,,0.85,0.6,
github:378100179,github:378100179,Repositories,github:378100179;github:241780220,Epileptic-EEG-Classfication-Using-Deep-Learning,mkfzdmr,,,This repository contains the trained deep learning models for the detection and prediction of Epileptic seizures. ,,https://github.com/mkfzdmr/Epileptic-EEG-Classfication-Using-Deep-Learning,English,Exclude,Not classification-focused,Epileptic-EEG-Classfication-Using-Deep-Learning,,,,,0.85,0.6,
github:102040002,github:102040002,Repositories,github:102040002;github:273223500;github:492143713,EEG-Classification,tevisgehr,,,This project was a joint effort with the neurology labs at UNL and UCD Anschutz to use deep learning to classify EEG data.,https://github.com/tevisgehr/EEG-Classification,https://github.com/tevisgehr/EEG-Classification,English,Include,,EEG-Classification,Exclude,Duplicate study,Duplicate group,,0.99,0.6,
github:158693975,github:158693975,Repositories,github:158693975;github:151831981,Epileptic-seizure-detection-,akshayg056,,,Epileptic seizure detection from EEG signals using Deep learning ,,https://github.com/akshayg056/Epileptic-seizure-detection-,English,Exclude,Not classification-focused,Epileptic-seizure-detection-,,,,,0.85,0.6,
github:195250370,github:195250370,Repositories,github:195250370,DeepEEGDataAugmentation,dfreer15,,,"Code for processing EEG data with Riemannian and deep learning-based classifiers. Additionally provides methods for data augmentation including intentionally imbalancing a dataset, and appending modified data to the training set.",https://github.com/dfreer15/DeepEEGDataAugmentation,https://github.com/dfreer15/DeepEEGDataAugmentation,English,Include,,DeepEEGDataAugmentation,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
github:689052781,github:689052781,Repositories,github:689052781,dpeeg,SheepTAO,,,Deep Learning with EEG.,,https://github.com/SheepTAO/dpeeg,English,Exclude,Not classification-focused,dpeeg,,,,,0.85,0.6,
github:322593295,github:322593295,Repositories,github:322593295,eeg_pre-diagnostic_screening,dll-ncai,,,A deep learning based platform for EEG signal classification,https://github.com/dll-ncai/eeg_pre-diagnostic_screening,https://github.com/dll-ncai/eeg_pre-diagnostic_screening,English,Include,,eeg_pre-diagnostic_screening,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
github:624356708,github:624356708,Repositories,github:624356708,DeepTransferEEG,sylyoung,,,,,https://github.com/sylyoung/DeepTransferEEG,English,Exclude,Not classification-focused,DeepTransferEEG,,,,,0.85,0.6,
github:273223500,github:273223500,Repositories,github:273223500;github:241780220,EEG-signal-classification-using-Deep-Learning,Rehan-A,,,,https://github.com/Rehan-A/EEG-signal-classification-using-Deep-Learning,https://github.com/Rehan-A/EEG-signal-classification-using-Deep-Learning,English,Include,,EEG-signal-classification-using-Deep-Learning,Exclude,Duplicate study,Duplicate group,,0.99,0.6,
github:151831981,github:151831981,Repositories,github:151831981,Epileptic-Seizure-Detection,Sharad24,,,"Deep Learning, Wavelet Analysis and Fourier Transforms for identification of abnormal EEG in Epilepsy patients",,https://github.com/Sharad24/Epileptic-Seizure-Detection,English,Exclude,Not classification-focused,Epileptic-Seizure-Detection,,,,,0.85,0.6,
github:89793032,github:89793032,Repositories,github:89793032;github:460690677,Deep-Learning-Models,ahasanpour,,,Deep Learning models used in EEG signals classification ,https://github.com/ahasanpour/Deep-Learning-Models,https://github.com/ahasanpour/Deep-Learning-Models,English,Include,,Deep-Learning-Models,Exclude,Duplicate study,Duplicate group,,0.99,0.6,
github:288726752,github:288726752,Repositories,github:288726752,EEGdenoiseNet,ncclabsustech,,,"EEGdenoiseNet, a benchmark dataset, that is suited for training and testing deep learning-based EEG denoising models, as well as for comparing the performance across different models.",,https://github.com/ncclabsustech/EEGdenoiseNet,English,Exclude,Not classification-focused,EEGdenoiseNet,,,,,0.85,0.6,
github:228572859,github:228572859,Repositories,github:228572859,EEG_RNN_Conv_Learning,ViacheslavBobrov,,,Learning Representations From EEG With Deep Recurrent-Convolutional Neural Networks,,https://github.com/ViacheslavBobrov/EEG_RNN_Conv_Learning,English,Exclude,Not classification-focused,EEG_RNN_Conv_Learning,,,,,0.85,0.6,
github:257805163,github:257805163,Repositories,github:257805163;github:241780220,Re-Deep-Convolution-Neural-Network-and-Autoencoders-Based-Unsupervised-Feature-Learning-of-EEG,bruAristimunha,,,,,https://github.com/bruAristimunha/Re-Deep-Convolution-Neural-Network-and-Autoencoders-Based-Unsupervised-Feature-Learning-of-EEG,English,Exclude,Not classification-focused,Re-Deep-Convolution-Neural-Network-and-Autoencoders-Based-Unsupervised-Feature-Learning-of-EEG,,,,,0.85,0.6,
github:97613610,github:97613610,Repositories,github:97613610;github:328795662,Emotion-Recognition,belaalb,,,Emotion recognition from EEG and physiological signals using deep neural networks,,https://github.com/belaalb/Emotion-Recognition,English,Exclude,Not classification-focused,Emotion-Recognition,,,,,0.85,0.6,
github:655727408,github:655727408,Repositories,github:655727408,brainmagick,facebookresearch,,,"Training and evaluation pipeline for MEG and EEG brain signal encoding and decoding using deep learning. Code for our paper ""Decoding speech perception from non-invasive brain recordings"" published in Nature Machine Intelligence, 2023.",,https://github.com/facebookresearch/brainmagick,English,Exclude,Not classification-focused,brainmagick,,,,,0.85,0.6,
github:328795662,github:328795662,Repositories,github:328795662;github:241780220,multi-channel-eeg-deep-cnn-emotion-recognition,dmdaksh,,,Automated Accurate Emotion Recognition using Rhythm-Specific Deep Convolutional Neural Network Technique with Multi-Channel EEG Signals,,https://github.com/dmdaksh/multi-channel-eeg-deep-cnn-emotion-recognition,English,Exclude,Not classification-focused,multi-channel-eeg-deep-cnn-emotion-recognition,,,,,0.85,0.6,
github:182146509,github:182146509,Repositories,github:182146509;github:241780220,Deep-neural-network-Transfer-learning-EEG-MEG-,thesujitroy,,,,,https://github.com/thesujitroy/Deep-neural-network-Transfer-learning-EEG-MEG-,English,Exclude,Not classification-focused,Deep-neural-network-Transfer-learning-EEG-MEG-,,,,,0.85,0.6,
github:208553156,github:208553156,Repositories,github:208553156;github:241780220,Deep-Learning-for-EEG-Based-Biometrics,IoBT-VISTEC,,,Affective EEG-Based Person Identification Using the Deep Learning Approach (IEEE Transactions on Cognitive and Developmental Systems),,https://github.com/IoBT-VISTEC/Deep-Learning-for-EEG-Based-Biometrics,English,Exclude,Not classification-focused,Deep-Learning-for-EEG-Based-Biometrics,,,,,0.85,0.6,
github:795238657,github:795238657,Repositories,github:795238657,neuro-green,Roche,,,This project contains the code for a deep learning architecture to analyze EEG data.,,https://github.com/Roche/neuro-green,English,Exclude,Not classification-focused,neuro-green,,,,,0.85,0.6,
github:241780220,github:241780220,Repositories,github:241780220;github:634883952;github:460690677,Deep-EEG,james-sungjae-lee,,,Time-Series Classification of Multichannel EEG Signal Data using Statistical Methods and 1D-CNN,https://github.com/james-sungjae-lee/Deep-EEG,https://github.com/james-sungjae-lee/Deep-EEG,English,Include,,Deep-EEG,Exclude,Duplicate study,Duplicate group,,0.99,0.6,
github:92044556,github:92044556,Repositories,github:92044556,DeepLearing-EEG,Albocal,,,Testing models with eeg data,,https://github.com/Albocal/DeepLearing-EEG,English,Exclude,Not classification-focused,DeepLearing-EEG,,,,,0.85,0.6,
github:493031977,github:493031977,Repositories,github:493031977,DeepLearningProject,James-Mc1ntyre,,,Using Deep Learning techniques to classify Motor Imagery Electroencephalography (EEG) signals,https://github.com/James-Mc1ntyre/DeepLearningProject,https://github.com/James-Mc1ntyre/DeepLearningProject,English,Include,,DeepLearningProject,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
github:115763153,github:115763153,Repositories,github:115763153,BCI-P300,amr-farahat,,,BCI project using Deep Learning to decode EEG signals.,,https://github.com/amr-farahat/BCI-P300,English,Exclude,Not classification-focused,BCI-P300,,,,,0.85,0.6,
github:426620362,github:426620362,Repositories,github:426620362,EEGANet,IoBT-VISTEC,,,"EEG Artifact Removal Using Deep Learning (source code, IEEE Journal of Biomedical and Health Informatics)",,https://github.com/IoBT-VISTEC/EEGANet,English,Exclude,Not classification-focused,EEGANet,,,,,0.85,0.6,
github:634883952,github:634883952,Repositories,github:634883952,SEED-EEG-Deep-neural-network,patrickdmiller,,,residual deep cnn and lstm for classifying SEED data,https://github.com/patrickdmiller/SEED-EEG-Deep-neural-network,https://github.com/patrickdmiller/SEED-EEG-Deep-neural-network,English,Include,,SEED-EEG-Deep-neural-network,Exclude,No performance metrics reported,No metrics found in full text,,0.9,0.6,
github:492143713,github:492143713,Repositories,github:492143713,DL4EEG-Classification,YeZiyi1998,,,The implementation of deep learning models for EEG classification.,https://github.com/YeZiyi1998/DL4EEG-Classification,https://github.com/YeZiyi1998/DL4EEG-Classification,English,Include,,DL4EEG-Classification,Exclude,Insufficient methodological detail,No DL architecture mention in full text or abstract,,0.8,0.6,
github:532545267,github:532545267,Repositories,github:532545267,BSc-Thesis-Project,mehrshad-sdtn,,,A Deep Learning Based approach for diagnosis of Schizophrenia using EEG brain recordings,,https://github.com/mehrshad-sdtn/BSc-Thesis-Project,English,Exclude,Not classification-focused,BSc-Thesis-Project,,,,,0.85,0.6,
github:250355203,github:250355203,Repositories,github:250355203,ECE-C247-EEG-GAN,krishk97,,,"GAN and VAE implementations to generate artificial EEG data to improve motor imagery classification. Data based on BCI Competition IV, datasets 2a. Final project for UCLA's EE C247: Neural Networks and Deep Learning course.",https://github.com/krishk97/ECE-C247-EEG-GAN,https://github.com/krishk97/ECE-C247-EEG-GAN,English,Include,,ECE-C247-EEG-GAN,Exclude,No performance metrics reported,No metrics found in full text,,0.9,0.6,
github:460690677,github:460690677,Repositories,github:460690677,Towards-Best-Practice-of-Interpreting-Deep-Learning-Models-for-EEG-based-BCI,cuijiancorbin,,,"In this project, we implemented 7 interpretation techniques on two benchmark deep learning models ""EEGNet"" and ""InterpretableCNN"" for EEG-based BCI. The methods include:  gradient×input, DeepLIFT, integrated gradient, layer-wise relevance propagation (LRP), saliency map, deconvolution, and guided backpropagation",,https://github.com/cuijiancorbin/Towards-Best-Practice-of-Interpreting-Deep-Learning-Models-for-EEG-based-BCI,English,Exclude,Not classification-focused,Towards-Best-Practice-of-Interpreting-Deep-Learning-Models-for-EEG-based-BCI,,,,,0.85,0.6,
